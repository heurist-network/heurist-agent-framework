metadata:
  agent: FirecrawlSearchAgent
  test_file: firecrawl_search_agent.py
  timestamp: '2025-09-16T17:09:09.031564'
  total_tests: 6
  passed: 6
  failed: 0
results:
  natural_language_query_with_analysis:
    input:
      query: What are the latest developments in zero knowledge proofs?
      raw_data_only: false
    output:
      response: "Zero-knowledge proofs (ZKPs) are a rapidly evolving area in cryptography,\
        \ allowing one party to prove the truth of a statement to another without\
        \ revealing any additional information beyond the validity of that statement.\
        \ This technology is gaining significant traction across various domains,\
        \ including privacy-preserving authentication, blockchain scalability, and\
        \ secure finance.\n\nHere are some of the latest developments:\n\n**1. Enabling\
        \ Verifiable AI with ZKPs:**\n*   A major challenge in AI is the lack of trust\
        \ due to \"hallucinations\" or incorrect outputs. ZKPs offer a solution by\
        \ allowing AI models to prove the correctness of their computations without\
        \ exposing proprietary code or sensitive training data.\n*   The concept of\
        \ \"Zero-Knowledge Proof of Training (ZKPoT)\" is emerging, enabling developers\
        \ to verify that an AI model was trained on a specific dataset and adhered\
        \ to certain parameters, thus enhancing trust in AI outputs while preserving\
        \ intellectual property.\n*   Compared to other security protocols like homomorphic\
        \ encryption, ZKPs are more efficient for AI deployment as they don't require\
        \ encryption/decryption processes, leading to faster processing times and\
        \ reduced costs.\n\n**2. Advancements in ZKP Programming and Development:**\n\
        *   The development of Zero-Knowledge Proof (ZKP) programs remains complex,\
        \ requiring specialized knowledge in finite field arithmetic, constraint systems,\
        \ and cryptographic \"gadgets.\"\n*   New tools and frameworks are being developed\
        \ to simplify ZKP programming. For instance, \"ZK-Coder\" is an agentic framework\
        \ that leverages large language models (LLMs) to generate ZKP code from natural\
        \ language specifications.\n*   ZK-Coder employs a multi-stage process:\n\
        \    *   **Constraint Formulation:** Translating natural language problems\
        \ into a structured \"ZK Sketch Language\" (ZKSL), which abstracts away ZK-specific\
        \ details.\n    *   **Constraint-Guided Analysis and Retrieval:** Analyzing\
        \ the ZKSL sketch to extract constraints and retrieve relevant ZKP gadget\
        \ usage patterns from a curated knowledge base.\n    *   **Interactive Generation\
        \ and Repair:** The LLM generates ZK code using the retrieved hints, with\
        \ an interactive loop that uses compilers and test executors as oracles to\
        \ identify and repair syntactic and semantic errors.\n*   This framework has\
        \ shown significant improvements in generating correct ZKP programs in languages\
        \ like Circom and Noir, with success rates improving from around 17-32% to\
        \ 83-94%.\n\n**3. Integration of ZKPs with Post-Quantum Cryptography:**\n\
        *   Researchers are developing new cryptographic systems that combine identity-based\
        \ authentication with blind signatures and zero-knowledge proofs, specifically\
        \ designed to be resistant to attacks from future quantum computers.\n*  \
        \ One such scheme utilizes the CSIDH (Commutative Supersingular Isogeny Diffie-Hellman)\
        \ framework, which is known for its post-quantum security properties.\n* \
        \  These developments aim to streamline key management, enhance privacy in\
        \ applications like e-cash and voting, and ensure the honesty of verifiers\
        \ without compromising sensitive data, all while maintaining efficiency and\
        \ compact signature sizes.\n\n**4. Expanding Applications of ZKPs:**\n*  \
        \ Beyond blockchain scalability and privacy-preserving transactions (e.g.,\
        \ zk-SNARKs on Ethereum), ZKPs are being explored for:\n    *   **Identity\
        \ Verification:** Enabling Know Your Customer (KYC) and Anti-Money Laundering\
        \ (AML) checks without disclosing private user data, balancing compliance\
        \ with privacy.\n    *   **Secure Finance:** Facilitating secure and confidential\
        \ financial transactions in decentralized finance (DeFi).\n    *   **Privacy-Preserving\
        \ Authentication:** Allowing users to authenticate themselves without revealing\
        \ their identity.\n\nIn summary, the field of zero-knowledge proofs is experiencing\
        \ significant theoretical and practical advancements. The focus is not only\
        \ on improving the underlying cryptographic primitives but also on making\
        \ ZKP development more accessible and integrating this powerful technology\
        \ into broader applications, particularly in AI and post-quantum secure systems."
      data: &id001
        status: success
        data:
          results:
          - title: Large Language Models for Zero-Knowledge Proof Code Generation
            description: Zero-knowledge proofs (ZKPs) are increasingly deployed in
              domains such as privacy-preserving authentication, blockchain scalability,
              and secure finance.
            url: https://arxiv.org/html/2509.11708v1
            markdown: '[License: CC BY-NC-SA 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)


              arXiv:2509.11708v1 \[cs.SE\] 15 Sep 2025


              # From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation


              Report issue for preceding element


              Zhantong Xue

              [0009-0000-3419-9431](https://orcid.org/0009-0000-3419-9431 "ORCID identifier")Hong
              Kong University of Science and TechnologyHong KongChina[zxueai@cse.ust.hk](mailto:zxueai@cse.ust.hk), Pingchuan
              Ma

              [0000-0001-7680-2817](https://orcid.org/0000-0001-7680-2817 "ORCID identifier")Hong
              Kong University of Science and TechnologyHong KongChinaCipherInsight
              LimitedHong KongChina[pmaab@cse.ust.hk](mailto:pmaab@cse.ust.hk), Zhaoyu
              Wang

              [0009-0009-6892-1264](https://orcid.org/0009-0009-6892-1264 "ORCID identifier")Hong
              Kong University of Science and TechnologyHong KongChina[zwangjz@cse.ust.hk](mailto:zwangjz@cse.ust.hk) and Shuai
              Wang

              [0000-0002-0866-0308](https://orcid.org/0000-0002-0866-0308 "ORCID identifier")Hong
              Kong University of Science and TechnologyHong KongChinaCipherInsight
              LimitedHong KongChina[shuaiw@cse.ust.hk](mailto:shuaiw@cse.ust.hk)


              Report issue for preceding element


              (2025; 11 September 2025)


              ###### Abstract.


              Report issue for preceding element


              Zero-knowledge proofs (ZKPs) are increasingly deployed in domains such
              as

              privacy-preserving authentication, blockchain scalability, and secure
              finance.

              However, authoring ZK programs remains challenging: unlike mainstream

              programming, ZK development requires reasoning about finite field arithmetic,

              constraint systems, and gadgets, making it knowledge-intensive and error-prone.

              While large language models (LLMs) have demonstrated strong code generation

              capabilities in general-purpose languages, their effectiveness for ZK

              programming, where correctness hinges on both language mastery and gadget-level

              reasoning, remains unexplored. To address this gap, we propose ZK-Eval,

              a domain-specific evaluation pipeline that probes LLM capabilities at
              three

              levels: language knowledge, gadget competence, and end-to-end program

              generation. Our evaluation of four state-of-the-art LLMs reveals that
              models

              excel at surface-level syntax but struggle with gadget usage and semantic

              correctness, often yielding incorrect programs. Based on these insights,
              we

              introduce ZK-Coder, an agentic framework that augments LLMs with

              constraint sketching, guided retrieval, and interactive repair. Experiments
              on

              Circom and Noir show substantial gains, with success rates improving
              from

              17.35% to 83.38% and from 32.21% to 90.05%, respectively. With

              ZK-Eval and ZK-Coder, we establish a foundation for

              systematically measuring and augmenting LLMs in ZK code generation to
              lower

              barriers for practitioners and advance trustworthy computation.


              Report issue for preceding element


              Zero-Knowledge Proofs, Large Language Models, Code Generation


              ††copyright: acmlicensed††journalyear: 2025††doi: XXXXXXX.XXXXXXX††journalvolume:
              X††journalnumber: X††article: X††journalyear: 2025††publicationmonth:
              9††copyright: none††ccs: Software and its engineering Automatic programming††ccs:
              Security and privacy Cryptography††ccs: Software and its engineering Domain
              specific languages††ccs: Computing methodologies Natural language processing


              ## 1\. Introduction


              Report issue for preceding element


              _Zero-knowledge proofs (ZKPs)_ are a powerful cryptographic primitive
              that

              allow one party to prove knowledge of a statement without revealing
              the

              underlying witness. In practice, this means proving that a computation
              or claim

              is correct while keeping sensitive inputs private. ZKPs have moved far
              beyond

              theory: they are now central to privacy-preserving authentication, blockchain

              scalability, and emerging applications across finance and security

              domains (Gupta, [2025](https://arxiv.org/html/2509.11708v1#bib.bib30
              ""); Lavin et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib42
              ""); team, [2024](https://arxiv.org/html/2509.11708v1#bib.bib64 "")).

              As demand for trustworthy computation grows, the ability to author,
              test, and

              verify ZKP programs has become a first-class concern in the software
              engineering

              community (Takahashi et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib62
              ""); Hochrainer et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib32
              ""); Xu et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib77
              ""); Pailoor et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib51
              ""); Jiang et al., [2025a](https://arxiv.org/html/2509.11708v1#bib.bib36
              "")).


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x1.png)Figure
              1. Illustrative Comparison Between the Process of Mainstream and ZK
              Programming.Report issue for preceding element


              However, authoring ZK programs is challenging. Unlike mainstream programming,

              which builds on the von Neumann model and imperative execution, ZKP
              programs

              boil down to specifying and proving mathematical _constraints_ over
              finite

              fields. Its development requires reasoning about finite field arithmetic,

              constraint systems, and _gadgets_ — a novel concept advocated by modern

              ZKP frameworks to encode reusable, domain-specific building blocks.
              As shown in

              Fig. [1](https://arxiv.org/html/2509.11708v1#S1.F1 "Figure 1 ‣ 1. Introduction
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation") and

              Table [1](https://arxiv.org/html/2509.11708v1#S1.T1 "Table 1 ‣ Figure
              2 ‣ 1. Introduction ‣ From Evaluation to Enhancement: Large Language
              Models for Zero-Knowledge Proof Code Generation"), ZK programs do not
              describe how to

              _execute_ a computation but how to _prove_ its correctness by

              compiling constraints into arithmetic circuits. Developers must specify

              equations over inputs, outputs, and intermediate variables, carefully
              wiring

              gadgets to enforce correctness. Even small omissions or miswirings can
              yield

              satisfiable but unsound constraint systems, leading to errors that compilers

              rarely flag. This makes ZK development knowledge-intensive, error-prone,
              and

              inaccessible to non-experts, despite significant progress in proof systems
              and

              verification tools (Chaliasos et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib11
              ""); Pailoor et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib51
              ""); Takahashi et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib62
              "")).


              Report issue for preceding element


              Table 1. Comparison of Mainstream and ZK Programming.Report issue for
              preceding element


              | Aspect | Mainstream | ZK Program |

              | --- | --- | --- |

              | Paradigm | Imperative/OOP/Func | Constraint Systems |

              | Comp. Model | von Neumann Arch | Arithmetic Circuits |

              | Purpose | to Compute | to Prove |

              | Data Types | Int/Float/Str/… | Finite Field Elements |

              | Mutability | Dynamic | Static |

              | Turing-complete? | Yes | No |

              | Control Flow | If/Loop/Recursion | Limited |

              | Side Effects | Yes | No, Pure Math |


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x2.png)Figure
              2. Overview of ZK-Eval and ZK-Coder.Report issue for preceding element


              Report issue for preceding element


              As a result, ZK programming demands significantly more time and expertise
              than

              mainstream software development, posing a steep barrier to entry for
              many

              practitioners. In contrast, recent advances in large language models
              (LLMs) have

              lowered this barrier in general-purpose languages by demonstrating strong
              code

              generation capabilities (Jiang et al., [2025b](https://arxiv.org/html/2509.11708v1#bib.bib38
              "")), achieving impressive results on

              benchmarks such as HumanEval (Chen et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib13
              "")) and

              MBPP (Research, [2021](https://arxiv.org/html/2509.11708v1#bib.bib54
              "")), and powering widely adopted tools like GitHub

              Copilot (GitHub, [2025](https://arxiv.org/html/2509.11708v1#bib.bib28
              "")) and Cursor (team, [2025](https://arxiv.org/html/2509.11708v1#bib.bib63
              "")). This contrast naturally raises

              the question: _to what extent can modern LLMs assist in generating ZK
              code_

              _from natural language specifications?_ Answering this question requires
              more

              than surface-level benchmarking. Compared to programming in mainstream

              languages, success in ZK development hinges on two competencies: (i)
              knowledge

              of domain-specific languages (DSLs) and their toolchains, and (ii) mastery
              of

              gadgets as building blocks for constraint systems. Existing benchmarks
              focus

              only on mainstream languages and overlook these unique requirements.


              Report issue for preceding element


              To address this gap, we introduce ZK-Eval, a domain-specific evaluation

              pipeline that probes LLM capability at three levels: language knowledge,

              gadget-level competence, and end-to-end program code generation (left
              panel of

              Fig. [2](https://arxiv.org/html/2509.11708v1#S1.F2 "Figure 2 ‣ 1. Introduction
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation")). We anticipate that this design would provide

              a structured way to pinpoint where models succeed, where they fail,
              and why,

              rather than treating code generation as a monolithic task.

              Applying ZK-Eval to four state-of-the-art LLMs (including advanced

              reasoning models like GPT-o4-mini and GPT-o3) reveals a clear pattern.
              While

              models perform strongly on surface-level language knowledge, their accuracy

              drops significantly when reasoning about gadgets or assembling complete

              programs, often producing code that compiles but fails semantically.
              These

              results underscore both the promise of LLMs in lowering barriers to
              ZK

              development and the need for augmentations to bridge the gap between
              syntactic

              knowledge and reliable code generation.

              Motivated by these findings, we present ZK-Coder (right panel of

              Fig. [2](https://arxiv.org/html/2509.11708v1#S1.F2 "Figure 2 ‣ 1. Introduction
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation")), an agentic framework that augments LLMs with

              constraint sketching, retrieval, and interactive repair. By grounding
              generation

              in constraint reasoning and guided gadget usage, ZK-Coder achieves

              substantial gains in reliability, improving success rates from 17.35%
              to

              83.38% on Circom and from 32.21% to 90.05% on Noir. In summary, our

              contributions are as follows:


              Report issue for preceding element


              1. (1)



              We propose ZK-Eval, a three-stage evaluation pipeline for

              systematically assessing LLM capabilities in ZK code generation.


              Report issue for preceding element


              2. (2)



              We introduce ZK-Coder, an agentic framework that augments

              LLMs with constraint sketching, guided retrieval, and interactive repair
              to

              improve reliability.


              Report issue for preceding element


              3. (3)



              We evaluate the performance of four state-of-the-art LLMs on

              ZK-Eval and demonstrate how ZK-Coder substantially

              improves end-to-end code generation.


              Report issue for preceding element



              ## 2\. Background


              Report issue for preceding element


              ### 2.1. Zero-Knowledge Proofs and Programming Frameworks


              Report issue for preceding element


              Zero-knowledge proofs (ZKPs) are cryptographic protocols that allow
              one party to

              prove to another that a statement is true without revealing any information

              beyond the validity of the statement itself. Formally, the following
              properties

              are desired for a correct ZKP program.


              Report issue for preceding element


              1. (1)



              Completeness: If a statement is true, an honest prover can

              convince the verifier of its validity.


              Report issue for preceding element


              2. (2)



              Soundness: If a statement is false, no dishonest prover can

              convince the verifier of its validity.


              Report issue for preceding element


              3. (3)



              Zero-Knowledge: If a statement is true, the verifier learns

              nothing beyond the validity of the statement itself.


              Report issue for preceding element



              These properties make ZKPs particularly useful in privacy-preserving

              applications (Gupta, [2025](https://arxiv.org/html/2509.11708v1#bib.bib30
              ""); team, [2024](https://arxiv.org/html/2509.11708v1#bib.bib64 "");
              Lavin et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib42 "")).
              However, achieving these properties

              relies on the correct implementation of the underlying cryptographic
              primitives

              and protocols with respect to the high-level intent. Consequently, writing
              ZKP

              programs can be challenging due to the complexity of the underlying

              field-arithmetic mathematics and the need for specialized knowledge
              in

              cryptography (Pailoor et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib51
              ""); Wen et al., [2024b](https://arxiv.org/html/2509.11708v1#bib.bib74
              ""); Chaliasos et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib11
              "")).


              Report issue for preceding element


              Table 2. Tools for Programming Zero-Knowledge Proofs


              | Frontend | DSL | Compiler | GitHub repository |

              | --- | --- | --- | --- |

              | Circom (Bellés-Muñoz et al., [2022](https://arxiv.org/html/2509.11708v1#bib.bib6
              "")) | Circom | Rust | iden3/circom (1.5K∗) |

              | Noir (Aztec Labs, [2025](https://arxiv.org/html/2509.11708v1#bib.bib4
              "")) | Rust-like | Rust | noir-lang/noir (1.2K∗) |

              | Leo (Chin et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib14
              "")) | Rust-like | Rust | AleoHQ/leo (4.8K∗) |

              | ZoKrates (Contributors, [2025c](https://arxiv.org/html/2509.11708v1#bib.bib19
              "")) | Python-like | Rust | Zokrates/ZoKrates (1.9K∗) |


              Report issue for preceding element


              Loosely speaking, developers need to translate their high-level intent
              into an

              arithmetic representation R​(x,w)=1R(x,w)=1, where xx denotes public
              inputs, ww

              denotes the private witness, and RR is a collection of polynomial equations

              over field elements. To ease the development process, several programming

              frameworks have emerged, providing higher-level abstractions and DSLs
              for

              expressing ZKP

              computations (Sheybani et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib56
              ""); Ozdemir et al., [2022](https://arxiv.org/html/2509.11708v1#bib.bib50
              ""); Thomas, [2022](https://arxiv.org/html/2509.11708v1#bib.bib67 "")).
              In Table [2](https://arxiv.org/html/2509.11708v1#S2.T2 "Table 2 ‣ 2.1.
              Zero-Knowledge Proofs and Programming Frameworks ‣ 2. Background ‣ From
              Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation"), we review several

              representative frontend frameworks, including Circom, Noir, and others.
              These

              frameworks differ not only in syntax but also in how they expose the
              underlying

              constraint system, which directly impacts the difficulty of automatic
              code

              generation. Circom requires developers to think in terms of low-level
              circuit

              wiring and explicit constraints, which poses challenges for LLM-based
              generation

              since the model must produce correct and efficient circuit

              templates (Hochrainer et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib32
              ""); Chaliasos et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib10
              ""); Takahashi et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib62
              "")). Noir, by contrast, adopts a Rust-like syntax and enforces

              type safety, making it closer to conventional programming languages
              and thus

              more approachable for LLMs trained on general-purpose code

              corpora (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              ""); Jiang et al., [2024b](https://arxiv.org/html/2509.11708v1#bib.bib37
              ""), [2025b](https://arxiv.org/html/2509.11708v1#bib.bib38 "")).

              As a concurrent effort, there are also emerging frameworks that target

              general-purpose languages, such as SP1 (Labs, [2025](https://arxiv.org/html/2509.11708v1#bib.bib41
              "")), Nexus (Contributors, [2025a](https://arxiv.org/html/2509.11708v1#bib.bib17
              "")), and RISC

              Zero (Contributors, [2025b](https://arxiv.org/html/2509.11708v1#bib.bib18
              "")), which compiles Rust code into a restricted instruction set

              and generates ZK proofs over the execution trace within a virtual machine.

              However, these frameworks often come with significant performance overheads
              due

              to the complexity of instruction emulation within the virtual machine.

              Therefore, we consider them as an orthogonal direction to our work for
              reducing

              the burden of writing ZKP programs. Taken together, these tools illustrate
              the

              diverse design space of ZKP programming frontends, and highlight why
              aligning

              LLM-based code generation with specific framework characteristics is
              essential

              for usability and correctness.


              Report issue for preceding element


              In this work, we focus on Circom and Noir for two main reasons. First,
              they are

              the most widely adopted general-purpose ZK frontends in both academia
              and

              industry, with active communities and production deployments (e.g.,
              Circom in

              Ethereum-based rollups, Noir in Aztec). This ensures that advances in

              LLM-assisted code generation for these languages can have immediate
              practical

              impact. Second, they represent two complementary design paradigms that
              are

              highly relevant for evaluating code generation: Circom exposes low-level,

              circuit-oriented constructs where the challenge for LLMs is to correctly

              translate high-level intent into constraint wiring, whereas Noir provides
              a

              Rust-like syntax with strong typing and higher-level abstractions, which
              better

              aligns with the training data of current LLMs. By studying both, we
              capture the

              spectrum from circuit-level specification to program-level ergonomics,
              allowing

              us to analyze how LLMs handle different abstraction levels in ZKP development.


              Report issue for preceding element


              ### 2.2. LLM-based Code Generation


              Report issue for preceding element


              Large Language Models (LLMs) have emerged as powerful assistants in
              software

              development, enabling code generation from natural language prompts
              with tools

              like GitHub Copilot, Cursor, and model-driven agents quickly translating
              intent

              into code (Jiang et al., [2024b](https://arxiv.org/html/2509.11708v1#bib.bib37
              ""), [2025b](https://arxiv.org/html/2509.11708v1#bib.bib38 "")). These
              systems are reshaping

              engineering workflows, aiding in writing, testing, and documenting code
              by

              drawing on vast amounts of publicly available repositories and

              documentation (GitHub, [2025](https://arxiv.org/html/2509.11708v1#bib.bib28
              "")).


              Report issue for preceding element


              ##### Framework.


              Report issue for preceding element


              Modern LLM-based code generation typically follows an

              agentic framework (Zhang et al., [2024a](https://arxiv.org/html/2509.11708v1#bib.bib81
              ""); Wang et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib73
              "")), where the model

              acts as an intelligent assistant, interpreting user intent, retrieving
              relevant

              information, and producing code snippets or entire functions as needed.
              This

              process often involves multiple iterations, with the model refining
              its output

              based on user feedback and additional context. In this way, it can leverage

              off-the-shelf LLMs effectively without code-specific

              fine-tuning (Dong et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib24
              ""); Pan et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib52
              "")). However, to the best of our

              knowledge, there has been limited exploration of LLMs for code generation
              in the

              context of low-resource or DSLs such as those used in ZKPs.


              Report issue for preceding element


              ##### Benchmark.


              Report issue for preceding element


              As an important part of LLM-based code generation

              research, benchmarks play a crucial role in understanding model performance
              and

              guiding future improvements. Currently, their accuracy and reasoning
              ability are

              usually evaluated on standard benchmarks on mainstream programming languages

              such as HumanEval (Chen et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib13
              "")) and MBPP (Research, [2021](https://arxiv.org/html/2509.11708v1#bib.bib54
              "")).

              However, evaluation tools for low-resource and DSLs remain limited,
              hindering

              comprehensive assessments of LLM performance in these

              contexts (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              ""); Giagnorio et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib27
              "")). Code generation for ZKP

              programs exemplifies the challenges and opportunities in this space.
              Though

              benchmarks for low-resource

              languages (Cassano et al., [2022](https://arxiv.org/html/2509.11708v1#bib.bib9
              ""); Yang et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib78
              "")) and DSLs (Liu et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib46
              ""); Abukhalaf et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib3
              "")) exist,

              to our knowledge, no standardized benchmark suite specifically targets
              ZKP code

              generation, requiring tailored benchmarks and evaluation strategies.


              Report issue for preceding element


              ## 3\. Measuring LLM Capability for ZK Code Generation


              Report issue for preceding element


              As discussed in Sec. [1](https://arxiv.org/html/2509.11708v1#S1 "1.
              Introduction ‣ From Evaluation to Enhancement: Large Language Models
              for Zero-Knowledge Proof Code Generation") and Sec. [2.1](https://arxiv.org/html/2509.11708v1#S2.SS1
              "2.1. Zero-Knowledge Proofs and Programming Frameworks ‣ 2. Background
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation"), ZK

              programming follows a proof-oriented model: developers translate high-level

              specifications into algebraic constraints over a finite field and produce
              proofs

              of satisfiability. This shift yields the workflow depicted in

              Fig. [1](https://arxiv.org/html/2509.11708v1#S1.F1 "Figure 1 ‣ 1. Introduction
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation"), from constraint

              specification to implementation by composing gadgets and finally proof

              generation. We therefore assess two capabilities essential for end-to-end

              success: ➀ language and toolchain knowledge and ➁ gadget-level

              competence.


              Report issue for preceding element


              1. (1)



              Language and Toolchain Knowledge. Developers must understand

              syntax, typing rules, semantics of field operations, and the structure
              of

              witness assignments. Weakness in any of these areas routinely leads
              to

              programs that cannot be compiled, or programs that compile but encode
              an

              invalid relation.


              Report issue for preceding element


              2. (2)



              Gadget-level Competence. Many basic operations in ZKP

              programs are not natively attainable in the programming frameworks.
              Instead,

              developers must rely on a library of pre-defined gadgets that encapsulate

              these operations with optimized implementations. Gadget-level competence

              refers to the ability to effectively utilize these gadgets in the context
              of

              ZKP development and, when necessary, implement new ones from scratch.


              Report issue for preceding element



              Taken together, these two capabilities form the foundation of end-to-end

              generation of ZK programs. Without reliable language and toolchain knowledge,

              LLMs are unable to produce compilable programs, while without gadget-level

              competence, the resulting programs cannot faithfully encode the intended

              relations. In practice, developers move between applying syntax and
              compilation

              rules to structure programs and assembling or extending gadgets to realize

              non-trivial constraints, and for LLMs, success also hinges on integrating
              these

              skills that bridge surface-level language fluency with the deeper ability
              to

              model arithmetic and logical constraints. Existing benchmarks, however,

              primarily target mainstream programming models, leaving this special
              integration

              of capabilities unexplored. This gap motivates our study: to systematically

              measure and evaluate LLM capability for ZK code generation. To study
              that, our

              evaluation pipeline introduces ZK-Eval, which explicitly measures both

              dimensions and assesses how they combine in end-to-end generation tasks.


              Report issue for preceding element


              ### 3.1. ZK-Eval Benchmark


              Report issue for preceding element


              In this section, we present the curation of ZK-Eval. Instead of

              focusing solely on end-to-end program generation, we aim to measure
              the

              individual competencies that contribute to successful ZK code generation.
              Below,

              we outline the key components of ZK-Eval.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x3.png)Figure
              3. The Design of MCQ Benchmark Evaluating LLM’s Knowledge on ZK Languages.Report
              issue for preceding element


              #### 3.1.1. Language and Toolchain Knowledge


              Report issue for preceding element


              We first evaluate whether LLMs possess the foundational knowledge required
              to

              author programs in ZK languages. To construct this evaluation, we curate
              a knowledge

              base covering the two most widely used languages, Circom and Noir. As
              shown in

              the left side of Fig. [3](https://arxiv.org/html/2509.11708v1#S3.F3
              "Figure 3 ‣ 3.1. ZK-Eval Benchmark ‣ 3. Measuring LLM Capability for
              ZK Code Generation ‣ From Evaluation to Enhancement: Large Language
              Models for Zero-Knowledge Proof Code Generation"), sources are collected
              through

              automated web crawling of official documentation, including language

              specifications, tutorials, and API references (e.g.,

              circomlib(iden3, [2025](https://arxiv.org/html/2509.11708v1#bib.bib33
              "")) for Circom and the Noir standard library).

              In addition, we manually gather publicly available examples from GitHub

              repositories (TEZCAN, [2025b](https://arxiv.org/html/2509.11708v1#bib.bib66
              ""); Sirin, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib58
              ""); Contributors, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib16
              ""); Thor, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib68
              "")) and online tutorials (TEZCAN, [2025a](https://arxiv.org/html/2509.11708v1#bib.bib65
              "")) to ensure coverage of

              idiomatic usage.


              Report issue for preceding element


              Based on this knowledge base, as shown in the middle of

              Fig. [3](https://arxiv.org/html/2509.11708v1#S3.F3 "Figure 3 ‣ 3.1.
              ZK-Eval Benchmark ‣ 3. Measuring LLM Capability for ZK Code Generation
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation"), we design a pipeline to automatically generate

              multiple-choice questions, a format widely adopted in prior evaluations
              of

              language models (Hendrycks et al., [2020](https://arxiv.org/html/2509.11708v1#bib.bib31
              ""); Myrzakhan et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib48
              ""); Zellers et al., [2019](https://arxiv.org/html/2509.11708v1#bib.bib80
              ""); Clark et al., [2018](https://arxiv.org/html/2509.11708v1#bib.bib15
              "")). Inspired by earlier work on LLM-driven

              question generation (Liu et al., [2020](https://arxiv.org/html/2509.11708v1#bib.bib44
              ""); Abbasiantaeb et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib2
              ""); Long et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib47
              ""); Ji et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib35
              "")), our pipeline iteratively samples subsets of documents and

              provides them to a large model, which composes candidate questions and
              answers.

              This process is repeated until the full document collection has been

              exhaustively covered, producing a diverse set of drafts.


              Report issue for preceding element


              All generated questions are then subjected to rigorous expert validation
              (right

              side of Fig. [3](https://arxiv.org/html/2509.11708v1#S3.F3 "Figure 3
              ‣ 3.1. ZK-Eval Benchmark ‣ 3. Measuring LLM Capability for ZK Code Generation
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation")). Human reviewers examine each question

              for factual correctness, clarity, and alignment with the intended level
              of

              difficulty. Cross-checking is performed among the authors to ensure
              agreement,

              and questions that do not meet these standards are either corrected
              or

              discarded. Topic coverage is also verified to ensure that all major
              aspects of

              the knowledge base are represented. We categorize the questions into
              four

              groups: _basic syntax_ (language grammar such as datatypes, statements,

              operators, control flows, signals and buses), _advanced topics_ (e.g.,

              taggings, traits, generics), _API references_ (standard library templates

              and functions), and _compiler principles_ (translation from source code
              to

              arithmetic circuits). A summary of the questions and representative
              examples is

              shown in Fig. [4](https://arxiv.org/html/2509.11708v1#S3.F4 "Figure
              4 ‣ 3.1.1. Language and Toolchain Knowledge ‣ 3.1. ZK-Eval Benchmark
              ‣ 3. Measuring LLM Capability for ZK Code Generation ‣ From Evaluation
              to Enhancement: Large Language Models for Zero-Knowledge Proof Code
              Generation"). As shown, the final benchmark

              consists of 172 questions for Circom and 164 for Noir, with a balanced

              distribution across the four categories. The full set of questions is
              provided

              in the Artifact.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x4.png)Figure
              4. Illustrative MCQ on Basic Circom Syntax with a Summary of Knowledge
              Categories.Report issue for preceding element![Refer to caption](https://arxiv.org/html/2509.11708v1/x5.png)Figure
              5. The Design of Gadget Benchmark on LLM’s Ability to Use or Implement
              Gadgets to Encode Constraints.Report issue for preceding element


              #### 3.1.2. Using and Implementing Gadgets to Encode Constraints


              Report issue for preceding element


              The second dimension of ZK-Eval assesses the ability of LLMs to use
              and

              implement gadgets to encode constraints, which are the fundamental building

              blocks of ZK programs. To construct this evaluation, we curate a representative

              set of gadgets from three complementary sources, as shown in

              Fig. [5](https://arxiv.org/html/2509.11708v1#S3.F5 "Figure 5 ‣ 3.1.1.
              Language and Toolchain Knowledge ‣ 3.1. ZK-Eval Benchmark ‣ 3. Measuring
              LLM Capability for ZK Code Generation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation"). First,
              circomlib(iden3, [2025](https://arxiv.org/html/2509.11708v1#bib.bib33
              "")),

              the official standard library of Circom, provides canonical implementations
              of

              common gadgets that developers routinely instantiate. Second,

              zk-kit(Nico Serrano, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib49
              "")) extends this idea to a broader ecosystem,

              offering more reusable gadget implementations across multiple ZK languages.

              Third, as an important observation, many gadgets share similar logical
              and

              arithmetic structures with primitives in SMT solvers. To capture this

              perspective, we leverage the Z3Py (Research, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib55
              "")) interface to the Z3 SMT

              solver (De Moura and Bjørner, [2008](https://arxiv.org/html/2509.11708v1#bib.bib22
              "")). These sources span both language-specific and

              language-agnostic perspectives, ensuring that our benchmark captures
              the core

              constraint patterns encountered in practice.


              Report issue for preceding element


              The resulting gadget set consists of 35 gadgets covering a wide range
              of

              categories: (i) _basic checks_, including range tests and comparisons;
              (ii)

              _logical gates_, such as AND, OR, XOR, and equality; (iii) _arithmetic_

              _operators_, including addition, subtraction, multiplication, division,

              exponentiation, modular reduction, and inversion; and (iv) _composite_

              _operators_, such as sum, distinct, and multiplexors (see the full list
              in the

              Supplementary Material). This collection is sufficiently expressive
              to simulate the primitive layer

              of typical ZK development workflows: any non-trivial circuit can be
              realized

              through the composition of these gadgets.


              Report issue for preceding element


              For every gadget in the set, we author a concise task description. Test
              cases

              are crafted to validate both _completeness_: accepting input assignments

              and _soundness_: rejecting assignments. For logical gates, this corresponds

              to enumerating the truth table; for arithmetic and composite gadgets,
              it is

              manually constructed based on their semantics. These tests ensure that

              correctness is evaluated not only in terms of producing the right outputs,
              but

              also in enforcing the intended constraints.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x6.png)Figure
              6. The Design of End-to-end ZK Program Generation Benchmark Adapted
              from HumanEval.Report issue for preceding element


              #### 3.1.3. End-to-End ZK Program Generation


              Report issue for preceding element


              The third dimension of ZK-Eval evaluates the capability of LLMs to

              perform full end-to-end ZK program generation, which requires the model
              to

              integrate language proficiency and gadget-level competence to assemble
              complete

              programs that encode non-trivial problem specifications. We build the
              benchmark

              on the top of the widely used HumanEval dataset (Chen et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib13
              "")) with

              ZKP-specific adaptions, as shown in Fig. [6](https://arxiv.org/html/2509.11708v1#S3.F6
              "Figure 6 ‣ 3.1.2. Using and Implementing Gadgets to Encode Constraints
              ‣ 3.1. ZK-Eval Benchmark ‣ 3. Measuring LLM Capability for ZK Code Generation
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation"). In

              particular, we exclude tasks involving (i) string manipulation, (ii)

              floating-point arithmetic, and (iii) outputs of variable length. Strings
              and

              floating-point numbers are not natively supported by Circom or Noir,
              while

              variable-length outputs are incompatible with the static nature of arithmetic

              circuits. Following prior work (Myrzakhan et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib48
              "")), each task is

              automatically annotated by an LLM and verified by experts to ensure
              accurate

              filtering, yielding a set of 68 standalone tasks suitable for ZK program

              generation.


              Report issue for preceding element


              To reflect the verification nature of ZK programs, we further reformulate
              the

              problem statements. Original HumanEval tasks are expressed as _construction_

              _problems_, in which a function computes an output S=P​(I)S=P(I) for
              input II. In contrast, ZK programs implement _verification problems_,
              where the

              goal is to check whether a candidate solution SS satisfies the intended

              relation for II. We therefore restate each task as a verification function

              V​(I,S)∈{0,1}V(I,S)\\in\\{0,1\\}, which outputs one if and only if the
              candidate

              solution is correct.


              Report issue for preceding element


              For each task, we construct an executable Python oracle that implements
              the

              verification semantics independently of any ZK framework, serving as
              a ground

              truth reference. Following prior work (Yuan et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib79
              ""); Siddiq et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib57
              "")), we

              then instruct an LLM to generate two Python scripts for test case generation:

              one producing input-solution pairs (I,S)(I,S) that should be accepted,
              and the

              other producing pairs that should be rejected. This dual design is crucial,
              as

              existing code-generation benchmarks provide only accepting examples
              (verifying

              acceptance of correct input-solution pairs) but do not evaluate rejection

              behavior. This ensures that generated programs are tested both for

              _soundness_ (rejecting invalid ones) and _completeness_ (accepting

              valid ones).


              Report issue for preceding element


              To ensure the benchmark offers a rigorous and faithful assessment, all
              test

              cases are first executed against the Python oracle and then validated
              and

              cross-checked by authors for clarity, correctness, and corner-case coverage,

              following practices in prior

              benchmarks (Liu et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib45
              ""); Zhang et al., [2024b](https://arxiv.org/html/2509.11708v1#bib.bib82
              ""); Wang et al., [2022a](https://arxiv.org/html/2509.11708v1#bib.bib71
              "")).

              Whenever inconsistencies are detected at any stage, the corresponding
              step is

              re-executed or manually corrected. If corner-case is found lacking,
              the test

              case generator is revised accordingly.


              Report issue for preceding element


              ### 3.2. Measurement Settings


              Report issue for preceding element


              Using ZK-Eval, we measure LLMs’ competencies on ZK code generation.
              Our

              study is guided by the following three research questions (RQs):


              Report issue for preceding element


              - •



              RQ1: Language & Toolchain Knowledge. Do LLMs understand the

              syntax, semantics, and standard libraries of Circom and Noir?


              Report issue for preceding element


              - •



              RQ2: Gadget-Level Competence. Can LLMs reliably use or

              implement constraint gadgets, the building blocks of ZK programs?


              Report issue for preceding element


              - •



              RQ3: End-to-End Generation. Can LLMs integrate these skills

              to produce complete, correct ZK programs?


              Report issue for preceding element



              Each RQ corresponds directly to one component of ZK-Eval. For RQ1,

              models are tested on curated multiple-choice questions covering language

              knowledge. For RQ2, they are instructed to implement gadget tasks which
              are then

              automatically validated against accepting and rejecting test cases.
              For RQ3,

              they attempt end-to-end program generation from reformulated HumanEval
              tasks,

              with correctness judged by soundness and completeness against dual test
              suites.


              Report issue for preceding element


              Model Selection. We evaluate 4 representative LLMs: OpenAI’s reasoning

              models _GPT-o4-mini_ and _GPT-o3_, along with _DeepSeek-V3_ and

              _Qwen3_. This mix of reasoning and open-source non-reasoning ones allows
              us

              to assess both family-specific and general trends. All models are run
              under

              identical prompts and budgets, with 10 samples per task to estimate
              pass rates

              and reduce variance.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x7.png)Figure
              7. Accuracy of LLMs and Human Experts on the MCQ Benchmark for ZK Language
              Knowledge.Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x8.png)


              Figure 8. LLM Performance on End-to-end ZK Benchmarks. Annotated with
              average accuracy.Report issue for preceding element


              Report issue for preceding element![Refer to caption](https://arxiv.org/html/2509.11708v1/x9.png)Figure
              9. Average Error Distribution of Gadget Implementations Across Languages,
              Types, and Causes.Report issue for preceding element


              ### 3.3. (RQ1) Language & Toolchain Knowledge


              Report issue for preceding element


              Fig. [3.2](https://arxiv.org/html/2509.11708v1#S3.SS2 "3.2. Measurement
              Settings ‣ 3. Measuring LLM Capability for ZK Code Generation ‣ From
              Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation") summarizes performance on the

              multiple-choice question set. Reasoning models perform best, with GPT-o4-mini

              reaching 88.1% and GPT-o3 87.2%. Open-source non-reasoning models perform

              noticeably worse, with DeepSeek V3 at 79.5% and Qwen3 at 78.9%. The
              human

              expert for reference scores 88.7%, similar to the reasoning models.
              Overall,

              LLMs demonstrate strong competence in ZK language knowledge, achieving
              accuracy

              within a few percentage points of the human expert.


              Report issue for preceding element


              Finding ①: On Circom and Noir, LLMs display strong competence in ZK

              language knowledge. Reasoning models surpass open-source ones and perform

              similar to human experts.

              Report issue for preceding element


              We further examine performance across question categories and languages.
              LLMs

              achieve their highest accuracy on questions about basic syntax and API

              references, reflecting familiarity with fundamental constructs and widely
              used

              library templates. In contrast, accuracy drops on advanced topics such
              as

              traits, signal taggings, and generics, which extend expressiveness but
              are less

              commonly encountered. The lowest performance is observed on compiler
              principles,

              which probe understanding of how source programs are transformed into
              arithmetic

              circuits. These results indicate that while LLMs are proficient in surface-level

              language usage, they struggle with deeper aspects of language design
              and

              compilation. Notably, there is no significant difference between Circom
              and

              Noir, suggesting that model competence reflects general exposure to
              ZK languages

              rather than language-specific familiarity.


              Report issue for preceding element


              Finding ②: LLMs excel at surface-level knowledge such as syntax and

              API references, but exhibit weaknesses in advanced language features
              and

              compiler principles.Report issue for preceding element


              These findings are consistent with the nature of the knowledge base:
              official

              documents, standard libraries, public tutorials, and open-source examples
              are

              all widely accessible training material to LLMs. Therefore, it is anticipated

              that LLMs can achieve strong performance on such content.


              Report issue for preceding element


              ### 3.4. (RQ2) Gadget-Level Competence


              Report issue for preceding element


              Building on the language knowledge observed in RQ1, we next assess whether
              LLMs

              can effectively apply this knowledge in ZK programming, specifically
              in using or

              implementing gadgets. Model outputs were analyzed with automated scripts
              that

              classified errors based on compiler diagnostics and test outcomes. From
              their

              distinct linguistic and functional effects, we grouped errors into six

              categories: (i) _constraint enforcement_, where models failed to encode

              relations using equality constructs ( ===Report issue for preceding
              element in Circom, assertReport issue for preceding element in

              Noir); (ii) _modules_, involving incorrect instantiation or usage of

              library components; (iii) _signal handling_, specific to Circom, where

              mistakes occurred in declaring, assigning, or referencing signals; (iv)

              _syntax & parsing_, where the generated code violated grammar rules;
              (v)

              _typing & resolution_, where data types or variables were used

              inconsistently or incorrectly; and (vi) _semantic errors_, where code

              compiled but failed functional correctness tests.


              Report issue for preceding element


              Fig. [9](https://arxiv.org/html/2509.11708v1#S3.F9 "Figure 9 ‣ 3.2.
              Measurement Settings ‣ 3. Measuring LLM Capability for ZK Code Generation
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation") shows the results on the gadget benchmark.

              Performance is consistently weak: even the best-performing category,
              logical

              operations, reached only 52% accuracy in Circom and 49% in Noir. Comparison

              gadgets scored lower (37% and 20%), while arithmetic and composite gadgets

              dropped to extremely low accuracy. This contrasts sharply with the strong

              results on language-level knowledge: when asked to operationalize this
              knowledge

              into gadgets, LLMs largely fail to produce correct, testable implementations.

              This gap reflects the difficulty of code generation for low-resource

              DSLs (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              "")), exacerbated in ZK programming by limited and

              fragmented resources (Sheybani et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib56
              "")).


              Report issue for preceding element


              Finding ③: On Circom and Noir languages, LLMs perform consistently

              weak on using or implementing constraint gadgets across all categories.Report
              issue for preceding element


              Typing and resolution errors are the most frequent. Noir enforces strict
              type

              matching in binary operations, disallowing implicit casts between fields
              and

              integers, while Circom distinguishes sharply between variables and signals.

              Models frequently mix types, reference undeclared identifiers, or redefine

              variables, causing compilation failures. Signal handling errors, unique
              to

              Circom, are the next most common, including declaring signals inside

              control-flow, reassigning them multiple times, or using them before

              initialization. Constraint enforcement errors also recur: instead of
              encoding

              equalities with ===Report issue for preceding element or assertReport
              issue for preceding element, models generate invalid forms

              such as non-quadratic constraints in Circom or deprecated constructs
              in Noir.

              These issues stem from ZK-specific semantics absent in conventional
              languages.


              Report issue for preceding element


              Performance further varies by gadget type, reflecting library support
              and

              algebraic complexity. Logical operations and comparisons, being boolean

              primitives or supported by libraries, are most tractable. Arithmetic
              and

              composite gadgets, such as exponentiation, modulo, floor division, or
              composites

              like sum, product, and distinct, lack native support

              and must be implemented from scratch. These tasks demand reasoning over
              field

              arithmetic, careful handling of inverses and negatives, and explicit
              soundness

              constraints. The very low accuracy here underscores the inability of
              current

              models to generate gadgets beyond those directly provided in libraries.


              Report issue for preceding element


              Finding ④: LLMs handle boolean and comparison gadgets better than

              arithmetic and composite ones, where ZK-specific semantics and limited
              library

              support demand non-trivial reasoning.Report issue for preceding element


              ### 3.5. (RQ3) End-to-End Generation


              Report issue for preceding element


              Fig. [8](https://arxiv.org/html/2509.11708v1#S3.F8 "Figure 8 ‣ 3.2.
              Measurement Settings ‣ 3. Measuring LLM Capability for ZK Code Generation
              ‣ From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
              Proof Code Generation") summarizes the results on the end-to-end

              generation benchmark. Compared to language knowledge and gadget-level
              tasks,

              performance drops substantially across all models. For Circom, accuracy
              is very

              low: GPT-o3 reaches only 20% semantically correct and 22% syntactically
              valid

              programs, while Qwen3 drops to 5% and 9%. Noir results are somewhat
              higher but

              still limited, with GPT-o4-mini at 32% and 40% and Qwen3 at 10% and
              19%.

              Across all settings, semantic correctness lags behind syntactic validity,

              showing that many compilable programs still fail to encode the intended

              verification relation.


              Report issue for preceding element


              Several trends emerge from these results. First, Noir tasks consistently
              yield

              higher success rates than Circom, likely due to Noir’s simpler type
              system and

              cleaner syntax, which reduce opportunities for errors such as signal
              misuse or

              type mismatches that are pervasive in Circom. Second, reasoning models

              substantially outperform open-source ones: GPT-o4-mini and GPT-o3 are
              2–3 times

              more successful than DeepSeek V3 and Qwen3 across both languages, confirming
              the

              gap already observed in earlier tasks. Finally, the gap between syntactic
              and

              semantic correctness underscores that compilation alone is insufficient
              for

              assessing ZK program quality: many outputs are compilable but wrong.


              Report issue for preceding element


              Finding ⑤: LLMs perform poorly on end-to-end code generation:

              reasoning models beats open-source ones; Noir is easier than Circom;
              many

              programs compile but remain incorrect.Report issue for preceding element


              ## 4\. Augmenting LLMs for ZK Code Generation


              Report issue for preceding element


              Our study reveals a gap between LLMs’ surface-level knowledge of ZK
              DSLs and

              their ability to construct correct gadgets or complete programs. Models
              can

              recall syntax and library references but struggle to translate this
              knowledge

              into valid constraint systems. To bridge this gap, we introduce

              ZK-Coder, an agentic framework for end-to-end ZK code generation. We

              first summarize the design principles derived from our findings, then
              present

              the system.


              Report issue for preceding element


              ### 4.1. Design Principles Learned from the Findings


              Report issue for preceding element


              Findings ① and ② show that LLMs possess a strong knowledge of

              ZK DSL syntax, semantics, and standard libraries, achieving near expert-level

              accuracy even on advanced features. This reflects their absorption of
              publicly

              available documentation and indicates their potential for ZK code generation.

              Despite this, limitations remain that motivate our further exploration.


              Report issue for preceding element


              In Findings ③ and ④, we observe that this knowledge does not

              translate into reliable gadget-level generation. Generated code frequently

              suffers from typing errors, signal mismanagement, and faulty constraint

              enforcement, reflecting the scarcity of training examples with concrete
              gadget

              implementations. To bridge this gap between knowing the language and
              encoding

              correct programs, we introduce a sketch language in ZK-Coder that

              abstracts ZKP’s underlying constraint system. To further link them to
              curated

              hints, ZK-Coder leverages retrieval-augmented generation

              (RAG) (Gao et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib26
              "")) to guide gadget usage. Loosely speaking, RAG

              trades brittle memorization for grounding: once the needed gadgets are

              identified, retrieval supplies exact usage patterns that collapse the
              search

              space and curb gadget hallucinations. This strategy explicitly mirrors
              how

              developers consult a codebook and enables composition of verified snippets
              for

              rare gadgets that pretraining scarcely covers.


              Report issue for preceding element


              Finally, Findings ③ and ⑤ highlight end-to-end program

              generation as the most challenging setting, where generated programs
              often fail

              due to syntactic errors or semantic mismatches. These failures directly

              undermine the reliability and necessitate mechanisms to improve validity
              and

              faithfulness. To mitigate these failures, ZK-Coder introduces a

              correctness-centric interactive loop. The LLM proposes a program, queries
              a

              compiler as an oracle to check syntactic validity, and, once compilable,

              executes test cases as an oracle to check intended semantics. By observing

              diagnostics and counterexamples, ZK-Coder repairs its code and iterates

              the “generate-compile-test-repair” loop until both syntactic and

              semantic checks pass. This interaction transforms failures into actionable

              feedback and guides candidates toward valid, faithful programs.


              Report issue for preceding element


              ### 4.2. ZK-Coder


              Report issue for preceding element


              Based on these design principles, we developed ZK-Coder, illustrated
              in

              Fig. [10](https://arxiv.org/html/2509.11708v1#S4.F10 "Figure 10 ‣ 4.2.
              ZK-Coder ‣ 4. Augmenting LLMs for ZK Code Generation ‣ From Evaluation
              to Enhancement: Large Language Models for Zero-Knowledge Proof Code
              Generation"). ZK-Coder augments LLMs with a structured

              pipeline that bridges natural-language problem descriptions and executable
              ZK

              programs. It consists of three main stages: ➀ constraint formulation,

              ➁ constraint-guided analysis and retrieval, and ➂ interactive

              generation and repair. In ➀, problem statements are translated into

              lightweight sketch language. Then, in ➁, the sketch is analyzed to

              extract its constraints, which are used to retrieve relevant usage patterns
              on

              gadgets from a curated knowledge base. Finally, in ➂, the LLM generates

              the target ZK code using the retrieved hints, interactively repairing
              it with

              the help of syntax and semantic oracles until correctness is achieved.
              We detail

              the design of these stages in this section, and present an illustrative
              workflow

              with concrete code examples in the Supplementary Material.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x10.png)Figure
              10. Illustrative Overview on the Design of ZK-Coder.Report issue for
              preceding element


              #### 4.2.1. Constraint Formulation in Sketch Language.


              Report issue for preceding element


              |     |     |     |

              | --- | --- | --- |

              |  | ProgramP::=defverify(engine,x1:τ1,…,xn:τn):S∗Typeτ::=Field​∣Bool∣​Vec\[​τ​\]StmtS::=x=E∣engine.add(Φ)∣forxinR:S∗∣ifΦ:S∗\[else:S∗\]∣return
              engineRangeR::=range​(E)∣range​(E,E)FormulaΦ::=A0​∣not​Φ∣​Φ​and​Φ​∣Φ​or​Φ∣​all​(Φ​for​x​in​R)∣any​(Φ​for​x​in​R)AtomA0::=E⋈E∣G​(E1,…,En)ExprE::=n∈ℤ∣True∣False∣x∣(E)∣E+E∣E−E∣E∗E∣E/E∣E%E∣E//E∣…RelOp⋈::===​∣!=∣​<​∣<=∣​>​∣>=∣​and​∣or∣​xorPrimitivesG::=distinct​(E)​∣select​(E,E,E)∣​abs​(E)​∣sum​(E​for​x​in​R)∣​…\\begin{array}\[\]{rrcl}\\textsc{Program}&P&::=&\\texttt{def}\
              \\texttt{verify}(\\texttt{engine},\ x\_{1}\\!:\\!\\tau\_{1},\ \\ldots,\
              x\_{n}\\!:\\!\\tau\_{n}):\ S^{\*}\\\\[2.0pt\]<br>\\textsc{Type}&\\tau&::=&\\texttt{Field}\\mid\\texttt{Bool}\\mid\\texttt{Vec\[}\\tau\\texttt{\]}\\\\[2.0pt\]<br>\\textsc{Stmt}&S&::=&x=E\\mid\\texttt{engine.add}(\\Phi)\\mid\\texttt{for}\
              x\ \\texttt{in}\ R:\ S^{\*}\\mid\\texttt{if}\ \\Phi:\ S^{\*}\[\\texttt{else}:\
              S^{\*}\]\\mid\\texttt{return engine}\\\\[2.0pt\]<br>\\textsc{Range}&R&::=&\\texttt{range}(E)\\mid\\texttt{range}(E,E)\\\\[2.0pt\]<br>\\textsc{Formula}&\\Phi&::=&A\_{0}\\mid\\texttt{not}\
              \\Phi\\mid\\Phi\ \\texttt{and}\ \\Phi\\mid\\Phi\ \\texttt{or}\ \\Phi\\mid\\texttt{all}(\\Phi\
              \\texttt{for}\ x\ \\texttt{in}\ R)\\mid\\texttt{any}(\\Phi\ \\texttt{for}\
              x\ \\texttt{in}\ R)\\\\[2.0pt\]<br>\\textsc{Atom}&A\_{0}&::=&E\ \\mathrel{\\bowtie}\
              E\\mid G(E\_{1},\\ldots,E\_{n})\\\\[2.0pt\]<br>\\textsc{Expr}&E&::=&n\\in\\mathbb{Z}\\mid\\texttt{True}\\mid\\texttt{False}\\mid
              x\\mid(E)\\mid E\ +\ E\\mid E\ -\ E\\mid E\ \*\ E\\mid E\ /\ E\\mid
              E\\%E\\mid E//E\\mid\\ldots\\\\[2.0pt\]<br>\\textsc{RelOp}&\\bowtie&::=&\\texttt{==}\\mid\\texttt{!=}\\mid\\texttt{<}\\mid\\texttt{<=}\\mid\\texttt{>}\\mid\\texttt{>=}\\mid\\texttt{and}\\mid\\texttt{or}\\mid\\texttt{xor}\\\\[2.0pt\]<br>\\textsc{Primitives}&G&::=&\\texttt{distinct}(E)\\mid\\texttt{select}(E,E,E)\\mid\\texttt{abs}(E)\\mid\\texttt{sum}(E\
              \\texttt{for}\ x\ \\texttt{in}\ R)\\mid\\ldots\\end{array} |  |


              Figure 11. The Abstract Grammar of the ZK Sketch Language.Report issue
              for preceding element


              The first stage of ZK-Coder reasons and translates a natural-language

              problem description into a structured representation of ZKP programs.
              In

              accordance to our observations in Sec. [3.4](https://arxiv.org/html/2509.11708v1#S3.SS4
              "3.4. (RQ2) Gadget-Level Competence ‣ 3. Measuring LLM Capability for
              ZK Code Generation ‣ From Evaluation to Enhancement: Large Language
              Models for Zero-Knowledge Proof Code Generation") as well as prior work
              on

              sketching and planning for code generation (Wang et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib70
              ""); Deng et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib23
              ""); Li et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib43
              ""); Jiang et al., [2024a](https://arxiv.org/html/2509.11708v1#bib.bib39
              ""); Wen et al., [2024a](https://arxiv.org/html/2509.11708v1#bib.bib75
              "")), we introduce a lightweight intermediate

              language, the ZK Sketch Language (ZKSL; Fig. [11](https://arxiv.org/html/2509.11708v1#S4.F11
              "Figure 11 ‣ 4.2.1. Constraint Formulation in Sketch Language. ‣ 4.2.
              ZK-Coder ‣ 4. Augmenting LLMs for ZK Code Generation ‣ From Evaluation
              to Enhancement: Large Language Models for Zero-Knowledge Proof Code
              Generation")) that

              shares a similar essence with Python and Z3 ecosystem while abstracting
              away

              ZK-specific details.

              In ZKSL, a Program consists of a single verifyReport issue for preceding
              element function with

              typed parameters and a sequence of statements (Stmt); statements

              include assignments, assertions via engine.add(Φ\\Phi)Report issue for
              preceding element, bounded loops

              and conditionals, and an optional return. Formulas Φ\\Phi are built

              from relational atoms E⋈EE\\bowtie E and gadget calls G​(⋅)G(\\cdot).
              Its primitives

              (literals, arithmetic operators, etc.) align with the gadgets used in

              Sec. [3.1.1](https://arxiv.org/html/2509.11708v1#S3.SS1.SSS1 "3.1.1.
              Language and Toolchain Knowledge ‣ 3.1. ZK-Eval Benchmark ‣ 3. Measuring
              LLM Capability for ZK Code Generation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation").


              Report issue for preceding element


              ZK-Coder prompts LLMs to generate ZKSL sketches from problem

              specifications. Then, to ensure well-formedness, ZK-Coder incorporates

              a checker that validates sketches on syntactic validity, type/arity
              consistency,

              and closure. If a sketch is invalid, feedback is provided to the LLM
              to refine

              its output. Since ZKSL is ZK-agnostic, it isolates constraint reasoning
              from

              ZK-specific syntax and semantics and reduces the generation complexity.


              Report issue for preceding element


              #### 4.2.2. Constraint-Guided Analysis and Retrieval.


              Report issue for preceding element


              In addition to sketching and planning with ZKSL, RAG has been shown
              powerful to

              aid LLM-based code generation in low-resource, domain-specific

              languages (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              "")). After obtaining a ZK-agnostic sketch,

              ZK-Coder analyzes its constraints and retrieves ZK-specific

              implementation guidance, bridging the abstract ZKSL specification and
              the

              concrete gadget implementations required in particular ZK DSLs.


              Report issue for preceding element


              We traverse the ZKSL sketch, collecting each constraint introduced via

              engine.add(⋅\\cdot)Report issue for preceding element. Operators are
              canonicalized: aliases are

              normalized (e.g., >=Report issue for preceding element is normalized
              to GreaterEqThanReport issue for preceding element) and

              operator variants are distinguished by arity and types (e.g., XOr: Bool

              ×\\times Bool →\\rightarrow BoolReport issue for preceding element vs.
              XOr: Field ×\\times Field

              →\\rightarrow FieldReport issue for preceding element). Non-constraint
              constructs (e.g., folded constants, loop

              statements or conditional guards that emit no constraints) are discarded.
              The

              result is an ordered, typed set of constraint primitives corresponding
              to the

              required gadgets.


              Report issue for preceding element


              To build a knowledge base for retrieval, we curate a collection of gadget
              and

              their usage examples either from the standard libraries of ZK DSLs or
              from

              verified implementations. With the knowledge base, ZK-Coder performs

              constraint-guided retrieval to fetch relevant usage patterns on gadgets
              for each

              constraint primitive. Retrieval enforces exact operator/type/arity matching,
              and

              hints are emitted in the ZKSL order to preserve program flow during
              generation.

              In this way, ZK-Coder effectively grounds generation in precise

              constraint analysis and structured retrieval.


              Report issue for preceding element


              #### 4.2.3. Interactive Generation and Repair.


              Report issue for preceding element


              With the sketch generated in ➀ and the hints retrieved in ➁,

              ZK-Coder proceeds to the final stage of end-to-end code generation.
              As

              pointed out in prior work (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              ""); Wang et al., [2022b](https://arxiv.org/html/2509.11708v1#bib.bib72
              ""); Bi et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib8
              ""); Skreta et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib59
              "")), introducing a

              feedback loop that leverages compilers and test executors as oracles
              can

              substantially improve code generation reliability. Motivated by this,

              ZK-Coder implements an interactive generate-repair loop to ensure both

              syntactic validity and semantic correctness of the generated ZK programs.
              The

              loop alternates between code generation, compilation checks, and execution-based

              testing, iteratively refining the program until it meets all correctness

              criteria.


              Report issue for preceding element


              Given the ZKSL sketch specification and constraint-specific hints, the
              LLM

              produces a candidate program. Then, ZK-Coder submits the program to
              the

              ZKP compiler (i.e., Circom or Noir) for compilation. If ZK-Coder

              observes compilation errors (e.g., syntax errors, type mismatches, or
              illegal

              signal operations), it extracts the diagnostics and feeds them back
              to the LLM

              for repair. The LLM refines the program based on this feedback, producing
              a new

              candidate that is again submitted for compilation. This process repeats
              until a

              compilable program is obtained. With a compilable program, ZK-Coder

              generates a set of test cases and validates the program on these cases
              on the

              fly. If any test case fails, ZK-Coder collects the counterexample and

              feeds it back to the LLM for further repair. This loop continues until
              the

              program successfully passes all test cases or the retry limit is reached.
              This

              interactive approach in ZK-Coder converts failures into constructive

              feedback and augments the LLM’s ability to produce reliable ZK programs.


              Report issue for preceding element


              ## 5\. Evaluation


              Report issue for preceding element


              We evaluate ZK-Coder on the task of generating zero-knowledge programs

              from natural language specifications. Our evaluation is structured around
              the

              following research questions, with a focus on end-to-end generation.
              To clarify,

              we do not re-evaluate language knowledge (RQ1) or gadget-level coding
              (RQ2): the

              former is established in Sec. [3.3](https://arxiv.org/html/2509.11708v1#S3.SS3
              "3.3. (RQ1) Language & Toolchain Knowledge ‣ 3. Measuring LLM Capability
              for ZK Code Generation ‣ From Evaluation to Enhancement: Large Language
              Models for Zero-Knowledge Proof Code Generation"), and the latter is
              handled by our

              retrieval mechanism in Sec. [4.2.2](https://arxiv.org/html/2509.11708v1#S4.SS2.SSS2
              "4.2.2. Constraint-Guided Analysis and Retrieval. ‣ 4.2. ZK-Coder ‣
              4. Augmenting LLMs for ZK Code Generation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation"). Given
              that said, we

              include an ablation study RQ5.


              Report issue for preceding element


              - •



              RQ4 (End-to-End Performance): How does ZK-Coder

              perform compared to baseline methods in generating correct ZK programs?


              Report issue for preceding element


              - •



              RQ5 (Ablation Study): What is the effect of each design

              component, including the ZK sketch language, constraint-guided retrieval,
              and

              the interactive repair loop?


              Report issue for preceding element


              - •



              RQ6 (Robust Generalization): Beyond the standard benchmark,

              adapted HumanEval, how well does ZK-Coder transfer to newer and

              more challenging tasks?


              Report issue for preceding element


              - •



              RQ7 (Failure Analysis): When ZK-Coder fails, what

              are the common failure patterns, and how might they inform future research?


              Report issue for preceding element



              ### 5.1. Experimental Setup


              Report issue for preceding element


              Our experiments are organized according to the research questions outlined

              above.


              Report issue for preceding element


              For RQ4 (End-to-End Performance), we evaluate on the adapted HumanEval

              benchmark from ZK-Eval, using the two strongest OpenAI’s reasoning

              models from our measurement study: GPT-o4-mini and GPT-o3. This comparison

              establishes how well ZK-Coder outperforms baseline methods in

              generating correct and provable ZK programs.


              Report issue for preceding element


              For RQ5 (Ablation Study), we conduct an ablation study on GPT-o4-mini,

              selectively disabling each design component of ZK-Coder, including the

              sketch language, constraint-guided retrieval, and the interactive repair
              loop.

              This aims to quantify their individual impact on overall performance.


              Report issue for preceding element


              For RQ6 (Robust Generalization), we construct a new dataset following

              the adaptation methodology of ZK-Eval using LiveCodeBench. Unlike the

              simple and potentially contaminated HumanEval, this benchmark contains
              harder,

              contamination-free, and more recent tasks. We evaluate whether ZK-Coder

              continues to maintain high performance under more challenging scenarios.


              Report issue for preceding element


              Finally, for RQ7 (Failure Analysis), we analyze cases where

              ZK-Coder fails, categorizing the dominant error patterns and their

              underlying causes. This analysis highlights limitations of the current
              pipeline

              and suggests avenues for future research.


              Report issue for preceding element


              All experiments are conducted under a fixed repair budget of up to 8
              iterations

              for syntax checking and repair, and 1 iteration for semantic checking
              and

              comparison. Each task is executed 10 times to compute Pass@1 accuracy,
              ensuring

              statistical stability. The evaluation is conducted on a Linux (Ubuntu
              22.04 LTS)

              server equipped with 256 GiB of RAM.


              Report issue for preceding element


              ### 5.2. RQ4: End-to-End Performance


              Report issue for preceding element


              We evaluate the end-to-end performance of ZK-Coder. To the best of our

              knowledge, since no prior work directly addresses zero-knowledge program

              generation from natural language, we establish a simple but meaningful
              baseline:

              directly prompting the model to produce circuit code from the task description

              and input specification, without any sketching, retrieval, or repair.
              This

              setting captures the raw capability of LLMs and provides a lower bound
              against

              which the contributions of ZK-Coder can be measured.


              Report issue for preceding element


              During the evaluation, we meticulously document the performance for
              the pipeline

              in three key stages: (1) _Sketch correctness_ measures whether the initial

              ZK sketch produced from the natural language description is correct
              by passing

              all hidden test cases; (2) _Repair pass rate_ is conditioned on all

              correctly generated sketches, and reports the fraction of these that
              can be

              successfully repaired by the interactive repair loop; (3) _Program_

              _correctness_ is conditioned on all successfully repaired programs,
              and measures

              the proportion that pass all hidden test cases. The final _overall_

              _accuracy_ aggregates across the full pipeline, reflecting end-to-end
              program

              generation accuracy. In addition, we report the _average token cost_
              for

              each model, which quantifies the spending.


              Report issue for preceding element


              Table 3. Comparative Per-stage Performance (Accuracy, Tokens) of ZK-Coder
              and Baseline.


              | Language | Model | ZK-Coder Per-stage Performance | ZK-Coder Overall
              | Baseline |

              | --- | --- | --- | --- | --- |

              | (1) Sketch | (2) Repair | (3) Program | Accuracy | Avg. | Accuracy
              | Avg. |

              | --- | --- | --- | --- | --- | --- | --- |

              | Correctness | Pass Rate | Correctness | (Pass@1) | Token | (Pass@1)
              | Token |

              | --- | --- | --- | --- | --- | --- | --- |

              | Circom | GPT-o4-mini | 94.12% | 91.72% | 96.59% | 83.38% | 2350.31
              | 17.35% | 436.98 |

              | GPT-o3 | 97.30% | 94.73% | 96.82% | 89.23% | 2253.29 | 20.29% | 433.35
              |

              | Noir | GPT-o4-mini | 94.12% | 97.97% | 97.66% | 90.05% | 648.95 |
              32.21% | 152.18 |

              | GPT-o3 | 97.21% | 97.43% | 99.38% | 94.12% | 765.46 | 27.94% | 195.34
              |


              Report issue for preceding element


              Table [3](https://arxiv.org/html/2509.11708v1#S5.T3 "Table 3 ‣ 5.2.
              RQ4: End-to-End Performance ‣ 5. Evaluation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation") summarizes
              the comparative performance of

              ZK-Coder and the baseline across both Circom and Noir. Across all

              settings, ZK-Coder achieves substantial gains over the baseline. On

              Circom, GPT-o4-mini and GPT-o3 reach overall pass rates of 83.38% and
              89.23%,

              respectively, compared to only 17.35% and 20.29% for the baseline. Noir
              shows

              a similar trend, with GPT-o4-mini reaching 90.05% and GPT-o3 achieving
              the

              highest overall rate of 94.12%, far outperforming the corresponding
              baseline

              results of 32.21% and 27.94%.


              Report issue for preceding element


              The per-stage breakdown highlights the robustness of the pipeline. Sketch

              correctness exceeds 94% across all configurations, showing that initial

              translation into ZK sketches is highly reliable. The repair loop maintains

              strong success rates, above 91% in Circom and above 97% in Noir, ensuring
              that

              most sketches can be generated into valid programs. Final program correctness

              surpasses 96% in all cases, confirming that the integration of sketching,

              repair, and semantic validation yields consistently executable and provable

              programs.


              Report issue for preceding element


              We also note that ZK-Coder incurs a higher token cost compared to the

              baseline, which is expected since our agentic pipeline includes sketching,
              RAG

              and interactive repair. However, the cost remains modest in practice,
              with each

              task requiring fewer than 3,000 tokens on average, corresponding to
              less than

              0.1 USD per task, making the gains in correctness highly cost-effective.


              Report issue for preceding element


              Answer to RQ4:ZK-Coder delivers a significant improvement in end-to-end

              performance over the baseline method. These results confirm that our
              pipeline

              substantially enhances the performance on LLM-generating ZK programs.Report
              issue for preceding element


              ### 5.3. RQ5: Ablation Study


              Report issue for preceding element![Refer to caption](https://arxiv.org/html/2509.11708v1/x11.png)Figure
              12. Accuracy Comparison of ZK-Coder Ablation Variants.Report issue for
              preceding element


              To assess the role of each major component in ZK-Coder, we conduct an

              ablation study where individual modules are disabled or replaced. The
              following

              variants are considered:


              Report issue for preceding element


              - •



              No RAG (V1): Disables constraint-guided retrieval augmented

              generation, forcing the model to rely solely on its internal knowledge.


              Report issue for preceding element


              - •



              No Sketch (V2): Removes the intermediate ZK sketch reasoning

              and directly prompts the model to output full programs with RAG and
              the

              interactive repair loop.


              Report issue for preceding element


              - •



              No Syntax Repair (V3): Eliminates the interactive repair loop

              for syntax errors.


              Report issue for preceding element


              - •



              No Semantic Repair (V4): Retains syntax repair but disables

              semantic repair.


              Report issue for preceding element


              - •



              Similarity-based RAG (V5): Replaces our constraint-guided

              retrieval with a naive similarity-based retrieval using surface-level

              embedding similarity.


              Report issue for preceding element


              - •



              Only Repair (V6): Omits both retrieval and sketching,

              relying exclusively on the repair loop applied to direct generations.


              Report issue for preceding element



              Figure [12](https://arxiv.org/html/2509.11708v1#S5.F12 "Figure 12 ‣
              5.3. RQ5: Ablation Study ‣ 5. Evaluation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation") presents
              the pass@1 accuracy for each ablation

              variant across Circom and Noir. The results show that every component
              plays a

              critical role in the overall success of ZK-Coder. Removing RAG (V1)

              reduces accuracy from 83.38% to 67.21% on Circom, and from 90.05% to
              89.22%

              on Noir. Disabling the sketch reasoning stage (V2) causes further degradation

              (71.32% on Circom, 87.50% on Noir), highlighting the value of sketching
              as a

              scaffold for task understanding and constraint reasoning. The most severe
              drop

              arises from removing syntax repair (V3), with accuracy falling to 35.00%
              on

              Circom and 41.39% on Noir, demonstrating that interactive repair is

              indispensable. Disabling semantic repair (V4) also leads to measurable

              reductions (81.18% on Circom, 87.99% on Noir), confirming that semantic

              validation contributes to robustness. Substituting constraint-guided
              retrieval

              with a naive similarity-based strategy (V5) yields weaker performance
              (69.87%

              on Circom, 89.41% on Noir), suggesting that constraint-guided retrieval
              is more

              effective than surface-level matching. Finally, the “Only Repair” variant
              (V6)

              performs poorly, especially on Circom (59.12%), indicating that repair
              alone

              cannot compensate for the absence of sketching and retrieval.


              Report issue for preceding element


              Answer to RQ5: The ablation study shows that the strong performance
              of

              ZK-Coder relies on the synergy of sketching, constraint-guided RAG,
              and

              interactive repair. Removing or weakening any of these components causes

              substantial accuracy drops.Report issue for preceding element


              ### 5.4. RQ6: Robust Generalization


              Report issue for preceding element


              To assess whether ZK-Coder sustains strong performance on harder, more

              recent, and contamination-free tasks, we evaluate on

              LiveCodeBench (Jain et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib34
              "")), a recently introduced benchmark

              designed to be contamination free. We select all tasks labeled as medium

              difficulty, filter and adapt them using the methodology introduced in

              Sec. [3.1.3](https://arxiv.org/html/2509.11708v1#S3.SS1.SSS3 "3.1.3.
              End-to-End ZK Program Generation ‣ 3.1. ZK-Eval Benchmark ‣ 3. Measuring
              LLM Capability for ZK Code Generation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation"), resulting
              in a set of 34 tasks (details

              refer to the Supplementary Material). This offers a more challenging
              and realistic testbed for ZK

              program generation.


              Report issue for preceding element


              Table 4. ZK-Coder Code Generation Performance on the Adapted LiveCodeBench
              Benchmark.


              |     |     |     |

              | --- | --- | --- |

              | Language | ZK-Coder | Baseline |

              | Circom | 72.25% | 2.97% |


              |     |     |     |

              | --- | --- | --- |

              | Language | ZK-Coder | Baseline |

              | Noir | 82.32% | 14.72% |


              Report issue for preceding element


              Table [4](https://arxiv.org/html/2509.11708v1#S5.T4 "Table 4 ‣ 5.4.
              RQ6: Robust Generalization ‣ 5. Evaluation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation") presents
              the results.

              ZK-Coder achieves 72.25% accuracy on Circom and 82.32% on Noir,

              dramatically outperforming the baseline scores of 2.97% and 14.72%,

              respectively. These results indicate that even on a harder and

              contamination-free benchmark, ZK-Coder continues to deliver strong

              accuracy and robust generalization.


              Report issue for preceding element


              Answer to RQ6:ZK-Coder’s performance on LiveCodeBench confirms that
              the

              pipeline generalizes effectively to harder and contamination-free tasks.Report
              issue for preceding element


              ### 5.5. RQ7: Failure Analysis


              Report issue for preceding elementTable 5. Distribution of ZK-Coder’s
              Code Generation Failures.


              | Language | Benchmark | Repair Budget | Sketch | False | False | Mixed
              False |

              | --- | --- | --- | --- | --- | --- | --- |

              | Exceed | Incorrect | Accept | Reject | Accept & Reject |

              | --- | --- | --- | --- | --- |

              | Circom | Humaneval | 46.09% | 34.78% | 0.87% | 14.78% | 3.48% |

              | LiveCodeBench | 36.26% | 37.36% | 9.89% | 15.38% | 1.10% |

              | Noir | Humaneval | 17.33% | 53.33% | 5.33% | 17.33% | 6.67% |

              | LiveCodeBench | 23.53% | 58.82% | 0.00% | 17.65% | 0.00% |


              Report issue for preceding element


              Table [5](https://arxiv.org/html/2509.11708v1#S5.T5 "Table 5 ‣ 5.5.
              RQ7: Failure Analysis ‣ 5. Evaluation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation") reports
              the distribution of

              ZK-Coder’s failure cases across Circom and Noir on both HumanEval and

              LiveCodeBench. Each column corresponds to a distinct failure mode. _Repair_

              _Budget Exceed_ indicates cases where the repair budget was exhausted
              without

              producing any compilable program. _Sketch Incorrect_ denotes that the

              generated ZKSL sketch failed hidden test cases, suggesting a misunderstanding
              of

              the task requirements. _False Accept_ corresponds to programs that

              erroneously accept invalid witnesses, while _False Reject_ refers to

              programs that incorrectly reject valid witnesses. _Mixed False Accept
              &_

              _Reject_ captures programs that simultaneously exhibit both types of
              errors,

              reflecting severe constraint mis-specification.


              Report issue for preceding element


              The data reveal that the two dominant sources of failure are _Repair
              Budget_

              _Exceed_ and _Sketch Incorrect_. In both Circom and Noir, these two
              together

              account for over 80% of failures on both benchmarks. _Repair Budget_

              _Exceed_ often arises when the model is unable to generate any compilable

              program, which due to gaps in pretraining exposure to ZK-specific constructs.

              _Sketch Incorrect_, on the other hand, point to deeper misunderstandings
              of

              the natural language description, where the task is not properly captured
              in the

              ZKSL representation. The less frequent categories (false accept, false
              reject,

              and mixed errors) typically stem from incorrect constraint enforcement
              when

              translating a valid sketch into a concrete circuit. These errors indicate
              local

              implementation mistakes rather than systemic failures of the pipeline.


              Report issue for preceding element


              Answer to RQ7: In summary, _Repair Budget Exceed_ and _Sketch Incorrect_

              constitute the most critical bottlenecks for robust end-to-end generation.
              The

              former highlights the need for more ZK-specific training data to improve
              raw

              generation capabilities, while the latter underscores the difficulty
              of

              grounding natural language descriptions in precise constraints.Report
              issue for preceding element


              ## 6\. Related Work


              Report issue for preceding element


              ##### LLM for DSL Code Generation.


              Report issue for preceding element


              Emerging research has investigated the

              use of LLMs for generating code in DSLs, a task made challenging by
              limited

              training data and specialized syntax (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              "")). To mitigate these

              difficulties, grammar prompting has been proposed to guide LLMs with
              partial

              grammars and thereby improve the well-formedness of generated

              programs (Wang et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib69
              "")). RAG techniques further enhance DSL generation

              by supplying relevant API documentation or code

              samples (Pimparkhede et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib53
              ""); Bassamzadeh and Methani, [2024](https://arxiv.org/html/2509.11708v1#bib.bib5
              "")). For DSLs where correctness guarantees are critical,

              approaches based on formal verification (Councilman et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib20
              "")) and

              verified lifting (Bhatia et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib7
              "")) strengthen

              reliability by coupling generated code with machine-checkable proofs.
              Our work

              advances this line of research by focusing on DSLs for zero-knowledge
              proofs.


              Report issue for preceding element


              ##### Code Generation Benchmarks.


              Report issue for preceding element


              Most benchmarks for LLM-based code

              generation focus on general-purpose languages (Jain et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib34
              ""); Chen et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib13
              "")), with limited support for DSLs. A recent

              survey (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              "")) reviews existing DSL benchmarks and emphasizes the

              lack of standardized evaluation resources, highlighting the need for
              benchmarks

              that capture DSL-specific paradigms, idioms, and practical applications.
              In the

              case of ZKPs, to our knowledge, no systematic benchmark exists for ZKP
              code

              generation that reflects ZK-specific requirements, namely proving a
              computation,

              a static arithmetic-circuit model, and correctness defined by both acceptance

              and rejection. We provide a solution for this gap with ZK-Eval,

              studying code generation bottlenecks and evaluating end-to-end tasks.


              Report issue for preceding element


              ##### Software Engineering for ZKP


              Report issue for preceding element


              The software engineering community has

              recently begun to explore tools and methodologies for ZKP development.
              Numerous

              researches have proposed to improve the security of ZKPs. Static analysis
              tools

              such as Circomspect (Dahlgren, [2022](https://arxiv.org/html/2509.11708v1#bib.bib21
              "")), ZKAP (Wen et al., [2024b](https://arxiv.org/html/2509.11708v1#bib.bib74
              "")),

              QED2(Pailoor et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib51
              "")), and

              halo2-analyzer (Soureshjani et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib60
              "")) identify specific vulnerability

              patterns, while testing tools like MTZK (Xiao et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib76
              "")) and

              zkFuzz (Takahashi et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib62
              "")) use fuzzing to expose security issues. In this

              work, we focus on reducing the burden of writing ZKP programs by leveraging

              LLMs’ capabilities, complementing these efforts by helping developers
              audit and

              refine their code.


              Report issue for preceding element


              ## 7\. Discussion, Limitation and Future Work


              Report issue for preceding element


              ##### ZKP Program Complexity.


              Report issue for preceding element


              Program complexity for ZKPs is measured by

              the size of arithmetic circuits. It is a critical factor in the efficiency
              and

              scalability of ZKP systems, directly determining prover cost and overall

              performance. To reduce that, a range of compilers have been proposed
              to optimize

              circuit construction (Stronati et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib61
              ""); Aztec Labs, [2025](https://arxiv.org/html/2509.11708v1#bib.bib4
              ""); Ozdemir et al., [2022](https://arxiv.org/html/2509.11708v1#bib.bib50
              "")), while

              new protocols reduce complexity through advanced arithmetizations with
              custom

              gates and lookup arguments (Chen et al., [2023](https://arxiv.org/html/2509.11708v1#bib.bib12
              ""); Gabizon et al., [2019](https://arxiv.org/html/2509.11708v1#bib.bib25
              "")). On the

              programmer side, several techniques further improve efficiency, such
              as adopting

              ZK-friendly hash functions (Grassi et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib29
              "")), gate packing, and

              aggregating bits into single field elements. For LLM-based code generation,

              however, producing efficient circuits is more difficult than generating
              correct

              ones. As future work, we plan to survey optimization techniques and
              guide LLMs

              in incorporating these strategies.


              Report issue for preceding element


              ##### LLM Training and Fine-tuning.


              Report issue for preceding element


              Recent studies show that LLMs struggle

              with DSLs and other low-resource languages due to the lack of high-quality

              training data (Joel et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib40
              "")), a challenge that is particularly acute in

              the context of ZKPs (Sheybani et al., [2025](https://arxiv.org/html/2509.11708v1#bib.bib56
              "")).

              This scarcity also limits the feasibility of fine-tuning approaches.
              Our work

              takes a step toward mitigating this limitation by systematizing the
              generation

              of program examples in ZK DSLs, which can support targeted training
              and domain

              adaptation of LLMs. These examples may be used as a complementary resource
              for

              future research in ZK code generation.


              Report issue for preceding element


              ##### Threat to Validity.


              Report issue for preceding element


              Our study on language knowledge relies on

              multiple-choice QA pairs that were initially generated with LLM assistance.

              Although some of these questions may contain leading hints or incorrect
              answers,

              we address this risk through repeated human validation and cross checking,

              ensuring that any residual noise has limited influence on the results.
              The

              evaluation in ZK-Eval employs carefully designed test cases that check

              both accepting and rejecting behaviors of generated programs and gadget
              usages.

              While test cases cannot fully guarantee correctness, they are constructed
              to

              include representative corner cases and to enforce soundness and completeness

              requirements, thereby reducing the likelihood of false positives. Furthermore,

              the gadget suite used by ZK-Eval and ZK-Coder consists of 35

              representative components selected for their prevalence in ZK libraries
              and for

              their coverage of core patterns. This set strikes a balance between
              complexity

              and tractability, spanning arithmetic, boolean, comparison, etc., and
              has

              already demonstrated clear performance improvements in evaluation. Looking

              forward, the suite is designed for incremental extension, allowing more
              advanced

              and cryptographic composites to be incorporated in future work.


              Report issue for preceding element


              ## 8\. Conclusion


              Report issue for preceding element


              We presented ZK-Eval, the first benchmark for systematically assessing

              LLM capability in ZK program synthesis, and showed that while models
              master

              language knowledge, they struggle with gadget construction and end-to-end

              synthesis. To address these gaps, we introduced ZK-Coder, a

              retrieval-augmented framework that guides LLMs from abstract constraint
              sketches

              to executable ZK code through constraint-guided retrieval and syntax-semantic

              repair. We show that ZK-Coder significantly improves the code

              generation capability of LLMs on both Circom and Noir.


              Report issue for preceding element


              ## References


              Report issue for preceding element


              - (1)↑

              - Abbasiantaeb et al. (2024)↑

              Zahra Abbasiantaeb, Yifei

              Yuan, Evangelos Kanoulas, and Mohammad

              Aliannejadi. 2024.


              Let the llms talk: Simulating human-to-human

              conversational qa via zero-shot llm-to-llm interactions. In

              _Proceedings of the 17th ACM International_

              _Conference on Web Search and Data Mining_. 8–17.


              - Abukhalaf et al. (2023)↑

              Seif Abukhalaf, Mohammad

              Hamdaqa, and Foutse Khomh.

              2023.


              On Codex prompt engineering for OCL generation: an

              empirical study. In _2023 IEEE/ACM 20th_

              _International Conference on Mining Software Repositories (MSR)_. IEEE,

              148–157.


              - Aztec Labs (2025)↑

              Aztec Labs.

              2025.


              Noir: A Domain-Specific Language for Zero-Knowledge

              Programming.


              [https://noir-lang.org](https://noir-lang.org/ "").


              Accessed: 2025-08.


              - Bassamzadeh and Methani (2024)↑

              Nastaran Bassamzadeh and

              Chhaya Methani. 2024.


              A comparative study of DSL code generation:

              Fine-tuning vs. optimized retrieval augmentation.


              _arXiv preprint arXiv:2407.02742_

              (2024).


              - Bellés-Muñoz et al. (2022)↑

              Marta Bellés-Muñoz,

              Miguel Isabel, Jose Luis Muñoz-Tapia,

              Albert Rubio, and Jordi Baylina.

              2022.


              Circom: A circuit description language for building

              zero-knowledge applications.


              _IEEE Transactions on Dependable and Secure_

              _Computing_ 20, 6 (2022),

              4733–4751.


              - Bhatia et al. (2024)↑

              Sahil Bhatia, Jie Qiu,

              Niranjan Hasabnis, Sanjit A. Seshia,

              and Alvin Cheung. 2024.


              Verified Code Transpilation with LLMs.


              arXiv:2406.03003 \[cs.PL\]


              [https://arxiv.org/abs/2406.03003](https://arxiv.org/abs/2406.03003
              "")

              - Bi et al. (2024)↑

              Zhangqian Bi, Yao Wan,

              Zheng Wang, Hongyu Zhang,

              Batu Guan, Fangxin Lu,

              Zili Zhang, Yulei Sui,

              Hai Jin, and Xuanhua Shi.

              2024.


              Iterative Refinement of Project-Level Code Context

              for Precise Code Generation with Compiler Feedback.


              arXiv:2403.16792 \[cs.CL\]


              [https://arxiv.org/abs/2403.16792](https://arxiv.org/abs/2403.16792
              "")

              - Cassano et al. (2022)↑

              Federico Cassano, John

              Gouwar, Daniel Nguyen, Sydney Nguyen,

              Luna Phipps-Costin, Donald Pinckney,

              Ming-Ho Yee, Yangtian Zi,

              Carolyn Jane Anderson, Molly Q Feldman,

              Arjun Guha, Michael Greenberg, and

              Abhinav Jangda. 2022.


              MultiPL-E: A Scalable and Extensible Approach to

              Benchmarking Neural Code Generation.


              arXiv:2208.08227 \[cs.LG\]


              [https://arxiv.org/abs/2208.08227](https://arxiv.org/abs/2208.08227
              "")

              - Chaliasos et al. (2025)↑

              Stefanos Chaliasos, Imam

              Al-Fath, and Alastair Donaldson.

              2025.


              Towards Fuzzing Zero-Knowledge Proof Circuits

              (Short Paper). In _Proceedings of the 34th ACM_

              _SIGSOFT International Symposium on Software Testing and Analysis_.

              98–104.


              - Chaliasos et al. (2024)↑

              Stefanos Chaliasos, Jens

              Ernstberger, David Theodore, David Wong,

              Mohammad Jahanara, and Benjamin

              Livshits. 2024.


              {\\{SoK}\\}: What Don’t We Know? Understanding

              Security Vulnerabilities in {\\{SNARKs}\\}. In

              _33rd USENIX Security Symposium (USENIX Security_

              _24)_. 3855–3872.


              - Chen et al. (2023)↑

              Binyi Chen, Benedikt

              Bünz, Dan Boneh, and Zhenfei

              Zhang. 2023.


              HyperPlonk: Plonk with Linear-Time Prover and

              High-Degree Custom Gates. In _Advances in_

              _Cryptology - EUROCRYPT 2023: 42nd Annual International Conference on
              the_

              _Theory and Applications of Cryptographic Techniques, Lyon, France,
              April_

              _23–27, 2023, Proceedings, Part II_ (Lyon, France).

              Springer-Verlag, Berlin, Heidelberg,

              499–530.


              [doi:10.1007/978-3-031-30617-4\_17](https://doi.org/10.1007/978-3-031-30617-4_17
              "")

              - Chen et al. (2021)↑

              Mark Chen, Jerry Tworek,

              Heewoo Jun, Qiming Yuan,

              Henrique Ponde De Oliveira Pinto, Jared

              Kaplan, Harri Edwards, Yuri Burda,

              Nicholas Joseph, Greg Brockman,

              et al. 2021.


              Evaluating large language models trained on code.


              _arXiv preprint arXiv:2107.03374_

              (2021).


              - Chin et al. (2021)↑

              Collin Chin, Howard Wu,

              Raymond Chu, Alessandro Coglio,

              Eric McCarthy, and Eric Smith.

              2021.


              Leo: A programming language for formally verified,

              zero-knowledge applications.


              _Cryptology ePrint Archive_

              (2021).


              - Clark et al. (2018)↑

              Peter Clark, Isaac

              Cowhey, Oren Etzioni, Tushar Khot,

              Ashish Sabharwal, Carissa Schoenick,

              and Oyvind Tafjord. 2018.


              Think you have solved question answering? try arc,

              the ai2 reasoning challenge.


              _arXiv preprint arXiv:1803.05457_

              (2018).


              - Contributors (\[n. d.\])↑

              Noir Contributors.

              \[n. d.\].


              Noir Examples.


              [https://github.com/noir-lang/noir-examples](https://github.com/noir-lang/noir-examples
              "").


              Accessed: 2025-08.


              - Contributors (2025a)↑

              Nexus Contributors.

              2025a.


              Nexus zkVM: A Zero-Knowledge Virtual Machine.


              [https://nexus.xyz/zkvm](https://nexus.xyz/zkvm "").


              - Contributors (2025b)↑

              RISC Zero Contributors.

              2025b.


              RISC Zero: Universal Zero Knowledge.


              [https://risczero.com/](https://risczero.com/ "").


              - Contributors (2025c)↑

              Zokrates Contributors.

              2025c.


              ZoKrates: A toolbox for zkSNARKs.


              [https://zokrates.github.io/](https://zokrates.github.io/ "").


              - Councilman et al. (2025)↑

              Aaron Councilman, David

              Fu, Aryan Gupta, Chengxiao Wang,

              David Grove, Yu-Xiong Wang, and

              Vikram Adve. 2025.


              Towards Formal Verification of LLM-Generated Code

              from Natural Language Prompts.


              _arXiv preprint arXiv:2507.13290_

              (2025).


              - Dahlgren (2022)↑

              Fredrick Dahlgren.

              2022.


              It pays to be Circomspect.


              [https://blog.trailofbits.com/2022/09/15/it-pays-to-be-circomspect/](https://blog.trailofbits.com/2022/09/15/it-pays-to-be-circomspect/
              "").


              - De Moura and Bjørner (2008)↑

              Leonardo De Moura and

              Nikolaj Bjørner. 2008.


              Z3: An efficient SMT solver. In

              _International conference on Tools and Algorithms_

              _for the Construction and Analysis of Systems_. Springer,

              337–340.


              - Deng et al. (2024)↑

              Xun Deng, Sicheng Zhong,

              Honghua Dong, Jingyu Hu,

              Sidi Mohamed Beillahi, Xujie Si, and

              Fan Long. 2024.


              Assessing code generation with intermediate

              languages.


              _arXiv preprint arXiv:2407.05411_

              (2024).


              - Dong et al. (2025)↑

              Yihong Dong, Xue Jiang,

              Jiaru Qian, Tian Wang,

              Kechi Zhang, Zhi Jin, and

              Ge Li. 2025.


              A Survey on Code Generation with LLM-based Agents.


              _arXiv preprint arXiv:2508.00083_

              (2025).


              - Gabizon et al. (2019)↑

              Ariel Gabizon, Zachary J.

              Williamson, and Oana-Madalina Ciobotaru.

              2019.


              PLONK: Permutations over Lagrange-bases for

              Oecumenical Noninteractive arguments of Knowledge.


              _IACR Cryptol. ePrint Arch._

              2019 (2019), 953.


              [https://api.semanticscholar.org/CorpusID:201685538](https://api.semanticscholar.org/CorpusID:201685538
              "")

              - Gao et al. (2023)↑

              Yunfan Gao, Yun Xiong,

              Xinyu Gao, Kangxiang Jia,

              Jinliu Pan, Yuxi Bi,

              Yixin Dai, Jiawei Sun,

              Haofen Wang, and Haofen Wang.

              2023.


              Retrieval-augmented generation for large language

              models: A survey.


              _arXiv preprint arXiv:2312.10997_

              2, 1 (2023).


              - Giagnorio et al. (2025)↑

              Alessandro Giagnorio,

              Alberto Martin-Lopez, and Gabriele

              Bavota. 2025.


              Enhancing code generation for low-resource

              languages: No silver bullet.


              _arXiv preprint arXiv:2501.19085_

              (2025).


              - GitHub (2025)↑

              GitHub. 2025.


              GitHub Copilot.


              [https://github.com/features/copilot](https://github.com/features/copilot
              "").


              - Grassi et al. (2021)↑

              Lorenzo Grassi, Dmitry

              Khovratovich, Christian Rechberger, Arnab

              Roy, and Markus Schofnegger.

              2021.


              Poseidon: A new hash function for

              {\\{Zero-Knowledge}\\} proof systems. In _30th_

              _USENIX Security Symposium (USENIX Security 21)_. 519–535.


              - Gupta (2025)↑

              Sandeep Gupta.

              2025.


              Zero-Knowledge Proofs for Privacy-Preserving

              Systems: A Survey Across Blockchain, Identity, and Beyond.


              _Engineering and Technology Journal_

              10, 07 (July

              2025), 5755–5761.


              [doi:10.47191/etj/v10i07.23](https://doi.org/10.47191/etj/v10i07.23
              "")

              - Hendrycks et al. (2020)↑

              Dan Hendrycks, Collin

              Burns, Steven Basart, Andy Zou,

              Mantas Mazeika, Dawn Song, and

              Jacob Steinhardt. 2020.


              Measuring massive multitask language

              understanding.


              _arXiv preprint arXiv:2009.03300_

              (2020).


              - Hochrainer et al. (2024)↑

              Christoph Hochrainer,

              Anastasia Isychev, Valentin Wüstholz,

              and Maria Christakis. 2024.


              Fuzzing Processing Pipelines for Zero-Knowledge

              Circuits.


              _arXiv preprint arXiv:2411.02077_

              (2024).


              - iden3 (2025)↑

              iden3. 2025.


              circomlib: Standard Library for the Circom Language.


              [https://github.com/iden3/circomlib](https://github.com/iden3/circomlib
              "").


              Accessed: 2025-08-27.


              - Jain et al. (2024)↑

              Naman Jain, King Han,

              Alex Gu, Wen-Ding Li,

              Fanjia Yan, Tianjun Zhang,

              Sida Wang, Armando Solar-Lezama,

              Koushik Sen, and Ion Stoica.

              2024.


              Livecodebench: Holistic and contamination free

              evaluation of large language models for code.


              _arXiv preprint arXiv:2403.07974_

              (2024).


              - Ji et al. (2025)↑

              Zimo Ji, Daoyuan Wu,

              Wenyuan Jiang, Pingchuan Ma,

              Zongjie Li, and Shuai Wang.

              2025.


              Measuring and Augmenting Large Language Models for

              Solving Capture-the-Flag Challenges.


              _arXiv preprint arXiv:2506.17644_

              (2025).


              - Jiang et al. (2025a)↑

              Jinan Jiang, Xinghao

              Peng, Jinzhao Chu, and Xiapu Luo.

              2025a.


              ConsCS: Effective and Efficient Verification of

              Circom Circuits. In _2025 IEEE/ACM 47th_

              _International Conference on Software Engineering (ICSE)_. IEEE Computer

              Society, 737–737.


              - Jiang et al. (2024b)↑

              Juyong Jiang, Fan Wang,

              Jiasi Shen, Sungju Kim, and

              Sunghun Kim. 2024b.


              A survey on large language models for code

              generation.


              _arXiv preprint arXiv:2406.00515_

              (2024).


              - Jiang et al. (2025b)↑

              Juyong Jiang, Fan Wang,

              Jiasi Shen, Sungju Kim, and

              Sunghun Kim. 2025b.


              A Survey on Large Language Models for Code

              Generation.


              _ACM Trans. Softw. Eng. Methodol._

              (July 2025).


              [doi:10.1145/3747588](https://doi.org/10.1145/3747588 "")Just Accepted.


              - Jiang et al. (2024a)↑

              Xue Jiang, Yihong Dong,

              Lecheng Wang, Zheng Fang,

              Qiwei Shang, Ge Li, Zhi

              Jin, and Wenpin Jiao. 2024a.


              Self-Planning Code Generation with Large Language

              Models.


              _ACM Trans. Softw. Eng. Methodol._

              33, 7, Article 182

              (Sept. 2024), 30 pages.


              [doi:10.1145/3672456](https://doi.org/10.1145/3672456 "")

              - Joel et al. (2024)↑

              Sathvik Joel, Jie JW Wu,

              and Fatemeh H Fard. 2024.


              A survey on llm-based code generation for

              low-resource and domain-specific programming languages.


              _arXiv preprint arXiv:2410.03981_

              (2024).


              - Labs (2025)↑

              Succinct Labs.

              2025.


              SP1: A Rust-based framework for zero-knowledge

              proofs.


              [https://github.com/succinctlabs/sp1](https://github.com/succinctlabs/sp1
              "").


              - Lavin et al. (2024)↑

              Ryan Lavin, Xuekai Liu,

              Hardhik Mohanty, Logan Norman,

              Giovanni Zaarour, and Bhaskar

              Krishnamachari. 2024.


              A survey on the applications of zero-knowledge

              proofs.


              _arXiv preprint arXiv:2408.00243_

              (2024).


              - Li et al. (2023)↑

              Jia Li, Ge Li,

              Yongmin Li, and Zhi Jin.

              2023.


              Structured Chain-of-Thought Prompting for Code

              Generation.


              arXiv:2305.06599 \[cs.SE\]


              [https://arxiv.org/abs/2305.06599](https://arxiv.org/abs/2305.06599
              "")

              - Liu et al. (2020)↑

              Bang Liu, Haojie Wei,

              Di Niu, Haolan Chen, and

              Yancheng He. 2020.


              Asking questions the human way: Scalable

              question-answer generation from text corpus. In

              _Proceedings of the web conference 2020_.

              2032–2043.


              - Liu et al. (2025)↑

              Kaiyuan Liu, Youcheng

              Pan, Yang Xiang, Daojing He,

              Jing Li, Yexing Du, and

              Tianrun Gao. 2025.


              ProjectEval: A Benchmark for Programming Agents

              Automated Evaluation on Project-Level Code Generation.


              _arXiv preprint arXiv:2503.07010_

              (2025).


              - Liu et al. (2023)↑

              Mingjie Liu, Nathaniel

              Pinckney, Brucek Khailany, and Haoxing

              Ren. 2023.


              Verilogeval: Evaluating large language models for

              verilog code generation. In _2023 IEEE/ACM_

              _International Conference on Computer Aided Design (ICCAD)_. IEEE,

              1–8.


              - Long et al. (2024)↑

              Lin Long, Rui Wang,

              Ruixuan Xiao, Junbo Zhao,

              Xiao Ding, Gang Chen, and

              Haobo Wang. 2024.


              On llms-driven synthetic data generation, curation,

              and evaluation: A survey.


              _arXiv preprint arXiv:2406.15126_

              (2024).


              - Myrzakhan et al. (2024)↑

              Aidar Myrzakhan,

              Sondos Mahmoud Bsharat, and Zhiqiang

              Shen. 2024.


              Open-llm-leaderboard: From multi-choice to

              open-style questions for llms evaluation, benchmark, and arena.


              _arXiv preprint arXiv:2406.07545_

              (2024).


              - Nico Serrano (\[n. d.\])↑

              Vivian Plasencia Nico Serrano.

              \[n. d.\].


              ZK-Kit: A monorepo of reusable libraries for

              zero-knowledge technologies.


              [https://github.com/zk-kit/zk-kit](https://github.com/zk-kit/zk-kit
              "").


              Accessed: 2025-08.


              - Ozdemir et al. (2022)↑

              Alex Ozdemir, Fraser

              Brown, and Riad S Wahby.

              2022.


              CirC: Compiler infrastructure for proof systems,

              software verification, and more. In _2022 IEEE_

              _Symposium on Security and Privacy (SP)_. IEEE, 2248–2266.


              - Pailoor et al. (2023)↑

              Shankara Pailoor, Yanju

              Chen, Franklyn Wang, Clara

              Rodríguez, Jacob Van Geffen, Jason

              Morton, Michael Chu, Brian Gu,

              Yu Feng, and Işıl Dillig.

              2023.


              Automated detection of under-constrained circuits

              in zero-knowledge proofs.


              _Proceedings of the ACM on Programming_

              _Languages_ 7, PLDI

              (2023), 1510–1532.


              - Pan et al. (2025)↑

              Ruwei Pan, Hongyu Zhang,

              and Chao Liu. 2025.


              CodeCoR: An LLM-based self-reflective multi-agent

              framework for code generation.


              _arXiv preprint arXiv:2501.07811_

              (2025).


              - Pimparkhede et al. (2024)↑

              Sameer Pimparkhede, Mehant

              Kammakomati, Srikanth Tamilselvam, Prince

              Kumar, Ashok Pon Kumar, and Pushpak

              Bhattacharyya. 2024.


              DocCGen: Document-based Controlled Code Generation.


              arXiv:2406.11925 \[cs.SE\]


              [https://arxiv.org/abs/2406.11925](https://arxiv.org/abs/2406.11925
              "")

              - Research (2021)↑

              Google Research.

              2021.


              MBPP: Mostly Basic Python Problems Dataset.


              [https://github.com/google-research/google-research/tree/master/mbpp](https://github.com/google-research/google-research/tree/master/mbpp
              "").


              Accessed: 2025-08.


              - Research (\[n. d.\])↑

              Microsoft Research.

              \[n. d.\].


              Z3 API in Python.


              [https://ericpony.github.io/z3py-tutorial/guide-examples.htm](https://ericpony.github.io/z3py-tutorial/guide-examples.htm
              "").


              Accessed: 2025-08.


              - Sheybani et al. (2025)↑

              Nojan Sheybani, Anees

              Ahmed, Michel Kinsy, and Farinaz

              Koushanfar. 2025.


              Zero-Knowledge Proof Frameworks: A Systematic

              Survey.


              arXiv:2502.07063 \[cs.CR\]


              [https://arxiv.org/abs/2502.07063](https://arxiv.org/abs/2502.07063
              "")

              - Siddiq et al. (2023)↑

              Mohammed Latif Siddiq,

              Joanna Santos, Ridwanul Hasan Tanvir,

              Noshin Ulfat, Fahmid Al Rifat, and

              V Carvalho Lopes. 2023.


              Exploring the effectiveness of large language

              models in generating unit tests.


              _arXiv preprint arXiv:2305.00418_

              1, 3 (2023).


              - Sirin (\[n. d.\])↑

              P. D. Sirin.

              \[n. d.\].


              Circom Example.


              [https://github.com/pisuthd/circom-example](https://github.com/pisuthd/circom-example
              "").


              Accessed: 2025-08.


              - Skreta et al. (2023)↑

              Marta Skreta, Naruki

              Yoshikawa, Sebastian Arellano-Rubach, Zhi

              Ji, Lasse Bjørn Kristensen, Kourosh

              Darvish, Alán Aspuru-Guzik, Florian

              Shkurti, and Animesh Garg.

              2023.


              Errors are useful prompts: Instruction guided task

              programming with verifier-assisted iterative prompting.


              _arXiv preprint arXiv:2303.14100_

              (2023).


              - Soureshjani et al. (2023)↑

              Fatemeh Heidari Soureshjani,

              Mathias Hall-Andersen, MohammadMahdi

              Jahanara, Jeffrey Kam, Jan Gorzny, and

              Mohsen Ahmadvand. 2023.


              Automated analysis of halo2 circuits.


              _Cryptology ePrint Archive_

              (2023).


              - Stronati et al. (2024)↑

              Marco Stronati, Denis

              Firsov, Antonio Locascio, and Benjamin

              Livshits. 2024.


              Clap: a Semantic-Preserving Optimizing eDSL for

              Plonkish Proof Systems.


              _arXiv preprint arXiv:2405.12115_

              (2024).


              - Takahashi et al. (2025)↑

              Hideaki Takahashi, Jihwan

              Kim, Suman Jana, and Junfeng Yang.

              2025.


              zkFuzz: Foundation and Framework for Effective

              Fuzzing of Zero-Knowledge Circuits.


              _arXiv preprint arXiv:2504.11961_

              (2025).


              - team (2025)↑

              Cursor team.

              2025.


              Cursor.


              [https://cursor.com](https://cursor.com/ "").


              - team (2024)↑

              Tangem team.

              2024.


              Zero-Knowledge Proofs in Blockchain: Beyond Privacy

              to Scalability and Security.


              [https://tangem.com/en/blog/post/zero-knowledge-proofs-in-blockchain-beyond-privacy-to-scalability-and-security/](https://tangem.com/en/blog/post/zero-knowledge-proofs-in-blockchain-beyond-privacy-to-scalability-and-security/
              "")

              - TEZCAN (2025a)↑

              ERHAN TEZCAN.

              2025a.


              Circom 101.


              [https://circom.erhant.me/](https://circom.erhant.me/ "").


              Accessed: 2025-08.


              - TEZCAN (2025b)↑

              ERHAN TEZCAN.

              2025b.


              Circomkit Examples.


              [https://github.com/erhant/circomkit-examples/](https://github.com/erhant/circomkit-examples/
              "").


              Accessed: 2025-08.


              - Thomas (2022)↑

              Morgan Thomas.

              2022.


              Orbis specification language: a type theory for

              zk-SNARK programming.


              _Cryptology ePrint Archive_

              (2022).


              - Thor (\[n. d.\])↑

              Thor. \[n. d.\].


              Circuit Examples.


              [https://github.com/thor314/circuit-examples](https://github.com/thor314/circuit-examples
              "").


              Accessed: 2025-08.


              - Wang et al. (2023)↑

              Bailin Wang, Zi Wang,

              Xuezhi Wang, Yuan Cao,

              Rif A Saurous, and Yoon Kim.

              2023.


              Grammar prompting for domain-specific language

              generation with large language models.


              _Advances in Neural Information Processing_

              _Systems_ 36 (2023),

              65030–65055.


              - Wang et al. (2024)↑

              Evan Wang, Federico

              Cassano, Catherine Wu, Yunfeng Bai,

              Will Song, Vaskar Nath,

              Ziwen Han, Sean Hendryx,

              Summer Yue, and Hugh Zhang.

              2024.


              Planning in natural language improves llm search

              for code generation.


              _arXiv preprint arXiv:2409.03733_

              (2024).


              - Wang et al. (2022a)↑

              Shiqi Wang, Zheng Li,

              Haifeng Qian, Chenghao Yang,

              Zijian Wang, Mingyue Shang,

              Varun Kumar, Samson Tan,

              Baishakhi Ray, Parminder Bhatia,

              et al. 2022a.


              ReCode: Robustness evaluation of code generation

              models.


              _arXiv preprint arXiv:2212.10264_

              (2022).


              - Wang et al. (2022b)↑

              Xin Wang, Yasheng Wang,

              Yao Wan, Fei Mi, Yitong

              Li, Pingyi Zhou, Jin Liu,

              Hao Wu, Xin Jiang, and

              Qun Liu. 2022b.


              Compilable Neural Code Generation with Compiler

              Feedback.


              arXiv:2203.05132 \[cs.CL\]


              [https://arxiv.org/abs/2203.05132](https://arxiv.org/abs/2203.05132
              "")

              - Wang et al. (2025)↑

              Yanlin Wang, Wanjun

              Zhong, Yanxian Huang, Ensheng Shi,

              Min Yang, Jiachi Chen,

              Hui Li, Yuchi Ma,

              Qianxiang Wang, and Zibin Zheng.

              2025.


              Agents in software engineering: Survey, landscape,

              and vision.


              _Automated Software Engineering_

              32, 2 (2025),

              1–36.


              - Wen et al. (2024b)↑

              Hongbo Wen, Jon Stephens,

              Yanju Chen, Kostas Ferles,

              Shankara Pailoor, Kyle Charbonnet,

              Isil Dillig, and Yu Feng.

              2024b.


              Practical Security Analysis of

              {\\{Zero-Knowledge}\\} Proof Circuits. In _33rd_

              _USENIX Security Symposium (USENIX Security 24)_.

              1471–1487.


              - Wen et al. (2024a)↑

              Jiaxin Wen, Jian Guan,

              Hongning Wang, Wei Wu, and

              Minlie Huang. 2024a.


              Unlocking reasoning potential in large langauge

              models by scaling code-form planning.


              _arXiv preprint arXiv:2409.12452_

              (2024).


              - Xiao et al. (2025)↑

              Dongwei Xiao, Zhibo Liu,

              Yiteng Peng, and Shuai Wang.

              2025.


              Mtzk: Testing and exploring bugs in zero-knowledge

              (zk) compilers. In _NDSS_.


              - Xu et al. (2025)↑

              Pei Xu, Yulei Sui, and

              Mark Staples. 2025.


              Towards Source Mapping for Zero-Knowledge Smart

              Contracts: Design and Preliminary Evaluation. In

              _Proceedings of the 34th ACM SIGSOFT International_

              _Symposium on Software Testing and Analysis_. 200–209.


              - Yang et al. (2023)↑

              John Yang, Akshara

              Prabhakar, Karthik Narasimhan, and

              Shunyu Yao. 2023.


              InterCode: standardizing and benchmarking

              interactive coding with execution feedback. In

              _Proceedings of the 37th International Conference on_

              _Neural Information Processing Systems_ (New Orleans, LA, USA)

              _(NIPS ’23)_. Curran Associates

              Inc., Red Hook, NY, USA, Article

              1035, 29 pages.


              - Yuan et al. (2023)↑

              Zhiqiang Yuan, Yiling

              Lou, Mingwei Liu, Shiji Ding,

              Kaixin Wang, Yixuan Chen, and

              Xin Peng. 2023.


              No more manual tests? evaluating and improving

              chatgpt for unit test generation.


              _arXiv preprint arXiv:2305.04207_

              (2023).


              - Zellers et al. (2019)↑

              Rowan Zellers, Ari

              Holtzman, Yonatan Bisk, Ali Farhadi,

              and Yejin Choi. 2019.


              Hellaswag: Can a machine really finish your

              sentence?


              _arXiv preprint arXiv:1905.07830_

              (2019).


              - Zhang et al. (2024a)↑

              Kechi Zhang, Jia Li,

              Ge Li, Xianjie Shi, and

              Zhi Jin. 2024a.


              CodeAgent: Enhancing Code Generation with

              Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges.

              In _Proceedings of the 62nd Annual Meeting of the_

              _Association for Computational Linguistics (Volume 1: Long Papers)_.

              13643–13658.


              - Zhang et al. (2024b)↑

              Shudan Zhang, Hanlin

              Zhao, Xiao Liu, Qinkai Zheng,

              Zehan Qi, Xiaotao Gu,

              Xiaohan Zhang, Yuxiao Dong, and

              Jie Tang. 2024b.


              Naturalcodebench: Examining coding performance

              mismatch on humaneval and natural user prompts.


              _arXiv preprint arXiv:2405.04520_

              (2024).



              ## Appendix A Illustrative Workflow Example


              Report issue for preceding element


              We demonstrate the workflow using ZK-Coder to generate a ZKP program

              that can be used to prove the correctness of a Sudoku assignment in

              Fig. [13](https://arxiv.org/html/2509.11708v1#A1.F13 "Figure 13 ‣ Appendix
              A Illustrative Workflow Example ‣ From Evaluation to Enhancement: Large
              Language Models for Zero-Knowledge Proof Code Generation"). Given a
              4×44\\times 4 Sudoku grid, the

              goal is to verify that each row, column, and 2×22\\times 2 block contains
              all

              digits 11–44 exactly once.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x12.png)Figure
              13. ZK-Coder’s Illustrative Example Workflow on Proving Sudoku Correctness.Report
              issue for preceding element


              In this illustrative workflow example, ZK-Coder first reads the problem

              description and formulates it in ZKSL, encoding the necessary constraints
              on the

              Sudoku grid. The checker validates the sketch and analyzes it to extract
              the set

              of constraint gadgets required. For each gadget, relevant implementation
              hints

              are retrieved, and an initial Circom implementation is generated. The
              compiler

              then checks this program for syntactic validity, returning diagnostics
              that

              guide interactive refinement. Once the code compiles, the model is prompted
              to

              generate a small test instance. If the resulting prover behavior deviates
              from

              expectations, the model is asked to repair the program. This repair
              loop

              continues until either the program passes the LLM-supplied tests or
              the retry

              budget is exhausted.


              Report issue for preceding element


              We also present two concrete program examples generated by ZK-Coder
              for

              this Sudoku problem, one in Circom

              (Fig. [14](https://arxiv.org/html/2509.11708v1#A1.F14 "Figure 14 ‣ Appendix
              A Illustrative Workflow Example ‣ From Evaluation to Enhancement: Large
              Language Models for Zero-Knowledge Proof Code Generation")) and one
              in Noir

              (Fig. [15](https://arxiv.org/html/2509.11708v1#A1.F15 "Figure 15 ‣ Appendix
              A Illustrative Workflow Example ‣ From Evaluation to Enhancement: Large
              Language Models for Zero-Knowledge Proof Code Generation")). Both programs
              implement the

              same verification logic. We annotated the source code with comments
              to point out

              key sections, such as input signal declarations, gadget imports or

              implementations, and composing gadgets with field arithmetic operations
              to

              implement the constraints outlined in the ZKSL sketch.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x13.png)Figure
              14. Example Circom Program Generated by ZK-Coder.Report issue for preceding
              element![Refer to caption](https://arxiv.org/html/2509.11708v1/x14.png)Figure
              15. Example Noir Program Generated by ZK-Coder.Report issue for preceding
              element


              ## Appendix B Filtered Tasks in Dataset Curation


              Report issue for preceding element


              As introduced in the main paper, our dataset construction is based on
              adapting

              existing programming tasks from HumanEval (Chen et al., [2021](https://arxiv.org/html/2509.11708v1#bib.bib13
              "")) and

              LiveCodeBench (Jain et al., [2024](https://arxiv.org/html/2509.11708v1#bib.bib34
              "")). To ensure that tasks are suitable

              for ZK DSLs (no floating-point numbers, no string manipulation, no I/O,

              deterministic output length, etc.), we filter the tasks using a combination
              of

              LLM assisted filtering and manual inspection. We now present the complete
              set of

              filtered tasks in Table [6](https://arxiv.org/html/2509.11708v1#A2.T6
              "Table 6 ‣ Appendix B Filtered Tasks in Dataset Curation ‣ From Evaluation
              to Enhancement: Large Language Models for Zero-Knowledge Proof Code
              Generation") and

              Table [7](https://arxiv.org/html/2509.11708v1#A2.T7 "Table 7 ‣ Appendix
              B Filtered Tasks in Dataset Curation ‣ From Evaluation to Enhancement:
              Large Language Models for Zero-Knowledge Proof Code Generation").


              Report issue for preceding element


              Table 6. Filtered tasks from HumanEval.


              |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |

              | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
              --- | --- | --- | --- | --- | --- |

              | Filtered Task IDs from HumanEval (Total 68 Tasks) |

              | 3 | 5 | 8 | 9 | 13 | 24 | 31 | 33 | 35 | 36 | 37 | 39 | 40 | 41 |
              42 | 43 | 46 |

              | 49 | 52 | 53 | 55 | 57 | 59 | 60 | 62 | 63 | 65 | 69 | 70 | 72 | 73
              | 75 | 76 | 77 |

              | 83 | 85 | 88 | 90 | 94 | 97 | 102 | 106 | 108 | 109 | 110 | 114 |
              115 | 116 | 121 | 122 | 123 |

              | 126 | 127 | 128 | 131 | 135 | 138 | 139 | 142 | 145 | 146 | 147 |
              150 | 151 | 152 | 155 | 157 | 159 |


              Report issue for preceding elementTable 7. Filtered tasks from LiveCodeBench.


              |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |     |

              | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
              --- | --- | --- | --- | --- | --- |

              | Filtered Task IDs from LiveCodeBench (Total 34 Tasks) |

              | 43 | 44 | 62 | 66 | 78 | 94 | 119 | 124 | 129 | 153 | 156 | 172 |
              203 | 225 | 232 | 240 | 243 |

              | 250 | 261 | 265 | 280 | 290 | 297 | 305 | 322 | 323 | 336 | 346 |
              353 | 367 | 373 | 375 | 384 | 389 |


              Report issue for preceding element


              ## Appendix C Supplementary Results


              Report issue for preceding element


              In this section, we present supplementary results that complement the
              main

              findings of the paper but were omitted earlier due to space limitations.


              Report issue for preceding element


              ### C.1. Error Distribution For Gadget Implementation


              Report issue for preceding element


              Previously, we reported the error distribution averaged across four
              models.

              Here, we provide the per-model error distributions. The breakdown by
              individual

              model is consistent with the overall trend: OpenAI’s reasoning models
              outperform

              open-source models, and the most common error types remain consistent
              across

              models.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x15.png)Figure
              16. Error Distribution on GPT-o4-mini.Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x16.png)


              Figure 17. Error Distribution on GPT-o3.Report issue for preceding element


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x17.png)Figure
              18. Error Distribution on DeepSeek-V3.Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2509.11708v1/x18.png)


              Figure 19. Error Distribution on Qwen3.Report issue for preceding element


              Report issue for preceding element


              ## Appendix D Complete Set of Constraint Gadgets


              Report issue for preceding element


              The constraint gadgets used in the main paper during both measurement
              and

              augmentation. In measurement, they serve as the targets for evaluating
              LLMs’

              ability to correctly employ or implement gadgets when expressing constraints.
              In

              augmentation, they are treated as primitive operators in the sketch
              language,

              and in constraint-guided retrieval we prepared knowledge snippets for
              each

              gadget to assist LLMs in code generation.


              Report issue for preceding element


              The collection of gadgets is consolidated from three sources: (i) the
              official

              Circom standard library (iden3, [2025](https://arxiv.org/html/2509.11708v1#bib.bib33
              "")), (ii) the ZK-kit

              library (Nico Serrano, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib49
              "")), and (iii) the Z3Py API (Research, [\[n. d.\]](https://arxiv.org/html/2509.11708v1#bib.bib55
              "")). The complete list

              is shown in Table [8](https://arxiv.org/html/2509.11708v1#A4.T8 "Table
              8 ‣ Appendix D Complete Set of Constraint Gadgets ‣ From Evaluation
              to Enhancement: Large Language Models for Zero-Knowledge Proof Code
              Generation"). We classify gadgets into five

              categories: Logical, Bitwise, Comparison, Arithmetic, and Composite,
              according

              to their functionality. The typing column specifies input and output
              types,

              which are used to disambiguate operators during constraint-guided retrieval.

              While this set is not exhaustive, it spans a wide range of common constraints
              in

              ZK programming. We expect to extend it with additional gadgets in future
              work.


              Report issue for preceding element


              Table 8. List of constraint gadgets used in measurement and augmentation.


              | Name | Category | Typing | Source |

              | --- | --- | --- | --- |

              | And | Logical | Bool ×\\times Bool →\\rightarrow Bool | Circomlib,
              Z3Py |

              | And∗ | Logical | Bool ×…×\\times\\ldots\\times Bool →\\rightarrow
              Bool | Circomlib, Z3Py |

              | Or | Logical | Bool ×\\times Bool →\\rightarrow Bool | Circomlib,
              Z3Py |

              | Or∗ | Logical | Bool ×…×\\times\\ldots\\times Bool →\\rightarrow Bool
              | Circomlib,Z3Py |

              | XOr | Logical | Bool ×\\times Bool →\\rightarrow Bool | Circomlib,
              Z3Py |

              | XOr∗ | Logical | Bool ×…×\\times\\ldots\\times Bool →\\rightarrow
              Bool | Circomlib, Z3Py |

              | Not | Logical | Bool →\\rightarrow Bool | Circomlib, Z3Py |

              | Or⋄ | Bitwise | Field ×\\times Field →\\rightarrow Field | Z3Py |

              | Or⋄∗ | Bitwise | Field ×…×\\times\\ldots\\times Field →\\rightarrow
              Field | Z3Py |

              | And⋄ | Bitwise | Field ×\\times Field →\\rightarrow Field | Z3Py |

              | And⋄∗ | Bitwise | Field ×…×\\times\\ldots\\times Field →\\rightarrow
              Field | Z3Py |

              | XOr⋄ | Bitwise | Field ×\\times Field →\\rightarrow Field | Z3Py |

              | XOr⋄∗ | Bitwise | Field ×…×\\times\\ldots\\times Field →\\rightarrow
              Field | Z3Py |

              | Equal | Comparison | Field ×\\times Field →\\rightarrow Bool | Circomlib,
              ZK-Kit, Z3Py |

              | NotEqual | Comparison | Field ×\\times Field →\\rightarrow Bool |
              Circomlib, ZK-Kit, Z3Py |

              | LessThan | Comparison | Field ×\\times Field →\\rightarrow Bool |
              Circomlib, ZK-Kit, Z3Py |

              | LessThanOrEqual | Comparison | Field ×\\times Field →\\rightarrow
              Bool | Circomlib, ZK-Kit, Z3Py |

              | GreaterThan | Comparison | Field ×\\times Field →\\rightarrow Bool
              | Circomlib, ZK-Kit, Z3Py |

              | GreaterThanOrEqual | Comparison | Field ×\\times Field →\\rightarrow
              Bool | Circomlib, ZK-Kit, Z3Py |

              | Add | Arithmetic | Field ×\\times Field →\\rightarrow Field | Z3Py
              |

              | Subtract | Arithmetic | Field ×\\times Field →\\rightarrow Field |
              Z3Py |

              | Multiply | Arithmetic | Field ×\\times Field →\\rightarrow Field |
              Z3Py |

              | Divide | Arithmetic | Field ×\\times Field →\\rightarrow Field | Z3Py
              |

              | Modulo | Arithmetic | Field ×\\times Field →\\rightarrow Field | ZK-Kit,
              Z3Py |

              | Power | Arithmetic | Field ×\\times Field →\\rightarrow Field | Z3Py
              |

              | FloorDivide | Arithmetic | Field ×\\times Field →\\rightarrow Field
              | ZK-Kit, Z3Py |

              | Negate | Arithmetic | Field →\\rightarrow Field | Circomlib, Z3Py
              |

              | Absolute | Arithmetic | Field →\\rightarrow Field | Circomlib, Z3Py
              |

              | Inverse | Arithmetic | Field →\\rightarrow Field | Circomlib, Z3Py
              |

              | Sign | Arithmetic | Field →\\rightarrow Field | Circomlib, Z3Py |

              | Conditional | Composite | Bool ×\\times Field ×\\times Field →\\rightarrow
              Field | Circomlib, Z3Py |

              | Conditional⋄ | Composite | Bool ×\\times Bool ×\\times Bool →\\rightarrow
              Bool | Circomlib, Z3Py |

              | Sum∗ | Composite | Field ×…×\\times\\ldots\\times Field →\\rightarrow
              Field | Z3Py |

              | Product∗ | Composite | Field ×…×\\times\\ldots\\times Field →\\rightarrow
              Field | Z3Py |

              | Distinct∗ | Composite | Field ×…×\\times\\ldots\\times Field →\\rightarrow
              Field | Z3Py |


              Report issue for preceding element


              Report IssueReport Issue for Selection


              Generated by

              [L\\

              A\\

              T\\

              Exml![[LOGO]](<Base64-Image-Removed>)](https://math.nist.gov/~BMiller/LaTeXML/)'
            metadata:
              keywords: Zero-Knowledge Proofs,  Large Language Models,  Code Generation
              title: 'From Evaluation to Enhancement: Large Language Models for Zero-Knowledge
                Proof Code Generation'
              favicon: https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png
              language: en
              viewport: width=device-width, initial-scale=1, shrink-to-fit=no
              scrapeId: ac3641b8-724f-4535-879e-42a04c111d07
              sourceURL: https://arxiv.org/html/2509.11708v1
              url: https://arxiv.org/html/2509.11708v1
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
          - title: 'Zero-Knowledge Proofs: A Beginner''s Guide - Dock Labs'
            description: Zero-Knowledge Proofs are a technology in online security
              that enables the verification of information without revealing the information
              itself.
            url: https://www.dock.io/post/zero-knowledge-proofs
            markdown: 'By clicking "Accept", you agree to the storing of cookies on
              your device to enhance site navigation, analyze site usage and assist
              in our marketing efforts. [More info](https://www.dock.io/cookies)


              [Deny](https://www.dock.io/post/zero-knowledge-proofs#) [Accept](https://www.dock.io/post/zero-knowledge-proofs#)


              [![dock logo](https://cdn.prod.website-files.com/5e97941735e37a5ef19d10aa/675f9b97d3c4e451855d83fb_logo-by-docklabs-light.svg)](https://www.dock.io/)


              [Log in](https://certs.dock.io/) [Try free](https://certs.dock.io/)


              Ready to get started?


              [Sign up to Truvera](https://truvera.io/) [Request Free Consultation](https://www.dock.io/request-free-consultation)


              ### Company


              - [About us](https://www.dock.io/verifiable-credentials-company)

              - [Pricing](https://www.dock.io/pricing)

              - [Contact us](https://www.dock.io/contact)


              ### Truvera Platform


              - [Issue verifiable credentials](https://www.dock.io/feature/issue-verifiable-credentials)

              - [Instant verification](https://www.dock.io/feature/instantly-verify-credentials)

              - [ID wallet](https://www.dock.io/feature/identity-wallet)

              - [Digital ID Ecosystem](https://www.dock.io/digital-identity-ecosystem)

              - [Automated paid verification](https://www.dock.io/paid-credential-verification)

              - [Blockchain](https://www.dock.io/post/zero-knowledge-proofs#)

              - [Zero-knowledge proofs](https://www.dock.io/feature/zero-knowledge-proofs)

              - [Interoperability](https://www.dock.io/feature/interoperable)


              ### Developers


              - [Documentation](https://docs.dock.io/)

              - [Github](https://github.com/docknetwork)

              - [Mobile Wallet SDK](https://github.com/docknetwork/react-native-sdk)

              - [Status](https://dockstatus.io/)


              ### Industries


              - [KYC / IDV](https://www.dock.io/industries/kyc-and-idv)

              - [IAM](https://www.dock.io/industries/iam)

              - [Biometrics](https://www.dock.io/feature/biometric-bound-credentials)

              - [Other Organizations](https://www.dock.io/deploy-faster)

              - [Reusable KYB](https://www.dock.io/industries/reusable-kyb)

              - [Delegatable Authority](https://www.dock.io/industries/delegated-authority)


              ### Resources


              - [Blog](https://blog.dock.io/)

              - [Live events](https://www.dock.io/live-events)

              - [Terms](https://www.dock.io/terms-of-service)

              - [Privacy](https://www.dock.io/privacy)


              [![dock logo](https://cdn.prod.website-files.com/5e97941735e37a5ef19d10aa/675f9d583d5ef80a20a5f15c_logo-by-docklabs-dark.svg)](https://www.dock.io/)


              Copyright © 2024 Dock Labs AG'
            metadata:
              og:description: Learn about the game-changing benefits and applications
                of Zero-Knowledge Proof technology for organizations and individuals.
              twitter:card: summary_large_image
              og:title: 'Zero-Knowledge Proofs: A Beginner''s Guide'
              og:type: website
              robots: noindex
              favicon: https://cdn.prod.website-files.com/5e97941735e37a5ef19d10aa/67625b45b651d18ddc7e168e_favicon.png
              google-site-verification: lcJ26M_Y0MwabQDI2gntB5sc8stnY-C7yJchSeIeOvw
              og:image: https://cdn.prod.website-files.com/6311eb97e2519f5dbb9ea0cb/67615af17d114ec6630ca6f2_zero-knowledge%20proofs.webp
              viewport:
              - width=device-width, initial-scale=1
              - width=device-width, initial-scale=1
              og:image:height: '630'
              ogDescription: Learn about the game-changing benefits and applications
                of Zero-Knowledge Proof technology for organizations and individuals.
              og:image:width: '1200'
              twitter:image: https://cdn.prod.website-files.com/6311eb97e2519f5dbb9ea0cb/67615af17d114ec6630ca6f2_zero-knowledge%20proofs.webp
              language: EN
              description: Learn about the game-changing benefits and applications
                of Zero-Knowledge Proof technology for organizations and individuals.
              title: 'Zero-Knowledge Proofs: A Beginner''s Guide'
              ogTitle: 'Zero-Knowledge Proofs: A Beginner''s Guide'
              twitter:title: 'Zero-Knowledge Proofs: A Beginner''s Guide'
              twitter:description: Learn about the game-changing benefits and applications
                of Zero-Knowledge Proof technology for organizations and individuals.
              ogImage: https://cdn.prod.website-files.com/6311eb97e2519f5dbb9ea0cb/67615af17d114ec6630ca6f2_zero-knowledge%20proofs.webp
              scrapeId: ba6b340d-0c95-4e2e-837f-58d15e820272
              sourceURL: https://www.dock.io/post/zero-knowledge-proofs
              url: https://www.dock.io/post/zero-knowledge-proofs
              statusCode: 200
              contentType: text/html
              proxyUsed: basic
              cacheState: miss
          - title: What is Zero-Knowledge Proof? - OneKey
            description: ZKPs enable one party to prove the truth of a statement to
              another party without revealing any additional information beyond the
              validity of that statement.
            url: https://onekey.so/blog/ecosystem/what-is-zero-knowledge-proof/
            markdown: '## Key Takeaways


              • Zero-knowledge proofs (ZKPs) enable privacy-preserving verification
              in blockchain transactions.


              • Key properties of ZKPs include completeness, soundness, and zero-knowledge.


              • ZKPs are essential for private transactions, scalability solutions,
              and identity verification in decentralized systems.


              In the evolving landscape of blockchain and [cryptocurrency](https://onekey.so/blog/ecosystem/what-is-cryptocurrency/),
              zero-knowledge proofs (ZKPs) have emerged as a foundational cryptographic
              technology that balances privacy with verifiability. ZKPs enable one
              party to prove the truth of a statement to another party without revealing
              any additional information beyond the validity of that statement. This
              breakthrough is redefining how privacy and security are achieved across
              decentralized systems.


              ## The Fundamentals of Zero-Knowledge Proof


              At its core, a zero-knowledge proof is a cryptographic protocol involving
              two parties: the **prover** and the **verifier**. The prover must convince
              the verifier that they possess certain knowledge—such as a secret key
              or correct transaction information—without exposing the underlying data
              itself.


              To be considered a genuine zero-knowledge proof, the process must satisfy
              three essential properties:


              - **Completeness**: If the statement is true, an honest prover can convince
              the verifier of this fact.

              - **Soundness**: If the statement is false, no dishonest prover can
              convince the verifier otherwise, except with a negligible probability.

              - **Zero-Knowledge**: No information is revealed to the verifier except
              for the validity of the statement being proven.


              These foundational properties distinguish ZKPs from other types of proofs
              and have been formalized and widely discussed in the cryptographic literature
              ( [Wikipedia: Zero-knowledge proof](https://en.wikipedia.org/wiki/Zero-knowledge_proof)).


              ## How Zero-Knowledge Proofs Work in Blockchain


              ZKPs have become instrumental in solving some of the most pressing challenges
              in blockchain technology: privacy, scalability, and data confidentiality.
              Blockchains are inherently transparent, meaning that all transaction
              data is publicly accessible. ZKPs enable the validation of transactions
              and data without disclosing sensitive details, which is crucial for
              both individual users and enterprise adoption.


              For example, **zk-SNARKs** (Zero-Knowledge Succinct Non-Interactive
              Arguments of Knowledge) are used extensively on the [Ethereum](https://onekey.so/blog/ecosystem/what-is-ethereum/)
              blockchain to power privacy-preserving smart contracts and confidential
              transactions. These cryptographic protocols allow users to prove ownership
              or the validity of a transaction without revealing the transaction’s
              contents ( [read more on Chainalysis](https://www.chainalysis.com/blog/introduction-to-zero-knowledge-proofs-zkps/)).


              ## Real-World Applications and Industry Use Cases


              Zero-knowledge proofs are at the heart of several innovative blockchain
              projects. Here are some key applications:


              - **Private Transactions**: ZKPs enable the confirmation of transaction
              validity without exposing sender, receiver, or amount information. This
              is crucial for privacy-focused cryptocurrencies and decentralized finance
              ( [DeFi](https://onekey.so/blog/ecosystem/what-is-defi-decentralized-finance/))
              platforms.

              - **Scalability Solutions**: By enabling off-chain computations with
              on-chain verification, ZKPs reduce blockchain congestion and boost transaction
              throughput, supporting the growth of dApps and enterprise solutions.

              - **Identity Verification**: ZKPs allow for KYC (Know Your Customer)
              and AML (Anti-Money Laundering) checks to be performed without disclosing
              private user data, enabling compliance and user privacy ( [overview
              on Chainlink Education Hub](https://chain.link/education-hub/zero-knowledge-proof-projects)).


              ## Why Zero-Knowledge Proofs Matter Now


              With the increasing concern over digital privacy and the expanding adoption
              of blockchain across industries, zero-knowledge proofs are more relevant
              than ever. They [address](https://onekey.so/blog/ecosystem/what-is-a-crypto-wallet-address/)
              users’ growing demands for both transparency and confidentiality, underpinning
              developments in decentralized identity, confidential [DeFi](https://onekey.so/blog/ecosystem/what-is-defi-decentralized-finance/),
              and enterprise blockchain solutions ( [industry news and analysis](https://chain.link/education/zero-knowledge-proof-zkp)).


              As the industry moves toward more advanced use cases and regulatory
              scrutiny, ZKPs are set to become a cornerstone for achieving privacy-preserving
              compliance and scalable Web3 infrastructure.


              ## The Role of Hardware Wallets in Zero-Knowledge Proof-Based Systems


              While zero-knowledge proofs provide strong privacy guarantees at the
              protocol level, safeguarding cryptographic secrets, such as private
              keys used in ZKP-based transactions, remains a user’s responsibility.
              Here, hardware wallets like OneKey play a vital role by keeping private
              keys securely offline, reducing the risk of compromise during the generation
              and signing of zero-knowledge proofs.


              By integrating support for cutting-edge cryptographic standards and
              advanced protocols, OneKey ensures users can participate in privacy-first
              blockchain ecosystems with confidence. This commitment to secure key
              management is especially important as more decentralized applications
              leverage zero-knowledge cryptography to enhance privacy and scalability.


              ## Learn More


              Zero-knowledge proofs are shaping the future of blockchain privacy and
              scalability. To dive deeper into technical foundations and explore the
              latest ZKP-powered projects, visit these references:


              - [Zero-Knowledge Proof (ZKP) — Explained – Chainlink](https://chain.link/education/zero-knowledge-proof-zkp)

              - [Introduction to Zero-Knowledge Proofs – Chainalysis](https://www.chainalysis.com/blog/introduction-to-zero-knowledge-proofs-zkps/)

              - [Zero-knowledge proofs explained – Circularise](https://www.circularise.com/blogs/zero-knowledge-proofs-explained-in-3-examples)


              As the blockchain ecosystem evolves, technologies like zero-knowledge
              proofs and secure hardware wallets such as OneKey will continue to empower
              users with both privacy and control.


              ## Secure Your Crypto Journey with OneKey


              [View details for OneKey Pro](https://onekey.so/products/onekey-pro-hardware-wallet)
              ![OneKey Pro](https://onekey.so/blog/_next/static/media/pro.367119db.jpg?x-tos-process=image/resize,w_3840,q_80/format,webp)


              ### OneKey Pro


              Truly wireless. Fully offline.

              The most advanced air-gapped cold wallet.


              Get Pro


              [View details for OneKey Classic 1S](https://onekey.so/products/onekey-classic-1s-hardware-wallet)
              ![OneKey Classic 1S](https://onekey.so/blog/_next/static/media/classic1s.72266e39.jpg?x-tos-process=image/resize,w_3840,q_80/format,webp)![OneKey
              Classic 1S](https://onekey.so/blog/_next/static/media/classic1s-mobile.c8871fc4.jpg?x-tos-process=image/resize,w_1920,q_80/format,webp)


              ### OneKey Classic 1S


              Ultra-thin. Pocket-ready. Bank-grade secure.


              Start Classic


              [View details for OneKey Sifu](https://onekey.so/products/onekey-sifu)
              ![OneKey Sifu](https://onekey.so/blog/_next/static/media/sifu.7a018a1c.jpg?x-tos-process=image/resize,w_3840,q_80/format,webp)![OneKey
              Sifu](https://onekey.so/blog/_next/static/media/sifu-mobile.b91b5b3f.jpg?x-tos-process=image/resize,w_1920,q_80/format,webp)


              ### OneKey Sifu


              1-on-1 wallet setup with OneKey Experts.


              Ask Sifu


              ## Keep Reading


              [![The Hidden Risks of Card Wallets: Is Convenience Really Equal to
              Security?](https://asset-strapi.onekey.so/portal/strapi/generated_image_1757923528_1_0c8ed523f4.jpg?x-tos-process=image/resize,w_1080,q_80/format,webp)\\

              \\

              Ecosystem\\

              \\

              Sep 15\\

              \\

              **The Hidden Risks of Card Wallets: Is Convenience Really Equal to Security?**](https://onekey.so/blog/ecosystem/the-hidden-risks-of-card-wallets-is-convenience-really-equal-to-security/)[![A
              Long-Term Holder’s Guide to Crypto](https://asset-strapi.onekey.so/portal/strapi/generated_image_1757669058_1_9a6e1213b1.jpg?x-tos-process=image/resize,w_1080,q_80/format,webp)\\

              \\

              Ecosystem\\

              \\

              Sep 12\\

              \\

              **A Long-Term Holder’s Guide to Crypto**](https://onekey.so/blog/ecosystem/a-long-term-holders-guide-to-crypto/)[![How
              to Earn Passive Income from Holding Crypto](https://asset-strapi.onekey.so/portal/strapi/generated_image_1757669039_1_323a18d9aa.jpg?x-tos-process=image/resize,w_1080,q_80/format,webp)\\

              \\

              Ecosystem\\

              \\

              Sep 12\\

              \\

              **How to Earn Passive Income from Holding Crypto**](https://onekey.so/blog/ecosystem/how-to-earn-passive-income-from-holding-crypto/)'
            metadata:
              ogTitle: What is Zero-Knowledge Proof?
              ogSiteName: OneKey Blog
              ogDescription: Discover how zero-knowledge proofs (ZKPs) are revolutionizing
                privacy and security in blockchain technology, enabling verifiable
                transactions without revealing sensitive information.
              keywords: hardware wallet, defi, nft, btc, eth, near, fantom, solana,
                algo, starcoin, metamask, glow, trezor, ledger, safepal, keystone,
                imtoken, tokenpocket, rainbow wallet
              twitter:creator: '@OneKeyHQ'
              description: Discover how zero-knowledge proofs (ZKPs) are revolutionizing
                privacy and security in blockchain technology, enabling verifiable
                transactions without revealing sensitive information.
              ogUrl: https://onekey.so/blog/ecosystem/what-is-zero-knowledge-proof/
              robots: index
              og:title: What is Zero-Knowledge Proof?
              og:url: https://onekey.so/blog/ecosystem/what-is-zero-knowledge-proof/
              og:image: https://asset-strapi.onekey.so/portal/strapi/generated_image_1754641132_3_16x9_b74c06f8ef.jpg
              next-size-adjust: ''
              favicon: https://onekey.so/blog/favicon.png
              twitter:card: summary_large_image
              og:site_name: OneKey Blog
              og:type: article
              twitter:image: https://asset-strapi.onekey.so/portal/strapi/generated_image_1754641132_3_16x9_b74c06f8ef.jpg
              language: en
              title: What is Zero-Knowledge Proof?
              ogImage: https://asset-strapi.onekey.so/portal/strapi/generated_image_1754641132_3_16x9_b74c06f8ef.jpg
              viewport: width=device-width, initial-scale=1
              og:description: Discover how zero-knowledge proofs (ZKPs) are revolutionizing
                privacy and security in blockchain technology, enabling verifiable
                transactions without revealing sensitive information.
              twitter:site: '@OneKeyHQ'
              twitter:description: Discover how zero-knowledge proofs (ZKPs) are revolutionizing
                privacy and security in blockchain technology, enabling verifiable
                transactions without revealing sensitive information.
              twitter:title: What is Zero-Knowledge Proof?
              scrapeId: ed45d5f3-9167-460c-b0a5-f78229daf843
              sourceURL: https://onekey.so/blog/ecosystem/what-is-zero-knowledge-proof/
              url: https://onekey.so/blog/ecosystem/what-is-zero-knowledge-proof/
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
          - title: Identity-based Blind Signatures Enhance Privacy With Honest Zero
              ...
            description: Researchers have developed a new cryptographic system that
              combines identity-based authentication with blind signatures and zero-knowledge
              proofs, ...
            url: https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/
            markdown: '[Skip to content](https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/#primary)


              [![Identity-based Blind Signatures Enhance Privacy with Honest Zero-Knowledge
              Verification](https://quantumzeitgeist.com/wp-content/uploads/random_n-15.jpg)](https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/)


              The need for streamlined and secure authentication drives ongoing research
              into innovative cryptographic systems, and a team led by Soumya Bhoumik
              and Sarbari Mitra from Fort Hays State University, along with Rohit
              Raj Sharma and Kuldeep Namdeo from Maulana Azad National Institute of
              Technology, now presents a new approach to identity-based blind signatures.
              Building on earlier work in the field, they propose a scheme that combines
              the privacy of blind signatures with a method for ensuring the honesty
              of the verifier, without compromising sensitive data. The researchers
              utilise the CSIDH framework, a cryptographic system resistant to attacks
              from quantum computers, to create a post-quantum secure solution. This
              development represents a significant step towards building cryptographic
              systems that are both scalable and secure in an era where traditional
              encryption methods face increasing threats, offering enhanced privacy
              and reliability for a range of applications.


              This scheme simplifies key management by using a user’s identity, such
              as an email address, directly as their public key. Blind signatures
              allow a signer to sign a message without knowing its content, protecting
              privacy in applications like e-cash and voting. The scheme achieves
              post-quantum security by leveraging the computational difficulty of
              problems in supersingular isogeny cryptography, specifically the Commutative
              Group Action. The scheme builds upon the CSIDH key exchange protocol,
              utilizing the class group action within CSIDH to construct the signature.


              A zero-knowledge honest verifier protocol is integrated to enhance privacy
              and integrity, ensuring the verifier confirms the signature’s validity
              without learning the signer’s secret key. Blindness is achieved through
              an isogeny-based sigma protocol, inspired by Schnorr signatures, which
              uses constant-size randomness for compact signatures. The scheme’s security
              is formally proven in the standard model, based on the presumed hardness
              of the Gap Isogeny Problem and its multi-target variant. Key advantages
              include resistance to quantum computer attacks, simplified key management,
              message privacy, compact signature sizes, and overall efficiency.


              Performance analysis indicates a computational cost of O(n²) for phases
              like setup, extraction, and verification. Signature sizes are reported
              as 9KB for 128-bit security and 37KB for 256-bit security, with relatively
              compact key sizes. This research addresses a critical need for secure
              and privacy-preserving cryptographic solutions in the face of the growing
              threat of quantum computers.


              ### Post-Quantum Blind Signatures with Zero-Knowledge Proofs


              Researchers developed a novel Identity-Based Blind Signature (IBBS)
              scheme that enhances privacy and verifier honesty. This scheme leverages
              the computational hardness of isogenies within the CSIDH framework to
              provide robust security in a post-quantum cryptographic landscape. The
              team simplified the master key setup, utilizing a single element from
              a specific mathematical space instead of more complex structures. This
              approach eliminates the need for traditional certificates, streamlining
              cryptographic processes and improving scalability. A key innovation
              lies in the adoption of an n-dimensional vector structure, replacing
              a traditional matrix representation, which significantly reduces computational
              overhead while maintaining the same level of security.


              The team sampled the master key from a specialized set, guaranteeing
              its invertibility and preventing potential weaknesses in key generation.
              Security analysis demonstrates that breaking this scheme would also
              require solving a computationally hard problem within the CSIDH framework,
              establishing a strong link between the scheme’s security and well-established
              cryptographic assumptions. Performance evaluations confirm the practical
              viability of this scheme for privacy-preserving applications requiring
              both security and efficiency. The method achieves correctness, blindness,
              and existential unforgeability under adaptive chosen-message and chosen-identity
              attacks, solidifying its position as a robust and scalable cryptographic
              solution for the future.


              ### Post-Quantum Blind Signatures Ensure Privacy and Honesty


              Scientists have developed a new identity-based blind signature scheme
              that eliminates the need for traditional certificates, offering a more
              efficient and scalable approach to cryptographic systems. This scheme,
              built upon the CSIDH framework, combines blind signatures for privacy
              with a zero-knowledge proof to ensure verifier honesty without revealing
              additional information, achieving post-quantum security. The team’s
              design leverages the properties of CSIDH, a post-quantum secure system
              based on supersingular isogenies, providing strong protection against
              potential adversaries while maintaining computational efficiency. The
              research demonstrates the effectiveness of this scheme in safeguarding
              privacy and verifier honesty through rigorous security analysis in the
              standard cryptographic model.


              Performance evaluations confirm the practical viability of this solution
              for privacy-preserving applications, showcasing a significant advancement
              in secure and scalable cryptography for the post-quantum era. The computational
              cost of the scheme scales linearly with the security parameter, denoted
              as ‘n’, with complexities of O(n²) for phases like setup, extraction,
              and verification. Detailed analysis reveals that the sizes of all keys
              and protocol messages grow linearly with ‘n’, ensuring compact keys
              and signatures even at high security levels. At a 128-bit security level,
              the signature size is approximately 9 KB, increasing to 37 KB at 256-bit
              security.


              These results demonstrate a practical solution for resource-constrained
              environments, such as IoT sensors and mobile devices, offering compact
              structures and efficient operations. The team’s work establishes a foundation
              for future research, including extensions to support dynamic revocation
              and threshold signing, and optimization of CSIDH implementations for
              side-channel resistance. This innovative scheme represents a significant
              step towards building secure, scalable, and privacy-preserving cryptographic
              systems for the future.


              ### Identity-Based Blind Signatures for Post-Quantum Security


              This work presents a new identity-based blind signature scheme that
              leverages the properties of the CSIDH cryptographic framework to provide
              post-quantum security. The scheme combines identity-based cryptography,
              which eliminates the need for traditional certificate authorities, with
              blind signatures to protect the privacy of the signer. A zero-knowledge
              protocol is integrated to ensure the honesty of the verifier without
              revealing any additional information. The researchers demonstrate the
              scheme’s security through a formal reduction to the presumed hardness
              of specific computational problems related to supersingular isogenies,
              establishing existential unforgeability under adaptive chosen-message
              attacks.


              Performance evaluations confirm the practicality of the approach, with
              key and signature sizes scaling favorably even for high security levels,
              making it suitable for resource-constrained devices like IoT sensors.
              The scheme achieves compact signatures and efficient operations, requiring
              only linear time for signing, verification, and key extraction with
              respect to the security parameter. The authors acknowledge that the
              current scheme does not include features for dynamic revocation of identities
              or threshold signing capabilities. Future research will focus on addressing
              these limitations and further optimizing CSIDH implementations to enhance
              resistance against side-channel attacks. The team reports no conflicts
              of interest related to this work.


              **👉 More information**


              🗞 _CSI-IBBS: Identity-Based Blind Signature using CSIDH_


              **🧠 ArXiv:** [https://arxiv.org/abs/2509.06127](https://arxiv.org/abs/2509.06127)


              Tags:


              [blind signatures](https://quantumzeitgeist.com/tag/blind-signatures/)
              [Cryptographic Schemes](https://quantumzeitgeist.com/tag/cryptographic-schemes/)
              [CSIDH](https://quantumzeitgeist.com/tag/csidh/) [Identity-based cryptography](https://quantumzeitgeist.com/tag/identity-based-cryptography/)
              [isogenies](https://quantumzeitgeist.com/tag/isogenies/) [post-quantum
              cryptography](https://quantumzeitgeist.com/tag/post-quantum-cryptography/)
              [Privacy Preservation](https://quantumzeitgeist.com/tag/privacy-preservation/)
              [scalable cryptography](https://quantumzeitgeist.com/tag/scalable-cryptography/)
              [verifier honesty](https://quantumzeitgeist.com/tag/verifier-honesty/)
              [Zero-Knowledge Proofs](https://quantumzeitgeist.com/tag/zero-knowledge-proofs/)


              [![Quantum News](https://quantumzeitgeist.com/wp-content/uploads/quantum_news-1-150x150.jpg)](https://quantumzeitgeist.com/author/quantum-news/)


              [**Quantum News** \\

              As the Official Quantum Dog (or hound) by role is to dig out the latest
              nuggets of quantum goodness. There is so much happening right now in
              the field of technology, whether AI or the march of robots. \\

              \\

              But Quantum occupies a special space. Quite literally a special space.
              A Hilbert space infact, haha! Here I try to provide some of the news
              that might be considered breaking news in the Quantum Computing space.](https://quantumzeitgeist.com/author/quantum-news/)


              ### Latest Posts by Quantum News:


              [![La3ni2o7-delta Exhibits 80 K Superconductivity and Meissner Effect
              Confirmed Via Diamond Quantum Sensors](https://quantumzeitgeist.com/wp-content/uploads/1-811-150x150.png)\\

              \\

              **La3ni2o7-delta Exhibits 80 K Superconductivity and Meissner Effect
              Confirmed Via Diamond Quantum Sensors** September 16, 2025](https://quantumzeitgeist.com/quantum-la3ni2o7-delta-exhibits-superconductivity-meissner-effect-confirmed-diamond/)
              [![Nonlinear Theory Modifications Do Not Violate Second Law, Study of
              Readout Devices Confirms](https://quantumzeitgeist.com/wp-content/uploads/1-779-150x150.png)\\

              \\

              **Nonlinear Theory Modifications Do Not Violate Second Law, Study of
              Readout Devices Confirms** September 15, 2025](https://quantumzeitgeist.com/nonlinear-theory-modifications-not-violate-second-law-readout/)
              [![Loss Behavior in Supervised Learning with Entangled States Demonstrates
              Improved Quality in Quantum Machine Learning Models](https://quantumzeitgeist.com/wp-content/uploads/ent_120-2-150x150.jpg)\\

              \\

              **Loss Behavior in Supervised Learning with Entangled States Demonstrates
              Improved Quality in Quantum Machine Learning Models** September 15,
              2025](https://quantumzeitgeist.com/supervised-learning-quantum-machine-states-models-loss-behavior-entangled-demonstrates-quality/)


              Quantum Computing \| Quantum Zeitgeist \| Substack


              [![Logo](https://substackcdn.com/image/fetch/$s_!9W-e!,w_170,c_limit,f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffafdbfdd-7313-4b62-8567-966a819c83e7_500x500.png)](https://quantumzeitgeist.substack.com/)


              # [Quantum Computing](https://quantumzeitgeist.substack.com/)


              Quantum Computing Latest News and Views, Covering Quantum and AI


              By Quantum Zeitgeist

              · Over 3,000 subscribers


              Subscribe


              By subscribing you agree to [Substack''s Terms of Use](https://quantumzeitgeist.substack.com/tos?utm_source=embed_publication),
              [our Privacy Policy](https://quantumzeitgeist.substack.com/privacy?utm_source=embed_publication)
              and [our Information collection notice](https://substack.com/ccpa?utm_source=embed_publication#personal-data-collected)


              [![Substack](https://substackcdn.com/image/fetch/$s_!R0u0!,w_200,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Fsubstack_wordmark.black.png)](https://substack.com/?utm_source=embed&utm_content=quantumzeitgeist)'
            metadata:
              article:tag:
              - blind signatures
              - Cryptographic Schemes
              - CSIDH
              - Identity-based cryptography
              - isogenies
              - post-quantum cryptography
              - Privacy Preservation
              - scalable cryptography
              - verifier honesty
              - Zero-Knowledge Proofs
              twitter:card:
              - summary_large_image
              - summary_large_image
              favicon: https://quantumzeitgeist.com/wp-content/uploads/QuantumZ_1_ico-1.ico
              og:image:width: '1408'
              theme-color: '#111827'
              ogDescription: Researchers have developed a new cryptographic system
                that combines identity-based authentication with blind signatures
                and zero-knowledge proofs, creating a privacy-preserving and secure
                method resistant to attacks from future quantum computers
              og:image:
              - https://quantumzeitgeist.com/wp-content/uploads/random_n-15.jpg
              - https://substackcdn.com/image/fetch/$s_!XTYb!,f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Fquantumzeitgeist.substack.com%2Ftwitter%2Fsubscribe-card.jpg%3Fv%3D-1421982968%26version%3D9
              article:published_time: '2025-09-10T19:39:00+00:00'
              og:url:
              - https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/
              - https://quantumzeitgeist.substack.com/embed
              - https://substack.com/session-attribution-frame
              twitter:title:
              - Identity-based Blind Signatures Enhance Privacy With Honest Zero-Knowledge
                Verification
              - Quantum Computing | Quantum Zeitgeist | Substack
              twitter:data2: 5 minutes
              og:type:
              - article
              - article
              norton-safeweb-site-verification:
              - 24usqpep0ejc5w6hod3dulxwciwp0djs6c6ufp96av3t4whuxovj72wfkdjxu82yacb7430qjm8adbd5ezlt4592dq4zrvadcn9j9n-0btgdzpiojfzno16-fnsnu7xd
              - 24usqpep0ejc5w6hod3dulxwciwp0djs6c6ufp96av3t4whuxovj72wfkdjxu82yacb7430qjm8adbd5ezlt4592dq4zrvadcn9j9n-0btgdzpiojfzno16-fnsnu7xd
              description: Researchers have developed a new cryptographic system that
                combines identity-based authentication with blind signatures and zero-knowledge
                proofs, creating a privacy-preserving and secure method resistant
                to attacks from future quantum computers, Quantum Computing Latest
                News and Views, Covering Quantum and AI. Click to read Quantum Computing,
                by Quantum Zeitgeist, a Substack publication with thousands of subscribers.
              og:image:type: image/jpeg
              og:locale: en_US
              ogSiteName: Quantum Zeitgeist
              ogImage: https://quantumzeitgeist.com/wp-content/uploads/random_n-15.jpg
              twitter:image:
              - https://quantumzeitgeist.com/wp-content/uploads/random_n-15.jpg
              - https://substackcdn.com/image/fetch/$s_!XTYb!,f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Fquantumzeitgeist.substack.com%2Ftwitter%2Fsubscribe-card.jpg%3Fv%3D-1421982968%26version%3D9
              twitter:data1: Quantum News
              language: en-US
              twitter:label2: Time to read
              author:
              - Quantum Zeitgeist
              - Substack
              article:section: Quantum Cryptography
              twitter:creator: '@QuantumStateX'
              title: Identity-based Blind Signatures Enhance Privacy With Honest Zero-Knowledge
                Verification
              viewport:
              - width=device-width, initial-scale=1
              - width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0,
                viewport-fit=cover
              - width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0,
                viewport-fit=cover
              ogTitle: Identity-based Blind Signatures Enhance Privacy With Honest
                Zero-Knowledge Verification
              robots:
              - follow, index, max-snippet:300, max-image-preview:standard
              - noindex
              twitter:label1: Written by
              msapplication-TileImage: https://quantumzeitgeist.com/wp-content/uploads/QuantumZ_1_ico-1.ico
              og:image:secure_url: https://quantumzeitgeist.com/wp-content/uploads/random_n-15.jpg
              og:image:height: '768'
              ogLocale: en_US
              publishedTime: '2025-09-10T19:39:00+00:00'
              og:description:
              - Researchers have developed a new cryptographic system that combines
                identity-based authentication with blind signatures and zero-knowledge
                proofs, creating a privacy-preserving and secure method resistant
                to attacks from future quantum computers
              - Quantum Computing Latest News and Views, Covering Quantum and AI.
                Click to read Quantum Computing, by Quantum Zeitgeist, a Substack
                publication with thousands of subscribers.
              ogUrl: https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/
              og:image:alt: Identity-based Blind Signatures Enhance Privacy with Honest
                Zero-Knowledge Verification
              og:site_name: Quantum Zeitgeist
              og:title:
              - Identity-based Blind Signatures Enhance Privacy With Honest Zero-Knowledge
                Verification
              - Quantum Computing | Quantum Zeitgeist | Substack
              twitter:description:
              - Researchers have developed a new cryptographic system that combines
                identity-based authentication with blind signatures and zero-knowledge
                proofs, creating a privacy-preserving and secure method resistant
                to attacks from future quantum computers
              - Quantum Computing Latest News and Views, Covering Quantum and AI.
                Click to read Quantum Computing, by Quantum Zeitgeist, a Substack
                publication with thousands of subscribers.
              twitter:site: '@QuantumStateX'
              scrapeId: 921e8a9b-7a71-4b90-936e-1cc19e7d2681
              sourceURL: https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/
              url: https://quantumzeitgeist.com/identity-based-blind-signatures-enhance-privacy-honest-zero/
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
          - title: AI Needs Zero-Knowledge Proofs to Thrive | The AI Journal
            description: Embracing Zero-Knowledge Proofs is not just a technological
              upgrade but a strategic move for a secure, transparent, and universally
              adopted AI ecosystem.
            url: https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
            markdown: '![](https://aijourn.com/wp-content/uploads/2025/09/Cysic_Feature_Image-780x470.png)


              ## **Introduction: AI Can’t Be Trusted**


              We can’t trust AI models anymore, and AI hallucinations are to blame.
              AI hallucination refers to incorrect or misleading results that AI models
              generate due to insufficient training data, incorrect assumptions, or
              biased data used to train the model.


              In 2025, [over 378 million people](https://www.edge-ai-vision.com/2025/02/global-ai-adoption-to-surge-20-exceeding-378-million-users-in-2025/#:~:text=AI%20adoption%20has%20skyrocketed%20over,to%20314%20million%20last%20year.)
              worldwide use AI-powered tools, an increase of 64.4 million compared
              to 2024. The ability of AI to deliver accurate information is crucial
              as the number of users increases, but this is not the case.


              [Research conducted by OpenAI](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf)
              on their latest and most powerful models, o3 and o4-mini, found that
              o3 hallucinated 33% of the time, while o4-mini’s fault rate sits at
              48%. In the same report, it is found that hallucinations are double
              the rate of their older o1 model. OpenAI does not know why and hypothesises
              that as newer models “make more claims overall”, it often leads to “more
              inaccurate/hallucinated claims”.


              As more enterprises look to AI for business solutions, the lack of accuracy
              and reliability is showing that AI is not ready for mass adoption.


              AI’s functions come into question when it is unable to provide factual
              answers. Adoption and the growth of this sector will come to a standstill
              if we are unable to establish confidence in AI models. This problem
              is not new. ChatGPT has always included a disclaimer saying, “ChatGPT
              can make mistakes. Check important info.” below the chatbox.


              To overcome this fundamental lack of trust and enable AI’s widespread
              adoption, AI needs Zero-Knowledge Proofs (ZKPs), as they allow verifiable
              AI outputs while protecting intellectual property


              ## **The Privacy Paradox Is Keeping AI Hallucinations Around**


              The answer to why developers have yet to implement a solution to unverifiable
              AI output is the [privacy paradox](https://www.cyberjournalist.net/2024/03/23/privacy-paradox-challenges-the-balance-between-transparency-and-data-protection/).
              It’s described as the inability to implement both security and transparency
              without compromising either.


              For developers and enterprises, user trust is paramount for industry
              growth. Without verifiable trust, AI-powered platforms risk a severe
              lack of adoption. To make the issue worse, some examples of the failures
              of AI were quite public.


              In 2024, Air Canada was [ordered to pay damages](https://www.theregister.com/2024/02/15/air_canada_chatbot_fine/)
              to a passenger after its AI-powered virtual assistant provided incorrect
              information. More recently, in 2025, the [Chicago Sun-Times and Philadelphia
              Inquirer took reputational hits](https://chicago.suntimes.com/news/2025/05/20/syndicated-content-sunday-print-sun-times-ai-misinformation)
              when editions featured a list of recommended books that don’t exist
              due to AI-generated misinformation.


              Security layers (e.g., traditional encryption, firewalls) are implemented
              in AI, but it is still inadequate for solving this specific challenge.
              Through these security layers, developers are unable to prove the accuracy
              of their AI models’ outputs without exposing their proprietary code
              or sensitive training data, creating an impossible choice between trust
              and intellectual property.


              ## **The Solution Already Exists: Zero-Knowledge Proofs**


              Zero-Knowledge Proof (ZKP), a well-established technology commonly used
              as a security layer in the cryptocurrency sector, provides protection
              that AI can benefit from. It is a cryptographic process that allows
              one party to prove to another that a statement is true or that a computation
              was performed correctly without revealing any information beyond the
              validity of the statement itself.


              Why is ZKP the solution? ZKP solves the privacy paradox and beyond.


              Unlike [traditional security layers](https://medium.com/@RocketMeUpCybersecurity/zero-knowledge-proofs-zkps-for-privacy-preserving-digital-identity-in-decentralized-systems-69ab615473f6),
              ZKP does not require the process of sharing data. Instead, it requires
              proving possession of specific knowledge or satisfaction of certain
              conditions, much like your ID being able to verify your age without
              revealing any additional information beyond your birth year.


              Applying ZK to AI, it can verify the correctness of a computation without
              disclosing the details and process of the computation.  This allows
              businesses to provide verifiable accuracy of their AI-powered platforms
              to users while safeguarding intellectual property.


              A specific application of ZKP, known as [Zero-Knowledge Proof of Training
              (ZKPoT)](https://www.researchgate.net/publication/389946978_Zero-Knowledge_Proof-Based_Consensus_for_Blockchain-Secured_Federated_Learning),
              can further enhance trust by verifying the integrity of the training
              process itself. ZKPoT allows developers to prove that an AI model was
              trained on a specific dataset or adhered to certain parameters without
              revealing training data. This ensures that users can trust that outputs
              are based on reliable training, solving AI hallucinations while preserving
              proprietary information.


              Currently, security protocols such as [homomorphic encryption](https://www.supermicro.com/en/glossary/homomorphic-encryption)
              exist, but when compared against ZKP, it is less efficient. ZKP does
              not require the process of encryption/decryption, cutting processing
              time and cost, making it more scalable for widespread AI deployment,
              especially for smaller-scale enterprises and developers in the AI sector.


              Some may say that, in the same way AI requires specialised hardware,
              ZKP implementation does as well, which raises costs for developers.
              Current prices of high-performance chips for AI and ZK functions are
              priced around [$10,000 – $12,000 per unit, for enterprise-level AI tasks](https://www.puppyagent.com/en/blog/How-Much-Does-AI-Hardware-Really-Cost-A-Deep-Dive-into-the-Numbers).


              Despite the high prices of specialised hardware, costs can be reduced
              through using [tokenised hardware](https://coinmarketcap.com/academy/glossary/computefi),
              removing the need for developers or smaller enterprises to own and maintain
              specialised chips. Democratising access to the technology.


              ## **It Is Time To Have Knowledge about Zero-Knowledge**


              Embracing Zero-Knowledge Proofs is not just a technological upgrade
              but a strategic move for a secure, transparent, and universally adopted
              AI ecosystem. Building user and stakeholder trust is crucial for the
              success of AI-powered platforms. Improper execution damages reputation,
              user experience, and trust.


              Reluctance to embrace Zero-Knowledge Proofs will set the industry back,
              especially with AI models trained on unverified data. In order to overcome
              this, we must prepare for what’s next, not react to what is.


              Adopting ZKP offers verifiable computation and privacy-preserving transparency,
              enabling more AI solutions to be built and unlocking new applications.
              As developers, it is our responsibility to build trustworthy systems,
              as the future of AI hinges on trust. Without solving this, the industry
              risks obsolescence.


              ## Author


              - ![](https://aijourn.com/wp-content/uploads/2024/05/The-AI-Journal-1.png)






              [AIJ Guest Post](https://aijourn.com/author/theaijournal/ "AIJ Guest
              Post")






              [View all posts](https://aijourn.com/author/theaijournal/ "View all
              posts")[Email](mailto:stories@theaijournal.co.uk)[Website](https://aijourn.com/)



              [![Photo of AIJ Guest Post](https://aijourn.com/wp-content/uploads/2024/05/The-AI-Journal-1.png)](https://aijourn.com/author/theaijournal/)[AIJ
              Guest Post](https://aijourn.com/author/theaijournal/ "AIJ Guest Post")
              [Send an email](mailto:stories@theaijournal.co.uk "Send an email")19
              hours ago


              4 minutes read


              ### Related Articles


              [![AI chatbot helping students with university admissions process online](data:image/svg+xml,%3Csvg%20xmlns=''http://www.w3.org/2000/svg''%20viewBox=''0%200%20390%20220''%3E%3C/svg%3E)](https://aijourn.com/ai-chat-support-university-admissions/)


              ### [How AI Chat Support is Simplifying University Admissions for Students](https://aijourn.com/ai-chat-support-university-admissions/)


              26 minutes ago


              [![](data:image/svg+xml,%3Csvg%20xmlns=''http://www.w3.org/2000/svg''%20viewBox=''0%200%20390%20220''%3E%3C/svg%3E)](https://aijourn.com/cracking-the-code-of-ai-success-dont-ignore-data-integrity/)


              ### [Cracking the Code of AI Success: Don’t Ignore Data Integrity](https://aijourn.com/cracking-the-code-of-ai-success-dont-ignore-data-integrity/)


              2 hours ago


              [![](data:image/svg+xml,%3Csvg%20xmlns=''http://www.w3.org/2000/svg''%20viewBox=''0%200%20390%20220''%3E%3C/svg%3E)](https://aijourn.com/private-aviation-runs-on-expectations-meeting-them-requires-a-redesign/)


              ### [Private aviation runs on expectations: Meeting them requires a
              redesign](https://aijourn.com/private-aviation-runs-on-expectations-meeting-them-requires-a-redesign/)


              3 hours ago


              [![](data:image/svg+xml,%3Csvg%20xmlns=''http://www.w3.org/2000/svg''%20viewBox=''0%200%20390%20220''%3E%3C/svg%3E)](https://aijourn.com/improving-claim-accuracy-strategies-for-detecting-duplicate-healthcare-insurance-claims/)


              ### [Improving Claim Accuracy: Strategies for Detecting Duplicate Healthcare
              Insurance Claims](https://aijourn.com/improving-claim-accuracy-strategies-for-detecting-duplicate-healthcare-insurance-claims/)


              3 hours ago


              [Facebook](https://www.facebook.com/sharer.php?u=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "Facebook") [X](https://x.com/intent/post?text=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive&url=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "X") [LinkedIn](https://www.linkedin.com/shareArticle?mini=true&url=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/&title=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive
              "LinkedIn") [Reddit](https://reddit.com/submit?url=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/&title=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive
              "Reddit") [Messenger](fb-messenger://share?app_id=5303202981&display=popup&link=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/&redirect_uri=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "Messenger") [Messenger](https://www.facebook.com/dialog/send?app_id=5303202981&display=popup&link=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/&redirect_uri=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "Messenger") [Share via Email](mailto:?subject=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive&body=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "Share via Email")


              [Facebook](https://www.facebook.com/sharer.php?u=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "Facebook") [X](https://x.com/intent/post?text=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive&url=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "X") [LinkedIn](https://www.linkedin.com/shareArticle?mini=true&url=https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/&title=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive
              "LinkedIn") [WhatsApp](https://api.whatsapp.com/send?text=AI%20Needs%20Zero-Knowledge%20Proofs%20to%20Thrive%20https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              "WhatsApp")


              [Back to top button](https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/#go-to-tie-body)


              [Close](https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/#)


              Search for


              [Close](https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/#)


              Search for


              [Close](https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/#)'
            metadata:
              title: AI Needs Zero-Knowledge Proofs to Thrive | The AI Journal
              ogUrl: https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              robots: follow, index, max-snippet:-1, max-video-preview:-1, max-image-preview:large
              google-adsense-platform-domain: sitekit.withgoogle.com
              ogTitle: AI Needs Zero-Knowledge Proofs to Thrive | The AI Journal
              twitter:data2: 4 minutes
              favicon: https://aijourn.com/wp-content/uploads/2024/04/cropped-The-AI-Journal-1-32x32.png
              og:image:width: '1024'
              og:image: https://aijourn.com/wp-content/uploads/2025/09/Cysic_Feature_Image-1024x574.png
              google-adsense-platform-account: ca-host-pub-2644536267352236
              ogSiteName: The AI Journal
              generator:
              - Site Kit by Google 1.155.0
              - 'Elementor 3.29.2; features: e_font_icon_svg, additional_custom_breakpoints,
                e_local_google_fonts; settings: css_print_method-external, google_font-enabled,
                font_display-auto'
              - WP Rocket 3.19.2.1
              og:image:height: '574'
              og:description: We can’t trust AI models anymore, and AI hallucinations
                are to blame. AI hallucination refers to incorrect or misleading results
                that AI models generate due
              og:url: https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              twitter:title: AI Needs Zero-Knowledge Proofs to Thrive | The AI Journal
              twitter:label2: Time to read
              ogLocale: en_GB
              language: en-GB
              og:image:alt: AI Needs Zero-Knowledge Proofs to Thrive
              msapplication-TileImage: https://aijourn.com/wp-content/uploads/2024/04/cropped-The-AI-Journal-1-270x270.png
              outreach_verification: JM8ibyBfMlecCe6uH6fn
              article:section: Future of AI
              og:type: article
              og:title: AI Needs Zero-Knowledge Proofs to Thrive | The AI Journal
              publishedTime: '2025-09-15T13:37:39+00:00'
              og:image:secure_url: https://aijourn.com/wp-content/uploads/2025/09/Cysic_Feature_Image-1024x574.png
              og:image:type: image/png
              article:published_time: '2025-09-15T13:37:39+00:00'
              twitter:card: summary_large_image
              twitter:image: https://aijourn.com/wp-content/uploads/2025/09/Cysic_Feature_Image-1024x574.png
              ogImage: https://aijourn.com/wp-content/uploads/2025/09/Cysic_Feature_Image-1024x574.png
              twitter:label1: Written by
              twitter:data1: AIJ Guest Post
              viewport: width=device-width, initial-scale=1.0
              og:site_name: The AI Journal
              twitter:description: We can’t trust AI models anymore, and AI hallucinations
                are to blame. AI hallucination refers to incorrect or misleading results
                that AI models generate due
              description: We can’t trust AI models anymore, and AI hallucinations
                are to blame. AI hallucination refers to incorrect or misleading results
                that AI models generate due
              og:locale: en_GB
              ogDescription: We can’t trust AI models anymore, and AI hallucinations
                are to blame. AI hallucination refers to incorrect or misleading results
                that AI models generate due
              scrapeId: 2a78f611-5c7b-4e9b-9ee3-1ed56f4ff61b
              sourceURL: https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              url: https://aijourn.com/ai-needs-zero-knowledge-proofs-to-thrive/
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
    description: Natural language query with AI analysis for zero knowledge proofs
    status: success
  natural_language_query_raw_data:
    input:
      query: What are the latest developments in zero knowledge proofs?
      raw_data_only: true
    output:
      response: ''
      data: *id001
    description: Natural language query with raw data only for zero knowledge proofs
    status: success
  direct_search:
    input:
      tool: firecrawl_web_search
      tool_arguments:
        search_term: zero knowledge proofs recent advancements
    output:
      response: ''
      data:
        status: success
        data:
          results:
          - title: The Power and Potential of Zero-Knowledge Proofs
            description: While the power, potential, and practical application of
              ZKPs has accelerated over recent years, a challenge and opportunity
              lie ahead. As ...
            url: https://cacm.acm.org/news/the-power-and-potential-of-zero-knowledge-proofs/
            markdown: '[Skip to content](https://cacm.acm.org/news/the-power-and-potential-of-zero-knowledge-proofs/#content)


              - [Further Reading](https://cacm.acm.org/news/the-power-and-potential-of-zero-knowledge-proofs/#FurtherReading)


              How can you prove something with nothing, confirm the correctness of
              a transaction with no underlying information, and design software that
              runs as required but does not reveal how it achieves its functionality?


              The answer is zero-knowledge proofs (ZKPs), developed by computer scientists
              and mathematicians who acknowledge they are counterintuitive, and now
              are beginning to move out of the sphere of theoretical computer science,
              through the realm of possibility and into practical commercial applications.


              The notion of ZKPs was introduced in a 1986 paper by Oded Goldreich
              at Technion, the Israel Institute of Technology in Haifa, Israel; Silvio
              Micali at the Massachusetts Institute of Technology; and Avi Wigderson
              at the Hebrew University in Jerusalem, Israel. The paper demonstrated
              the generality and wide applicability of such proofs, stating, “These
              are probabilistic and interactive proofs that, for the members of a
              language, efficiently demonstrate membership in the language without
              conveying any additional knowledge.”


              An example based on the _Where’s Waldo_ books was offered by Tom Gur,
              a professor in the department of computer science and technology at
              the U.K.’s University of Cambridge. “Suppose I am playing a game of
              Where’s Waldo with primary kids. I want to prove I know where he is
              without revealing his location. If I take a large piece of black paper
              and cut a small hole in it and put it on the page so that Waldo’s face
              can be seen, I can prove that I know where Waldo is without revealing
              his location.”


              Gur added, “These proofs admit more powerful properties than traditional
              nondeterministic polynomial time (NP) proofs. One can prove a statement
              without revealing any information other than its correctness.”


              ZKPs are the result of many years of research into how to solve some
              of the biggest problems in science and mathematics, a move away from
              lengthy documents designed to show proof and towards an interactive
              proof involving a proofer and verifier. Essentially, they use a cryptographic
              protocol that allows a proofer to convince a verifier that a statement
              is true without revealing any additional information.


              Gur noted increasing interest in ZKPs as a means of proving a statement
              while retaining privacy and ensuring information security. “Today, these
              proofs are a major force in blockchain transactions and are also being
              applied in other large real-world systems that need to prove a transaction
              has been made while revealing zero information,” he said. While focused
              on the theoretical computer science behind ZKPs, Gur also helps industry
              partners understand the possibilities of the technology.


              Michele Ciampi, a Chancellor’s Fellow at The University of Edinburgh
              in Scotland and a specialist in ZKPs and cryptography, referred to the
              early work of Goldreich, Micali, and Wigderson, saying, “This is a beautiful
              theorem. It doesn’t matter how complex a statement is, it is possible
              to produce mathematical proof that conveys nothing more than the fact
              the statement is true.”


              Amit Sahai, a professor of computer science at the University of California,
              Los Angeles (UCLA), noted that early views described ZKPs for general
              statements as “beautiful math objects” that were impractical because
              they were so slow and inefficient. “In the 1990s, I couldn’t imagine
              that ZKPs for general statements would be used in a practical way, but
              I was wrong. It is fascinating to see how that has changed,” he said.


              In a use case of economic capacity, Ciampi described convincing another
              person that you have enough cryptocurrency for a particular purpose,
              without telling them how much you have. “I don’t show the number of
              coins I have, but can prove the number of coins I have exceeds a certain
              threshold,” he said.


              Where a large volume of computation is required and data is transferred
              to a cloud service provider, ZKPs can be used to verify the data computation
              is correct and in line with stated rules. In this scenario, the cloud
              gets access to the data to perform the computation. Hiding the data
              from the cloud service provider is a more advanced problem, but can
              be resolved using fully homomorphic encryption (FHE) that encrypts the
              data and allows it to be processed without being decrypted.


              How can you be sure that ZKP computations are correct? “Randomness,”
              said Ciampi. “To prove that a computation is correct, the verifier checks
              a few locations and gains confidence that the proof is correct, despite
              having no knowledge of the underlying information.”


              Ciampi collaborates with U.S. universities on ZKP research and development
              and has received interest in his work on the use of ZKPs in digital
              identity from the Scottish government. He notes that the more data we
              share, the more it becomes a concern, requiring sophisticated techniques
              to protect that data.


              ZKPs can be applied to use cases in a variety of industries, especially
              where data integrity and accuracy are crucial. These include online
              security, data privacy, digital identity, gaming, healthcare records,
              verifying transactions, online voting systems, network security and
              authentication, digital signatures on blockchain networks, and tracing
              carbon emissions without revealing sensitive information.


              They also are in continual development in terms of not only application,
              but also technical improvements in areas such as speed and efficiency.
              As part of his work, Sahai studied the feasibility of ZKPs, such as
              the use of elliptic curves to improve the speed of proofs, and a focus
              on blockchain that has allowed a step-change in the development of proofs
              and attracted interest, investment, and practical application from industry.


              “Technology development is happening right now,” Sahai said, citing
              his activity in designing ZK software that runs as required, but does
              not reveal how it achieves its functionality. This, he said, is “far
              from anything practical,” but certainly has potential.


              On a more practical level, Sahai offered the example of using a driver
              license to provide proof of a person’s identity when applying for a
              post at a company. “A driving license document verifies who the person
              is, but provides too much information about them. If the company wants
              specific information, the person can respond using ZKP technology that
              exposes only required credentials, such as address and birth year. Imagine
              a world of applications where you can selectively reveal information,
              but where the recipient can also be sure that the information is accurate.”


              Imagine, too, a world with fewer hard-copy documents, fewer opportunities
              for mistakes, data breaches, and data manipulation, and more opportunities
              to manage and control your own data.


              [Fermah](https://www.fermah.xyz/), a start-up founded in 2023 that released
              its universal proof generation layer in September 2024, aims to encourage
              the use of ZKPs by providing a tokenized marketplace that comprises
              a supply side of equipment such as GPUs, CPUs, and FPGAs to generate
              proofs and a demand side of proof seekers. In the middle, the Fermah
              Matchmaker, which is neutral to all proof systems, uses an algorithm
              to match the supply and demand sides. By aggregating demand from various
              sources, suppliers can achieve economies of scale and reduce the costs
              of proof generation on the demand side.


              Vanishree Rao, founder of Fermah, has 15 years’ experience in designing
              and building ZKPs, was involved in development of the Mina and Midnight
              protocols, and completed a Ph.D. in cryptography at UCLA under the auspices
              of Sahai. She explained, “At Fermah, we completely take away the pain
              of proof generation and reduce the expense of generating proofs. Customers
              simply send proof requests and receive proofs that they can easily verify.”


              The company’s early customers are in the blockchain space and need ZK-rollups
              that provide a scaling solution by moving computation off-chain while
              storing transaction data on-chain and using ZKPs to validate transactions
              while increasing transaction throughput and reducing costs. There is
              more to come. “We want to generate proofs for the world and we want
              the world to embrace ZKPs on the basis of their power, capability, and
              credibility,” said Rao.


              Eli Ben-Sasson, co-founder and president of Israeli firm [StarkWare](https://starkware.co/),
              a provider of scalability, security, and privacy for blockchain applications
              using ZKPs, has been researching cryptographic and zero-knowledge proofs
              of computational integrity since he received his Ph.D. in theoretical
              computer science from the Hebrew University in 2001. He is also a co-inventor
              of the ZK-STARK, Fast Reed-Solomon IOP of Proximity (FRI), and Zerocash
              protocols, and a founding scientist of cryptocurrency firm Zcash.


              In moving beyond the use of ZKPs for privacy and security to deliver
              scalability, Ben-Sasson noted, for example, that it isn’t possible to
              poll everyone to prove the integrity of election results, but it is
              possible to ask thousands of people across the country to get a feel
              for what has happened without revealing any personal information.


              Like Ciampi, Ben-Sasson suggested a mathematical approach to integrity
              that does not require inspection of every step of a computation, and
              instead samples random locations to discover whether the computation
              has integrity, made an error, or has been manipulated in some way. “This
              is extremely efficient compared to initial processes that didn’t have
              enough computers to manage all the information,” he said.


              Further efficiencies have been achieved by using a variant of Fast Fourier
              Transform (FFT), a mathematical technique for converting a signal from
              the time domain into the frequency domain. “We have used a version of
              FFT to take on the hardest part of proof generation and make it really
              fast,” explained Ben-Sasson.


              StarkWare also uses the FRI protocol, which is now ubiquitous to blockchain,
              and ZK-STARKs, a type of ZKP that improves scalability, transparency,
              and security compared to other ZKP variants such as ZK-Snarks that require
              a trusted party to generate a common reference string that can be a
              security concern. ZK-STARKs does not require a trusted setup.


              StarkWare, as a provider of infrastructure to commercial third parties,
              also has developed Cairo, a Rust-inspired programming language that
              can be used by developers to create STARK-provable programs for general
              computation. “Blockchain and ZKPs are two technologies that innovate
              on integrity,” Ben-Sasson said. “Blockchain solves problems through
              open and transparent networks that everyone can inspect. ZKPs solve
              integrity with brilliant math.”


              While the power, potential, and practical application of ZKPs has accelerated
              over recent years, a challenge and opportunity lie ahead. As quantum
              computing gets closer to reality, current cryptography systems may prove
              vulnerable. STARKs, however, could save the day as they are considered
              the most scalable, safe, and secure post-quantum cryptography.


              ## Further Reading


              - _Ben-Sasson, E., et al._ **Scalable, transparent, and post-quantum
              secure computational integrity, _Cryptology ePrint Archive_ (2018).**


              - _Goldreich, O., Micali, S., and Wigderson, A_.


              **Proofs that Yield Nothing But their Validity or All Languages in NP
              Have Zero-Knowledge Proof Systems, _Journal of the Association for Computing
              Machinery, Vol 38_ No 1, July 1991, pp 691-72**


              - _Gur, T., O’Connor, J., and Spooner, N._


              **Perfect Zero-Knowledge PCPs for #P. In _Proceedings of the 56th Annual
              ACM Symposium on Theory of Computing_. 2024.**


              - _Thaler, J._


              **Proofs, arguments, and zero-knowledge. _Foundations and Trends® in
              Privacy and Security_ _4_: 2–4 (2022): 117-660.**


              - _Vadhan, S. P._


              **A study of statistical zero-knowledge proofs, Diss. Massachusetts
              Institute of Technology, 1999.**



              Submit an Article to CACM


              CACM welcomes unsolicited [submissions](https://cacm.acm.org/author-guidelines/#CACMsubmission)
              on topics of relevance and value to the computing community.


              You Just Read


              #### The Power and Potential of Zero-Knowledge Proofs


              [View in the ACM Digital Library](https://dl.acm.org/doi/10.1145/3735505)


              © 2025 ACM 0001-0782/25/8


              ### DOI


              10.1145/3735505


              ### August 2025 Issue


              Vol. 68 No. 8


              Pages: 11-13


              [Table of Contents](https://cacm.acm.org/issue/august-2025/)


              ### Related Reading


              - [Zero-Knowledge Proofs and Their Role within the Blockchain](https://cacm.acm.org/article/zero-knowledge-proofs-and-their-role-within-the-blockchain/)


              [Security and Privacy](https://cacm.acm.org/category/security-and-privacy/)


              - [BLOG@CACM](https://cacm.acm.org/section/blogcacm/)


              [Unlocking the Potential of Zero-Knowledge Proofs in Blockchain](https://cacm.acm.org/blogcacm/unlocking-the-potential-of-zero-knowledge-proofs-in-blockchain/)


              [Artificial Intelligence and Machine Learning](https://cacm.acm.org/category/artificial-intelligence-machine-learning/)


              - [News](https://cacm.acm.org/section/news/)


              [Learning to Trust Quantum Computers](https://cacm.acm.org/news/learning-to-trust-quantum-computers/)


              [Architecture and Hardware](https://cacm.acm.org/category/architecture-and-hardware/)


              - [Research and Advances](https://cacm.acm.org/section/research/)


              [Technical Perspective: Catching Lies (and Mistakes) in Offloaded Computation](https://cacm.acm.org/research/technical-perspective-catching-lies-and-mistakes-in-offloaded-computation/)


              [Computing Applications](https://cacm.acm.org/category/computing-applications/)



              ### Join the Discussion (0)


              #### Become a Member or Sign In to Post a Comment


              [Sign In](https://cacm.acm.org/wp-login.php?saml_sso) [Sign Up](https://accounts.acm.org/)


              [BLOG@CACM](https://cacm.acm.org/section/blogcacm/) Sep 15 2025


              [Airlines Rely on the Cloud](https://cacm.acm.org/blogcacm/airlines-rely-on-the-cloud/)


              Hazel Raoult


              [Architecture and Hardware](https://cacm.acm.org/category/architecture-and-hardware/)


              [![aerial view of clouds from an airplane window](https://cacm.acm.org/wp-content/uploads/2025/09/091225.BLOG_.Airlines-Rely-G.jpg)](https://cacm.acm.org/blogcacm/airlines-rely-on-the-cloud/)


              [News](https://cacm.acm.org/section/news/) Sep 12 2025


              [How Far Away Is Quantum Supremacy?](https://cacm.acm.org/news/how-far-away-is-quantum-supremacy/)


              Jennifer Goforth Gregory


              [Architecture and Hardware](https://cacm.acm.org/category/architecture-and-hardware/)


              [![balls of light in 3D field, illustration](https://cacm.acm.org/wp-content/uploads/2025/09/091225.News_.How-Far-Away-G.jpg)](https://cacm.acm.org/news/how-far-away-is-quantum-supremacy/)


              [News](https://cacm.acm.org/section/news/) Sep 10 2025


              [Improving Everyday Computer-Human Interactions](https://cacm.acm.org/news/improving-everyday-computer-human-interactions/)


              [Paul Marks](https://cacm.acm.org/author/paul-marks/ "Posts by Paul
              Marks")


              [Architecture and Hardware](https://cacm.acm.org/category/architecture-and-hardware/)


              [![robots holding a microphone, a wrench, and a camera](https://cacm.acm.org/wp-content/uploads/2025/09/090325.News_.Improving-Everyday.jpg)](https://cacm.acm.org/news/improving-everyday-computer-human-interactions/)


              ### Shape the Future of Computing


              ACM encourages its members to take a direct hand in shaping the future
              of the association. There are more ways than ever to get involved.


              [Get Involved](https://www.acm.org/about-acm/get-involved)


              ### Communications of the ACM (CACM) is now a fully Open Access publication.


              By opening CACM to the world, we hope to increase engagement among the
              broader computer science community and encourage non-members to discover
              the rich resources ACM has to offer.


              [Learn More](https://cacm.acm.org/news/cacm-is-becoming-open-access)'
            metadata:
              generator: WordPress 6.7.3
              favicon: https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=32
              viewport: width=device-width, initial-scale=1
              msapplication-TileImage: https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=270
              title: The Power and Potential of Zero-Knowledge Proofs – Communications
                of the ACM
              robots: max-image-preview:large
              language: en-US
              scrapeId: 129ae540-5491-42ad-863b-6cd406864785
              sourceURL: https://cacm.acm.org/news/the-power-and-potential-of-zero-knowledge-proofs/
              url: https://cacm.acm.org/news/the-power-and-potential-of-zero-knowledge-proofs/
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
          - title: '[PDF] Advances in Zero-Knowledge Proofs: Bridging the Gap between
              ...'
            description: This dissertation presents a series of novel zero-knowledge
              proof (ZKP) protocols—Libra, deVirgo,. Orion, and Pianist—each achieving
              ...
            url: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-35.pdf
            markdown: "# Advances in Zero-Knowledge Proofs: Bridging the Gap between\
              \ Theory and Practice\n\nTiancheng Xie\n\n# Electrical Engineering and\
              \ Computer Sciences University of California, Berkeley\n\nTechnical\
              \ Report No. UCB/EECS-2024-35 [http://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-35.html](http://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-35.html)\n\
              \nMay 1, 2024\n\nCopyright $\\\\circledcirc$ 2024, by the author(s).\
              \ All rights reserved.\n\nPermission to make digital or hard copies\
              \ of all or part of this work for personal or classroom use is granted\
              \ without fee provided that copies are not made or distributed for profit\
              \ or commercial advantage and that copies bear this notice and the full\
              \ citation on the first page. To copy otherwise, to republish, to post\
              \ on servers or to redistribute to lists, requires prior specific permission.\n\
              \nAdvances in Zero-Knowledge Proofs: Bridging the Gap between Theory\
              \ and Practice\n\nBy\n\nTiancheng Xie\n\nA dissertation submitted in\
              \ partial satisfaction of the\n\nrequirements for the degree of\n\n\
              Doctor of Philosophy\n\nin\n\nComputer Science\n\nin the\n\nGraduate\
              \ Division\n\nof the\n\nUniversity of California, Berkeley\n\nCommittee\
              \ in charge:\n\nProfessor Dawn Song, Chair Associate Professor Alessandro\
              \ Chiesa Associate Professor Nikhil Srivastava\n\nSpring 2023\n\nCopyright\
              \ 2023 By Tiancheng Xie\n\n# Abstract\n\nAdvances in Zero-Knowledge\
              \ Proofs: Bridging the Gap between Theory and Practice\n\nBy\n\nTiancheng\
              \ Xie\n\nDoctor of Philosophy in Computer Science\n\nUniversity of California,\
              \ Berkeley\n\nProfessor Dawn Song, Chair\n\nThis dissertation presents\
              \ a series of novel zero-knowledge proof (ZKP) protocols—Libra, deVirgo,\
              \ Orion, and Pianist—each achieving significant improvements in proof\
              \ generation speed. Zeroknowledge proofs are critical cryptographic\
              \ tools, enabling secure and privacy-preserving transactions without\
              \ revealing sensitive information. However, their practical adoption\
              \ is hindered by the inefficiency of existing proof generation methods.\n\
              \nOur research proposes four distinct protocols, each making substantial\
              \ contributions to the efficiency of ZKP generation. We begin with the\
              \ Libra protocol, which introduces a more efficient proof construction\
              \ method compared to state-of-the-art ZKPs at that time. Next, we present\
              \ the deVirgo protocol, which builds upon Libra’s design and further\
              \ optimizes proof generation by leveraging the power of parallelization.\n\
              \nThe third protocol, Orion, takes a different approach, resulting in\
              \ significant improvements in proof generation speed. We detail the\
              \ innovative design and methodology of Orion, highlighting its unique\
              \ features and performance gains.\n\nFinally, we introduce the Pianist\
              \ protocol, which employs parallel computation strategies to achieve\
              \ remarkable improvements in proof generation speed and is compatible\
              \ with existing popular protocol Plonk. Pianist builds upon the foundation\
              \ established by Plonk, while incorporating novel techniques to enhance\
              \ performance.\n\nThe dissertation includes a comprehensive comparative\
              \ analysis of the four proposed protocols, evaluating their scalability,\
              \ security, and practicality. In conclusion, our research contributes\
              \ to the field of cryptography by providing a series of innovative ZKP\
              \ protocols that significantly enhance proof generation speed, paving\
              \ the way for more widespread adoption of privacy-preserving technologies.\n\
              \n# Contents\n\nContents ii\n\nList of Figures iv\n\nList of Tables\
              \ v\n\n# Introduction 1\n\n1.1 Achieving Optimal Prover time 2\n\n1.2\
              \ Distributed Proving 3\n\n# 2 Libra: Succinct Zero-Knowledge Proofs\
              \ with Optimal Prover Computation 6\n\n2.1 Introduction 7\n\n2.2 Preliminaries\
              \ 12\n\n2.3 GKR Protocol with Linear Prover Time 20\n\n2.4 Zero-Knowledge\
              \ Argument Protocols 29\n\n2.5 Implementation and Evaluation . 39\n\n\
              # 3 Orion: Zero Knowledge Proof with Linear Prover Time\n\n# 46\n\n\
              3.1 Introduction . 47\n\n3.2 Preliminary 52\n\n3.3 Testing Algorithm\
              \ for Lossless Expander . 56\n\n3.4 Our new Zero-Knowledge Argument\
              \ 61\n\n3.5 Experiments . . 67\n\n3.6 Appendix . 71\n\n3.7 Proof of\
              \ Lemma 3.3.2 . 71\n\n3.8 Proof of Theorem 3.4.2 72\n\n3.9 Encoding\
              \ circuit . 72\n\n3.10 Proof of Theorem 3.4.3 . 73\n\n# 4 Pianist: Scalable\
              \ zkRollups via Fully Distributed Zero-Knowledge Proofs 75\n\n4.1 Introduction\
              \ . 76\n\n4.2 Preliminaries 79\n\n4.3 Constraint System And Distributed\
              \ Polynomial IOP Protocol 81\n\n4.4 Fully Distributed SNARK . 88\n\n\
              4.5 Robust Collaborative Proving System 90\n\n4.6 Experiments . 91\n\
              \n4.7 Discussions 94\n\n4.8 Proof of Theorem 4.3.3 99\n\n4.9 Proof of\
              \ Theorem 4.5.2 101\n\n# 5 zkBridge: Trustless Cross-chain Bridges Made\
              \ Practical 103\n\n5.1 Introduction 104\n\n5.2 Background 107\n\n5.3\
              \ zkBridge Protocol 110\n\n5.4 Distributed proof generation 115\n\n\
              5.5 Reducing proof size and verifier time . 126\n\n5.6 Implementation\
              \ and Evaluation . 127\n\n5.7 Related work 133\n\n# Bibliography 135\n\
              \n# List of Figures\n\n2.1 Comparisons of prover time, proof size and\
              \ verification time between Libra and existing zero-knowledge proof\
              \ systems. . 43\n\n3.1 An example of lossless expander. $\\\\begin{array}\
              \ { r } { k = 6 , k ^ { \\\\prime } = 9 , g = 3 , \\\\delta = 1 , \\\
              \\epsilon = \\\\frac { 1 } { 6 } } \\\\end{array}$ 49\n\n3.2 An illustration\
              \ of code switching. The circuit on the right for Check 1,2 and Check\
              \ 3,4 is the same. 63\n\n3.3 Running time of our expander testing algorithm.\
              \ 68\n\n3.4 Performance of polynomial commitments. 69\n\n3.5 Performance\
              \ of zero-knowledge arguments on R1CS. 70\n\n4.1 Prover time of Pianist\
              \ for zkRollups transaction verification. 97\n\n4.2 Prover time of random\
              \ circuits . 97\n\n4.3 Memory consumption of random circuit . 97\n\n\
              4.4 Comparison between the prover time of a single node in Pianist and\
              \ Plonk for sub-circuit with the same size 98\n\n5.1 The design of zkBridge\
              \ illustrated with the example of cross-chain token transfer. The components\
              \ in shade belongs to zkBridge. For clarity we only show one direction\
              \ of the bridge and the opposite direction is symmetric. . 110\n\n5.2\
              \ Prover time of deVirgo and the original Virgo for Cosmos block header\
              \ verification. . . 131\n\n# List of Tables\n\n2.1 Comparison of Libra\
              \ to existing ZKP systems, where $( \\\\mathcal { G } , \\\\mathcal\
              \ { P } , \\\\mathcal { V } , \\| \\\\pi \\| )$ denote the trusted setup\
              \ algorithm, the prover algorithm, the verification algorithm and the\
              \ proof size respectively. Also, $C$ is the size of the log-space uniform\
              \ circuit with depth $d$ , and $n$ is the size of its input. The numbers\
              \ are for a circuit computing the root of a Merkle tree with 256 leaves\
              \ (511 instances of SHA256).¹ . 9\n\n2.2 Prover time of our linear GKR\
              \ and previous GKR variants. 41\n\n3.1 Comparison to existing ZKP schemes\
              \ with linear prover time. $N$ is the size of the circuit/R1CS and $c\
              \ \\\\geq 2$ is a constant. \\* The verifier time is achieved in the\
              \ preprocessing setting. In addition, the scheme in \\[GLSTW\\] achieves\
              \ $O ( { \\\\sqrt { N } } )$ verifier for structured circuits in the\
              \ non-preprocessing setting. 48\n\n4.1 Comparisons of our schemes to\
              \ existing distributed ZKP protocols given $M$ distributed machines\
              \ on the circuit with $M$ sub-circuits and total $N$ gates, where each\
              \ sub-circuit has $\\\\begin{array} { r } { T = \\\\frac { N } { M }\
              \ } \\\\end{array}$ gates. $\\\\mathcal { P } \\_ { i }$ time denotes\
              \ the prover time per machine, Comm. denotes the total communication\
              \ among machines, $\\| \\\\pi \\|$ denotes the proof size, and $\\\\\
              nu$ time denotes the verifier time. . . 78\n\n4.2 Extra time to merge\
              \ proofs on $\\\\mathcal { P } \\_ { 0 }$ . 94\n\n5.1 The verification\
              \ circuit size of deVirgo 127\n\n5.2 Evaluation results. RV is the shorthand\
              \ for recursive verification. 130\n\n5.3 Prover hardware configuration.\
              \ 132\n\n# Acknowledgments\n\nI would like to express my deepest gratitude\
              \ to my advisor, Prof. Dawn Song, for her unwavering support, guidance,\
              \ and mentorship throughout my Ph.D. journey. Her profound expertise,\
              \ insightful feedback, and constant encouragement have been invaluable\
              \ to my research and personal growth. Prof. Song’s dedication to her\
              \ students and commitment to fostering a nurturing academic environment\
              \ have truly inspired me, and I am incredibly fortunate to have had\
              \ the opportunity to learn from such an outstanding advisor.\n\nIn addition,\
              \ I would like to extend my heartfelt appreciation to my Postdoc mentor,\
              \ Dr. Yupeng Zhang, currently an Assistant Professor at Texas A&M University.\
              \ Dr. Zhang has been instrumental in my academic development, providing\
              \ invaluable guidance and expertise as he introduced me to the field.\
              \ His enthusiasm for research, deep understanding of the subject matter,\
              \ and unwavering commitment to my success have been truly inspiring.\
              \ I am immensely grateful for his mentorship and the countless hours\
              \ he has dedicated to helping me grow both academically and professionally.\n\
              \nFurthermore, I would like to extend my sincere gratitude to Prof.\
              \ Elaine Shi from Carnegie Mellon University for her invaluable assistance\
              \ during the early stages of my research. Prof. Shi’s collaboration\
              \ and insights have greatly contributed to the development of my work,\
              \ and her guidance has been instrumental in shaping my research direction.\
              \ We have had the pleasure of coauthoring two papers, and I am truly\
              \ grateful for the knowledge and expertise she has shared with me throughout\
              \ our collaboration.\n\nI would also like to acknowledge and thank the\
              \ distinguished group of professors who have made significant contributions\
              \ as co-authors in various stages of my research. I am grateful for\
              \ the opportunity to work with Prof. Peihan Miao, Dr. Saikrishna Badrinarayanan,\
              \ Prof. Muthu Venkitasubramaniam, Prof. Carmit Hazay, Prof. Charalampos\
              \ (Babis) Papamanthou, Prof. Fan Zhang, and Prof. Dan Boneh. Each of\
              \ these esteemed scholars has provided invaluable insights, expertise,\
              \ and encouragement, greatly enriching my work and enhancing my understanding\
              \ of the field. Collaborating with such a talented and dedicated group\
              \ of researchers has been an immense privilege, and I deeply appreciate\
              \ their contributions to my academic growth.\n\nMy student co-authors:\
              \ Jiaheng Zhang, Tianyi Liu, Zhiyong Fang, Rishabh Bhadauria, and Weikai\
              \ Lin, are talented and dedicated individuals. Their passion for research,\
              \ hard work, and innovative ideas have not only enriched our collaborative\
              \ projects but also contributed to my personal growth as a researcher.\
              \ I am grateful for the opportunity to learn from and work with such\
              \ a remarkable group of students, and I look forward to witnessing their\
              \ future achievements in the field.\n\nMoreover, I am truly fortunate\
              \ to have been surrounded by an incredible group of friends throughout\
              \ my academic journey, who have provided both intellectual and emotional\
              \ support. I would like to extend a special mention to my dear friend,\
              \ co-author, and roommate, Jiaheng Zhang. His unwavering support, constant\
              \ encouragement, and dedication to our shared passion for research have\
              \ made a lasting impact on my life. Jiaheng’s camaraderie, companionship,\
              \ and brilliant mind have enriched my experiences during our time together.\n\
              \nI would like to express my heartfelt appreciation to the following\
              \ friends who have shared countless memorable moments with me, whether\
              \ it was playing games, enjoying dinner, or simply engaging in thoughtful\
              \ conversations, Bicheng Gao, Wanxin Cai, Duxing Hao, Yiwei Bai, Enze\
              \ Zhang, Yue Qiu, Zhipeng Cai, Guangxin Lyu, Fukang She, Yile Dai, Ruyang\
              \ Sun, Linjie Zhou, Youning Chen, Xiaojun Xu, Huichen Li, Xuan Zhang,\
              \ Haoming Lu, Yunqi Li, Lun Wang, Sijun Tan, Zhe Ye, Yanpei Liu, Lianmin\
              \ Zheng, Ying Sheng, Weikeng Chen, Xiaoyuan Liu, Zecong Hu, Lunjia Hu,\
              \ and Cheng Wan. A special acknowledgment goes to Lianmin Zheng and\
              \ Ying Sheng, who have not only been my roommates but also my pillars\
              \ of support during this journey.\n\nThe laughter, camaraderie, and\
              \ encouragement from this remarkable group of friends have greatly contributed\
              \ to my well-being and success, and I will cherish these friendships\
              \ for a lifetime.\n\nFinally, I would like to express my deepest love\
              \ and gratitude to my family, who have been my bedrock of support throughout\
              \ my life. To my cousin, Xuan Wan, I am grateful for the encouragement\
              \ and camaraderie we have shared. Your presence in my life has been\
              \ a source of comfort and inspiration.\n\nMost importantly, I would\
              \ like to extend my heartfelt appreciation to my parents, whose importance\
              \ in my life cannot be overstated. My father, Wenping Xie, and my mother,\
              \ Liu Yang, have always believed in me, encouraged me, and provided\
              \ unwavering love and care. Their sacrifices, guidance, and understanding\
              \ have been instrumental in shaping who I am today, and their constant\
              \ presence has been a source of strength and inspiration throughout\
              \ my academic journey. I am eternally grateful for their love and support,\
              \ and I dedicate this work to them as a testament to their unwavering\
              \ belief in my abilities.\n\n# Chapter 1\n\n# Introduction\n\nThe rapid\
              \ advancement of technology has led to a growing need for secure and\
              \ efficient cryptographic protocols, particularly in the realm of privacy-preserving\
              \ computation. Zero-knowledge proofs (ZKPs) have emerged as a powerful\
              \ cryptographic primitive, enabling one party to prove the validity\
              \ of a statement without revealing any additional information about\
              \ the underlying data. However, a major challenge in the practical deployment\
              \ of ZKPs is the efficiency of proof generation, as it has a direct\
              \ impact on the overall performance and scalability of privacy-preserving\
              \ applications.\n\nThis thesis focuses on the development and optimization\
              \ of novel techniques to significantly improve the proof generation\
              \ speed of zero-knowledge proofs. We propose a series of innovative\
              \ protocols, divided into two parts: the first part, consisting of Libra\
              \ and Orion, aims to achieve optimal prover complexity, while the second\
              \ part, comprising deVirgo and Pianist, focuses on enabling distributed\
              \ provers. These protocols leverage cutting-edge cryptographic techniques,\
              \ advanced optimizations, and novel constructions to enhance the performance\
              \ and scalability of ZKPs in real-world applications.\n\nIn the first\
              \ part of this thesis, we introduce Libra, a protocol that addresses\
              \ the existing limitations of proof generation speed by employing an\
              \ optimal GKR protocol and introducing several optimizations. We then\
              \ present Orion, which provides an optimal polynomial commitment, offering\
              \ substantial performance improvements over previous protocols and combined\
              \ with Libra, we can achieve optimal prover complexity.\n\nIn the second\
              \ part, we describe deVirgo, a protocol that builds upon the advancements\
              \ made by Libra and Orion, and focuses on enabling distributed provers.\
              \ deVirgo further improves proof generation speed by incorporating a\
              \ novel recursive composition technique. Lastly, we introduce Pianist,\
              \ a groundbreaking protocol that leverages parallelization techniques\
              \ to facilitate distributed provers, setting a new benchmark in the\
              \ field of zero-knowledge proofs.\n\nThroughout this thesis, we provide\
              \ rigorous security analysis and comprehensive performance evaluations\
              \ for each proposed protocol, demonstrating their practicality and effectiveness\
              \ in various privacy-preserving applications. By significantly improving\
              \ the proof generation speed of zeroknowledge proofs and enabling distributed\
              \ provers, our work not only advances the state-of-theart in cryptographic\
              \ research but also paves the way for more widespread adoption of privacy\n\
              \npreserving technologies across diverse domains.\n\n# 1.1 Achieving\
              \ Optimal Prover time\n\nPrevious protocols require a prover running\
              \ quasi-linear time in the statement size, and each statement needs\
              \ a separate trusted setup. They are both time-consuming. The first\
              \ part of this thesis focuses on the development and optimization of\
              \ Libra\\[XZZPS19a\\] and Orion\\[XZS22\\], two innovative zero-knowledge\
              \ proof systems that aim to achieve optimal prover complexity. These\
              \ protocols build upon cutting-edge cryptographic techniques and advanced\
              \ optimizations to improve the efficiency of proof generation in various\
              \ privacy-preserving applications. We also developed libraries of these\
              \ protocols and released codes online \\[Libb; Vira; Virb\\] for developers.\n\
              \n# 1.1.1 Libra\n\nLibra is built upon a new linear-time algorithm for\
              \ the prover of the interactive proof protocol by Goldwasser, Kalai,\
              \ and Rothblum\\[GKR15\\], also known as the GKR protocol. Additionally,\
              \ Libra employs an efficient approach to convert the GKR protocol into\
              \ a zero-knowledge proof using small masking polynomials. Notably, Libra\
              \ features a one-time trusted setup that depends only on the size of\
              \ the input to the circuit and not on the circuit logic.\n\nNot only\
              \ does Libra boast excellent asymptotic performance, but it is also\
              \ highly efficient in practice. For instance, our implementation demonstrates\
              \ that it takes only 200 seconds to generate a proof for constructing\
              \ a SHA2-based Merkle tree root on 256 leaves, outperforming all existing\
              \ zeroknowledge proof systems. Both the proof size and verification\
              \ time of Libra are highly competitive, making it a significant advancement\
              \ in the field of zero-knowledge proofs.\n\n# 1.1.2 Orion\n\nIn this\
              \ subsection, we introduce Orion, a groundbreaking zero-knowledge argument\
              \ system that achieves $O ( N )$ prover time of field operations and\
              \ hash functions, and $O ( \\\\log ^ { 2 } N )$ proof size. Orion stands\
              \ out for its concretely efficient performance, addressing the high\
              \ overhead on proof generation time that has limited the efficiency\
              \ and scalability of existing schemes with succinct proof size.\n\n\
              Our implementation of Orion demonstrates remarkable performance, with\
              \ a prover time of 3.09 seconds and a proof size of 1.5MB for a circuit\
              \ with $2 ^ { 2 0 }$ multiplication gates. Notably, the prover time\
              \ is the fastest among all existing succinct proof systems, and the\
              \ proof size is an order of magnitude smaller than a recent scheme proposed\
              \ by Golovnev et al. in 2021 \\[GLSTW\\].\n\nOrion’s efficiency improvements\
              \ can be attributed to two novel techniques. Firstly, we propose a new\
              \ algorithm for testing whether a random bipartite graph is a lossless\
              \ expander graph based on the densest subgraph algorithm. This approach\
              \ allows us to sample lossless expander with overwhelming probability,\
              \ improving the efficiency and/or security of all existing zero-knowledge\
              \ argument schemes with linear prover time. The testing algorithm based\
              \ on the densest subgraph may also be of independent interest for other\
              \ applications of expander graphs.\n\nSecondly, we develop an efficient\
              \ proof composition scheme called code switching, which reduces the\
              \ proof size from square root to polylogarithmic in the size of the\
              \ computation. This scheme is built on the encoding circuit of a linear\
              \ code and demonstrates that the witness of a second zero-knowledge\
              \ argument is the same as the message in the linear code. The proof\
              \ composition introduces only a small overhead on the prover time, further\
              \ enhancing the performance of Orion.\n\nBy combining Orion with Libra,\
              \ a fully optimal prover in terms of complexity can be achieved, significantly\
              \ advancing the field of zero-knowledge proofs.\n\n# 1.2 Distributed\
              \ Proving\n\nThe second part of this thesis presents another line of\
              \ work focused on parallelizing and distributing zero-knowledge proof\
              \ systems. In this direction, we introduce deVirgo\\[Xie+22\\], a novel\
              \ protocol that builds upon the Libra and Virgo protocols to achieve\
              \ parallel and distributed proof generation. This approach improves\
              \ the scalability and efficiency of zero-knowledge proofs, expanding\
              \ their applicability in various privacy-preserving applications.\n\n\
              deVirgo takes advantage of the strengths of both Libra and Virgo. By\
              \ parallelizing the prover and enabling distributed proof generation,\
              \ deVirgo tackles the challenges posed by large-scale computations and\
              \ high prover complexity, which have traditionally limited the practicality\
              \ of zeroknowledge proof systems.\n\nThe development of deVirgo represents\
              \ a significant advancement in the field of zero-knowledge proofs, enhancing\
              \ their performance and scalability.\n\nAnother significant protocol\
              \ is Pianist, a significant protocol built on the Plonk proof system,\
              \ leverages key features and optimizations such as bi-variate KZG\\\
              [KZG\\] commitments and Lagrangebased techniques. These innovations\
              \ make the distributed proving system more scalable and efficient.\n\
              \nThe bi-variate KZG commitments with Lagrange-based techniques aim\
              \ at reducing the size of communication between machines. As a result,\
              \ Pianist achieves a significantly reduced communication overhead of\
              \ just several kilobytes.\n\n# 1.2.1 deVirgo\n\nIn this subsection,\
              \ we delve into the details of deVirgo, a distributed SNARK protocol\
              \ designed for data-parallel circuits. Data-parallel circuits, as mentioned\
              \ earlier, consist of multiple identical sub-circuits with no connections\
              \ between them. This characteristic allows each sub-circuit to be processed\
              \ independently, providing an opportunity to accelerate proof generation\
              \ by handling them in parallel.\n\ndeVirgo is built upon the Virgo protocol\
              \ for two main reasons: firstly, Virgo does not require a trusted setup\
              \ and is plausibly post-quantum secure; secondly, Virgo is among the\
              \ fastest protocols with succinct verification time and proof size for\
              \ large-scale problems. deVirgo extends Virgo to handle data-parallel\
              \ arithmetic circuits, achieving optimal scalability without any overhead\
              \ on proof size. The protocol is specifically designed to process data-parallel\
              \ circuits with N copies using N parallel machines, resulting in N times\
              \ faster performance than the original Virgo while maintaining the same\
              \ proof size.\n\nThe deVirgo protocol operates with a master node and\
              \ several ordinary nodes, with the master node responsible for aggregating\
              \ messages and proofs from distributed machines. This setup eliminates\
              \ the need for a linear increase in proof size, which would occur if\
              \ each sub-circuit generated its proof separately. The protocol is composed\
              \ of two primary building blocks: the GKR protocol and the polynomial\
              \ commitment (PC) scheme.\n\nThe GKR protocol consists of d sumcheck\
              \ protocols for a circuit of depth d, and in the distributed sumcheck\
              \ protocol of deVirgo, the master node aggregates messages from all\
              \ machines in every round. This approach maintains the same proof size\
              \ as the original sumcheck protocol, saving a factor N over the naive\
              \ distributed protocol.\n\nIn the distributed PC protocol, the commitment\
              \ phase is optimized, allowing the master node to aggregate N commitments\
              \ into one, rather than sending N commitments directly to the verifier.\
              \ During the opening phase, the proof can also be aggregated, improving\
              \ the proof size by a logarithmic factor in the size of the polynomial.\n\
              \nBy combining these techniques, deVirgo offers a powerful and efficient\
              \ solution for processing data-parallel circuits, paving the way for\
              \ more scalable and practical zero-knowledge proof systems.\n\n# 1.2.2\
              \ Pianist\n\nIn this subsection, we introduce Pianist, a fully distributed\
              \ zero-knowledge proof (ZKP) system designed to enhance the scalability\
              \ of blockchain technologies such as zkRollups and zkEVM. One of the\
              \ primary challenges in deploying blockchains is the limited throughput\
              \ of transactions. Pianist addresses this issue by distributing the\
              \ ZKP generation process across multiple machines, significantly reducing\
              \ the burden on individual machines and improving overall efficiency.\n\
              \nPianist is built upon Plonk, a highly efficient ZKP system with a\
              \ universal trusted setup. The proposed distributed ZKP scheme enables\
              \ proof generation to be distributed across multiple participants in\
              \ a mining pool-like model. Pianist’s first protocol is tailored for\
              \ data-parallel circuits, offering a prover time complexity of $O (\
              \ T \\\\log T + M \\\\log M )$ per machine when using M machines to\
              \ process M sub-circuits of size T each. This is in contrast to the\
              \ $O ( M T \\\\log M T )$ prover time complexity of the original Plonk\
              \ on a single machine.\n\nThe protocol ensures minimal communication\
              \ among machines, with $O ( 1 )$ communication per machine. The proof\
              \ size and verifier time complexity are also $O ( 1 )$ , which is the\
              \ same as the original Plonk. Furthermore, Pianist’s second protocol,\
              \ with minor modifications, can support general circuits with arbitrary\
              \ connections while maintaining the same proving, verifying, and communication\
              \ complexities.\n\nThe Pianist system, when implemented, can generate\
              \ a proof for 8,192 transactions in just 313 seconds using 64 machines.\
              \ This represents a $6 4 \\\\mathrm { x }$ improvement in scalability\
              \ compared to the original Plonk scheme. The communication per machine\
              \ is a mere $2 . 1 \\ \\\\mathrm { K B }$ , independent of the number\
              \ of machines and circuit size. The proof size is $2 . 2 \\ \\\\mathrm\
              \ { K B }$ , and the verifier time is $3 . 5 ~ \\\\mathrm { m s }$ .\
              \ Pianist also shows similar improvements for general circuits; for\
              \ example, it takes only 5 seconds to generate a proof for a randomly\
              \ generated circuit with $2 ^ { 2 } 5$ gates using 32 machines, which\
              \ is 24.2 times faster than Plonk on a single machine.\n\nBy leveraging\
              \ Pianist’s distributed ZKP schemes, blockchain technologies can achieve\
              \ higher scalability and efficiency, enabling broader adoption in various\
              \ applications.\n\n# 1.2.3 Cross-chain bridges for blockchains\n\nIn\
              \ this subsection, we introduce zkBridge, a highly efficient and secure\
              \ cross-chain bridge designed for the increasingly diverse blockchain\
              \ ecosystem. As various blockchains coexist, cross-chain communication\
              \ becomes a crucial building block, and zkBridge aims to address this\
              \ need.\n\nExisting cross-chain bridge solutions often face performance\
              \ issues or rely on trust assumptions, which can result in compromised\
              \ security. With over 1.5 billion USD lost in attacks against bridges,\
              \ there is a pressing need for a more secure solution. zkBridge addresses\
              \ this issue by providing strong security without external trust assumptions\
              \ and using succinct proofs to guarantee correctness while reducing\
              \ on-chain verification costs.\n\nzkBridge takes advantage of the distributed\
              \ proof systems deVirgo (or use the alternative Pianist), which offer\
              \ significant performance improvements over existing solutions. By utilizing\
              \ these proof systems, zkBridge can achieve dramatically faster proof\
              \ generation speed, enabling secure and efficient cross-chain communication.\n\
              \nMoreover, the modular design of zkBridge allows it to support a wide\
              \ range of use cases and capabilities, such as message passing, token\
              \ transferring, and computational logic operating on state changes across\
              \ different chains. To demonstrate the practicality of zkBridge, a prototype\
              \ bridge from Cosmos to Ethereum was implemented, showcasing its ability\
              \ to handle large proof circuits that other systems cannot efficiently\
              \ manage. The evaluation of this prototype revealed that zkBridge achieves\
              \ practical performance, with proof generation taking less than 20 seconds\
              \ and onchain verification costing less than 230K gas. Additionally,\
              \ the implementation and evaluation of the direction from Ethereum to\
              \ other EVM-compatible chains, like BSC, further proved zkBridge’s versatility\
              \ and efficiency.\n\nOverall, zkBridge serves as an innovative and highly\
              \ effective solution for cross-chain communication in the multi-chain\
              \ ecosystem, leveraging the power of distributed proof systems like\
              \ deVirgo to ensure secure, scalable, and efficient performance.\n\n\
              # Chapter 2\n\n# Libra: Succinct Zero-Knowledge Proofs with Optimal\
              \ Prover Computation\n\nWe present Libra, the first zero-knowledge proof\
              \ system that has both optimal prover time and succinct proof size/verification\
              \ time. In particular, if $C$ is the size of the circuit being proved\
              \ (i) the prover time is $O ( C )$ irrespective of the circuit type;\
              \ (ii) the proof size and verification time are both $O ( d \\\\log\
              \ C )$ for $d$ -depth log-space uniform circuits (such as RAM programs).\
              \ In addition Libra features an one-time trusted setup that depends\
              \ only on the size of the input to the circuit and not on the circuit\
              \ logic. Underlying Libra is a new linear-time algorithm for the prover\
              \ of the interactive proof protocol by Goldwasser, Kalai and Rothblum\
              \ (also known as GKR protocol), as well as an efficient approach to\
              \ turn the GKR protocol to zero-knowledge using small masking polynomials.\
              \ Not only does Libra have excellent asymptotics, but it is also efficient\
              \ in practice. For example, our implementation shows that it takes 200\
              \ seconds to generate a proof for constructing a SHA2-based Merkle tree\
              \ root on 256 leaves, outperforming all existing zero-knowledge proof\
              \ systems. Proof size and verification time of Libra are also competitive.\n\
              \nThis work was previously published in \\[XZZPS19b\\].\n\n# 2.1 Introduction\n\
              \nZero-knowledge proofs (ZKP) are cryptographic protocols between two\
              \ parties, a prover and a verifier, in which the prover can convince\
              \ the verifier about the validity of a statement without leaking any\
              \ extra information beyond the fact that the statement is true. Since\
              \ they were first introduced by Goldwasser et al. \\[GMR89\\], ZKP protocols\
              \ have evolved from pure theoretical constructs to practical implementations,\
              \ achieving proof sizes of just hundreds of bytes and verification times\
              \ of several milliseconds, regardless of the size of the statement being\
              \ proved. Due to this successful transition to practice, ZKP protocols\
              \ have found numerous applications not only in the traditional computation\
              \ delegation setting but most importantly in providing privacy of transactions\
              \ in deployed cryptocurrencies (e.g., Zcash $\\[ { \\\\mathrm { B e\
              \ n } } + 1 4 \\] ,$ ) as well as in other blockchain research projects\
              \ (e.g., Hawk \\[KMSWP\\]).\n\nDespite such progress in practical implementations,\
              \ ZKP protocols are still notoriously hard to scale for large statements,\
              \ due to a particularly high overhead on generating the proof. For most\
              \ systems, this is primarily because the prover has to perform a large\
              \ number of cryptographic operations, such as exponentiation in an elliptic\
              \ curve group. And to make things worse the asymptotic complexity of\
              \ computing the proof is typically more than linear, e.g., $O ( C \\\
              \\log C )$ or even ${ \\\\bar { O ( C \\\\log ^ { 2 } C ) } }$ , where\
              \ $C$ is the size of the statement.\n\nUnfortunately, as of today we\
              \ are yet to construct a ZKP system whose prover time is optimal, i.e.,\
              \ linear in the size of the statement $C$ (this is irrespective of whether\
              \ the ZKP system has perstatement trusted setup, one-time trusted setup\
              \ or no trusted setup at all). The only notable exception is the recent\
              \ work by Bünz et al. \\[BBBPWM18\\] that however suffers from linear\
              \ verification time— for a detailed comparison see Table 2.1. Therefore\
              \ designing ZKP systems that enjoy linear prover time as well as succinct¹\
              \ proof size and verification time is an open problem, whose resolution\
              \ can have significant practical implications.\n\nOur contributions.\
              \ In this paper we propose Libra, the first ZKP protocol with linear\
              \ prover time and succinct proof size and verification time in the size\
              \ of the arithmetic circuit representing the statement $C$ , when the\
              \ circuit is log-space uniform. Libra is based on the doubly efficient\
              \ interactive proof protocol proposed by Goldwasser et al. in \\[GKR15\\\
              ] (referred as GKR protocol in this paper), and the verifiable polynomial\
              \ delegation scheme proposed by Zhang et al. in \\[ZGKPP17c\\]. As such\
              \ it comes with one-time trusted setup (and not per-statement trusted\
              \ setup) that depends only on the size of the input (witness) to the\
              \ statement that is being proved. Not only does Libra have excellent\
              \ asymptotic performance but also its prover outperforms in practice\
              \ all other ZKP systems while verification time and proof size are also\
              \ very competitive—see Table 2.1. Our concrete contributions are:\n\n\
              • GKR with linear prover time. Libra features a new linear-time algorithm\
              \ to generate a GKR proof. Our new algorithm does not require any pattern\
              \ in the circuit and our result subsumes all existing improvements on\
              \ the GKR prover assuming special circuit structures, such as regular\
              \ circuits in \\[Tha13a\\], data-parallel circuits in \\[Tha13a; Wah+17\\\
              ], circuits with different sub-copies in \\[ZGKPP18\\]. See related\
              \ work for more details.\n\n• Adding zero-knowledge. We propose an approach\
              \ to turn Libra into zero-knowledge efficiently. In particular, we show\
              \ a way to mask the responses of our linear-time prover with small random\
              \ polynomials such that the zero-knowledge variant of the protocol introduces\
              \ minimal overhead on the verification time compared to the original\
              \ (unmasked) construction.\n\n• Implementation and evaluation. We implement\
              \ Libra. Our implementation takes an arithmetic circuit with various\
              \ types of gates (fan-in 2 and degree $\\\\leq 2$ , such a $\\\\mathrm\
              \ { { s } } + , - , \\\\times \\\\mathrm { { , } }$ , AND, XOR, etc.)\
              \ and compiles it into a ZKP protocol. We conduct thorough comparisons\
              \ to all existing ZKP systems (see Section 2.1.1). We plan to release\
              \ our system as an open-source implementation.\n\n# 2.1.1 Comparing\
              \ to other ZKP Systems\n\nTable 2.1 shows a detailed comparison between\
              \ Libra and existing ZKP systems. First of all, Libra is the best among\
              \ all existing systems in terms of practical prover time. In terms of\
              \ asymptotics, Libra is the only system with linear prover time and\
              \ succinct verification and proof size for log-space uniform circuits.\
              \ The only other system with linear prover time is Bulletproofs \\[BBBPWM18\\\
              ] whose verification time is linear, even for log-space uniform circuits.\
              \ In the practical front, Bulletproofs prover time and verification\
              \ time are high, due to the large number of cryptographic operations\
              \ required for every gate of the circuit.\n\nThe proof and verification\
              \ of Libra are also competitive to other systems. In asymptotic terms,\
              \ our proof size is only larger than libSNARK \\[BSCTV14c\\] and Bulletproofs\
              \ \\[BBBPWM18\\], and our verification is slower than libSNARK \\[BSCTV14c\\\
              ] and libSTARK \\[BSBHR19\\]. Compared to Hyrax \\[WTSTW18\\], which\
              \ is also based on similar techniques with our work, Libra improves\
              \ the performance in all aspects (yet Hyrax does not have any trusted\
              \ setup). One can refer to Section 2.5 for a detailed description of\
              \ our experimental setting as well as a more detailed comparison.\n\n\
              Finally, among all systems, libSNARK \\[BSCTV14c\\] requires a trusted\
              \ setup for every statement, and Libra requires an one-time trusted\
              \ setup that depends on the input size. See Section 2.5.3 for a discussion\
              \ on removing trusted setup in Libra.\n\nLog-space uniform circuits.\
              \ Though the prover time in Libra is optimal for all circuits, the verification\
              \ time is succinct only when the circuit is structured (log-space uniform\
              \ with logarithmic depth). This is the best that can be achieved for\
              \ all ZKP protocols without per-circuit setup, as the verifier must\
              \ read the entire circuit, which takes linear time in the worst case.\
              \ We always refer to log-space uniform circuits when we say our scheme\
              \ is succinct in this paper, to differentiate from schemes with linear\
              \ verification time on all circuits (irrespective of whether the circuits\
              \ are log-space uniform or not). Schemes such as libSTARK \\[BSBHR19\\\
              ], zkVSQL \\[ZGKPP17a\\] and Hyrax \\[WTSTW18\\] also have such property.\n\
              \nIn practice, with the help of auxiliary input and circuit squashing,\
              \ most computations can be expressed as log-space uniform circuits with\
              \ low depth, such as matrix multiplication, image scaling and Merkle\
              \ hash tree in Section 2.5. Asymptotically, as shown in \\[BSCTV14c;\
              \ ZGKPP18; BSBHR19\\], all random memory access (RAM) programs can be\
              \ validated by circuits that are logspace uniform with log-depth in\
              \ the running time of the programs (but linear in the size of the programs)\
              \ by RAM-to-circuit reduction, which justifies the expressiveness of\
              \ such circuits.\n\nTable 2.1: Comparison of Libra to existing ZKP systems,\
              \ where $( \\\\mathcal { G } , \\\\mathcal { P } , \\\\mathcal { V }\
              \ , \\| \\\\pi \\| )$ denote the trusted setup algorithm, the prover\
              \ algorithm, the verification algorithm and the proof size respectively.\
              \ Also, $C$ is the size of the log-space uniform circuit with depth\
              \ $d$ , and $n$ is the size of its input. The numbers are for a circuit\
              \ computing the root of a Merkle tree with 256 leaves (511 instances\
              \ of SHA256).²\n\n|     |     |     |     |     |     |     |\n| ---\
              \ | --- | --- | --- | --- | --- | --- |\n|  | libSNARK \\[BSCTV14c\\\
              ]\\|\\[AHIV17\\] | Ligero | Hyrax \\[WTSTW18\\]\\[BSBHR19\\] | libSTARK\
              \ | Aurora \\[BSCRSVW19\\] | Libra |\n| 9 | O(C) per-statement trusted\
              \ setup | no trusted setupe | O(n) one-time trusted setupe |\n| P |\
              \ O(C log C) | O(C log C) | O(C log C) | O(C log? C) | O(C log C) |\
              \ O(C) |\n| V | 0(1) | O(C) | O(n + dlog C) | O(log2 C) | O(C) | O(d\
              \ log C) |\n| \\|r\\| | 0(1) | 0(C) | O(n+ dlog C) | O(log2 C) | O(log\
              \ C) | O(d log C) |\n| 9 | 1027s | NA | 210s |\n| P | 360s | 400s |\
              \ 1,041s | 2,022s | 3199s | 201s |\n| V | 0.002s | 4s | 9.9s | 0.044s\
              \ | 15.2s | 0.71s |\n| \\|r\\| | 0.13KB | 1,500KB | 185KB | 395KB |\
              \ 174.3KB | 51KB |\n\n# 2.1.2 Our Techniques\n\nOur main technical contributions\
              \ are a GKR protocol with linear prover time and an efficient approach\
              \ to turn the GKR protocol into zero-knowledge. We summarize the key\
              \ ideas behind these two contributions. The detailed protocols are presented\
              \ in Section 2.3 and 2.4 respectively.\n\nGKR with linear prover. Goldwasser\
              \ et al. \\[GKR15\\] showed an approach to model the evaluation of a\
              \ layered circuit as a sequence of summations on polynomials defined\
              \ by values in consecutive layers of the circuit. Using the famous sumcheck\
              \ protocol (see Section 2.2.3.1), they developed a protocol (the GKR\
              \ protocol) allowing the verifier to validate the circuit evaluation\
              \ in logarithmic time with a logarithmic size proof. However, the polynomials\
              \ in the protocol are multivariate with $2 s$ variables, where $S$ is\
              \ the number of gates in one layer of the circuit and $s = \\\\log S$\
              \ . Naively running the sumcheck protocol on these polynomials incurs\
              \ $S ^ { 2 }$ prover time, as there are at least $2 ^ { 2 s } = \\\\\
              bar { S } ^ { 2 }$ monomials in a $2 s$ -variate polynomial. Later,\
              \ Cormode et al. \\[CMT12\\] observed that these polynomials are sparse,\
              \ containing only $S$ nonzero monomials and improved the prover time\
              \ to $S \\\\log S$ .\n\nIn our new approach, we divide the protocol\
              \ into two separate sumchecks. In each sumcheck, the polynomial only\
              \ contains $s$ variables, and can be expressed as the product of two\
              \ multilinear polynomials. Utilizing the sparsity of the circuit, we\
              \ develop new algorithms to scan through each gate of the circuit and\
              \ compute the closed-form of all these multilinear polynomials explicitly,\
              \ which takes $O ( S )$ time. With this new way of representation, the\
              \ prover can deploy a dynamic programming technique to generate the\
              \ proofs in each sumcheck in $O ( S )$ time, resulting in a total prover\
              \ time of $O ( S )$ .\n\nEfficient zero-knowledge GKR. The original\
              \ GKR protocol is not zero-knowledge, since the messages in the proof\
              \ can be viewed as weighed sums of the values in the circuit and leak\
              \ information. In \\[ZGKPP17a; WTSTW18\\], the authors proposed to turn\
              \ the GKR protocol into zero-knowledge by hiding the messages in homomorphic\
              \ commitments, which incurs a big overhead in the verification time.\
              \ In \\[CFS17\\], Chiesa et al. proposed an alternative approach by\
              \ masking the protocol with random polynomials. However, the masking\
              \ polynomials are as big as the original ones and the prover time becomes\
              \ exponential, making the approach mainly of theoretical interest.\n\
              \nIn our scheme, we first show that in order to make the sumcheck protocol\
              \ zero-knowledge, the prover can mask it with a “small” polynomial.\
              \ In particular, the masking polynomial only contains logarithmically\
              \ many random coefficients. The intuition is that though the original\
              \ polynomial has $O ( 2 ^ { \\\\ell } )$ or more terms ( $\\\\ell$ is\
              \ the number of variables in the polynomial), the prover only sends\
              \ $O ( \\\\ell )$ messages in the sumcheck protocol. Therefore, it suffices\
              \ to mask the original polynomial with a random one with $O ( \\\\ell\
              \ )$ coefficients to achieve zero-knowledge. In particular, we set the\
              \ masking polynomial as the sum of $\\\\ell$ univariate random polynomials\
              \ with the same variable-degree. In Section 2.4.1, we show that the\
              \ entropy of this mask exactly counters the leakage of the sumcheck,\
              \ proving that it is sufficient and optimal.\n\nBesides the sumcheck,\
              \ the GKR protocol additionally leaks two evaluations of the polynomial\
              \ defined by values in each layer of the circuit. To make these evaluations\
              \ zero-knowledge, we mask the polynomial by a special low-degree random\
              \ polynomial. In particular, we show that after the mask, the verifier\
              \ in total learns 4 messages related to the evaluations of the masking\
              \ polynomial and we can prove zero-knowledge by making these messages\
              \ linearly independent. Therefore, the masking polynomial is of constant\
              \ size: it consists of 2 variables with variable degree 2.\n\n# 2.1.3\
              \ Related Work\n\nIn recent years there has been significant progress\
              \ in efficient ZKP protocols and systems. In this section, we discuss\
              \ related work in this area, with the focus on those with sublinear\
              \ proofs.\n\nQAP-based. Following earlier work of Ishai \\[IKO\\], Groth\
              \ \\[Gro10\\] and Lipmaa \\[Lip12\\], Gennaro et al. \\[GGPR13\\] introduced\
              \ quadratic arithmetic programs (QAPs), which forms the basis of most\
              \ recent implementations \\[PHGR13; BSCGTV13; BFRSBW13; BSCTV14a; $\\\
              \\mathrm { C o s } { + } 1 5$ ; WSRBW15; FFGKOP16\\] including libSNARK\
              \ \\[BSCTV14c\\]. The proof size in these systems is constant, and the\
              \ verification time depends only on the input size. Both these properties\
              \ are particularly appealing and have led to real-world deployments,\
              \ e.g., ZCash $\\[ { \\\\mathrm { B e n } } + 1 4 \\]$ . One of the\
              \ main bottlenecks, however, of QAP-based systems is the high overhead\
              \ in the prover running time and memory consumption, making it hard\
              \ to scale to large statements. In addition, a separate trusted setup\
              \ for every different statement is required.\n\nIOPs. Based on “(MPC)-in-the-head”\
              \ introduced in \\[IKOS07; GMO16; $\\\\mathrm { C h a } { + } 1 7 \\\
              ]$ , \\[AHIV17\\] proposed a ZKP scheme called Ligero. It only uses\
              \ symmetric key operations and the prover time is fast√ in practice.\
              \ However, it generates proofs of size $\\\\overset { \\\\cdot } { O\
              \ } ( \\\\sqrt { C } )$ , which is several megabytes in practice for\
              \ moderate-size circuits. In addition, the verification time is quasi-linear\
              \ to the size of the circuit. It is categorized as interactive PCP,\
              \ which is a special case of interactive oracle proofs (IOPs). IOP generalizes\
              \ the probabilistically checkable proofs (PCPs) where earlier works\
              \ of Kilian \\[Kil92\\] and Micali \\[Mic00\\] are built on. In the\
              \ IOP model, Ben-Sasson et al. built libstark \\[BSBHR19\\], a zero-knowledge\
              \ transparent argument of knowledge (zkSTARK).libstark does not rely\
              \ on trusted setup and executes in the RAM model of computation. Their\
              \ verification time is only linear to the description of the RAM program,\
              \ and succinct (logarithmic) in the time required for program execution.\
              \ Recently, Ben-Sasson et al. \\[BSCRSVW19\\] proposed Aurora, a new\
              \ ZKP system in the IOP model with the proof size of $O ( \\\\log ^\
              \ { 2 } C )$ .\n\nDiscrete log. Before Bulletproof \\[BBBPWM18\\], earlier\
              \ discrete-log based ZKP schemes include the work of Groth $\\[ \\\\\
              mathrm { G r o } 0 9 \\]$ , Bayer and Groth \\[BG12\\] and Bootle et\
              \ al. \\[BCCGP16\\]. The proof size of these schemes are larger than\
              \ Bulletproof either asymptotically or concretely.\n\nHash-based. Bootle\
              \ et al. \\[BCGGHJ17\\] proposed a ZKP scheme with linear prover time\
              \ and verification time. The verification only requires $O ( C )$ field\
              \ additions. However, the proof size is $O ( { \\\\sqrt { C } } )$ and\
              \ the constants are large as mentioned in the paper \\[BCGGHJ17\\].\n\
              \nInteractive proofs. The line of work that relates to our paper the\
              \ most is based on interactive proofs \\[GMR89\\]. In the seminal work\
              \ of \\[GKR15\\], Goldwasser et al. proposed an efficient interactive\
              \ proof for layered arithmetic circuits. Later, Cormode et al. \\[CMT12\\\
              ] improved the prover complexity of the interactive proof in \\[GKR15\\\
              ] to $O ( C \\\\log C )$ using multilinear extensions instead of low\
              \ degree extensions. Several follow-up works further reduce the prover\
              \ time assuming special structures of the circuit. For regular circuits\
              \ where the wiring pattern can be described in constant space and time,\
              \ Thaler \\[Tha13a\\] introduced a protocol with $O ( C )$ prover time;\
              \ for data parallel circuits with many copies of small circuits with\
              \ size $C ^ { \\\\prime }$ , a $O ( C \\\\log C ^ { \\\\prime } )$ protocol\
              \ is presented in the same work, later improved to $O ( C + C ^ { \\\
              \\prime } \\\\log C )$ by Wahby et al. in $\\[ \\\\mathrm { W a h }\
              \ { + } 1 7 \\]$ ; for circuits with many non-connected but different\
              \ copies, Zhang et al. showed a protocol with $O ( C \\\\log C ^ { \\\
              \\prime } )$ prover time.\n\nIn \\[ZGKPP17c\\], Zhang et al. extended\
              \ the GKR protocol to an argument system using a protocol for verifiable\
              \ polynomial delegation. Zhang et al. \\[ZGKPP18\\] and Wahby et al.\
              \ \\[WTSTW18\\] make the argument system zero-knowledge by putting all\
              \ the messages in the proof into homomorphic commitments, as proposed\
              \ by Cramer and Damgard in \\[CD98\\]. This approach introduces a high\
              \ overhead on the verification time compared to the plain argument system\
              \ without zero-knowledge, as each addition becomes a multiplication\
              \ and each multiplication becomes an exponentiation in the homomorphic\
              \ commitments. The multiplicative overhead is around two orders of magnitude\
              \ in practice. Additionally, the scheme of \\[WTSTW18\\], Hyrax, removes\
              \ the trusted setup of the argument system by introducing a new polynomial\
              \ delegation, increasing the proof size and verification time to $O\
              \ ( { \\\\sqrt { n } } )$ where $n$ is the input size of the circuit.\n\
              \nLattice-based. Recently Baum et al. \\[BBCDPGL18\\] proposed the first\
              \ lattice-based ZKP system with sub-linear proof size. The proof size\
              \ is $O ( \\\\sqrt { C \\\\log ^ { 3 } C } )$ , and the practical performance\
              \ is to be explored.\n\n# 2.2 Preliminaries\n\n# 2.2.1 Notation\n\n\
              In this paper, we use $\\\\lambda$ to denote the security parameter,\
              \ and $\\\\mathsf { n e g l } ( \\\\lambda )$ to denote the negligible\
              \ function in $\\\\lambda$ . “PPT” stands for probabilistic polynomial\
              \ time. We use $f ( ) , h ( )$ for polynomials, $x , y , z$ for vectors\
              \ of variables and $g , u , v$ for vectors of values. $x \\_ { i }$\
              \ denotes the $i$ -th variable in $x$ . We use bold letters such as\
              \ $\\\\mathbf { A }$ to represent arrays. For a multivariate polynomial\
              \ $f$ , its ”variable-degree” is the maximum degree of $f$ in any of\
              \ its variables.\n\nBilinear pairings. Let $\\\\mathbb { G } , \\\\\
              mathbb { G } \\_ { T }$ be two groups of prime order $p$ and let $g\
              \ \\\\in \\\\mathbb { G }$ be a generator. $\\\\textit { e } :$ $\\\\\
              mathbb { G } \\\\times \\\\mathbb { G } \\\\mathbb { G } \\_ { T }$\
              \ denotes a bilinear map and we use $\\\\mathsf { b p } = ( p , \\\\\
              mathbb { G } , \\\\mathbb { G } \\_ { T } , e , g ) \\\\gets \\\\mathsf\
              \ { B i l G e n } ( 1 ^ { \\\\lambda } )$ for the generation of parameters\
              \ for the bilinear map. Our scheme relies on the $q$ -Strong Bilinear\
              \ DiffieHellman ( $\\\\cdot \\\\boldsymbol { q }$ -SBDH) assumption\
              \ and an extended version of the Power Knowledge of Exponent (PKE) assumption.\n\
              \nAssumption 1 ( $\\\\dot { \\\\boldsymbol { q } }$ -Strong Bilinear\
              \ Diffie-Hellman). For any PPT adversary $\\\\mathcal { A }$ , the following\
              \ holds:\n\n$$\n\\\\begin{array} { r l } & { \\\\operatorname\\* { P\
              \ r } \\[ \\\\stackrel { \\\\mathrm { b p } \\\\mathrm { B i l } \\\\\
              mathsf { G e n } ( 1 ^ { \\\\lambda } ) } { s \\\\mathbb { Z } \\_ {\
              \ p } ^ { \\* } } \\\\quad : ( x , e ( g , g ) ^ { \\\\frac { 1 } {\
              \ s + x } } ) A ( \\\\mathrm { 1 } ^ { \\\\lambda } , \\\\sigma ) \\\
              ] \\\\leq \\\\mathsf { n e g l } ( \\\\lambda ) } \\ & { \\\\quad \\\
              \\sigma = ( \\\\mathsf { b p } , g ^ { s } , . . . , g ^ { s ^ { q }\
              \ } ) } \\\\end{array}\n$$\n\nThe second assumption is a generalization\
              \ of the $q$ -PKE assumption \\[Gro10\\] to multivariate polynomials,\
              \ proposed in \\[ZGKPP17c; ZGKPP17a\\]. Let $\\\\mathcal { W } \\_ {\
              \ \\\\ell , d }$ be the set of all multisets of ${ 1 , . . . , \\\\\
              ell }$ with the cardinality of each element being at most $d$ .\n\n\
              Assumption 2 ( $( d , \\\\ell )$ -Extended Power Knowledge of Exponent).\
              \ For any PPT adversary $\\\\mathcal { A }$ , there is a polynomial\
              \ time algorithm $\\\\mathcal { E }$ (takes the same randomness of $A$\
              \ as input) such that for all benign auxiliary inputs $z \\\\in { \\\
              \\bar { 0 } , 1 } ^ { \\\\mathsf { p o l y } ( \\\\lambda ) }$ the following\
              \ probability is negligible:\n\n$$\n{ \\\\begin{array} { r l } & { \\\
              \\mathrm { b p } \\\\ast \\\\mathrm { B i l @ e n ( 1 ) } } \\ & { s\
              \ \\_ { 1 } , \\\\ldots , s \\_ { \\\\ell } , s \\_ { \\\\ell + 1 }\
              \ , \\\\alpha \\\\xrightarrow { \\\\ell } Z \\_ { \\\\gamma } ^ { \\\
              \\ell } , s \\_ { 0 } = 1 } \\ & { \\\\sigma \\_ { 1 } = ( { g } \\\
              _ { \\\\mathrm { I } \\\\ell \\\\mathrm { W } ^ { s \\_ { i } } } ^\
              \ { \\\\ell } ) \\_ { W \\\\in \\\\mathcal { W } \\_ { \\\\ell , \\\\\
              ell } ; \\\\ell + 1 } ) } \\ { \\\\sigma \\_ { 2 } = ( { g ^ { \\\\\
              alpha } \\\\Pi \\_ { \\\\ell \\\\mathrm { W } ^ { s \\_ { i } } } }\
              \ \\_ { W \\\\in \\\\mathcal { W } \\_ { \\\\ell , \\\\ell } , g ^ {\
              \ \\\\alpha \\_ { \\\\ell + 1 } } } ) } \\ & { \\\\qquad \\\\sigma =\
              \ ( \\\\mathrm { b p } , \\\\sigma \\_ { 1 } , \\\\sigma \\_ { 2 } ,\
              \ g ^ { \\\\alpha } ) } \\ & { \\\\qquad \\\\mathbb { G } \\\\times\
              \ \\\\mathbb { G } \\\\ni ( h , \\\\tilde { h } ) \\\\gets A ( 1 ^ {\
              \ \\\\lambda } , \\\\sigma , z ) } \\ & { \\\\qquad ( a \\_ { 0 } ,\
              \ \\\\ldots , a \\_ { \\| \\\\mathcal { W } \\_ { \\\\ell , d } \\|\
              \ } , b ) \\\\gets \\\\mathcal { E } ( 1 ^ { \\\\lambda } , \\\\sigma\
              \ , z ) } \\\\end{array} \\\\quad \\\\underbrace { e ^ { \\\\alpha }\
              \ \\\\mathcal { W } ( h , g ^ { \\\\alpha } ) = e ( \\\\tilde { h }\
              \ , g ) } \\_ { W \\\\in \\\\mathcal { W } \\_ { \\\\ell , d } } } \\\
              \\mathrm { ~ s ~ n e g l } ( \\\\lambda )\n$$\n\n# 2.2.2 Interactive\
              \ Proofs and Zero-knowledge Arguments\n\nInteractive proofs. An interactive\
              \ proof allows a prover $\\\\mathcal { P }$ to convince a verifier $\\\
              \\nu$ the validity of some statement. The interactive proof runs in\
              \ several rounds, allowing $\\\\nu$ to ask questions in each round based\
              \ on $\\\\mathcal { P }$ ’s answers of previous rounds. We phrase this\
              \ in terms of $\\\\mathcal { P }$ trying to convince $\\\\nu$ that $f\
              \ ( x ) = 1$ . The proof system is interesting only when the running\
              \ time of $\\\\nu$ is less than the time of directly computing the function\
              \ $f$ . We formalize interactive proofs in the following:\n\nDefinition\
              \ 2.2.1. Let $f$ be a Boolean function. A pair of interactive machines\
              \ $\\\\langle \\\\mathcal { P } , \\\\mathcal { V } \\\\rangle$ is an\
              \ interactive proof for $f$ with soundness ϵ if the following holds:\n\
              \n• Completeness. For every $x$ such that $f ( x ) = 1$ it holds that\
              \ $\\\\operatorname\\* { P r } \\[ \\\\langle { \\\\mathcal { P } }\
              \ , \\\\mathcal { V } \\\\rangle ( x ) = a c c e p t \\] = 1 .$ . •\
              \ $\\\\epsilon$ -Soundness. For any $x$ with $f ( x ) \\\\neq 1$ and\
              \ any ${ \\\\mathcal { P } } ^ { \\* }$ it holds that $\\\\operatorname\\\
              * { P r } \\[ \\\\langle { \\\\mathcal { P } } ^ { \\* } , { \\\\mathcal\
              \ { V } } \\\\rangle = a c c e p t \\] \\\\leq \\\\epsilon$\n\nZero-knowledge\
              \ arguments. An argument system for an NP relationship $R$ is a protocol\
              \ between a computationally-bounded prover $\\\\mathcal { P }$ and a\
              \ verifier $\\\\nu$ . At the end of the protocol, $\\\\nu$ is convinced\
              \ by $\\\\mathcal { P }$ that there exists a witness $w$ such that $(\
              \ x ; w ) \\\\in R$ for some input $x$ . We focus on arguments of knowledge\
              \ which have the stronger property that if the prover convinces the\
              \ verifier of the statement validity, then the prover must know $w$\
              \ . We use $\\\\mathcal { G }$ to represent the generation phase of\
              \ the public key $\\\\mathsf { p k }$ and the verification key vk. Formally,\
              \ consider the definition below, where we assume $R$ is known to $\\\
              \\mathcal { P }$ and $\\\\nu$ .\n\nDefinition 2.2.2. Let $R$ be an NP\
              \ relation. A tuple of algorithm $( \\\\mathcal { G } , \\\\mathcal\
              \ { P } , \\\\mathcal { V } )$ is a zero-knowledge argument of knowledge\
              \ for $R$ if the following holds.\n\n• Correctness. For every $( \\\\\
              mathsf { p k } , \\\\mathsf { v k } )$ output by $\\\\mathcal { G }\
              \ ( 1 ^ { \\\\lambda } )$ and $( x , w ) \\\\in R ,$ ,\n\n$$\n\\\\langle\
              \ \\\\mathcal { P } ( \\\\mathsf { p k } , w ) , \\\\mathcal { V } (\
              \ \\\\mathsf { v k } ) \\\\rangle ( x ) = \\\\mathsf { a c c e p t }\n\
              $$\n\n• Soundness. For any PPT prover $\\\\mathcal { P }$ , there exists\
              \ a PPT extractor $\\\\varepsilon$ such that for every $( \\\\mathsf\
              \ { p k } , \\\\mathsf { v k } )$ output by $\\\\mathcal { G } ( 1 ^\
              \ { \\\\lambda } )$ and any $x$ , it holds that\n\n$$\n\\\\operatorname\\\
              * { P r } \\[ \\\\langle \\\\mathcal { P } ( \\\\mathsf { p k } ) ,\
              \ \\\\mathcal { V } ( \\\\mathsf { v k } ) \\\\rangle ( x ) = \\\\mathsf\
              \ { a c c e p t } \\\\wedge ( x , w ) \\\\notin R \\| w \\\\gets \\\\\
              varepsilon ( \\\\mathsf { p k } , x ) \\] \\\\le n e g I ( \\\\lambda\
              \ )\n$$\n\n• Zero knowledge. There exists a PPT simulator $s$ such that\
              \ for any PPT adversary $A$ , auxiliary input $z \\\\in \\\\overbar\
              \ { { { 0 , 1 } } ^ { \\\\mathsf { p o l y } ( \\\\lambda ) } $ , $(\
              \ x ; w ) \\\\in R ,$ , it holds that $\\\\begin{array} { r l } & {\
              \ \\\\mathrm { P r } \\\\left\\[ \\\\langle \\\\hat { \\\\mathcal P\
              \ } ( \\\\mathsf { p k } , w ) , \\\\hat { \\\\mathcal A } \\\\rangle\
              \ = \\\\mathsf { a c c e p t } : ( \\\\mathsf { p k } , \\\\mathsf {\
              \ v k } ) \\\\gets \\\\mathcal G ( \\\\mathsf { 1 } ^ { \\\\lambda }\
              \ ) ; ( x , w ) \\\\gets \\\\mathcal A ( z , \\\\mathsf { p k } , \\\
              \\mathsf { v k } ) \\\\right\\] = } \\ & { \\\\mathrm { P r } \\\\left\\\
              [ \\\\langle S ( \\\\mathsf { t r a p } , z , \\\\mathsf { p k } ) ,\
              \ \\\\hat { \\\\mathcal A } \\\\rangle = \\\\mathsf { a c c e p t }\
              \ : ( \\\\mathsf { p k } , \\\\mathsf { v k } , \\\\mathsf { t r a p\
              \ } ) \\\\gets S ( \\\\mathsf { 1 } ^ { \\\\lambda } ) ; ( x , w ) \\\
              \\gets A ( z , \\\\mathsf { p k } , \\\\mathsf { v k } ) \\\\right\\\
              ] } \\\\end{array}$\n\nWe say that $( \\\\mathcal { G } , \\\\mathcal\
              \ { P } , \\\\mathcal { V } )$ is a succinct argument system if the\
              \ running time of $\\\\nu$ and the total communication between $\\\\\
              mathcal { P }$ and $\\\\nu$ (proof size) are poly $( \\\\lambda , \\\
              | x \\| , \\\\log \\| w \\| )$ .\n\nProtocol 1 (Sumcheck). The protocol\
              \ proceeds in $\\\\ell$ rounds.\n\n• In the first round, $\\\\mathcal\
              \ { P }$ sends a univariate polynomial\n\n$$\nf \\_ { 1 } ( x \\_ {\
              \ 1 } ) \\\\stackrel { d e f } { = } \\\\displaystyle \\\\sum \\_ {\
              \ b \\_ { 2 } , \\\\ldots , b \\_ { \\\\ell } \\\\in { 0 , 1 } } f (\
              \ x \\_ { 1 } , b \\_ { 2 } , \\\\ldots , b \\_ { \\\\ell } ) ,\n$$\n\
              \n$\\\\nu$ checks $H = f \\_ { 1 } ( 0 ) + f \\_ { 1 } ( 1 )$ . Then\
              \ $\\\\nu$ sends a random challenge $r \\_ { 1 } \\\\in \\\\mathbb {\
              \ F }$ to $\\\\mathcal { P }$ .\n\n• In the $i$ -th round, where $2\
              \ \\\\leq i \\\\leq l - 1 , \\\\mathcal { P }$ sends a univariate polynomial\n\
              \n$$\nf \\_ { i } ( x \\_ { i } ) \\\\stackrel { d e f } { = } \\\\\
              sum \\_ { b \\_ { i + 1 } , \\\\ldots , b \\_ { \\\\ell } \\\\in { 0\
              \ , 1 } } f ( r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 } , x \\_ { i\
              \ } , b \\_ { i + 1 } , \\\\ldots , b \\_ { \\\\ell } ) ,\n$$\n\n$\\\
              \\nu$ checks $f \\_ { i - 1 } ( r \\_ { i - 1 } ) = f \\_ { i } ( 0\
              \ ) + f \\_ { i } ( 1 )$ , and sends a random challenge $r \\_ { i }\
              \ \\\\in \\\\mathbb { F }$ to $\\\\mathcal { P }$ .\n\n• In the $\\\\\
              ell$ -th round, $\\\\mathcal { P }$ sends a univariate polynomial\n\n\
              $$\n\\\\begin{array} { r } { f \\_ { \\\\ell } ( x \\_ { \\\\ell } )\
              \ \\\\overset { d e f } { = } f ( r \\_ { 1 } , r \\_ { 2 } , \\\\ldots\
              \ , r \\_ { l - 1 } , x \\_ { \\\\ell } ) , } \\\\end{array}\n$$\n\n\
              $\\\\nu$ checks $f \\_ { \\\\ell - 1 } ( r \\_ { \\\\ell - 1 } ) = f\
              \ \\_ { \\\\ell } ( 0 ) + f \\_ { \\\\ell } ( 1 )$ . The verifier generates\
              \ a random challenge $r \\_ { \\\\ell } ~ \\\\in$ $\\\\mathbb { F }$\
              \ . Given oracle access to an evaluation $f ( r \\_ { 1 } , r \\_ {\
              \ 2 } , \\\\ldots , r \\_ { \\\\ell } )$ of $f , \\\\nu$ will accept\
              \ if and only if $f \\_ { \\\\ell } ( r \\_ { \\\\ell } ) = f ( r \\\
              _ { 1 } , r \\_ { 2 } , \\\\ldots , r \\_ { \\\\ell } )$ . The instantiation\
              \ of the oracle access depends on the application of the sumcheck protocol.\n\
              \n# 2.2.3 GKR Protocol\n\nIn \\[GKR15\\], Goldwasser et al. proposed\
              \ an efficient interactive proof protocol for layered arithmetic circuits,\
              \ which we use as a building block for our new zero-knowledge argument\
              \ and is referred as the $G K R$ protocol. We present the detailed protocol\
              \ here.\n\n# 2.2.3.1 Sumcheck Protocol.\n\nThe sumcheck problem is a\
              \ fundamental problem that has various applications. The problem is\
              \ to sum a polynomial $f : \\\\mathbb { F } ^ { \\\\ell } \\\\to \\\\\
              mathbb { F }$ on the binary hypercube\n\n$$\n\\\\sum \\_ { b \\_ { 1\
              \ } , b \\_ { 2 } , . . . , b \\_ { \\\\ell } \\\\in { 0 , 1 } } f (\
              \ b \\_ { 1 } , b \\_ { 2 } , . . . , b \\_ { \\\\ell } ) .\n$$\n\n\
              Directly computing the sum requires exponential time in $\\\\ell$ ,\
              \ as there are $2 ^ { \\\\ell }$ combinations of $b \\_ { 1 } , \\\\\
              ldots , b \\_ { \\\\ell }$ . Lund et al. \\[LFKN92\\] proposed a sumcheck\
              \ protocol that allows a verifier $\\\\nu$ to delegate the computation\
              \ to a computationally unbounded prover $\\\\mathcal { P }$ , who can\
              \ convince $\\\\nu$ that $H$ is the correct sum. We provide a description\
              \ of the sumcheck protocol in Protocol 1. The proof size of the sumcheck\
              \ protocol is $O ( d \\\\ell )$ , where $d$ is the variable-degree of\
              \ $f$ , as in each round, $\\\\mathcal { P }$ sends a univariate polynomial\
              \ of one variable in $f$ , which can be uniquely defined by $d + 1$\
              \ points. The verifier time of the protocol is $O ( d \\\\ell )$ . The\
              \ prover time depends on the degree and the sparsity of $f$ , and we\
              \ will give the complexity later in our scheme. The sumcheck protocol\
              \ is complete and sound with $\\\\begin{array} { r } { \\\\epsilon =\
              \ \\\\frac { d \\\\ell } { \\| \\\\mathbb { F } \\| } } \\\\end{array}$\
              \ .\n\n# 2.2.3.2 GKR protocol\n\nUsing the sumcheck protocol as a building\
              \ block, Goldwasser et al. \\[GKR15\\] showed an interactive proof protocol\
              \ for layered arithmetic circuits.\n\nDefinition 2.2.3 (Multi-linear\
              \ Extension). Let $V : { 0 , 1 } ^ { \\\\ell } \\\\to \\\\mathbb { F\
              \ }$ be a function. The multilinear extension of $V$ is the unique polynomial\
              \ $\\\\tilde { V } : \\\\mathbb { F } ^ { l } \\\\mathbb { F }$ such\
              \ that $\\\\tilde { V } ( x \\_ { 1 } , x \\_ { 2 } , . . . , x \\_\
              \ { l } ) = V ( x \\_ { 1 } , x \\_ { 2 } , . . . , x \\_ { l } )$ for\
              \ all $x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\_ { l } \\\\in {\
              \ 0 , 1 } ^ { l }$ .\n\n$\\\\tilde { V }$ can be expressed as:\n\n$$\n\
              \\\\begin{array} { r l } & { \\\\tilde { V } ( x \\_ { 1 } , x \\_ {\
              \ 2 } , . . . , x \\_ { l } ) = \\\\sum \\_ { b \\\\in { 0 , 1 } ^ {\
              \ \\\\ell } } \\\\prod \\_ { i = 1 } ^ { l } \\[ ( ( 1 - x \\_ { i }\
              \ ) ( 1 - b \\_ { i } ) + x \\_ { i } b \\_ { i } ) \\\\cdot V ( b )\
              \ \\] } \\\\end{array}\n$$\n\nwhere $b \\_ { i }$ is $i$ -th bit of\
              \ $^ b$ .\n\nMultilinear extensions of arrays. Inspired by the close\
              \ form equation of the multilinear extension given above, we can view\
              \ an array $\\\\mathbf { A } = \\\\left( a \\_ { 0 } , a \\_ { 1 } ,\
              \ \\\\dotsc , a \\_ { n - 1 } \\\\right)$ as a function $A : { 0 , 1\
              \ } ^ { \\\\log n } \\\\to \\\\mathbb { F }$ such that $\\\\forall i\
              \ \\\\in \\[ 0 , n - 1 \\] , A ( i ) = a \\_ { i }$ . Therefore, in\
              \ this paper, we abuse the use of multilinear extension on an array\
              \ as the multilinear extension $\\\\tilde { A }$ of $A$ .\n\nHigh Level\
              \ Ideas. Let $C$ be a layered arithmetic circuit with depth $d$ over\
              \ a finite field $\\\\mathbb { F }$ . Each gate in the $i$ -th layer\
              \ takes inputs from two gates in the $( i + 1 )$ -th layer; layer 0\
              \ is the output layer and layer $d$ is the input layer. The protocol\
              \ proceeds layer by layer. Upon receiving the claimed output from $\\\
              \\mathcal { P }$ , in the first round, $\\\\nu$ and $\\\\mathcal { P\
              \ }$ run the sumcheck protocol to reduce the claim about the output\
              \ to a claim about the values in the layer above. In the $i$ -th round,\
              \ both parties reduce a claim about layer $i - 1$ to a claim about layer\
              \ $i$ through the sumcheck protocol. Finally, the protocol terminates\
              \ with a claim about the input layer $d$ , which can be checked directly\
              \ by $\\\\nu$ , or is given as an oracle access. If the check passes,\
              \ $\\\\nu$ accepts the claimed output.\n\nNotation. Before describing\
              \ the GKR protocol, we introduce some additional notations. We denote\
              \ the number of gates in the $i$ -th layer as $S \\_ { i }$ and let\
              \ $s \\_ { i } = \\\\lceil \\\\log S \\_ { i } \\\\rceil$ . (For simplicity,\
              \ we assume $S \\_ { i }$ is a power of 2, and we can pad the layer\
              \ with dummy gates otherwise.) We then define a function $V \\_ { i\
              \ } : { 0 , 1 } ^ { s \\_ { i } } \\\\to \\\\mathbb { F }$ that takes\
              \ a binary string $b \\\\in { 0 , 1 } ^ { s \\_ { i } }$ and returns\
              \ the output of gate $b$ in layer $i$ , where $b$ is called the gate\
              \ label. With this definition, $V \\_ { 0 }$ corresponds to the output\
              \ of the circuit, and $V \\_ { d }$ corresponds to the input layer.\
              \ Finally, we define two additional functions $a d d \\_ { i } , m u\
              \ l t \\_ { i } :$ ${ 0 , 1 } ^ { s \\_ { i - 1 } + 2 s \\_ { i } }\
              \ \\\\to { 0 , 1 }$ , referred as wiring predicates in the literature.\
              \ $a d d \\_ { i } \\ : ( m u l t \\_ { i } )$ takes one gate label\
              \ $z \\\\in { 0 , 1 } ^ { s \\_ { i - 1 } }$ in layer $i - 1$ and two\
              \ gate labels $x , y \\\\in { 0 , 1 } ^ { s \\_ { i } }$ in layer $i$\
              \ , and outputs 1 if and only if gate $z$ is an addition (multiplication)\
              \ gate that takes the output of gate $x , y$ as input. With these definitions,\
              \ $V \\_ { i }$ can be written as follows:\n\n$$\n\\\\begin{array} {\
              \ r } { V \\_ { i } ( z ) = \\\\displaystyle \\\\sum \\_ { x , y \\\\\
              in { 0 , 1 } ^ { s \\_ { i + 1 } } } ( a d d \\_ { i + 1 } ( z , x ,\
              \ y ) ( V \\_ { i + 1 } ( x ) + V \\_ { i + 1 } ( y ) ) } \\ { + m u\
              \ l t \\_ { i + 1 } ( z , x , y ) ( V \\_ { i + 1 } ( x ) V \\_ { i\
              \ + 1 } ( y ) ) ) } \\\\end{array}\n$$\n\nfor any $z \\\\in { 0 , 1\
              \ } ^ { s \\_ { i } }$ .\n\nIn the equation above, $V \\_ { i }$ is\
              \ expressed as a summation, so $\\\\nu$ can use the sumcheck protocol\
              \ to check that it is computed correctly. As the sumcheck protocol operates\
              \ on polynomials defined on $\\\\mathbb { F }$ , we rewrite the equation\
              \ with their multilinear extensions:\n\n$$\n\\\\begin{array} { r l }\
              \ & { \\\\tilde { V } \\_ { i } ( g ) = \\\\sum \\_ { x , y \\\\in {\
              \ 0 , 1 } ^ { s \\_ { i + 1 } } } f \\_ { i } ( x , y ) } \\ & { \\\\\
              qquad = \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } }\
              \ ( a \\\\tilde { d } d \\_ { i + 1 } ( g , x , y ) ( \\\\tilde { V\
              \ } \\_ { i + 1 } ( x ) + \\\\tilde { V } \\_ { i + 1 } ( y ) ) } \\\
              \ & { \\\\qquad + m \\\\tilde { u } l t \\_ { i + 1 } ( g , x , y )\
              \ ( \\\\tilde { V } \\_ { i + 1 } ( x ) \\\\tilde { V } \\_ { i + 1\
              \ } ( y ) ) ) , } \\\\end{array}\n$$\n\nwhere $g \\\\in \\\\mathbb {\
              \ F } ^ { s \\_ { i } }$ is a random vector.\n\nProtocol. With Equation\
              \ 2.2, the GKR protocol proceeds as follows. The prover $\\\\mathcal\
              \ { P }$ first sends the claimed output of the circuit to $\\\\nu$ .\
              \ From the claimed output, $\\\\nu$ defines polynomial $\\\\tilde {\
              \ V } \\_ { 0 }$ and computes $\\\\tilde { V } \\_ { 0 } ( g )$ for\
              \ a random $g \\\\in \\\\mathbb { F } ^ { s \\_ { 0 } }$ . $\\\\nu$\
              \ and $\\\\mathcal { P }$ then invoke a sumcheck protocol on Equation\
              \ 2.2 with $i = 0$ . As described in Section 2.2.3.1, at the end of\
              \ the sumcheck, $\\\\nu$ needs an oracle access to $f \\_ { i } ( u\
              \ , v )$ , where $u , v$ are randomly selected in $\\\\mathbb { F }\
              \ ^ { s \\_ { i + 1 } }$ . To compute $f \\_ { i } ( u , v )$ , $\\\\\
              nu$ computes $a \\\\tilde { d } d \\_ { i + 1 } ( u , v )$ and $\\ r\
              \ \\_ { m i t } \\_ { i + 1 } ( u , v )$ locally (they only depend on\
              \ the wiring pattern of the circuit, but not on the values), asks $\\\
              \\mathcal { P }$ to send $\\\\tilde { \\\\dot { V } } \\_ { 1 } ( u\
              \ )$ and $\\\\tilde { V \\_ { 1 } } ( v )$ and computes $f \\_ { i }\
              \ ( u , v )$ to complete the sumcheck protocol. In this way, $\\\\nu$\
              \ and $\\\\mathcal { P }$ reduces a claim about the output to two claims\
              \ about values in layer 1. $\\\\nu$ and $\\\\mathcal { P }$ could invoke\
              \ two sumcheck protocols on $\\\\tilde { V } \\_ { 1 } ( u )$ and $\\\
              \\tilde { V } \\_ { 1 } ( v )$ recursively to layers above, but the\
              \ number of claims and the sumcheck protocols would increase exponentially\
              \ in $d$ .\n\nCombining two claims: condensing to one claim. In \\[GKR15\\\
              ], Goldwasser et al. presented a protocol to reduce two claims $\\\\\
              tilde { V } \\_ { i } ( u )$ and $\\\\tilde { V } \\_ { i } ( v )$ to\
              \ one as following. $\\\\nu$ defines a line $\\\\gamma : \\\\mathbb\
              \ { F } \\\\mathbb { F } ^ { s \\_ { i } }$ such that $\\\\gamma ( 0\
              \ ) } = u , \\\\gamma ( 1 ) = v$ . $\\\\nu$ sends $\\\\gamma ( x )$\
              \ to $\\\\mathcal { P }$ . Then $\\\\mathcal { P }$ sends $\\\\nu$ a\
              \ degree $s \\_ { i }$ univariate polynomial $h ( x ) = \\\\tilde {\
              \ V } \\_ { i } ( \\\\gamma ( x ) )$ . $\\\\nu$ checks that $h ( 0 )\
              \ \\\\stackrel { \\\\cdot } { = } \\\\tilde { V } \\_ { i } ( u ) ,\
              \ h ( 1 ) = \\\\tilde { V } \\_ { i } ( v )$ . Then $\\\\nu$ randomly\
              \ chooses $r \\\\in \\\\mathbb { F }$ and computes a new claim $h (\
              \ r ) = \\\\tilde { V } \\_ { i } ( \\\\gamma ( r ) ) = \\\\tilde {\
              \ V } \\_ { i } ( w )$ on $w = \\\\gamma ( r ) \\\\in \\\\mathbb { F\
              \ } ^ { s \\_ { i } }$ . $\\\\nu$ sends $r , w$ to $\\\\mathcal { P\
              \ }$ . In this way, the two claims are reduced to one claim $\\\\tilde\
              \ { V } \\_ { i } ( w )$ . Combining this protocol with the sumcheck\
              \ protocol on Equation 2.2, $\\\\nu$ and $\\\\mathcal { P }$ can reduce\
              \ a claim on layer $i$ to one claim on layer $i + 1$ , and eventually\
              \ to a claim on the input, which completes the GKR protocol.\n\nCombining\
              \ two claims: random linear combination. In \\[CFS17\\], Chiesa et al.\
              \ proposed an alternative approach using random linear combinations.\
              \ Upon receiving the two claims $\\\\tilde { \\\\tilde { V } } \\_ {\
              \ i } ( u )$ and $\\\\tilde { V } \\_ { i } ( v )$ , $\\\\nu$ selects\
              \ $\\\\alpha \\_ { i } , \\\\beta \\_ { i } \\\\in \\\\mathbb { F }$\
              \ randomly and computes $\\\\alpha \\_ { i } \\\\tilde { V } \\_ { i\
              \ } ( u ) + \\\\beta \\_ { i } \\\\tilde { V } \\_ { i } ( v )$ . Based\
              \ on Equation 2.2, this\n\nrandom linear combination can be written\
              \ as\n\n$$\n\\\\begin{array} { r l } & { \\\\alpha \\_ { i } \\\\tilde\
              \ { V \\_ { i } } ( u ) + \\\\beta \\_ { i } \\\\tilde { V \\_ { i }\
              \ } ( v ) } \\ & { = \\\\alpha \\_ { i } \\\\displaystyle \\\\sum \\\
              _ { \\\\substack { x , y \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } }\
              \ ( a \\\\tilde { d } d \\_ { i + 1 } ( u , x , y ) ( \\\\tilde { V\
              \ } \\_ { i + 1 } ( x ) + \\\\tilde { V } \\_ { i + 1 } ( y ) ) + m\
              \ \\\\tilde { u } l t \\_ { i + 1 } ( u , x , y ) ( \\\\tilde { V }\
              \ \\_ { i + 1 } ( x ) \\\\tilde { V } \\_ { i - 1 } ( y ) ) } \\ & {\
              \ + \\\\beta \\_ { i } \\\\displaystyle \\\\sum \\_ { \\\\substack {\
              \ x , y \\\\in { 0 , 1 } ^ { s \\_ { i } } + 1 } } ( a \\\\tilde { d\
              \ } d \\_ { i + 1 } ( v , x , y ) ( \\\\tilde { V } \\_ { i + 1 } (\
              \ x ) + \\\\tilde { V } \\_ { i + 1 } ( y ) ) + m \\\\tilde { u } l\
              \ t \\_ { i + 1 } ( v , x , y ) ( \\\\tilde { V } \\_ { i + 1 } ( x\
              \ ) \\\\tilde { V } \\_ { i + 1 } ( y ) ) } \\ & { = \\\\displaystyle\
              \ \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { i } } + 1 } ( ( \\\
              \\alpha \\_ { i } a \\\\tilde { d } d \\_ { i + 1 } ( u , x , y ) +\
              \ \\\\beta \\_ { i } a \\\\tilde { d } d \\_ { i + 1 } ( v , x , y )\
              \ ) ( \\\\tilde { V } \\_ { i + 1 } ( x ) + \\\\tilde { V } \\_ { i\
              \ + 1 } ( y ) ) } \\ & { \\\\quad \\\\times \\_ { j \\\\in { 0 , 1 }\
              \ ^ { s \\_ { i } } + 1 } ( \\\\kappa \\_ { i } m \\\\tilde { u } l\
              \ t \\_ { i + 1 } ( u , x , y ) + \\\\beta \\_ { i } m \\\\tilde { u\
              \ } l t \\_ { i + 1 } ( v , x , y ) ) ( \\\\tilde { V } \\_ { i + 1\
              \ } ( x ) \\\\tilde { V } \\_ { i + 1 } ( y ) ) } \\ & { \\\\quad +\
              \ \\\\left( \\\\alpha \\_ { i } m \\\\tilde { u } l t \\_ { i + 1 }\
              \ ( u , x , y ) + \\\\beta \\_ { i } m \\\\tilde { u } l t \\_ { i +\
              \ 1 } ( v , x , y ) \\\\right) ( \\\\tilde { V } \\_ { i + 1 } ( x )\
              \ \\\\tilde { V } \\_ { i + 1 } ( y ) ) ) } \\ \\\\end{array}\n$$\n\n\
              $\\\\nu$ and $\\\\mathcal { P }$ then execute the sumcheck protocol\
              \ on Equation 2.3 instead of Equation 2.2. At the end of the sumcheck\
              \ protocol, $\\\\nu$ still receives two claims about $\\\\tilde { V\
              \ } \\_ { i + 1 }$ , computes their random linear combination and proceeds\
              \ to an layer above recursively until the input layer.\n\nIn our new\
              \ ZKP scheme, we will mainly use the second approach. The full GKR protocol\
              \ using random linear combinations is given in Protocol 2.\n\nTheorem\
              \ 2.2.4. \\[VSBW13\\]\\[Tha13a\\]\\[CMT12\\]\\[GKR15\\]. Let $C : \\\
              \\mathbb { F } ^ { n } \\\\to \\\\mathbb { F } ^ { k }$ be a depth-\
              \ $d$ layered arithmetic circuit. Protocol 2 is an interactive proof\
              \ for the function computed by $C$ with soundness $O ( d \\\\log \\\
              | C \\| / \\| \\\\mathbb { F } \\| )$ . It uses $O ( d \\\\log \\| C\
              \ \\| )$ rounds of interaction and running time of the prover $\\\\\
              mathcal { P }$ is $O ( \\| C \\| \\\\log \\| C \\| )$ . Let the optimal\
              \ computation time for all $a \\\\tilde { d } d \\_ { i }$ and mul˜\
              \ $t \\_ { i }$ be $T$ , the running time of $\\\\nu$ is $O ( n + k\
              \ + d \\\\log \\| C \\| + T )$ . For log-space uniform circuits it is\
              \ $T = { \\\\mathsf { p o l y l o g } } \\\\left\\| C \\\\right\\|$\
              \ .\n\nProtocol 2. Let $\\\\mathbb { F }$ be a prime field. Let $C$\
              \ : $\\\\mathbb { F } ^ { n } \\\\to \\\\mathbb { F } ^ { k }$ be a\
              \ $d$ -depth layered arithmetic circuit. $\\\\mathcal { P }$ wants to\
              \ convince that o $\\\\mathsf { u t } = C ( \\\\mathsf { i n } )$ where\
              \ in is the input from $\\\\nu$ , and out is the output. Without loss\
              \ of generality, assume $n$ and $k$ are both powers of 2 and we can\
              \ pad them if not.\n\n• Define the multilinear extension of array out\
              \ as $\\\\tilde { V } \\_ { 0 }$ . $\\\\nu$ chooses a random $\\\\boldsymbol\
              \ { g } \\\\in \\\\mathbb { F } ^ { s \\_ { 0 } }$ and sends it to $\\\
              \\mathcal { P }$ . Both parties compute $\\\\tilde { V \\_ { 0 } } (\
              \ g )$ .\n\n• $\\\\mathcal { P }$ and $\\\\nu$ run a sumcheck protocol\
              \ on\n\n$$\n\\\\tilde { V } \\_ { 0 } ( g ^ { ( 0 ) } ) = \\\\sum \\\
              _ { x , y \\\\in { 0 , 1 } ^ { s \\_ { 1 } } } { m \\\\tilde { u } l\
              \ t \\_ { 1 } ( g ^ { ( 0 ) } , x , y ) ( \\\\tilde { V } \\_ { 1 }\
              \ ( x ) \\\\tilde { V } \\_ { 1 } ( y ) ) + a \\\\tilde { d } d \\_\
              \ { 1 } ( g ^ { ( 0 ) } , x , y ) ( \\\\tilde { V } \\_ { 1 } ( x )\
              \ + \\\\tilde { V } \\_ { 1 } ( y ) ) }\n$$\n\nAt the end of the protocol,\
              \ $\\\\nu$ receives $\\\\tilde { V } \\_ { 1 } ( u ^ { ( 1 ) } )$ and\
              \ $\\\\tilde { V } \\_ { 1 } ( v ^ { ( 1 ) } )$ . $\\\\nu$ computes\
              \ $m \\\\tilde { u } l t \\_ { 1 } ( g ^ { ( 0 ) } , u ^ { ( 1 ) } ,\
              \ v ^ { ( 1 ) } )$ $a \\\\tilde { d } d \\_ { 1 } ( g ^ { ( 0 ) } ,\
              \ u ^ { ( 1 ) } , v ^ { ( \\\\bar { 1 } ) } )$ and checks that $\\\\\
              begin{array} { r l } { \\\\tilde { m u l t } \\_ { 1 } ( g ^ { ( 0 )\
              \ } , u ^ { ( 1 ) } , v ^ { ( 1 ) } ) \\\\tilde { V } \\_ { 1 } ( u\
              \ ^ { ( 1 ) } ) \\\\tilde { V } \\_ { 1 } ( v ^ { ( 1 ) } ) } & { {\
              \ } + } \\\\end{array}$ $a \\\\tilde { d } d \\_ { 1 } ( g ^ { ( 0 )\
              \ } , u ^ { ( 1 ) } , v ^ { ( 1 ) } ) ( \\\\tilde { V } \\_ { 1 } (\
              \ u ^ { ( 1 ) } ) + \\\\tilde { V } \\_ { 1 } ( v ^ { ( 1 ) } ) )$ equals\
              \ to the last message of the sumcheck.\n\n• For $i = 1 , . . . , d -\
              \ 1$ :\n\n– $\\\\nu$ randomly selects $\\\\alpha ^ { ( i ) } , \\\\\
              beta ^ { ( i ) } \\\\in \\\\mathbb { F }$ and sends them to $\\\\mathcal\
              \ { P }$ . – $\\\\mathcal { P }$ and $\\\\nu$ run the sumcheck on the\
              \ equation\n\n$$\n\\\\begin{array} { l } { { \\\\alpha ^ { ( i ) } \\\
              \\dot { V } \\_ { i } ( u ^ { ( i ) } ) + \\\\beta ^ { ( i ) } \\\\\
              dot { V } \\_ { i } ( v ^ { ( i ) } ) = } } \\ { { \\\\displaystyle\
              \ \\\\sum \\_ { \\\\substack { x , y \\\\in { 0 , 1 } ^ { s \\_ { i\
              \ + 1 } } } } ( ( \\\\alpha ^ { ( i ) } m \\\\tilde { u } l t \\_ {\
              \ i + 1 } ( u ^ { ( i ) } , x , y ) + \\\\beta ^ { ( i ) } m \\\\tilde\
              \ { u } l t \\_ { i + 1 } ( v ^ { ( i ) } , x , y ) ) ( \\\\tilde {\
              \ V } \\_ { i + 1 } ( x ) \\\\tilde { V } \\_ { i + 1 } ( y ) ) } }\
              \ \\ { { \\\\displaystyle \\\\qquad + ( \\\\alpha ^ { ( i ) } a \\\\\
              tilde { d } d \\_ { i + 1 } ( u ^ { ( i ) } , x , y ) + \\\\beta ^ {\
              \ ( i ) } a \\\\tilde { d } d \\_ { i + 1 } ( v ^ { ( i ) } , x , y\
              \ ) ) ( \\\\tilde { V } \\_ { i + 1 } ( x ) + \\\\tilde { V } \\_ {\
              \ i + 1 } ( y ) ) } } \\\\end{array}\n$$\n\n– At the end of the sumcheck\
              \ protocol, $\\\\mathcal { P }$ sends $\\\\mathcal { V } \\\\tilde {\
              \ V } \\_ { i + 1 } ( u ^ { ( i + 1 ) } )$ and $\\\\tilde { V } \\_\
              \ { i + 1 } ( v ^ { ( i + 1 ) } )$\n\n$\\\\textsuperscript { - \\\\\
              gamma }$ computes the right hand side of the above equation by replacing\
              \ $x$ and $y$ by $\\\\boldsymbol u ^ { ( i + 1 ) }$ and $\\\\boldsymbol\
              \ { v } ^ { ( i + 1 ) }$ respectively, and checks if it equals to the\
              \ last message of the sumcheck. If all checks in the sumcheck pass,\
              \ $V$ uses $\\\\tilde { V } \\_ { i + 1 } ( u ^ { ( \\\\bar { i } +\
              \ 1 ) } )$ and $\\\\tilde { V } \\_ { i + 1 } ( v ^ { ( i + 1 ) } )$\
              \ to proceed to the $( i + 1 )$ -th layer. Otherwise, $\\\\nu$ outputs\
              \ reject and aborts.\n\n• At the input layer $d , \\\\nu$ has two claims\
              \ $\\\\tilde { V } \\_ { d } ( u ^ { ( d ) } )$ and $\\\\tilde { V }\
              \ \\_ { d } ( v ^ { ( d ) } )$ . $\\\\nu$ queries the oracle of evaluations\
              \ of $\\\\tilde { V \\_ { d } }$ at $\\\\boldsymbol u ^ { ( d ) }$ and\
              \ $v ^ { ( d ) }$ and checks that they are the same as the two claims.\
              \ If yes, output accept; otherwise, output reject.\n\n# 2.2.4 Zero-Knowledge\
              \ Verifiable Polynomial Delegation Scheme\n\nLet $\\\\mathbb { F }$\
              \ be a finite field, $\\\\mathcal { F }$ be a family of $\\\\ell \\\\\
              cdot$ -variate polynomial over $\\\\mathbb { F }$ , and $d$ be a variable-degree\
              \ parameter. A zero-knowledge verifiable polynomial delegation scheme\
              \ (zkVPD) for $f \\\\in { \\\\mathcal { F } }$ and $t \\\\in \\\\mathbb\
              \ { F } ^ { \\\\ell }$ consists of the following algorithms:\n\n$$\n\
              \\\\begin{array} { r l } & { \\\\bullet \\\\quad ( \\\\mathsf { p p\
              \ } , \\\\mathsf { v p } ) \\\\gets \\\\mathsf { K e y G e n } ( 1 ^\
              \ { \\\\lambda } , \\\\ell , d ) , } \\ & { \\\\bullet \\\\quad \\\\\
              mathsf { c o m } \\\\gets \\\\mathsf { C o m m i t } ( f , r \\_ { f\
              \ } , \\\\mathsf { p p } ) , } \\ & { \\\\bullet \\\\quad { \\\\mathsf\
              \ { a c c e p t } , \\\\mathsf { r e j e c t } } \\\\gets \\\\mathsf\
              \ { C h e c k C o m m } ( \\\\mathsf { c o m } , \\\\mathsf { v p }\
              \ ) , } \\ & { \\\\bullet \\\\quad ( y , \\\\pi ) \\\\gets \\\\mathsf\
              \ { O p e n } ( f , t , r \\_ { f } , \\\\mathsf { p p } ) , } \\ &\
              \ { \\\\bullet \\\\quad { \\\\mathsf { a c c e p t } , \\\\mathsf {\
              \ r e j e c t } } \\\\gets \\\\mathsf { V e r i f y } ( \\\\mathsf {\
              \ c o m } , t , y , \\\\pi , \\\\mathsf { v p } ) . } \\\\end{array}\n\
              $$\n\nA zkVPD scheme satisfies correctness, soundness and zero knowledge,\
              \ which we formally define below.\n\nDefinition 2.2.5. Let $\\\\mathbb\
              \ { F }$ be a finite field, $\\\\mathcal { F }$ be a family of $\\\\\
              ell$ -variate polynomial over $\\\\mathbb { F }$ , and d be a variabledegree\
              \ parameter. A zero-knowledge verifiable polynomial delegation scheme\
              \ (zkVPD) consists of the following algorithms: $( \\\\mathsf { p p\
              \ } , \\\\mathsf { v p } ) \\\\gets \\\\mathsf { K e y G e n } ( 1 ^\
              \ { \\\\lambda } , \\\\ell , d )$ , $\\\\mathsf { c o m } \\\\gets \\\
              \\mathsf { C o m m i t } ( f , r \\_ { f } , \\\\mathsf { p p } )$ ,\n\
              \n${ \\\\mathsf { a c c e p t } , \\\\mathsf { r e j e c t } } \\\\\
              gets \\\\mathsf { C h e c k C o m m } ( \\\\mathsf { c o m } , \\\\\
              mathsf { v p } )$ , $( y , \\\\pi ) \\\\gets \\\\mathsf { O p e n }\
              \ ( f , t , r \\_ { f } , \\\\mathsf { p p } ) ,$ , ${ \\\\mathsf {\
              \ a c c e p t } , \\\\mathsf { r e j e c t } } \\\\gets \\\\mathsf {\
              \ V e r i f y }$ $( \\\\mathsf { c o m } , t , y , \\\\pi , \\\\mathsf\
              \ { v p } )$ , such that\n\n• Perfect Completeness For any polynomial\
              \ $f \\\\in { \\\\mathcal { F } }$ and value $t ,$ , the following probability\
              \ is $I$ .\n\n$$\n\\\\operatorname\\* { P r } \\_ { r \\_ { f } } \\\
              \\left\\[ \\\\begin{array} { c c } { ( \\\\mathsf { p p } , \\\\mathsf\
              \ { v p } ) \\\\gets \\\\mathsf { K e y G e n } ( 1 ^ { \\\\lambda }\
              \ , \\\\ell , d ) } & \\ { \\\\mathsf { c o m } \\\\gets \\\\mathsf\
              \ { C o m m i t } ( f , r \\_ { f } , \\\\mathsf { p p } ) : } & { \\\
              \\mathsf { C h e c k C o m m } ( \\\\mathsf { c o m } , \\\\mathsf {\
              \ v p } ) = \\\\mathsf { a c c e p t } \\ \\\\wedge } \\ { ( y , \\\\\
              pi ) \\\\gets \\\\mathsf { O p e n } ( f , t , r \\_ { f } , \\\\mathsf\
              \ { p p } ) } & { \\\\mathsf { V e r i f y } ( \\\\mathsf { c o m }\
              \ , t , y , \\\\pi , \\\\mathsf { v p } ) = \\\\mathsf { a c c e p t\
              \ } } \\\\end{array} \\\\right\\]\n$$\n\n• Binding For any PPT adversary\
              \ $\\\\mathcal { A }$ and benign auxiliary input $z \\_ { 1 } , z \\\
              _ { 2 }$ the following probability is negligible of $\\\\lambda$ :\n\
              \n$$\n\\\\begin{array} { r } { \\\\operatorname\\* { P r } \\[ ( \\\\\
              mathfrak { p p } , \\\\mathfrak { v p } ) \\\\mathsf { K e y G e n }\
              \ ( 1 ^ { \\\\lambda } , \\\\ell , d ) \\\\qquad \\\\mathsf { C h e\
              \ c k C o m m } ( \\\\mathrm { c o m } ^ { \\\\ast } , \\\\mathfrak\
              \ { v p } ) = \\\\mathsf { a c c e p t } \\\\wedge \\] } \\ { ( \\\\\
              pi ^ { \\\\ast } , \\\\mathsf { c o m } ^ { \\\\ast } , y ^ { \\\\ast\
              \ } , s t a t e ) A ( 1 ^ { \\\\lambda } , z \\_ { 1 } , \\\\mathfrak\
              \ { p p } ) : \\\\quad \\\\mathsf { V e r i f y } ( \\\\mathsf { c o\
              \ m } ^ { \\\\ast } , t ^ { \\\\ast } , y ^ { \\\\ast } , \\\\pi ^ {\
              \ \\\\ast } , \\\\mathfrak { v p } ) = \\\\mathsf { a c c e p t } \\\
              \\wedge } \\ { ( f ^ { \\\\ast } , t ^ { \\\\ast } , r \\_ { f } ^ {\
              \ \\\\ast } ) A ( 1 ^ { \\\\lambda } , z \\_ { 2 } , s t a t e , \\\\\
              mathfrak { p p } ) \\\\qquad \\\\mathsf { c o m } ^ { \\\\ast } = \\\
              \\mathsf { C o m m i t } ( f ^ { \\\\ast } , r \\_ { f } ^ { \\\\ast\
              \ } , \\\\mathfrak { p p } ) \\\\wedge \\\\qquad } \\ { ( y ^ { \\\\\
              ast } , \\\\pi ^ { \\\\ast } ) = \\\\mathsf { O p e n } ( f ^ { \\\\\
              ast } , t ^ { \\\\ast } , r \\_ { f } ^ { \\\\ast } , \\\\mathfrak {\
              \ p p } ) \\\\wedge } \\ { f ^ { \\\\ast } ( t ^ { \\\\ast } ) \\\\\
              neq y ^ { \\\\ast } \\] } \\\\end{array}\n$$\n\n• Zero Knowledge For\
              \ security parameter $\\\\lambda$ , polynomial $f$ , adversary $\\\\\
              mathcal { A }$ , and simulator $\\\\boldsymbol { s }$ , consider the\n\
              \nfollowing two experiments:\n\n${ \\\\mathsf { R e a l } } \\_ { \\\
              \\mathcal { A } , f } ( 1 ^ { \\\\lambda } ) .$ $I . ~ ( \\\\mathsf\
              \ { p p } , \\\\mathsf { v p } ) \\\\gets \\\\mathsf { K e y G e n }\
              \ ( 1 ^ { \\\\lambda } , \\\\ell , d )$ 2. $\\\\mathsf { c o m } \\\\\
              gets \\\\mathsf { C o m m i t } ( f , r \\_ { f } , \\\\mathsf { p p\
              \ } )$ 3. $k A ( 1 ^ { \\\\lambda } , \\\\mathsf { c o m } , \\\\mathsf\
              \ { v p } )$ 4. For $i = 1 , . . . , k$ repeat 5. 6.\n\n$\\\\mathsf\
              \ { I d e a l } \\_ { \\\\mathcal { A } , S } ( 1 ^ { \\\\lambda } )$\n\
              \n$$\nI . \\ ( \\\\mathsf { c o m } , \\\\mathsf { p p } , \\\\mathsf\
              \ { v p } , \\\\sigma ) \\\\gets \\\\mathsf { S i m } ( 1 ^ { \\\\lambda\
              \ } , \\\\ell , d )\n$$\n\n2. $k A ( 1 ^ { \\\\lambda } , \\\\mathsf\
              \ { c o m } , \\\\mathsf { v p } )$\n\n3. For $i = 1 , . . . , k$ repeat:\n\
              \n\n$$\n\\\\begin{array} { r l } & { \\\\begin{array} { l } { \\\\cdots\
              \ \\\\cdots \\\\cdots , \\\\cdots , \\\\cdots \\\\cdots \\\\operatorname\
              \ { s r e s e } } \\ { a ) } \\\\end{array} } \\ & { \\\\begin{array}\
              \ { l } { \\\\quad = \\\\begin{array} { l } { t \\_ { i } \\\\mathcal\
              \ { A } ( 1 ^ { \\\\lambda } , \\\\mathsf { c o m } , y \\_ { 1 } ,\
              \ \\\\ldots , y \\_ { i - 1 } , \\\\pi \\_ { 1 } , } \\ { \\\\cdots\
              \ , \\\\pi \\_ { i - 1 } , \\\\mathsf { v p } ) } \\ { b ) } \\\\end{array}\
              \ } \\ & { \\\\begin{array} { l } { \\\\displaystyle = b } \\\\end{array}\
              \ } \\ & { \\\\begin{array} { l } { \\\\displaystyle \\\\jmath \\_ {\
              \ i } , \\\\pi \\_ { i } ) \\\\mathrm { O p e n } ( f , t \\_ { i }\
              \ , r \\_ { f } , \\\\mathsf { p p } ) } \\ { \\\\displaystyle \\\\\
              jmath \\_ { \\* } \\\\mathcal { A } ( 1 ^ { \\\\lambda } , \\\\mathsf\
              \ { c o m } , ( y \\_ { 1 } , \\\\ldots , y \\_ { k } , \\\\pi \\_ {\
              \ 1 } , \\\\ldots , \\\\pi \\_ { k } ) , \\\\mathsf { v p } ) } \\ {\
              \ \\\\displaystyle \\\\jmath \\_ { u t p u t } b } \\\\end{array} }\
              \ \\\\end{array} } \\\\end{array} \\\\begin{array} { l } { \\\\begin{array}\
              \ { r l } { a ) \\ t \\_ { i } \\\\mathcal { A } ( 1 ^ { \\\\lambda\
              \ } , \\\\mathsf { c o m } , y \\_ { 1 } , \\\\ldots , y \\_ { i - 1\
              \ } , \\\\pi \\_ { 1 } , } \\ { \\\\cdots , \\\\pi \\_ { i - 1 } , \\\
              \\mathsf { v p } ) } \\ { b ) \\ ( y \\_ { i } , \\\\pi \\_ { i } ,\
              \ \\\\sigma ) \\\\mathsf { S i m } ( t \\_ { i } , \\\\sigma , \\\\\
              mathsf { p p } ) } \\ { \\\\displaystyle q \\_ { \\\\star } \\ b \\\\\
              mathcal { A } ( 1 ^ { \\\\lambda } , \\\\mathsf { c o m } , ( y \\_\
              \ { 1 } , \\\\ldots , y \\_ { k } , \\\\pi \\_ { 1 } , \\\\ldots , \\\
              \\pi \\_ { k } ) , \\\\mathsf { v p } ) } \\ { \\\\leq \\\\mathscr {\
              \ A } ( 1 ^ { \\\\lambda } , \\\\mathsf { c o m } , ( y \\_ { 1 } ,\
              \ \\\\ldots , y \\_ { k } , \\\\pi \\_ { 1 } , \\\\ldots , \\\\pi \\\
              _ { k } ) , } \\\\end{array} } \\\\end{array}\n$$\n\nFor any PPT adversary\
              \ $\\\\mathcal { A }$ and all polynomial $f \\\\in \\\\mathbb { F }$\
              \ , there exists simulator $s$ such that\n\n$$\n\\| \\\\operatorname\\\
              * { P r } \\[ \\\\mathsf { R e a l } \\_ { A , f } ( \\\\mathsf { 1\
              \ } ^ { \\\\lambda } ) = \\\\mathsf { 1 } \\] - \\\\operatorname\\*\
              \ { P r } \\[ \\\\mathsf { I d e a l } \\_ { A , S } ( \\\\mathsf {\
              \ 1 } ^ { \\\\lambda } ) = \\\\mathsf { 1 } \\] \\| \\\\leq \\\\mathsf\
              \ { n e g l } ( \\\\lambda ) .\n$$\n\n# 2.3 GKR Protocol with Linear\
              \ Prover Time\n\nIn this section we present a new algorithm (see Algorithm\
              \ 6) for the prover of the GKR protocol \\[GKR15\\] that runs in linear\
              \ time for arbitrary layered circuits. Before that, we present some\
              \ necessary building blocks.\n\n# 2.3.1 Linear-time sumcheck for a multilinear\
              \ function \\[Tha13a\\]\n\nIn \\[Tha13a\\], Thaler proposed a linear-time\
              \ algorithm for the prover of the sumcheck protocol on a multilinear\
              \ function $f$ on $\\\\ell$ variables (the algorithm runs in $O ( 2\
              \ ^ { \\\\ell } )$ time). We review this algorithm here. Recall that\
              \ in the $i$ -th round of the sumcheck protocol the prover sends the\
              \ verifier the univariate polynomial on $x \\_ { i }$\n\n$$\n\\\\sum\
              \ \\_ { b \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } , \\\\in { 0\
              \ , 1 } } f ( r \\_ { 1 } , \\\\dots , r \\_ { i - 1 } , x \\_ { i }\
              \ , b \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } ) ,\n$$\n\nwhere\
              \ $r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 }$ are random values chosen\
              \ by the verifier in previous rounds. Since $f$ is multilinear, it suffices\
              \ for the prover to send two evaluations of the polynomial at points\
              \ $t = 0$ and $t = 1$ , namely the evaluations\n\n$$\n\\\\sum \\_ {\
              \ b \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } , \\\\in { 0 , 1 }\
              \ } f ( r \\_ { 1 } , \\\\dots , r \\_ { i - 1 } , 0 , b \\_ { i + 1\
              \ } , \\\\dots , b \\_ { \\\\ell } )\n$$\n\nand\n\n$$\n\\\\sum \\_ {\
              \ b \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } , \\\\in { 0 , 1 }\
              \ } f ( r \\_ { 1 } , \\\\dots , r \\_ { i - 1 } , 1 , b \\_ { i + 1\
              \ } , \\\\dots , b \\_ { \\\\ell } ) .\n$$\n\nAlgorithm 1 $\\\\mathcal\
              \ { F } $ FunctionEvaluations(f, A, r1, . . . , rℓ)\n\nInput: Multilinear\
              \ $f$ on $\\\\ell$ variables, initial bookkeeping table $\\\\mathbf\
              \ { A }$ , random $r \\_ { 1 } , \\\\ldots , r \\_ { \\\\ell }$ ;\n\n\
              Output: All function evaluations $f ( r \\_ { 1 } , \\\\dots , r \\\
              _ { i - 1 } , t , b \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } )$\
              \ ;\n\n1: for $i = 1 , \\\\ldots , \\\\ell \\\\mathbf { d o }$\n\n2:\
              \ for $b \\\\in { 0 , 1 } ^ { \\\\ell - i } { \\\\mathfrak { c } }$\
              \ do $\\\\triangleright b$ is both a number and its binary representation.\n\
              \n3: for $t = 0 , 1 , 2$ do\n\n4: Let $f ( r \\_ { 1 } , \\\\dots ,\
              \ r \\_ { i - 1 } , t , b ) = \\\\mathbf { A } \\[ b \\] \\\\cdot (\
              \ 1 - t ) + \\\\mathbf { A } \\[ b + 2 ^ { \\\\ell - i } \\] \\\\cdot\
              \ t$\n\n5: end for\n\n6: $\\\\mathbf { A } \\[ b \\] = \\\\mathbf {\
              \ A } \\[ b \\] \\\\cdot ( 1 - r \\_ { i } ) + \\\\mathbf { A } \\[\
              \ b + 2 ^ { \\\\ell - i } \\] \\\\cdot r \\_ { i }$\n\n7: end for\n\n\
              8: end for\n\n9: Let $\\\\mathcal { F }$ contain all function evaluations\
              \ $f ( . )$ computed at Step 4\n\n10: return $\\\\mathcal { F }$\n\n\
              To compute the above sums the prover maintains a bookkeeping table $\\\
              \\mathbf { A }$ for $f$ . This table, at round $i$ , has $2 ^ { \\\\\
              ell - i + 1 }$ entries storing the values\n\n$$\nf ( r \\_ { 1 } , \\\
              \\ldots , r \\_ { i - 1 } , b \\_ { i } , b \\_ { i + 1 } , \\\\ldots\
              \ , b \\_ { \\\\ell } )\n$$\n\nfor all $b \\_ { i } , \\\\ldots , b\
              \ \\_ { \\\\ell } \\\\in { 0 , 1 }$ and is initialized with evaluations\
              \ of $f$ on the hypercube. For every entry of $\\\\mathbf { A }$ , the\
              \ prover subsequently computes, as in Step 4 of Algorithm 1 FunctionEvaluations²\
              \ two values\n\n$$\nf ( r \\_ { 1 } , \\\\dots , r \\_ { i - 1 } , 0\
              \ , b \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } ) { \\\\mathrm {\
              \ ~ a n d ~ } } f ( r \\_ { 1 } , \\\\dots , r \\_ { i - 1 } , 1 , b\
              \ \\_ { i + 1 } , \\\\dots , b \\_ { \\\\ell } ) .\n$$\n\nOnce these\
              \ function evaluations are in place, the prover can easily sum over\
              \ them and compute the required sumcheck messages as reguired by Relations\
              \ 2.4 and 2.5. This is done in Algorithm 2 SumCheck³.\n\nComplexity\
              \ analysis. Both Algorithms 1 and 2 run in $O ( 2 ^ { \\\\ell } )$ time:\
              \ The first iteration takes $O ( 2 ^ { \\\\ell } )$ , the second $O\
              \ ( 2 ^ { \\\\ell ^ { - 1 } } )$ and so on, and therefore the bound\
              \ holds.\n\n# 2.3.2 Linear-time sumcheck for products of multilinear\
              \ functions \\[Tha13a\\]\n\nThe linear-time sumcheck in the previous\
              \ section can be generalized to a product of two multilinear functions.\
              \ Let now $f$ and $g$ be two multilinear functions on $\\\\ell$ variables\
              \ each, we describe a linear-time algorithm to compute the messages\
              \ of the prover for the sumcheck on the product $f \\\\cdot g$ , as\
              \ proposed in \\[Tha13a\\]. Note that we cannot use Algorithm 2 here\
              \ since $f \\\\cdot g$ is not multilinear. However, similarly with the\
              \ single-function case, the prover must now send, at round $i$ , the\
              \ following evaluations at points $t = 0 , t = 1$ and $t = 2$\n\n$$\n\
              \\\\sum \\_ { b \\_ { i + 1 } , \\\\ldots , b \\_ { \\\\ell } , \\\\\
              in { 0 , 1 } } f ( r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 } , t , b\
              \ \\_ { i + 1 } , \\\\ldots , b \\_ { \\\\ell } ) \\\\cdot g ( r \\\
              _ { 1 } , \\\\ldots , r \\_ { i - 1 } , t , b \\_ { i + 1 } , \\\\ldots\
              \ , b \\_ { \\\\ell } )\n$$\n\nA $\\\\mathbf { \\| g o r i t h m 2 \\\
              \ { } a \\_ { 1 } , \\\\ldots , a \\_ { \\\\ell } } \\\\gets \\\\mathsf\
              \ { S u m C h e c k } ( f , \\\\mathbf { A } , r \\_ { 1 } , \\\\ldots\
              \ , r \\_ { \\\\ell } )$\n\nInput: Multilinear $f$ on $\\\\ell$ variables,\
              \ initial bookkeeping table $\\\\mathbf { A }$ , random $r \\_ { 1 }\
              \ , \\\\ldots , r \\_ { \\\\ell }$ ;\n\nOutput: $\\\\ell$ sumcheck messages\
              \ for $\\\\textstyle \\\\sum \\_ { x \\\\in { 0 , 1 } ^ { \\\\ell }\
              \ } f ( x )$ . Each message $a \\_ { i }$ consists of 3 elements $(\
              \ a \\_ { i 0 } , a \\_ { i 1 } , a \\_ { i 2 } )$ ;\n\n1: $\\\\mathcal\
              \ { F } $ FunctionEvaluations $( f , \\\\mathbf { A } , r \\_ { 1 }\
              \ , \\\\ldots , r \\_ { \\\\ell } )$\n\n2: for $i = 1 , \\\\dots , \\\
              \\ell$ do\n\n3: for $t \\\\in { 0 , 1 , 2 }$ do\n\n4: $\\\\begin{array}\
              \ { r } { a \\_ { i t } = \\\\sum \\_ { b \\\\in { 0 , 1 } ^ { \\\\\
              ell - i } } f \\\\big ( r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 } ,\
              \ t , b \\\\big ) } \\\\end{array}$ $\\\\triangleright$ All evaluations\
              \ needed are in $\\\\mathcal { F }$ . 5: end for\n\n6: end for\n\n7:\
              \ return ${ a \\_ { 1 } , \\\\ldots , a \\_ { \\\\ell } }$ ;\n\nAlgorithm\
              \ $\\\\mathbf { 3 } \\\\left{ a \\_ { 1 } , \\\\ldots , a \\_ { \\\\\
              ell } \\\\right} \\\\gets \\\\mathsf { S u m C h e c k P r o d u c t\
              \ } ( f , \\\\mathbf { A } \\_ { f } , g , \\\\mathbf { A } \\_ { g\
              \ } , r \\_ { 1 } , \\\\ldots , r \\_ { \\\\ell } )$\n\nInput: Multilinear\
              \ $f$ and $g$ , initial bookkeeping tables $\\\\mathbf { A } \\_ { f\
              \ }$ and $\\\\mathbf { A } \\_ { g }$ , random $r \\_ { 1 } , \\\\ldots\
              \ , r \\_ { \\\\ell }$ ;\n\nOutput: $\\\\ell$ sumcheck messages for\
              \ $\\\\textstyle \\\\sum \\_ { x \\\\in { 0 , 1 } ^ { \\\\ell } } f\
              \ ( x ) g ( x )$ . Each message $a \\_ { i }$ consists of 3 elements\n\
              \n$( a \\_ { i 0 } , a \\_ { i 1 } , a \\_ { i 2 } )$ ; 1: $\\\\mathcal\
              \ { F } $ FunctionEvaluations $( f , \\\\mathbf { A } \\_ { f } , r\
              \ \\_ { 1 } , \\\\ldots , r \\_ { \\\\ell } )$ 2: $\\\\mathcal { G }\
              \ $ FunctionEvaluations $( g , \\\\mathbf { A } \\_ { g } , r \\_ {\
              \ 1 } , \\\\ldots , r \\_ { \\\\ell } )$ 3: for $i = 1 , \\\\dots ,\
              \ \\\\ell$ do 4: for $t \\\\in { 0 , 1 , 2 }$ do 5: $\\\\begin{array}\
              \ { r } { a \\_ { i t } = \\\\sum \\_ { b \\\\in { 0 , 1 } ^ { \\\\\
              ell - i } } f ( r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 } , t , b )\
              \ \\\\cdot g ( r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 } , t , b ) \\\
              \\triangleright \\\\mathrm { A l l } } \\\\end{array}$ evaluations needed\
              \ are in $\\\\mathcal { F }$ and $\\\\mathcal { G }$ . 6: end for 7:\
              \ end for 8: return ${ a \\_ { 1 } , \\\\ldots , a \\_ { \\\\ell } }$\
              \ ;\n\nThe above can be easily computed by computing evaluations for\
              \ functions $f$ and $g$ separately using Algorithm 1 and the combining\
              \ the results using our new Algorithm 3 SumCheckProduct. We now have\
              \ the following lemma:\n\nLemma 2.3.1. Algorithm SumCheckProduct runs\
              \ in time $O ( 2 ^ { \\\\ell } )$\n\nProof. All loops in SumCheckProduct\
              \ require time $2 ^ { \\\\ell } + 2 ^ { \\\\ell - 1 } + \\\\ldots =\
              \ O ( 2 ^ { \\\\ell } )$ . Also SumCheckProduct calls FunctionEvaluations\
              \ twice (one for $f$ and one for $g$ ) and each such call takes $O (\
              \ 2 ^ { \\\\ell } )$ time.\n\n# 2.3.3 Linear-time sumcheck for GKR functions\n\
              \nLet us now consider the sumcheck problem on a particular class of\
              \ functions that are relevant for the GKR protocol (that is why we call\
              \ them GKR functions). In particular we want to compute the sumcheck\n\
              \n$$\n\\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 1\
              \ } ( g , x , y ) f \\_ { 2 } ( x ) f \\_ { 3 } ( y ) ,\n$$\n\nfor a\
              \ fixed point $g \\\\in \\\\mathbb { F } ^ { \\\\ell }$ , where $f \\\
              _ { 2 } ( x ) , f \\_ { 3 } ( x ) : \\\\mathbb { F } ^ { \\\\ell } \\\
              \\to \\\\mathbb { F }$ are multilinear extensions of arrays $\\\\mathbf\
              \ { A } \\_ { f \\_ { 2 } } , \\\\mathbf { A } \\_ { f \\_ { 3 } }$\
              \ of size $2 ^ { \\\\ell }$ , and function $f \\_ { 1 } : \\\\mathbb\
              \ { F } ^ { 3 \\\\ell } \\\\to \\\\mathbb { F }$ is the multilinear\
              \ extension of a sparse array with $O ( 2 ^ { \\\\ell } )$ (out of $2\
              \ ^ { 3 \\\\ell }$ possible) nonzero elements. It is not hard to see\
              \ that the sumcheck polynomials in GKR given by Equations 2.2 and 2.3\
              \ satisfy these properties.\n\nWe note here that applying Algorithm\
              \ 1 FunctionEvaluations for this particular class of polynomials would\
              \ lead to quadratic prover time. This is because $f \\_ { 1 }$ has $2\
              \ ^ { 2 \\\\ell }$ variables to sum on yielding $O ( 2 ^ { \\\\hat {\
              \ 2 } \\\\ell } )$ complexity. However, one could take advantage of\
              \ the sparsity of $f \\_ { 1 }$ : the prover can store only the $O (\
              \ 2 ^ { \\\\ell } )$ non-zero values of the bookkeeping table A. This\
              \ is exactly the approach used in many prior work \\[CMT12; $\\\\mathrm\
              \ { { W a h + 1 7 } }$ ; ZGKPP18\\]. However, with this approach, the\
              \ number of nonzero values that must be considered in Step 2 is always\
              \ at most $2 ^ { \\\\ell }$ , since it is not guaranteed that this number\
              \ will reduce to half (i.e., to $2 ^ { \\\\ell - i }$ ) after every\
              \ update in Step 6 of Algorithm 1 because it is sparse. Therefore, the\
              \ overall complexity becomes $O ( \\\\ell \\\\cdot 2 ^ { \\\\ell } )$\
              \ .\n\nIn this section we effectively reduce this bound to $O ( 2 ^\
              \ { \\\\ell } )$ . Our protocol divides the sumcheck into two phases:\
              \ the first $\\\\ell$ rounds bounding the variables of $x$ to a random\
              \ point $u$ , and the last $\\\\ell$ rounds bounding the variables of\
              \ $y$ to a random point $v$ . The central idea lies in rewriting Equation\
              \ 2.6 as follows\n\n$$\n\\\\begin{array} { l l l } { { \\\\sum \\_ {\
              \ x , y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 1 } ( g , x , y ) f\
              \ \\_ { 2 } ( x ) f \\_ { 3 } ( y ) } } & { { = } } & { { \\\\sum \\\
              _ { x \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 2 } ( x ) \\\\sum \\\
              _ { y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 1 } ( g , x , y ) f \\\
              _ { 3 } ( y ) } } \\ { { } } & { { = } } & { { \\\\sum \\_ { x \\\\\
              in { 0 , 1 } ^ { \\\\ell } } f \\_ { 2 } ( x ) h \\_ { g } ( x ) , }\
              \ } \\\\end{array}\n$$\n\nwhere $\\\\begin{array} { r } { h \\_ { g\
              \ } ( x ) = \\\\sum \\_ { y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ {\
              \ 1 } ( g , x , y ) f \\_ { 3 } ( y ) . } \\\\end{array}$\n\n# 2.3.3.1\
              \ Phase one.\n\nWith the formula above, in the first $\\\\ell$ rounds,\
              \ the prover and the verifier are running exactly a sumcheck on a product\
              \ of two multilinear functions $f \\_ { 2 } \\\\cdot h \\_ { g }$ ,\
              \ since functions $f \\_ { 2 }$ and $h \\_ { g }$ can be viewed as functions\
              \ only in $x$ — $y$ can be considered constant (it is always summed\
              \ on the hypercube). To compute the sumcheck messages for the first\
              \ $\\\\ell$ rounds, given their bookkeeping tables, we can call\n\n\
              $$\n\\\\mathsf { S u m C h e c k P r o d u c t } ( h \\_ { g } ( x )\
              \ , \\\\mathbf { A } \\_ { h \\_ { g } } , f \\_ { 2 } ( x ) , \\\\\
              mathbf { A } \\_ { f \\_ { 2 } } , u \\_ { 1 } , \\\\ldots , u \\_ {\
              \ \\\\ell } )\n$$\n\nin Algorithm 3. By Lemma 2.3.1 this will take $O\
              \ ( 2 ^ { \\\\ell } )$ time. We now show how to initialize the bookkeeping\
              \ tables in linear time.\n\n# Initializing the bookkeeping tables:\n\
              \nInitializing the bookkeeping table for $f \\_ { 2 }$ in $O ( 2 ^ {\
              \ \\\\ell } )$ time is trivial, since $f \\_ { 2 }$ is a multilinear\
              \ extension of an array and therefore the evaluations on the hypercube\
              \ are known. Initializing the bookkeeping table for $h \\_ { g }$ in\
              \ $O ( 2 ^ { \\\\ell } )$ time is more challenging but we can leverage\
              \ the sparsity of $f \\_ { 1 }$ . Consider the following lemma.\n\n\
              Lemma 2.3.2. Let $\\\\mathcal { N } \\_ { x }$ be the set of $\\\\left(\
              \ z , y \\\\right) \\\\in \\\\left{ 0 , 1 \\\\right} ^ { 2 \\\\ell }$\
              \ such that $f \\_ { 1 } ( z , x , y )$ is non-zero. Then for all $x\
              \ \\\\in { 0 , 1 } ^ { \\\\ell }$ , it is $\\\\begin{array} { r } {\
              \ h \\_ { g } ( x ) = \\\\sum \\_ { ( z , y ) \\\\in \\\\mathcal { N\
              \ } \\_ { x } } I ( g , z ) \\\\cdot f \\_ { 1 } ( z , x , y ) \\\\\
              cdot f \\_ { 3 } ( y ) } \\\\end{array}$ , where $\\\\begin{array} {\
              \ r } { I ( g , z ) = \\\\prod \\_ { i = 1 } ^ { \\\\ell } ( ( 1 - g\
              \ \\_ { i } ) ( 1 - z \\_ { i } ) + g \\_ { i } z \\_ { i } ) ) , }\
              \ \\\\end{array}$ ).\n\nProof. As $f \\_ { 1 }$ is a multilinear extension,\
              \ as shown in \\[Tha13a\\], we have $\\\\begin{array} { r } { f \\_\
              \ { 1 } ( g , x , y ) = \\\\sum \\_ { z \\\\in { 0 , 1 } ^ { \\\\ell\
              \ } } I ( g , z ) } \\\\end{array}$ $f \\_ { 1 } ( z , x , y )$ , where\
              \ $I$ is the multilinear extension of the identity polynomial, i.e.,\
              \ $I ( w , z ) = 1$ iff $w = z$ for all $w , \\\\dot { z } \\\\in {\
              \ 0 , 1 } ^ { \\\\ell }$ . Therefore, we have\n\n$$\nh \\_ { g } ( x\
              \ ) = \\\\sum \\_ { y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 1 } (\
              \ g , x , y ) f \\_ { 3 } ( y ) = \\\\sum \\_ { z , y \\\\in { 0 , 1\
              \ } ^ { \\\\ell } } I ( g , z ) f \\_ { 1 } ( z , x , y ) f \\_ { 3\
              \ } ( y ) = \\\\sum \\_ { ( z , y ) \\\\in { \\\\cal N } \\_ { x } }\
              \ I ( g , z ) \\\\cdot f \\_ { 1 } ( z , y ) ,\n$$\n\nMoreover, $\\\\\
              begin{array} { r } { I ( w , z ) = \\\\prod \\_ { i = 1 } ^ { \\\\ell\
              \ } ( ( 1 - w \\_ { i } ) ( 1 - z \\_ { i } ) + w \\_ { i } z \\_ {\
              \ i } ) ) } \\\\end{array}$ is the unique polynomial that evaluates\
              \ to 1 iff $w = z$ for all $w , z \\\\in { 0 , 1 } ^ { \\\\ell }$ .\
              \ As the multilinear extension is unique, we have $\\\\begin{array}\
              \ { r } { I ( g , z ) = \\\\prod \\_ { i = 1 } ^ { \\\\ell } ( ( 1 -\
              \ g \\_ { i } ) ( 1 - z \\_ { i } ) + } \\\\end{array}$ $g \\_ { i }\
              \ z \\_ { i } )$ ).\n\nLemma 2.3.3. The bookkeeping table $A \\_ { h\
              \ \\_ { g } }$ can be initialized in time $O ( 2 ^ { \\\\ell } )$\n\n\
              Proof. As $f \\_ { 1 }$ is sparse, $\\\\textstyle \\\\sum \\_ { x \\\
              \\in { 0 , 1 } ^ { \\\\ell } } \\| { \\\\mathcal { N } } \\_ { x } \\\
              | = O ( 2 ^ { \\\\ell } )$ . From Lemma 2.3.2, given the evaluations\
              \ of $I ( g , z )$ for all $z \\\\in { 0 , 1 } ^ { \\\\ell }$ , the\
              \ prover can iterate all $( z , y ) \\\\in \\\\mathcal { N } \\_ { x\
              \ }$ for all $x$ to compute ${ \\\\bf A } \\_ { h \\_ { g } }$ . The\
              \ full algorithm is presented in Algorithm 4.\n\nProcedure Precompute\
              \ $( g )$ is to evaluate $\\\\begin{array} { r } { \\\\mathbf { G }\
              \ \\[ z \\] = I ( g , z ) = \\\\prod \\_ { i = 1 } ^ { \\\\ell } ( (\
              \ 1 - g \\_ { i } ) ( 1 - z \\_ { i } ) + g \\_ { i } z \\_ { i } )\
              \ ) } \\\\end{array}$ for $z \\\\in { 0 , 1 } ^ { \\\\ell }$ . By the\
              \ closed-form of $I ( g , z )$ , the procedure iterates each bit of\
              \ $z$ , and multiples $1 - g \\_ { i }$ for $z \\_ { i } = 0$ and multiples\
              \ $g \\_ { i }$ for $z \\_ { i } = 1$ . In this way, the size of $\\\
              \\mathbf { G }$ doubles in each iteration, and the total complexity\
              \ is $O ( 2 ^ { \\\\ell } )$ .\n\nStep 8-9 computes $h \\_ { g } ( x\
              \ )$ using Lemma 2.3.2. When $f \\_ { 1 }$ is represented as a map of\
              \ $( z , x , y ) , f \\_ { 1 } ( z , x , y )$ for\n\nnon-zero values,\
              \ the complexity of these steps is $O ( 2 ^ { \\\\ell } )$ . In the\
              \ GKR protocol, this is exactly the representation\n\nof a gate in the\
              \ circuit, where $z , x , y$ are labels of the gate, its left input\
              \ and its right input, and $f \\_ { 1 } ( z , x , y ) = 1$\n\nWith the\
              \ bookkeeping tables, the prover runs SumCheckProduct $\\\\cdot ( h\
              \ \\_ { g } ( x ) , \\\\mathbf { A } \\_ { h \\_ { g } } , f \\_ { 2\
              \ } ( x ) , \\\\mathbf { A } \\_ { f \\_ { 2 } } , u \\_ { 1 } , \\\\\
              ldots , u \\_ { \\\\ell } )$ in Algorithm 3 and the total complexity\
              \ for phase one is $O ( 2 ^ { \\\\ell } )$ .\n\n# 2.3.3.2 Phase two.\n\
              \nAt this point, all variables in $x$ have been bounded to random numbers\
              \ $u$ . In the second phase, the equation to sum on becomes\n\n$$\n\\\
              \\sum \\_ { y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 1 } ( g , u ,\
              \ y ) f \\_ { 2 } ( u ) f \\_ { 3 } ( y )\n$$\n\nNote here that $f \\\
              _ { 2 } ( u )$ is merely a single value which we already computed in\
              \ phase one. Both $f \\_ { 1 } ( g , u , y )$ and $f \\_ { 3 } ( y )$\
              \ are polynomials on $y$ with $\\\\ell$ variables. Similar to phase\
              \ one, to compute the messages for the last $\\\\ell$ rounds we can\
              \ call\n\n$$\n\\\\mathrm { S u m } \\\\mathrm { C h e c k P r o d u\
              \ c t } ( f \\_ { 1 } ( g , u , y ) , \\\\mathbf { A } \\_ { f \\_ {\
              \ 1 } } , f \\_ { 3 } ( y ) \\\\cdot f \\_ { 2 } ( u ) , \\\\mathbf\
              \ { A } \\_ { f \\_ { 3 } } \\\\cdot f \\_ { 2 } ( u ) , v \\_ { 1 }\
              \ , \\\\ldots , v \\_ { \\\\ell } ) .\n$$\n\nNote here that $\\\\mathbf\
              \ { A } \\_ { f \\_ { 1 } }$ is the bookkeeping table for $f \\_ { 1\
              \ } ( g , u , y )$ , not the original sparse function $f \\_ { 1 } (\
              \ g , x , y )$ . Initializing the bookkeeping table for $f \\_ { 1 }$\
              \ :\n\nIt now remains to initialize the bookkeeping table for $f \\\
              _ { 1 } ( g , u , y )$ efficiently. Similar to phase one, we have the\
              \ following lemma:\n\n$\\\\mathbf { A l g o r i t h m 4 A } \\_ { h\
              \ \\_ { g } } \\\\gets \\| \\\\mathsf { n i t i a l i z e \\_ P h a\
              \ s e O n e } ( f \\_ { 1 } , f \\_ { 3 } , \\\\mathbf { A } \\_ { f\
              \ \\_ { 3 } } , g )$\n\nInput: Multilinear $f \\_ { 1 }$ and $f \\_\
              \ { 3 }$ , initial bookkeeping tables $\\\\mathbf { A } \\_ { f \\_\
              \ { 3 } }$ , random $g = g \\_ { 1 } , \\\\dotsc , g \\_ { \\\\ell }$\
              \ ;\n\nOutput: Bookkeeping table ${ \\\\bf A } \\_ { h \\_ { g } }$\
              \ ;\n\n1: procedure $\\\\mathbf { G } $ Precompute $( g )$ ▷ G is an\
              \ array of size $2 ^ { \\\\ell }$ .\n\n2: Set $\\\\mathbf { G } \\[\
              \ 0 \\] = 1$\n\n3: for $i = 0 , \\\\ldots , \\\\ell - 1$ do\n\n4: for\
              \ $b \\\\in { 0 , 1 } ^ { i } { \\\\bf d o }$\n\n5: $\\\\begin{array}\
              \ { r l } & { \\\\mathbf { G } \\[ b , \\\\dot { 0 } \\] = \\\\mathbf\
              \ { G } \\[ b \\] \\\\cdot ( 1 - g \\_ { i + 1 } ) } \\ & { \\\\mathbf\
              \ { G } \\[ b , 1 \\] = \\\\mathbf { G } \\[ b \\] \\\\cdot g \\_ {\
              \ i + 1 } } \\\\end{array}$\n\n6:\n\n7: end for\n\n8: end for\n\n9:\
              \ end procedure\n\n10: $\\\\forall x \\\\in { 0 , 1 } ^ { \\\\ell }$\
              \ , set $\\\\mathbf { A } \\_ { h \\_ { g } } \\[ x \\] = 0$\n\n11:\
              \ for every $( z , x , y )$ such that $f \\_ { 1 } ( z , x , y )$ is\
              \ non-zero do\n\n12: ${ \\\\bf A } \\_ { h \\_ { g } } \\[ x \\] = {\
              \ \\\\bf A } \\_ { h \\_ { g } } \\[ x \\] + { \\\\bf G } \\[ z \\]\
              \ \\\\cdot f \\_ { 1 } ( z , x , y ) \\\\cdot { \\\\bf A } \\_ { f \\\
              _ { 3 } } \\[ y \\]$\n\n13: end for\n\n14: return ${ \\\\bf A } \\_\
              \ { h \\_ { g } }$ ;\n\nLemma 2.3.4. Let $\\\\mathcal { N } \\_ { y\
              \ }$ be the set of $\\\\mathbf { \\\\eta } ^ { \\\\cdot } ( z , x )\
              \ \\\\in \\\\left{ 0 , 1 \\\\right} ^ { 2 \\\\ell }$ such that $f \\\
              _ { 1 } ( z , x , y )$ is non-zero. Then for all $y \\\\in { 0 , 1 }\
              \ ^ { \\\\ell }$ , it is $\\\\begin{array} { r } { f \\_ { 1 } ( g ,\
              \ u , y ) = \\\\sum \\_ { ( z , x ) \\\\in \\\\mathcal { N } \\_ { y\
              \ } } I ( g , z ) \\\\cdot I ( u , x ) \\\\cdot f \\_ { 1 } ( z , x\
              \ , y ) } \\\\end{array}$ .\n\nProof. This immediately follows from\
              \ the fact that $f \\_ { 1 }$ is a multilinear extension. We have $f\
              \ \\_ { 1 } ( g , u , y ) =$ $\\\\begin{array} { r } { \\\\sum \\_ {\
              \ z , y \\\\in { 0 , 1 } ^ { \\\\ell } } I ( g , z ) \\\\cdot I ( u\
              \ , x ) \\\\cdot f \\_ { 1 } ( z , x , y ) } \\\\end{array}$ , where\
              \ the closed from of $I$ is given in Lemma 2.3.2.\n\nLemma 2.3.5. The\
              \ bookkeeping table $A \\_ { f \\_ { 1 } }$ can be initialized in time\
              \ $O ( 2 ^ { \\\\ell } )$\n\nProof. Similar to Algorithm 4, he prover\
              \ again iterates all non-zero indices of $f \\_ { 1 }$ to compute it\
              \ using Lemma 2.3.4. The full algorithm is presented in Algorithm 5.\n\
              \nWe now summarize the final linear-time algorithm for computing the\
              \ prover messages for the sumcheck protocol on GKR functions. See Algorithm\
              \ 6 SumCheckGKR.\n\nTheorem 2.3.6. Algorithm SumCheckGKR runs in $O\
              \ ( 2 ^ { \\\\ell } )$ time.\n\nProof. Follows from Lemma 2.3.1, 2.3.3\
              \ and 2.3.5.\n\n|     |\n| --- |\n| Algorithm 5 Af, Initialize\\_PhaseTwo(f1,\
              \ g, u) |\n| Input: Multilinear f1, random g = g1, ..., ge and u = u1,...,\
              \ ue, |\n| Output: Bookkeeping table Af. |\n| 1: G Precompute(g) |\n\
              | 2: U Precompute(u) |\n| 3: Vy E{0,1}, set Af,\\[y\\] = 0 |\n| 4: for\
              \ every (z,x, y) such that f1(z, x, y) is non-zero do |\n| 5: Af\\[y\\\
              ] =Af1\\[y\\] +G\\[z\\]U\\[x\\]f1(z,x,y) 6: end for |\n| 7: return Af1;\
              \ |\n\nAl $\\\\mathbf { g o r i t h m 6 } \\\\left{ a \\_ { 1 } , \\\
              \\dots , a \\_ { 2 \\\\ell } \\\\right} \\\\gets \\\\mathsf { S u m\
              \ C h e c k G K R } ( f \\_ { 1 } , f \\_ { 2 } , f \\_ { 3 } , u \\\
              _ { 1 } \\\\dots , u \\_ { \\\\ell } , v \\_ { 1 } , \\\\dots , v \\\
              _ { \\\\ell } , g )$\n\nInput: Multilinear extensions $f \\_ { 1 } (\
              \ z , x , y )$ (with $O ( 2 ^ { \\\\ell } )$ non-zero entries), $f \\\
              _ { 2 } ( x ) , f \\_ { 3 } ( y )$ and their bookkeeping tables $\\\\\
              mathbf { A } \\_ { f \\_ { 2 } } , \\\\mathbf { A } \\_ { f \\_ { 3\
              \ } }$ , randomness $u = u \\_ { 1 } , \\\\ldots , u \\_ { \\\\ell }$\
              \ and $v = v \\_ { 1 } , \\\\ldots , v \\_ { \\\\ell }$ and point $g$\
              \ ;\n\nOutput: $2 \\\\ell$ sumcheck messages for $\\\\begin{array} {\
              \ r } { \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ {\
              \ 1 } ( g , x , y ) f \\_ { 2 } ( x ) f \\_ { 3 } ( y ) } \\\\end{array}$\
              \ ;\n\n1: $\\\\mathbf { A } \\_ { h \\_ { g } } $ Initialize\\_PhaseOne\
              \ $\\\\left( f \\_ { 1 } , f \\_ { 3 } , \\\\mathbf { A } \\_ { f \\\
              _ { 3 } } , g \\\\right)$\n\n2: {a1, $\\\\begin{array} { r } { \\\\\
              ldots , a \\_ { \\\\ell } } \\\\mathsf { S u m C h e c k P r o d u c\
              \ t } ( \\\\sum \\_ { y \\\\in { 0 , 1 } ^ { \\\\ell } } f \\_ { 1 }\
              \ ( g , x , y ) f \\_ { 3 } ( y ) , \\\\mathbf { A } \\_ { h \\_ { g\
              \ } } , f \\_ { 2 } , \\\\mathbf { A } \\_ { f \\_ { 2 } } , u \\_ {\
              \ 1 } , \\\\ldots , u \\_ { \\\\ell } ) } \\\\end{array}$ 3: $\\\\mathbf\
              \ { A } \\_ { f \\_ { 1 } } \\\\gets$ Initialize\\_PhaseTwo $( f \\\
              _ { 1 } , g , u )$\n\n4: { $\\\\begin{array} { r } { \\\\check { a }\
              \ \\_ { \\\\ell + 1 } ^ { \\* } , \\\\ldots , a \\_ { 2 \\\\ell } }\
              \ \\\\gets \\\\mathsf { S u m C h e c k P r o d u c t } ( f \\_ { 1\
              \ } ( g , u , y ) , \\\\mathbf { A } \\_ { f \\_ { 1 } } , f \\_ { 3\
              \ } ( y ) \\\\cdot f \\_ { 2 } ( u ) , \\\\mathbf { A } \\_ { f \\_\
              \ { 3 } } \\\\cdot f \\_ { 2 } ( u ) , v \\_ { 1 } , \\\\ldots , v \\\
              _ { k } ) . } \\\\end{array}$ . . , vℓ) 5: return ${ a \\_ { 1 } , \\\
              \\ldots , a \\_ { 2 \\\\ell } }$\n\n# 2.3.3.3 Generalizations of our\
              \ technique.\n\nOur technique can be extended to sumchecks of the general\
              \ type\n\n$$\n\\\\begin{array} { r } { \\\\sum \\_ { x \\_ { 1 } , x\
              \ \\_ { 2 } , \\\\ldots , x \\_ { c } \\\\in { 0 , 1 } ^ { c } } f \\\
              _ { 0 } ( g , x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\_ { c } )\
              \ f \\_ { 1 } ( x \\_ { 1 } ) f \\_ { 2 } ( x \\_ { 2 } ) \\\\ldots\
              \ f \\_ { c } ( x \\_ { c } ) , } \\\\end{array}\n$$\n\nwhere $c$ is\
              \ a constant, functions $f \\_ { i }$ are multilinear and $f \\_ { 0\
              \ } ( \\ u )$ is sparse and consists of linearly-many nonzero monomials.\
              \ We divide the protocol into $c$ phases similarly as above. This generalization\
              \ captures the sumcheck in the original GKR paper with identity polynomials\
              \ (see \\[GKR15\\]), and our new algorithms also improve the prover\
              \ time of this to linear.\n\n# 2.3.4 Putting everything together\n\n\
              The sumcheck protocol in GKR given by Equation 2.2 can be decomposed\
              \ into several instances that have the form of Equation 2.6 presented\
              \ in the previous section. The term\n\n$$\n\\\\sum \\_ { x , y \\\\\
              in { 0 , 1 } ^ { s \\_ { i + 1 } } } \\\\tilde { m u l t \\_ { i + 1\
              \ } } ( g , x , y ) ( \\\\tilde { V } \\_ { i + 1 } ( x ) \\\\tilde\
              \ { V } \\_ { i + 1 } ( y ) )\n$$\n\nis exactly the same as Equation\
              \ 2.6. The term $\\\\begin{array} { r } { \\\\sum \\_ { x , y \\\\in\
              \ { 0 , 1 } ^ { s \\_ { i + 1 } } } a \\\\tilde { d } d \\_ { i + 1\
              \ } ( g , x , y ) ( \\\\tilde { V } \\_ { i + 1 } ( x ) + \\\\tilde\
              \ { V } \\_ { i + 1 } ( y ) ) } \\\\end{array}$ can be viewed as:\n\n\
              $$\n\\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } a \\\
              \\tilde { d } d \\_ { i + 1 } ( g , x , y ) \\\\tilde { V } \\_ { i\
              \ + 1 } ( x ) + \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { i +\
              \ 1 } } } a \\\\tilde { d } d \\_ { i + 1 } ( g , x , y ) \\\\tilde\
              \ { V } \\_ { i + 1 } ( y )\n$$\n\nThe first sum can be computed using\
              \ the same protocol in Algorithm 6 without $f \\_ { 3 } ( y )$ , and\
              \ the second sum can be computed without $f \\_ { 2 } ( x )$ . The complexity\
              \ for both cases remains linear. Due to linearity of the sumcheck protocol,\
              \ the prover can execute these 3 instances simultaneously in every round,\
              \ and sum up the individual messages and send them to the veriifer.\n\
              \nCombining two claims. After the sumcheck in the GKR protocol is completed,\
              \ as described in Section 2.2.3, the prover and the verifier need to\
              \ combine the two claims about $\\\\tilde { V } \\_ { i + 1 }$ received\
              \ at the end of the sumcheck protocol to one to avoid the exponential\
              \ blow-up. There are two ways to combine the two claims and we show\
              \ how to do each of them in linear time.\n\nThe second approach using\
              \ random linear combinations is rather straight forward. After the output\
              \ layers, $\\\\mathcal { P }$ and $\\\\nu$ execute sumcheck protocol\
              \ on Equation 2.3 instead of Equations 2.2, which still satisfies the\
              \ properties of Equation 2.6. One could view it as 6 instances of Equation\
              \ 2.6 and the prover time is still linear. Moreover, there is a better\
              \ way to further improve the efficiency. Taking $\\\\begin{array} {\
              \ r } { \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } }\
              \ ( \\\\alpha \\_ { i } m \\\\tilde { u } l t \\_ { i + 1 } ( u , x\
              \ , y ) + } \\\\end{array}$ $\\\\beta \\_ { i } m \\\\tilde { u } l\
              \ t \\_ { i + 1 } ( v , x , y ) ) \\\\tilde { V } \\_ { i + 1 } ( x\
              \ ) \\\\tilde { V } \\_ { i + 1 } ( y )$ as an example, in Algorithm\
              \ 4, the prover runs Precompute twice on $u$ and $v$ to generate two\
              \ arrays $\\\\mathbf { G } \\_ { 1 }$ and $\\\\mathbf { G } \\_ { 2\
              \ }$ ), and sets $\\\\mathbf { G } \\[ b \\] = \\\\alpha \\_ { i } \\\
              \\mathbf { G } \\_ { 1 } \\[ b \\] + \\\\beta \\_ { i } \\\\mathbf {\
              \ G } \\_ { 2 } \\[ b \\]$ for all $b$ . The rest of the algorithms\
              \ remains the same. This only incurs a small overhead in practice in\
              \ our implementation, compared to the original algorithm on Equation\
              \ 2.6.\n\nThough with the approach above we already have a linear prover\
              \ GKR protocol, the technique to condense two points to one proposed\
              \ in the original GKR protocol \\[GKR15\\] may still be interesting\
              \ in some scenarios (e.g., in our implementation, we use this approach\
              \ in the last layer and only make one query to the multi-linear extension\
              \ of the input, which is more efficient practice). We present an algorithm\
              \ to reduce two claims about $\\\\tilde { V } \\_ { i + 1 }$ to one\
              \ in linear time. Recall that as described in Section 2.2.3, in the\
              \ $i$ -th layer, after the sumcheck, the verifier receives two claims\
              \ $\\\\tilde { V } ( u ) , \\\\tilde { V } ( v )$ . (Again we omit the\
              \ superscript and subscript of $i$ for the ease of interpretation.)\
              \ She then defines a line $\\\\gamma ( \\\\boldsymbol { x } ) : \\\\\
              mathbb { F } \\\\mathbb { F } ^ { s }$ such that $\\\\gamma ( 0 ) =\
              \ u , \\\\gamma ( 1 ) = v$ and the prover needs to provide $\\\\tilde\
              \ { V } ( \\\\gamma ( x ) )$ , a degree $s$ univariate polynomial, to\
              \ $\\\\nu$ . If the prover computes it naively, which was done in all\
              \ prior papers, it incurs $O ( s 2 ^ { s } )$ time, as it is equivalent\
              \ to evaluating $\\\\bar { V } \\\\bar { ( ) }$ at $s + 1$ points.\n\
              \n1: Initialize a binary tree $T$ with $s$ levels. We use $T \\_ { j\
              \ } \\[ b \\]$ to denote the $b$ -th node at level $j$ .\n\n2: for $b\
              \ \\\\in { 0 , 1 } ^ { s }$ do\n\n3: $T \\_ { s } \\[ b \\] = \\\\tilde\
              \ { V } ( b )$ .\n\n4: Multiply $T \\_ { s } \\[ b \\]$ with $b \\_\
              \ { s } ( c \\_ { s } x + d \\_ { s } ) + ( 1 - b \\_ { s } ) ( 1 -\
              \ c \\_ { s } x - d \\_ { s } ) .$\n\n5: end for\n\n6: for $j = s -\
              \ 1 , \\\\dotsc , 1$ do\n\n7: for $b \\\\in { 0 , 1 } ^ { j }$ do\n\n\
              8: $T \\_ { j } \\[ b \\] = T \\_ { j + 1 } \\[ b , 0 \\] + T \\_ {\
              \ j + 1 } \\[ b , 1 \\]$ .\n\n9: $T \\_ { j } \\[ b \\] = T \\_ { j\
              \ } \\[ b \\] \\\\cdot ( b \\_ { j } ( c \\_ { j } x + d \\_ { j } )\
              \ + ( 1 - b \\_ { j } ) ( 1 - c \\_ { j } x - d \\_ { j } ) ) .$\n\n\
              10: end for\n\n11: end for\n\n12: Output $T \\_ { 1 } \\[ 0 \\]$ .\n\
              \nIn our new algorithm, we write $\\\\tilde { V } ( \\\\gamma ( x )\
              \ ) ~ = ~ \\\\textstyle \\\\sum \\_ { y \\\\in { 0 , 1 } ^ { s } } I\
              \ ( \\\\gamma ( x ) , y ) \\\\tilde { V } ( y )$ , where $I ( a , b\
              \ )$ is an identity polynomial $I ( a , b ) = 0$ iff $a = b$ . This\
              \ holds by inspection of both sides on the Boolean hypercube. We then\
              \ evaluate the right side in linear time with a binary tree structure.\
              \ The key observation is that the identity polynomial can be written\
              \ as $\\\\begin{array} { r } { I ( { a } , { b } ) = \\\\prod \\_ {\
              \ j = 1 } ^ { s } ( a \\_ { j } b \\_ { j } + ( 1 - a \\_ { j } ) (\
              \ 1 - b \\_ { j } ) ) } \\\\end{array}$ , and we can process one variable\
              \ $( a \\_ { j } , b \\_ { j } )$ at a time and multiply them together\
              \ to get the final result.\n\nWe construct a binary tree with $2 ^ {\
              \ s }$ leaves and initialize each leaf $b \\\\in { 0 , 1 } ^ { s }$\
              \ with $\\\\tilde { V } ( \\\\boldsymbol { b } )$ . As $\\\\gamma (\
              \ x )$ is a linear polynomial, we write it as $\\\\gamma ( x ) = \\\
              [ c \\_ { 1 } , \\\\ldots , c \\_ { s } \\] ^ { T } x + \\[ d \\_ {\
              \ 1 } , \\\\ldots , d \\_ { s } \\] ^ { T }$ . At the leaf level, we\
              \ only consider the last variable of $I ( \\\\gamma ( x ) , y )$ . For\
              \ each leaf $b \\\\in { 0 , 1 } ^ { s }$ , we multiply the value with\
              \ $b \\_ { s } ( c \\_ { s } x + d \\_ { s } ) + ( 1 -$ $b \\_ { s }\
              \ ) ( 1 - c \\_ { s } x - d \\_ { s } )$ , the result of which is a\
              \ linear polynomial. For a node $b \\\\in { 0 , 1 } ^ { j }$ in the\
              \ intermediate level $j$ , we add the polynomials from its two children,\
              \ and multiply it with $b \\_ { j } ( c \\_ { j } x + d \\_ { j } )\
              \ + ( 1 - b \\_ { j } ) ( 1 - c \\_ { j } x - d \\_ { j } )$ , the part\
              \ in $I$ that corresponds to the $j$ -th variable. In this way, each\
              \ node in the $j$ -th level stores a degree $j$ polynomial. Eventually,\
              \ the root is the polynomial on the right side of degree $s$ , which\
              \ equals to $\\\\tilde { V } ( \\\\gamma ( x ) )$ . The algorithm is\
              \ given in Algorithm 7.\n\nTo see the complexity of Algorithm 7, both\
              \ the storage and the polynomial multiplication at level $j$ is $O (\
              \ s - j + 1 )$ in each node. So the total time is ${ \\\\cal O } ( \\\
              \\sum \\_ { j = 1 } ^ { s } \\\\bar { 2 } ^ { j } ( s - j + \\\\bar\
              \ { 1 } ) ) = { \\\\cal O } ( 2 ^ { s } )$ , which is linear to the\
              \ number of gates in the layer.\n\nAn alternative way to interpret this\
              \ result is to add an additional layer for each layer of the circuit\
              \ in GKR relaying the values. That is,\n\n$$\n\\\\tilde { V } \\_ {\
              \ i } ( g ) = \\\\sum \\_ { x \\\\in { 0 , 1 } ^ { s \\_ { i } } } I\
              \ ( g , x ) \\\\tilde { V } \\_ { i + 1 } ( x ) ,\n$$\n\nwhere $\\\\\
              tilde { V } \\_ { i } = \\\\tilde { V } \\_ { i + 1 }$ . Then when using\
              \ the random linear combination approach, the sumcheck is executed on\n\
              \n$$\n\\\\alpha \\\\tilde { V } \\_ { i } ( u ) + \\\\beta \\\\tilde\
              \ { V } \\_ { i } ( v ) = \\\\sum \\_ { x \\\\in { 0 , 1 } ^ { s \\\
              _ { i } } } ( \\\\alpha I ( u , x ) + \\\\beta I ( v , x ) ) \\\\tilde\
              \ { V } \\_ { i + 1 } ( x ) .\n$$\n\nAt the end of the sumcheck, the\
              \ verifier receives a single claim on $\\\\tilde { V } \\_ { i + 1 }\
              \ = \\\\tilde { V } \\_ { i }$ . The sumcheck can obviously run in linear\
              \ time, and the relay layers do not change the result of the circuit.\
              \ This approach is actually the same as the condensing to one point\
              \ in linear time above conceptually.\n\n# 2.4 Zero-Knowledge Argument\
              \ Protocols\n\nIn this section, we present the construction of our new\
              \ zero-knowledge argument system. In \\[ZGKPP17c\\], Zhang et al. proposed\
              \ to combine the GKR protocol with a verifiable polynomial delegation\
              \ protocol, resulting in an argument system. Later, in \\[ZGKPP17a;\
              \ WTSTW18\\], the construction was extended to zeroknowledge, by sending\
              \ all the messages in the GKR protocol in homomorphic commitments and\
              \ performing all the checks by zero-knowledge equality and product testing.\
              \ This incurs a high overhead for the verifier compared to the plain\
              \ version without zero-knowledge, as each multiplication becomes an\
              \ exponentiation and each equality check becomes a $\\\\Sigma$ -protocol,\
              \ which is around $1 0 0 \\\\times$ slower in practice.\n\nIn this paper,\
              \ we follow the same blueprint of combining GKR and VPD to obtain an\
              \ argument system, but instead show how to extend it to be zero-knowledge\
              \ efficiently. In particular, the prover masks the GKR protocol with\
              \ special random polynomials so that the verifier runs a “randomized”\
              \ GKR that leaks no extra information and her overhead is small. A similar\
              \ approach was used by Chiesa et al. in \\[CFS17\\]. In the following,\
              \ we present the zero-knowledge version of each building block, followed\
              \ by the whole zero-knowledge argument.\n\n# 2.4.1 Zero Knowledge Sumcheck\n\
              \nAs a core step of the GKR protocol, $\\\\mathcal { P }$ and $\\\\\
              nu$ execute a sumcheck protocol on Equation 2.2, during which $\\\\\
              mathcal { P }$ sends $\\\\nu$ evaluations of the polynomial at several\
              \ random points chosen by $\\\\nu$ . These evaluations leak information\
              \ about the values in the circuit, as they can be viewed as weighted\
              \ sums of these values.\n\nTo make the sumcheck protocol zero-knowledge,\
              \ we take the approach proposed by Chiesa et al. in \\[CFS17\\], which\
              \ is masking the polynomial in the sumcheck protocol by a random polynomial.\
              \ In this approach, to prove\n\n$$\n\\\\begin{array} { r } { H = \\\\\
              sum \\_ { x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\_ { \\\\ell }\
              \ \\\\in { 0 , 1 } } f ( x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\\
              _ { \\\\ell } ) , } \\\\end{array}\n$$\n\nthe prover generates a random\
              \ polynomial $g$ with the same variables and individual degrees of $f$\
              \ . She commits\n\nto the polynomial $g$ , and sends the verifier a\
              \ claim $\\\\begin{array} { r l r } { G = } & { { } } & { \\\\sum \\\
              \\mathrm { ~ \\\\underset { \\ r { \\ r = \\\\infty } } { ~ \\ u ~ {\
              \ ~ \\ u ~ { ~ g ( x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\_ { \\\
              \\ell } ) } } } ~ } } \\\\end{array}$ . The verifier picks $x \\_ {\
              \ 1 } , x \\_ { 2 } , . . . , x \\_ { \\\\ell } { \\\\in } { 0 , 1 }$\n\
              \na random number $\\\\rho$ , and execute a sumcheck protocol with the\
              \ prover on\n\n$$\n\\\\begin{array} { r } { H + \\\\rho G = \\\\sum\
              \ \\_ { x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\_ { \\\\ell } \\\
              \\in { 0 , 1 } } ( f ( x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\\
              _ { \\\\ell } ) + \\\\rho g ( x \\_ { 1 } , x \\_ { 2 } , \\\\ldots\
              \ , x \\_ { \\\\ell } ) ) . } \\\\end{array}\n$$\n\nAt the last round\
              \ of this sumcheck, the prover opens the commitment of $g$ at $g ( r\
              \ \\_ { 1 } , \\\\ldots , r \\_ { \\\\ell } )$ , and the verifier computes\
              \ $f ( r \\_ { 1 } , \\\\ldots , r \\_ { l } )$ by subtracting $\\\\\
              rho g ( r \\_ { 1 } , \\\\ldots , r \\_ { \\\\ell } )$ from the last\
              \ message, and compares it with the oracle access of $f$ . It is shown\
              \ that as long as the commitment and opening of $g$ are zero-knowledge,\
              \ the protocol is zero-knowledge. Intuitively, this is because all the\
              \ coefficients of $f$ are masked by those of $g$ . The soundness still\
              \ holds because of the random linear combination of $f$ and $g$ .\n\n\
              Unfortunately, the masking polynomial $g$ is as big as $f$ , and opening\
              \ it to a random point later is expensive. In \\[CFS17\\], the prover\
              \ sends a PCP oracle of $g$ , and executes a zero-knowledge sumcheck\
              \ to open it to a random point, which incurs an exponential complexity\
              \ for the prover. Even replacing it with the zkVPD protocol in \\[ZGKPP17a\\\
              ], the prover time is slow in practice.\n\nIn this paper, we show that\
              \ it suffices to mask $f$ with a small polynomial to achieve zero-knowledge.\
              \ In particular, we set $g ( x \\_ { 1 } , \\\\ldots , x \\_ { \\\\\
              ell } ) = a \\_ { 0 } + g \\_ { 1 } ( x \\_ { 1 } ) + g \\_ { 2 } (\
              \ x \\_ { 2 } ) + \\\\ldots + g \\_ { \\\\ell } ( x \\_ { \\\\ell }\
              \ ) .$ , where $g \\_ { i } ( x \\_ { i } ) = a \\_ { i , 1 } x \\_\
              \ { i } + a \\_ { i , 2 } x \\_ { i } ^ { 2 } +$ $\\\\cdots + a \\_\
              \ { i , d } x \\_ { i } ^ { d }$ is a random univariate polynomial of\
              \ degree $d$ ( $d$ is the variable degree of $f$ ). Note here that the\
              \ size of $g$ is only $O ( d \\\\ell )$ , while the size of $f$ is exponential\
              \ in $\\\\ell$ .\n\nThe intuition of our improvement is that the prover\
              \ sends $O ( d \\\\ell )$ messages in total to the verifier during the\
              \ sumcheck protocol, thus a polynomial $g$ with $O ( d \\\\ell )$ random\
              \ coefficients is sufficient to mask all the messages and achieve zero-knowledge.\
              \ We present the full protocol in Construction 1.\n\nThe completeness\
              \ of the protocol holds obviously. The soundness follows the soundness\
              \ of the sumcheck protocol and the random linear combination in step\
              \ 2 and 3, as proven in \\[CFS17\\]. We give a proof of zero knowledge\
              \ here.\n\nTheorem 2.4.1 (Zero knowledge). For every verifier $\\\\\
              nu ^ { \\* }$ and every $\\\\ell$ -variate polynomial $f : \\\\mathbb\
              \ { F } ^ { \\\\ell } \\\\to \\\\mathbb { F }$ with variable degree\
              \ $d \\_ { \\\\mathrm { { \\\\Omega } } }$ , there exists a simulator\
              \ $s$ such that given access to $\\\\begin{array} { r } { H = \\\\sum\
              \ \\_ { x \\_ { 1 } , x \\_ { 2 } , \\\\dots , x \\_ { \\\\ell } \\\\\
              in { 0 , 1 } } f ( x \\_ { 1 } , x \\_ { 2 } , \\\\dots , x \\_ { \\\
              \\ell } ) , } \\\\end{array}$ , $\\\\boldsymbol { s }$ is able to simulate\
              \ the partial view of $\\\\nu ^ { \\* }$ in step 1-4 of Construction\
              \ $I$ .\n\nProof. We build the simulator $s$ as following.\n\nConstruction\
              \ 1. We assume the existence of a zkVPD protocol defined in Section\
              \ 2.2.4. For sim\n\nplicity, we omit the randomness $r \\_ { f }$ and\
              \ public parameters pp, vp without any ambiguity. To prove\n\nthe claim\
              \ $H = \\\\qquad \\\\sum \\\\qquad f ( x \\_ { 1 } , x \\_ { 2 } , \\\
              \\ldots , x \\_ { \\\\ell } ) .$ : $x \\_ { 1 } , x \\_ { 2 } , . .\
              \ . , x \\_ { \\\\ell } { \\\\in } { 0 , 1 }$\n\n1. $\\\\mathcal { P\
              \ }$ selects a polynomial $g ( x \\_ { 1 } , \\\\ldots , x \\_ { \\\\\
              ell } ) = a \\_ { 0 } + g \\_ { 1 } ( x \\_ { 1 } ) + g \\_ { 2 } (\
              \ x \\_ { 2 } ) + \\\\ldots + g \\_ { l } ( x \\_ { \\\\ell } ) $ ,\
              \ where $g \\_ { i } ( x \\_ { i } ) \\ = \\ a \\_ { i , 1 } x \\_ {\
              \ i } + a \\_ { i , 2 } x \\_ { i } ^ { 2 } + . . . + a \\_ { i , d\
              \ } x \\_ { i } ^ { d }$ and all $a \\_ { i , j } s$ are uniformly random.\
              \ $\\\\mathcal { P }$ sends $H = \\\\Sigma \\\\qquad f ( x \\_ { 1 }\
              \ , x \\_ { 2 } , \\\\ldots , x \\_ { \\\\ell } ) ,$ $G = \\\\Sigma\
              \ \\\\qquad g ( x \\_ { 1 } , x \\_ { 2 } , \\\\dots , x \\_ { \\\\\
              ell } )$ and $\\\\mathsf { c o m } \\_ { g } \\ =$ $x \\_ { 1 } , x\
              \ \\_ { 2 } , . . . , x \\_ { \\\\ell } { \\\\in } { 0 , 1 }$ $x \\\
              _ { 1 } , x \\_ { 2 } , . . . , x \\_ { \\\\ell } { \\\\in } { 0 , 1\
              \ }$ Commit(g) to V.\n\n2. $\\\\nu$ uniformly selects $\\\\boldsymbol\
              \ { \\\\rho } \\\\in \\\\mathbb { F } ^ { \\* }$ , computes $H + \\\\\
              rho G$ and sends $\\\\rho$ to $\\\\mathcal { P }$ .\n\n3. $\\\\mathcal\
              \ { P }$ and $\\\\nu$ run the sumcheck protocol on\n\n\n$$\nH + \\\\\
              rho G = \\\\sum \\_ { x \\_ { 1 } , x \\_ { 2 } , \\\\ldots , x \\_\
              \ { \\\\ell } \\\\in { 0 , 1 } } \\\\left( f ( x \\_ { 1 } , x \\_ {\
              \ 2 } , \\\\ldots , x \\_ { \\\\ell } ) + \\\\rho g ( x \\_ { 1 } ,\
              \ x \\_ { 2 } , \\\\ldots , x \\_ { \\\\ell } ) \\\\right)\n$$\n\n4.\
              \ At the last round of the sumcheck protocol, $\\\\nu$ obtains a claim\
              \ $h \\_ { \\\\ell } ( r \\_ { \\\\ell } ) = f ( r \\_ { 1 } , r \\\
              _ { 2 } , \\\\ldots , r \\_ { \\\\ell } ) +$ $\\\\rho g ( r \\_ { 1\
              \ } , r \\_ { 2 } , \\\\ldots , r \\_ { \\\\ell } )$ . $\\\\mathcal\
              \ { P }$ and $\\\\nu$ opens the commitment of $g$ at $r = ( r \\_ {\
              \ 1 } , \\\\ldots , r \\_ { \\\\ell } )$ by $( g ( r ) , \\\\pi ) $\
              \ Open $( g , r )$ , Verify $( \\\\mathsf { c o m } \\_ { g } , g (\
              \ r ) , r , \\\\pi )$ . If Verify outputs reject, $\\\\nu$ aborts.\n\
              \n5. V computes $h \\_ { \\\\ell } ( r \\_ { \\\\ell } ) - \\\\rho g\
              \ ( r \\_ { 1 } , . . . , r \\_ { \\\\ell } )$ and compares it with\
              \ the oracle access of $f ( r \\_ { 1 } , \\\\ldots , r \\_ { \\\\ell\
              \ } )$ .\n\n6. $s$ selects a random polynomial $g ^ { \\* } ( x \\_\
              \ { 1 } , \\\\ldots , x \\_ { \\\\ell } ) = a \\_ { 0 } ^ { \\* } +\
              \ g \\_ { 1 } ^ { \\* } ( x \\_ { 1 } ) + g \\_ { 2 } ^ { \\* } ( x\
              \ \\_ { 2 } ) + \\\\cdot \\\\cdot \\\\cdot + g \\_ { \\\\ell } ^ { \\\
              * } ( x \\_ { \\\\ell } )$ , where $g \\_ { i } ^ { \\* } ( x \\_ {\
              \ i } ) =$ $a \\_ { i , 1 } ^ { \\* } x \\_ { i } + a \\_ { i , 2 }\
              \ ^ { \\* } x \\_ { i } ^ { 2 } + \\\\cdots + a \\_ { i , d } ^ { \\\
              * } x \\_ { i } ^ { d }$ . $s$ sends $\\\\begin{array} { r l r } { H\
              \ , G ^ { \\* } = } & { { } } & { \\\\sum \\\\qquad g ^ { \\* } ( x\
              \ \\_ { 1 } , x \\_ { 2 } , \\\\cdot \\\\cdot \\\\cdot , x \\_ { \\\\\
              ell } ) } \\\\end{array}$ and ${ \\\\mathsf { c o m } } \\_ { g ^ {\
              \ \\* } } =$ $x \\_ { 1 } , x \\_ { 2 } , \\\\cdots , x \\_ { \\\\ell\
              \ } { \\\\in } { 0 , 1 }$ Commit $( g ^ { \\* } )$ to $\\\\nu$ .\n\n\
              7. $s$ receives $\\\\rho \\\\neq 0$ from $\\\\nu ^ { \\* }$ .\n\n8.\
              \ $s$ selects a polynomial $f ^ { \\* } : \\\\mathbb { F } ^ { \\\\\
              ell } \\\\to \\\\mathbb { F }$ with variable degree $d$ uniformly at\
              \ random conditioning on $\\\\begin{array} { r l r } { { \\\\sum \\\
              _ { x \\_ { 1 } , x \\_ { 2 } , \\\\cdots , x \\_ { \\\\ell } \\\\in\
              \ { 0 , 1 } } f ^ { \\* } ( x \\_ { 1 } , x \\_ { 2 } , \\\\cdots ,\
              \ x \\_ { \\\\ell } ) = H . } } & { { } } & { \\\\mathrm { ~ \\\\mathscr\
              \ { S } ~ t h e n ~ e n g a g e s ~ i n ~ a ~ s u m ~ } } \\ { \\\\\
              rho G ^ { \\* } = \\\\sum \\_ { x \\_ { 1 } , x \\_ { 2 } , \\\\cdots\
              \ , x \\_ { \\\\ell } \\\\in { 0 , 1 } } ( f ^ { \\* } ( x \\_ { 1 }\
              \ , x \\_ { 2 } , \\\\cdots , x \\_ { \\\\ell } ) + \\\\rho g ^ { \\\
              * } ( x \\_ { 1 } , x \\_ { 2 } , \\\\cdots , x \\_ { \\\\ell } ) )\
              \ } \\\\end{array}$ mcheck protocol with $\\\\nu$ on $H +$\n\n9. Let\
              \ $r \\\\in \\\\mathbb { F } ^ { \\\\ell }$ be the point chosen by $\\\
              \\nu ^ { \\* }$ in the sumcheck protocol. $s$ runs $( g ^ { \\\\ast\
              \ } ( r ) , \\\\pi ) \\\\gets \\\\mathsf { O p e n } ( g ^ { \\\\ast\
              \ } , r )$ and sends them to $\\\\nu$ .\n\n\nAs both $g$ and $g ^ {\
              \ \\* }$ are randomly selected, and the zkVPD protocol is zero-knowledge,\
              \ it is obvious that step 1 and 4 in $s$ are indistinguishable from\
              \ those in the real world of Construction 1. It remains to show that\
              \ the sumchecks in step 3 of both worlds are indistinguishable.\n\n\
              To see that, recall that in round $i$ of the sumcheck protocol, $\\\\\
              nu$ receives a univariate polynomial $h \\_ { i } ( x \\_ { i } ) =$\
              \ P $h ( r \\_ { 1 } , \\\\ldots , r \\_ { i - 1 } , x \\_ { i } , b\
              \ \\_ { i + 1 } , \\\\ldots , b \\_ { \\\\ell } )$ where $h = f + \\\
              \\rho g$ . (The view of $\\\\nu ^ { \\* }$ is defined in the same $b\
              \ \\_ { i + 1 } , . . . , b \\_ { \\\\ell } { \\\\in } { 0 , 1 }$ way\
              \ with ${ h ^ { \\* } , f ^ { \\* } , g ^ { \\* } }$ and we omit the\
              \ repetition in the following.) As the variable degree of $f$ and $g$\
              \ is $d , \\\\mathcal { P }$ sends $\\\\mathcal { V } h \\_ { i } (\
              \ 0 ) , h \\_ { i } ( 1 ) , \\\\ldots , h \\_ { i } ( d )$ which uniquely\
              \ defines $h \\_ { i } ( x \\_ { i } )$ . These evaluations reveal $d\
              \ + 1$ independent linear constraints on the coefficients of $h$ . In\
              \ addition, note that when these evaluations are computed honestly by\
              \ $\\\\mathcal { P }$ $, h \\_ { i } ( 0 ) + h \\_ { i } ( 1 ) = h \\\
              _ { i - 1 } ( r \\_ { i - 1 } )$ , as required in the sumcheck protocol.\
              \ Therefore, in all $\\\\ell$ rounds of the sumcheck, $\\\\nu$ and $\\\
              \\nu ^ { \\* }$ receives $\\\\ell ( d + 1 ) - ( \\\\ell - 1 ) = \\\\\
              ell d + 1$ independent linear constraints on the coefficients of $h$\
              \ and $h ^ { \\* }$ .\n\nAs $h$ and $h ^ { \\* }$ are masked by $g$\
              \ and $g ^ { \\* }$ , each with exactly $\\\\ell d + 1$ coefficients\
              \ selected randomly, the two linear systems are identically distributed.\
              \ Therefore, step 3 of the ideal world is indistinguishable from that\
              \ of the real world.\n\n# 2.4.2 Zero knowledge GKR\n\nTo achieve zero-knowledge,\
              \ we replace the sumcheck protocol in GKR with the zero-knowledge version\
              \ described in the previous section. However, the protocol still leaks\
              \ additional information. In particular, at the end of the zero-knowledge\
              \ sumcheck, $\\\\nu$ queries the oracle to evaluate the polynomial on\
              \ a random point. When executed on Equation 2.2, this reveals two evaluations\
              \ of the polynomial $\\\\tilde { V } \\_ { i }$ defined by the values\
              \ in the $i$ -th layer of the circuit: $\\\\tilde { V } \\_ { i } (\
              \ u )$ and $\\\\tilde { V } \\_ { i } ( v )$ .\n\nTo prevent this leakage,\
              \ Chiesa et al.\\[CFS17\\] proposed to replace the multi-linear extension\
              \ $\\\\tilde { V } \\_ { i }$ with a low degree extension, such that\
              \ learning $\\\\tilde { V } \\_ { i } ( u )$ and $\\\\tilde { V } \\\
              _ { i } \\\\bar { ( v ) }$ does not leak any information about $V \\\
              _ { i }$ . Define a low degree extension of $V \\_ { i }$ as\n\n$$\n\
              \\\\begin{array} { r } { \\\\dot { V \\_ { i } } ( z ) \\\\stackrel\
              \ { d e f } { = } \\\\tilde { V \\_ { i } } ( z ) + Z \\_ { i } ( z\
              \ ) \\\\sum \\_ { w \\\\in { 0 , 1 } ^ { \\\\lambda } } R \\_ { i }\
              \ ( z , w ) , } \\\\end{array}\n$$\n\nwhere $\\\\begin{array} { r }\
              \ { Z ( z ) = \\\\prod \\_ { i = 1 } ^ { s \\_ { i } } z \\_ { i } (\
              \ 1 - z \\_ { i } ) } \\\\end{array}$ , i.e., $Z ( z ) = 0$ for all\
              \ $z \\\\in { 0 , 1 } ^ { s \\_ { i } }$ . $R \\_ { i } ( z , w )$ is\
              \ a random low-degree polynomial and $\\\\lambda$ is the security parameter.\
              \ With this low degree extension, Equation 2.2 becomes\n\n$$\n\\\\begin{array}\
              \ { r l } & { \\\\dot { V } \\_ { i } ( g ) = \\\\sum \\_ { x , y \\\
              \\in { 0 , 1 } ^ { s \\_ { i + 1 } } } \\\\tilde { m u l t } \\_ { i\
              \ + 1 } ( g , x , y ) ( \\\\dot { V } \\_ { i + 1 } ( x ) \\\\dot {\
              \ V } \\_ { i + 1 } ( y ) ) } \\ & { \\\\qquad + a \\\\tilde { d d }\
              \ \\_ { i + 1 } ( g , x , y ) ( \\\\dot { V } \\_ { i + 1 } ( x ) +\
              \ \\\\dot { V } \\_ { i + 1 } ( y ) ) + Z \\_ { i } ( g ) \\\\sum \\\
              _ { w \\\\in { 0 , 1 } ^ { \\\\lambda } } R \\_ { i } ( g , w ) } \\\
              \ & { \\\\qquad = \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { i\
              \ + 1 } } , w \\\\in { 0 , 1 } ^ { \\\\lambda } } ( I ( \\\\vec { 0\
              \ } , w ) \\\\cdot \\\\tilde { m u l t } \\_ { i + 1 } ( g , x , y )\
              \ ( \\\\dot { V } \\_ { i + 1 } ( x ) \\\\dot { V } \\_ { i + 1 } (\
              \ y ) ) } \\ & { \\\\qquad + a \\\\tilde { d d } \\_ { i + 1 } ( g ,\
              \ x , y ) ( \\\\dot { V } \\_ { i + 1 } ( x ) + \\\\dot { V } \\_ {\
              \ i + 1 } ( y ) ) + I ( ( x , y ) , \\\\vec { 0 } ) Z \\_ { i } ( g\
              \ ) R \\_ { i } ( g , w ) ) } \\\\end{array}\n$$\n\nwhere $I ( \\\\\
              vec { a } , \\\\vec { b } )$ is an identity polynomial $I ( \\\\vec\
              \ { a } , \\\\vec { b } ) = 0$ iff ${ \\\\vec { a } } = { \\\\vec {\
              \ b } }$ . The first equation holds because $\\\\dot { V \\_ { i } }$\
              \ agrees with $\\\\tilde { V } \\_ { i }$ on the Boolean hyper-cube\
              \ ${ 0 , 1 } ^ { s \\_ { i } }$ , as $Z \\_ { i } ( z ) = 0$ for binary\
              \ inputs. The second equation holds because the mask in $\\\\dot { V\
              \ \\_ { i } }$ is in the form of a “sum” and can be moved into the sumcheck\
              \ equation.\n\nWhen executing the zero-knowledge sumcheck protocol on\
              \ Equation 2.8, at the end of the protocol, $\\\\nu$ receives $\\\\\
              dot { V } \\_ { i + 1 } ( u )$ and $\\\\dot { V } \\_ { i + 1 } ( v\
              \ )$ for random points $u , v \\\\in \\\\mathbb { F } ^ { s \\_ { i\
              \ + 1 } }$ chosen by $\\\\nu$ . They no longer leak information about\
              \ $V \\_ { i + 1 }$ , as they are masked by $\\\\begin{array} { r }\
              \ { Z \\_ { i + 1 } ( z ) \\\\sum \\_ { w \\\\in { 0 , 1 } ^ { \\\\\
              lambda } } R \\_ { i + 1 } ( z , w ) } \\\\end{array}$ for $z = u$ and\
              \ $z = v$ . $\\\\nu$ computes $\\\\tilde { m u l t } \\_ { i + 1 } (\
              \ g , u , v )$ and $a \\\\tilde { d } d \\_ { i + 1 } ( g , u , v )$\
              \ as before, computes $Z \\_ { i } ( g ) , I ( \\\\vec { 0 } , c ) ,\
              \ I ( ( u , v ) , \\\\vec { 0 } )$ where $c \\\\in \\\\mathbb { F }\
              \ ^ { \\\\lambda }$ is a random point chosen by $\\\\nu$ for variable\
              \ $w$ , opens $R \\_ { i } ( g , w )$ at $c$ with $\\\\mathcal { P }$\
              \ through a polynomial commitment, and checks that together with $\\\
              \\dot { V } \\_ { i + 1 } ( u ) , \\\\dot { V } \\_ { i + 1 } ( \\\\\
              bar { v } )$ received from $\\\\mathcal { P }$ they are consistent with\
              \ the last message of the sumcheck. $\\\\nu$ then uses $\\\\dot { V\
              \ } \\_ { i + 1 } ( u ) , \\\\dot { V } \\_ { i + 1 } ( v )$ to proceed\
              \ to the next round.\n\nUnfortunately, similar to the zk sumcheck, the\
              \ masking polynomial $R \\_ { i }$ is very large in \\[CFS17\\]. Opening\
              \ $R \\_ { i }$ at a random point takes exponential time for $\\\\mathcal\
              \ { P }$ either using a PCP oracle as in \\[CFS17\\] or potentially\
              \ using a zkVPD, as $R$ has $s \\_ { i } + 2 s \\_ { i + 1 } + \\\\\
              lambda$ variables.\n\nIn this section, we show that we can set $R \\\
              _ { i }$ to be a small polynomial to achieve zero-knowledge. In particular,\
              \ $R \\_ { i }$ has only two variables with variable degree 2. This\
              \ is because in the $( i - 1 )$ -th round, $\\\\nu$ receives two evaluations\
              \ of $V \\_ { i }$ , $\\\\dot { V } \\_ { i } ( u )$ and $\\\\dot {\
              \ V } \\_ { i } ( v )$ , which are masked by $\\\\textstyle \\\\sum\
              \ \\_ { w } R \\_ { i } ( u , w )$ and $\\\\textstyle \\\\sum \\_ {\
              \ w } R \\_ { i } ( v , w )$ ; in the $i$ -th sumcheck, $\\\\nu$ opens\
              \ $R \\_ { i }$ at $R \\_ { i } ( u , c )$ and $R \\_ { i } ( v , c\
              \ )$ . It suffices to make these four evaluations linearly independent,\
              \ assuming the commitment and opening of $R \\_ { i }$ are using a zkVPD.\
              \ Therefore, we set the lowdegree term in Equation 2.7 as $\\\\begin{array}\
              \ { r } { Z \\_ { i } ( z ) \\\\sum \\_ { w \\\\in { 0 , 1 } } R \\\
              _ { i } ( z \\_ { 1 } , w ) } \\\\end{array}$ , i.e. $R \\_ { i }$ only\
              \ takes two variables, the first variable $z \\_ { 1 }$ of $z$ and an\
              \ extra variable $w \\\\in { 0 , 1 }$ instead of ${ 0 , 1 } ^ { \\\\\
              lambda }$ , with variable degree 2.\n\nThe full protocol is presented\
              \ in Construction 2. Here we use superscriptions (e.g., $\\\\boldsymbol\
              \ { u } ^ { ( i ) } .$ ) to denote random numbers or vectors for the\
              \ $i$ -th layer of the circuit.\n\nConstruction 2. 1. On a layered arithmetic\
              \ circuit $C$ with $d$ layers and input in, the prover $\\\\mathcal\
              \ { P }$ sends the output of the circuit out to the verifier $\\\\nu$\
              \ . 2. $\\\\mathcal { P }$ randomly selects polynomials $R \\_ { 1 }\
              \ ( z \\_ { 1 } , w ) , \\\\ldots , R \\_ { d } ( z \\_ { 1 } , w )\
              \ : \\\\mathbb { F } ^ { 2 } \\\\to \\\\mathbb { F }$ with variable\
              \ degree 2. $\\\\mathcal { P }$ commits to these polynomials by sending\
              \ ${ \\\\mathsf { c o m } } \\_ { i } \\\\gets { \\\\mathsf { C o m\
              \ m i t } } ( R \\_ { i } )$ to $\\\\nu$ for $i \\\\in \\[ 1 , d \\\
              ]$ . 3. V defines $\\\\dot { V } \\_ { 0 } ( z ) = \\\\tilde { V } \\\
              _ { 0 } ( z )$ , where $\\\\tilde { V } \\_ { 0 } ( z )$ is the multilinear\
              \ extension of out. $\\\\dot { V } \\_ { 0 } ( z )$ can be viewed as\
              \ a special case with $R \\_ { 0 } ( z \\_ { 1 } , w )$ being the $O$\
              \ polynomial. $\\\\nu$ evaluates it at a random point $\\\\dot { V }\
              \ \\_ { 0 } ( g ^ { ( 0 ) } )$ and sends $g ^ { ( 0 ) } \\ t o \\ \\\
              \\mathcal { P }$ .\n\n4. $\\\\mathcal { P }$ and $\\\\nu$ execute the\
              \ zero knowledge sumcheck protocol presented in Construction 1 on\n\n\
              $$\n\\\\begin{array} { r l r } { { \\\\dot { V } \\_ { 0 } ( g ^ { (\
              \ 0 ) } ) = \\\\sum \\_ { x , y \\\\in { 0 , 1 } ^ { s \\_ { 1 } } }\
              \ m \\\\tilde { u } l t \\_ { 1 } ( g ^ { ( 0 ) } , x , y ) ( \\\\dot\
              \ { V } \\_ { 1 } ( x ) \\\\dot { V } \\_ { 1 } ( y ) ) } } \\ & { }\
              \ & { + a \\\\tilde { d } d \\_ { 1 } ( g ^ { ( 0 ) } , x , y ) ( \\\
              \\dot { V } \\_ { 1 } ( x ) + \\\\dot { V } \\_ { 1 } ( y ) ) } \\\\\
              end{array}\n$$\n\nIf $\\\\mathsf { r } u \\_ { 1 } ^ { ( 1 ) } = v \\\
              _ { 1 } ^ { ( 1 ) }$ , $\\\\mathcal { P }$ aborts. At the end of the\
              \ protocol, $\\\\nu$ receives $\\\\dot { V } \\_ { 1 } ( u ^ { ( 1 )\
              \ } )$ and $\\\\dot { V } \\_ { 1 } ( v ^ { ( 1 ) } )$ . $\\\\nu$ computes\
              \ $\\\\tilde { m u l t \\_ { 1 } } ( g ^ { ( 0 ) } , u ^ { ( 1 ) } ,\
              \ v ^ { ( 1 ) } ) , a \\\\tilde { d } d \\_ { 1 } ( g ^ { ( 0 ) } ,\
              \ u ^ { ( 1 ) } , v ^ { ( 1 ) } )$ and checks that\n\n$$\n\\\\begin{array}\
              \ { r } { m \\\\tilde { u } l t \\_ { 1 } ( g ^ { ( 0 ) } , u ^ { (\
              \ 1 ) } , v ^ { ( 1 ) } ) \\\\dot { V } \\_ { 1 } ( u ^ { ( 1 ) } )\
              \ \\\\dot { V } \\_ { 1 } ( v ^ { ( 1 ) } ) + a \\\\tilde { d } d \\\
              _ { 1 } ( g ^ { ( 0 ) } , u ^ { ( 1 ) } , v ^ { ( 1 ) } ) ( \\\\dot\
              \ { V } \\_ { 1 } ( u ^ { ( 1 ) } ) + \\\\dot { V } \\_ { 1 } ( v ^\
              \ { ( 1 ) } ) ) } \\\\end{array}\n$$\n\nequals to the last message of\
              \ the sumcheck (evaluation oracle).\n\n5. For layer $i = 1 , \\\\ldots\
              \ , d - 1$ :\n\na) $\\\\nu$ randomly selects $\\\\alpha ^ { ( i ) }\
              \ , \\\\beta ^ { ( i ) } \\\\in \\\\mathbb { F }$ and sends them to\
              \ $\\\\mathcal { P }$ .\n\n$^ b$ ) Let $\\\\begin{array} { r } { M u\
              \ l t \\_ { i + 1 } ( x , y ) = \\\\alpha ^ { ( i ) } m \\\\tilde {\
              \ u } l t \\_ { i + 1 } ( u ^ { ( i ) } , x , y ) + \\\\beta ^ { ( i\
              \ ) } m \\\\tilde { u } l t \\_ { i + 1 } ( v ^ { ( i ) } , x , y )\
              \ } \\\\end{array}$ and $A d d \\_ { i + 1 } ( x , y ) = \\\\alpha ^\
              \ { ( i ) } a \\\\tilde { d } d \\_ { i + 1 } ( u ^ { ( i ) } , x ,\
              \ y ) + \\\\beta ^ { ( i ) } a \\\\tilde { d } d \\_ { i + 1 } ( v ^\
              \ { ( i ) } , x , y ) .$ $\\\\mathcal { P }$ and $\\\\nu$ run the zero\
              \ knowledge sumcheck on the equation\n\n$$\n\\\\begin{array} { r l }\
              \ & { \\\\alpha ^ { ( i ) } \\\\dot { V } \\_ { i } ( u ^ { ( i ) }\
              \ ) + \\\\beta ^ { ( i ) } \\\\dot { V } \\_ { i } ( v ^ { ( i ) } )\
              \ = } \\ & { \\\\qquad \\\\quad \\\\displaystyle \\\\sum \\_ { x , y\
              \ \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } ( I ( \\\\vec { 0 } , w )\
              \ \\\\cdot M u l t \\_ { i + 1 } ( x , y ) ( \\\\dot { V } \\_ { i +\
              \ 1 } ( x ) \\\\dot { V } \\_ { i + 1 } ( y ) ) } \\ & { \\\\qquad \\\
              \\quad \\\\displaystyle \\ w \\\\in { 0 , 1 } ^ { s \\_ { i } } } \\\
              \ & { \\\\qquad \\\\quad + A d d \\_ { i + 1 } ( x , y ) ( \\\\dot {\
              \ V } \\_ { i + 1 } ( x ) + \\\\dot { V } \\_ { i + 1 } ( y ) ) } \\\
              \ & { \\\\qquad \\\\quad + I ( ( x , y ) , \\\\vec { 0 } ) ( \\\\alpha\
              \ ^ { ( i ) } Z \\_ { i } ( u ^ { ( i ) } ) R \\_ { i } ( u \\_ { 1\
              \ } ^ { ( i ) } , w ) + \\\\beta ^ { ( i ) } Z \\_ { i } ( v ^ { ( i\
              \ ) } ) R \\_ { i } ( v \\_ { 1 } ^ { ( i ) } , w ) ) ) } \\\\end{array}\n\
              $$\n\n$\\\\dot { \\\\boldsymbol { \\\\cdot } } \\\\boldsymbol { u }\
              \ \\_ { 1 } ^ { ( i + 1 ) } = \\\\boldsymbol { v } \\_ { 1 } ^ { ( i\
              \ + 1 ) }$ $\\\\mathcal { P }$ aborts.\n\n$c$ ) At the end of the zero-knowledge\
              \ sumcheck protocol, $\\\\mathcal { P }$ sends $\\\\mathcal { V } \\\
              \\dot { V } \\_ { i + 1 } ( \\\\boldsymbol { u } ^ { ( i + 1 ) } )$\
              \ and $\\\\dot { V } \\_ { i + 1 } ( v ^ { ( i + 1 ) } ,$ d) $\\\\nu$\
              \ computes\n\n$$\na \\_ { i + 1 } = \\\\alpha ^ { ( i ) } m \\\\tilde\
              \ { u } l t \\_ { i + 1 } ( u ^ { ( i ) } , u ^ { ( i + 1 ) } , v ^\
              \ { ( i + 1 ) } ) + \\\\beta ^ { ( i ) } m \\\\tilde { u } l t \\_ {\
              \ i + 1 } ( v ^ { ( i ) } , u ^ { ( i + 1 ) } , v ^ { ( i + 1 ) } )\n\
              $$\n\nand\n\n$$\nb \\_ { i + 1 } = \\\\alpha ^ { ( i ) } a \\\\tilde\
              \ { d } d \\_ { i + 1 } ( u ^ { ( i ) } , u ^ { ( i + 1 ) } , v ^ {\
              \ ( i + 1 ) } ) + \\\\beta ^ { ( i ) } a \\\\tilde { d } d \\_ { i +\
              \ 1 } ( v ^ { ( i ) } , u ^ { ( i + 1 ) } , v ^ { ( i + 1 ) } )\n$$\n\
              \nlocally. $\\\\nu$ computes $Z \\_ { i } ( u ^ { ( i ) } ) , Z \\_\
              \ { i } ( v ^ { ( i ) } ) , I ( \\\\vec { 0 } , c ^ { ( i ) } ) , I\
              \ ( ( u ^ { ( i + 1 ) } , v ^ { ( i + 1 ) } ) , \\\\vec { 0 } )$ locally.\n\
              \ne) $\\\\mathcal { P }$ and $\\\\nu$ open $R \\_ { i }$ at two points\
              \ $R \\_ { i } ( u \\_ { 1 } ^ { ( i ) } , c ^ { ( i ) } )$ and $R \\\
              _ { i } ( v \\_ { 1 } ^ { ( i ) } , c ^ { ( i ) } )$ using Open and\
              \ Verify.\n\nf) V computes the following as the evaluation oracle and\
              \ uses it to complete the last step of the zero-knowledge sumcheck.\n\
              \n$$\n\\\\begin{array} { r l } & { I ( \\\\vec { 0 } , c ^ { ( i ) }\
              \ ) ( a \\_ { i + 1 } ( \\\\dot { V } \\_ { i + 1 } ( u ^ { ( i + 1\
              \ ) } ) \\\\dot { V } \\_ { i + 1 } ( v ^ { ( i + 1 ) } ) ) + } \\ &\
              \ { b \\_ { i + 1 } ( \\\\dot { V } \\_ { i + 1 } ( u ^ { ( i + 1 )\
              \ } ) + \\\\dot { V } \\_ { i + 1 } ( v ^ { ( i + 1 ) } ) ) + } \\ &\
              \ { I ( ( u ^ { ( i + 1 ) } , v ^ { ( i + 1 ) } ) , \\\\vec { 0 } )\
              \ ( \\\\alpha ^ { ( i ) } Z \\_ { i } ( u ^ { ( i ) } ) R \\_ { i }\
              \ ( u \\_ { 1 } ^ { ( i ) } , c ^ { ( i ) } ) + \\\\beta ^ { ( i ) }\
              \ Z \\_ { i } ( v ^ { ( i ) } ) R \\_ { i } ( v \\_ { 1 } ^ { ( i )\
              \ } , c ^ { ( i ) } ) ) } \\\\end{array}\n$$\n\nIf all checks in the\
              \ zero knowledge sumcheck and Verify passes, $\\\\nu$ uses $\\\\dot\
              \ { V } \\_ { i + 1 } ( u ^ { ( i + 1 ) } )$ and $\\\\dot { V } \\_\
              \ { i + 1 } ( v ^ { ( i + 1 ) } )$ to proceed to the $( i + 1 )$ -th\
              \ layer. Otherwise, $\\\\nu$ outputs reject and aborts.\n\n6. At the\
              \ input layer $d$ , $\\\\nu$ has two claims $\\\\dot { V } \\_ { d }\
              \ ( u ^ { ( d ) } )$ and $\\\\dot { V } \\_ { d } ( v ^ { ( d ) } )$\
              \ . $\\\\nu$ opens $R \\_ { d }$ at 4 points $R \\_ { d } ( u \\_ {\
              \ 1 } ^ { ( d ) } , 0 )$ , $R \\_ { d } ( u \\_ { 1 } ^ { ( d ) } ,\
              \ 1 ) , R \\_ { d } ( v \\_ { 1 } ^ { ( d ) } , 0 ) , R \\_ { d } (\
              \ v \\_ { 1 } ^ { ( d ) } , 1 )$ and checks that $\\\\dot { V } \\_\
              \ { d } ( u ^ { ( d ) } ) = \\\\tilde { V } \\_ { d } ( u ^ { ( d )\
              \ } ) + Z \\_ { d } ( u ^ { ( d ) } ) \\\\quad \\\\sum \\_ { \\\\substack\
              \ { - \\\\infty \\\\ldots + 1 } } R \\_ { d }$ $w \\\\in { 0 , 1 }$\
              \ ${ \\\\bf \\\\Phi } \\_ { u \\_ { 1 } } ^ { ( d ) } , w \\\\mathrm\
              \ { \\\\bf \\\\Phi } \\_ { u } n d \\\\dot { V } \\_ { d } ( v ^ { (\
              \ d ) } ) = \\\\tilde { V } \\_ { d } ( v ^ { ( d ) } ) + Z \\_ { d\
              \ } ( v ^ { ( d ) } ) \\\\sum \\_ { w \\\\in { 0 , 1 } } R \\_ { d }\
              \ ( v \\_ { 1 } ^ { ( d ) } , w ) ,$ given oracle access to two evaluates\
              \ of $\\\\tilde { V \\_ { d } }$ at $\\\\boldsymbol u ^ { ( d ) }$ and\
              \ $v ^ { ( d ) }$ . If the check passes, output accept; otherwise, output\
              \ reject.\n\nTheorem 2.4.2. Construction 2 is an interactive proof protocol\
              \ per Definition 2.2.1, for a function $f$ defined by a layered arithmetic\
              \ circuit $C$ such that $f ( \\\\mathsf { i n } , \\\\mathsf { o u t\
              \ } ) = 1$ iff $C ( \\\\mathfrak { i n } ) =$ out. In addition, for\
              \ every verifier $\\\\nu ^ { \\* }$ and every layered circuit $C$ ,\
              \ there exists a simulator $s$ such that given oracle access to out,\
              \ $s$ is able to simulate the partial view of $\\\\nu ^ { \\* }$ in\
              \ step 1-5 of Construction 2.\n\nThe completeness follows from the construction\
              \ explained above and the completeness of the zero knowledge sumcheck.\
              \ The soundness follows the soundness of the GKR protocol with low degree\
              \ extensions, as proven in \\[GKR15\\] and \\[CFS17\\]. We give the\
              \ proof of zero knowledge here.\n\nProof. With oracle access to out,\
              \ and the simulator $ { \\\\boldsymbol { S } } \\_ { s c }$ of the zero-knowledge\
              \ sumcheck protocol in Section 2.4.1 as a subroutine, we construct the\
              \ simulator $s$ as following:\n\n1. $s$ sends the out to $\\\\nu ^ {\
              \ \\* }$ . 2. $s$ randomly selects polynomials $R \\_ { 1 } ^ { \\*\
              \ } ( z \\_ { 1 } , w ) , \\\\ldots , R \\_ { d } ^ { \\* } ( z \\_\
              \ { 1 } , w ) \\ : \\ \\\\mathbb { F } ^ { 2 } \\ \\\\to \\ \\\\mathbb\
              \ { F }$ with variable degree 2. S commits to these polynomials by sending\
              \ ${ \\\\mathsf { c o m } } \\_ { i } \\\\gets { \\\\mathsf { C o m\
              \ m i t } } ( R \\_ { i } ^ { \\* } )$ to $\\\\nu ^ { \\* }$ for $i\
              \ \\\\in \\[ 1 , d \\]$ .\n\n2. $s$ receives $g ^ { ( 0 ) }$ from $\\\
              \\nu ^ { \\* }$ .\n\n3. $s$ calls $\\\\boldsymbol { S \\_ { s c } }$\
              \ to simulate the partial view of the zero knowledge sumcheck protocol\
              \ on\n\n\n$$\n\\\\dot { V } \\_ { 0 } ( g ^ { ( 0 ) } ) = \\\\sum \\\
              _ { x , y \\\\in { 0 , 1 } ^ { s \\_ { 1 } } } m \\\\tilde { u } l t\
              \ \\_ { 1 } ( g ^ { ( 0 ) } , x , y ) ( \\\\dot { V } \\_ { 1 } ( x\
              \ ) \\\\dot { V } \\_ { 1 } ( y ) ) + a \\\\tilde { d } d \\_ { 1 }\
              \ ( g ^ { ( 0 ) } , x , y ) ( \\\\dot { V } \\_ { 1 } ( x ) + \\\\dot\
              \ { V } \\_ { 1 } ( y ) )\n$$\n\nIf $u \\_ { 1 } ^ { ( 1 ) } = v \\\
              _ { 1 } ^ { ( 1 ) }$ , $\\\\boldsymbol { s }$ aborts. At the end of\
              \ the sumcheck, $s$ samples $\\\\dot { V } \\_ { 1 } ^ { \\* } ( u ^\
              \ { ( 1 ) } )$ and $\\\\dot { V } \\_ { 1 } ^ { \\* } ( v ^ { ( 1 )\
              \ } )$ such that $\\\\begin{array} { r } { \\\\widehat { m u l t 1 }\
              \ \\_ { 1 } ( g ^ { ( 0 ) } , \\\\dot { u } ^ { ( 1 ) } , v ^ { ( 1\
              \ ) } ) \\\\dot { V } \\_ { 1 } ^ { \\* } ( u ^ { ( 1 ) } ) \\\\dot\
              \ { V } \\_ { 1 } ^ { \\* } ( v ^ { ( 1 ) } ) + a \\\\tilde { d } d\
              \ \\_ { 1 } ( g ^ { ( 0 ) } , u ^ { ( 1 ) } , v ^ { ( 1 ) } ) \\\\left(\
              \ \\\\dot { V } \\_ { 1 } ^ { \\* } ( u ^ { ( 1 ) } ) + \\\\dot { V\
              \ } \\_ { 1 } ^ { \\* } ( v ^ { ( 1 ) } ) \\\\right) V \\_ { 1 } ^ {\
              \ \\* } ( u ^ { ( 1 ) } ) d \\_ { 1 } d \\_ { 1 } = 0 . } \\\\end{array}$\
              \ equals to the last message of the sumcheck.\n\n5. For layer $i = 1\
              \ , \\\\ldots , d - 1$ :\n\na) $s$ receives $\\\\alpha ^ { ( i ) } ,\
              \ \\\\beta ^ { ( i ) }$ from $\\\\nu ^ { \\* }$ .\n\nb) Le $\\\\begin{array}\
              \ { r } { \\\\cdot M u l t \\_ { i + 1 } ( x , y ) = \\\\alpha ^ { (\
              \ i ) } m \\\\tilde { u } l t \\_ { i + 1 } ( u ^ { ( i ) } , x , y\
              \ ) + \\\\beta ^ { ( i ) } m \\\\tilde { u } l t \\_ { i + 1 } ( v ^\
              \ { ( i ) } , x , y ) } \\\\end{array}$ and $A d d \\_ { i + 1 } ( x\
              \ , y ) = { \\\\alpha } ^ { ( i ) } a \\\\tilde { d } d \\_ { i + 1\
              \ } ( u ^ { ( i ) } , x , y ) + \\\\beta ^ { ( i ) } a \\\\tilde { d\
              \ } d \\_ { i + 1 } ( v ^ { ( i ) } , x , y ) .$ $s$ calls $\\\\mathcal\
              \ { S } \\_ { s c }$ to simulate the partial view of the zero knowledge\
              \ sumcheck protocol on\n\n$$\n\\\\begin{array} { r l } { \\\\alpha ^\
              \ { ( i ) } \\\\dot { V } \\_ { i } ( u ^ { ( i ) } ) + \\\\beta ^ {\
              \ ( i ) } \\\\dot { V } \\_ { i } ( v ^ { ( i ) } ) = } & { } \\ & {\
              \ \\\\qquad \\\\displaystyle \\\\sum \\_ { \\\\begin{array} { l } {\
              \ x , y \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } \\ { w \\\\in { 0 ,\
              \ 1 } ^ { s \\_ { i } } } \\\\end{array} } ( I ( \\\\vec { 0 } , w )\
              \ \\\\cdot M u l t \\_ { i + 1 } ( x , y ) ( \\\\dot { V } \\_ { i +\
              \ 1 } ( x ) \\\\dot { V } \\_ { i + 1 } ( y ) ) } \\ & { \\\\qquad \\\
              \\displaystyle + A d d \\_ { i + 1 } ( x , y ) ( \\\\dot { V } \\_ {\
              \ i + 1 } ( x ) + \\\\dot { V } \\_ { i + 1 } ( y ) ) } \\ & { \\\\\
              quad + I ( ( x , y ) , \\\\vec { 0 } ) ( \\\\alpha ^ { ( i ) } Z \\\
              _ { i } ( u ^ { ( i ) } ) R \\_ { i } ( u \\_ { 1 } ^ { ( i ) } , w\
              \ ) + \\\\beta ^ { ( i ) } Z \\_ { i } ( v ^ { ( i ) } ) R \\_ { i }\
              \ ( v \\_ { 1 } ^ { ( i ) } , w ) ) ) } \\\\end{array}\n$$\n\nIf u $u\
              \ \\_ { 1 } ^ { ( i + 1 ) } = v \\_ { 1 } ^ { ( i + 1 ) }$ S aborts.\n\
              \nc) At the end of the zero-knowledge sumcheck protocol, if $u \\_ {\
              \ 1 } ^ { ( i + 1 ) } = v \\_ { 1 } ^ { ( i + 1 ) }$ , $s$ aborts. Otherwise,\
              \ $s$ samples $\\\\dot { V } \\_ { i + 1 } ^ { \\* } ( u ^ { ( i + 1\
              \ ) } )$ and $\\\\dot { V } \\_ { i + 1 } ^ { \\* } ( v ^ { ( i + 1\
              \ ) } )$ randomly such that the following equals to the last message\
              \ of the sumcheck protocol.\n\n$\\\\begin{array} { r } { I ( \\\\vec\
              \ { 0 } , c ^ { ( i ) } ) ( a \\_ { i + 1 } ( \\\\dot { V } \\_ { i\
              \ + 1 } ^ { \\* } ( u ^ { ( i + 1 ) } ) \\\\dot { V } \\_ { i + 1 }\
              \ ^ { \\* } ( v ^ { ( i + 1 ) } ) ) + b \\_ { i + 1 } ( \\\\dot { V\
              \ } \\_ { i + 1 } ^ { \\* } ( u ^ { ( i + 1 ) } ) + \\\\dot { V } \\\
              _ { i + 1 } ^ { \\* } ( v ^ { ( i + 1 ) } ) ) ) } \\ { + I ( ( u ^ {\
              \ ( i + 1 ) } , v ^ { ( i + 1 ) } ) , \\\\vec { 0 } ) ( \\\\alpha ^\
              \ { ( i ) } Z \\_ { i } ( u ^ { ( i ) } ) R \\_ { i } ^ { \\* } ( u\
              \ \\_ { 1 } ^ { ( i ) } , c ^ { ( i ) } ) + \\\\beta ^ { ( i ) } Z \\\
              _ { i } ( v ^ { ( i ) } ) R \\_ { i } ^ { \\* } ( v \\_ { 1 } ^ { (\
              \ i ) } , c ^ { ( i ) } ) ) } \\\\end{array}$ $a \\_ { i + 1 } = \\\\\
              alpha ^ { ( i ) } m \\\\tilde { u } l t \\_ { i + 1 } ( u ^ { ( i )\
              \ } , u ^ { ( i + 1 ) } , v ^ { ( i + 1 ) } ) + \\\\beta ^ { ( i ) }\
              \ m \\\\tilde { u } l t \\_ { i + 1 } ( v ^ { ( i ) } , u ^ { ( i +\
              \ 1 ) } , v ^ { ( i + 1 ) } )$ and $b \\_ { i + 1 } = \\\\alpha ^ {\
              \ ( i ) } a \\\\tilde { d } d \\_ { i + 1 } ( u ^ { ( i ) } , u ^ {\
              \ ( i + 1 ) } , v ^ { ( i + 1 ) } ) + \\\\beta ^ { ( i ) } a \\\\tilde\
              \ { d } d \\_ { i + 1 } ( v ^ { ( i ) } , u ^ { ( i + 1 ) } , v ^ {\
              \ ( i + 1 ) } ) .$ $s$ sends $\\\\dot { V } \\_ { i + 1 } ( u ^ { (\
              \ i + 1 ) } )$ and $\\\\dot { V } \\_ { i + 1 } ( v ^ { ( i + 1 ) }\
              \ )$ to $\\\\nu ^ { \\* }$ . d) $\\\\nu ^ { \\* }$ computes the corresponding\
              \ values locally as in step 5(d) of Construction 2. e) $s$ opens $R\
              \ \\_ { i } ^ { \\* }$ at two points $R \\_ { i } ^ { \\* } ( u \\_\
              \ { 1 } ^ { ( i ) } , c ^ { ( i ) } )$ and $R \\_ { i } ^ { \\* } (\
              \ v \\_ { 1 } ^ { ( i ) } , c ^ { ( i ) } )$ using Open. f) $\\\\nu\
              \ ^ { \\* }$ performs the checks as in step 5(f) of Construction 2.\n\
              \nNote here that $\\\\nu ^ { \\* }$ can actually behave arbitrarily\
              \ in step 5(d) and 5(f) above. We include these steps to be consistent\
              \ with the real world in Construction 2 for the ease of interpretation.\n\
              \nTo prove zero-knowledge, step 1,3, 5(a), 5(d) and 5(f) are obviously\
              \ indistinguishable as $s$ only receives messages from $\\\\nu ^ { \\\
              * }$ . Step 2 and 5(e) of both worlds are indistinguishable because\
              \ of the zero knowledge property of the zkVPD, and the fact that $R\
              \ ^ { \\* }$ and $R$ are sampled randomly in both worlds. Step 4 and\
              \ 5(b) are indistinguishable as proven in Theorem 2.4.1 for $\\\\boldsymbol\
              \ { S \\_ { s c } }$ .\n\nIt remains to consider the messages received\
              \ at the end of step 4 and in step 5(c), namely $\\\\dot { V } \\_ {\
              \ i } ( u ^ { ( i ) } ) , \\\\dot { V } \\_ { i } ( v ^ { ( i ) } )$\
              \ and $\\\\dot { V } \\_ { i } ^ { \\* } ( u ^ { ( i ) } ) , \\\\dot\
              \ { V } \\_ { i } ^ { \\* } ( v ^ { ( i ) } )$ for $i = 1 , \\\\ldots\
              \ , d$ . In the real world, $\\\\dot { V } \\_ { i } ( z )$ is masked\
              \ by $\\\\sum \\_ { w \\\\in { 0 , 1 } } R \\_ { i } ( z \\_ { 1 } ,\
              \ w ) \\\\left( Z ( z ) \\\\right.$ is publicly known), thus $\\\\dot\
              \ { V } \\_ { i } ( u ^ { ( i ) } )$ and $\\\\dot { V } \\_ { i } (\
              \ v ^ { ( i ) } )$ are masked by $\\\\sum \\_ { \\\\prime \\\\in { 0\
              \ , 1 } } R \\_ { i } ( u \\_ { 1 } ^ { ( i ) } , w )$ and $\\\\sum\
              \ \\_ { \\\\prime \\\\in { 0 , 1 } } R \\_ { i } ( v \\_ { 1 } ^ { (\
              \ i ) } , w )$ correspondingly. In addition, in step 5(e), $\\\\nu ^\
              \ { \\* }$ opens $R \\_ { i }$ at $R \\_ { i } ( u \\_ { 1 } ^ { ( i\
              \ ) } , c ^ { ( i ) } )$ and $R \\_ { i } ( v \\_ { 1 } ^ { ( i ) }\
              \ , c ^ { ( i ) } )$ . To simplify the notation here, we consider only\
              \ a particular layer and omit the subscription and superscription of\
              \ $i$ . Let\n\n$R ( z \\_ { 1 } , w ) = a \\_ { 0 } + a \\_ { 1 } z\
              \ \\_ { 1 } + a \\_ { 2 } w + a \\_ { 3 } z \\_ { 1 } w + a \\_ { 4\
              \ } z \\_ { 1 } ^ { 2 } + a \\_ { 5 } w ^ { 2 } + a \\_ { 6 } z \\_\
              \ { 1 } ^ { 2 } w ^ { 2 }$ where $a \\_ { 0 } , \\\\ldots , a \\_ {\
              \ 6 }$ are randomly chosen. We can write the four evaluations above\
              \ as\n\n$$\n{ \\\\left\\[ \\\\begin{array} { l l l l l l l l } { 2 }\
              \ & { 2 u \\_ { 1 } } & { 1 } & { u \\_ { 1 } } & { 2 u \\_ { 1 } ^\
              \ { 2 } } & { 1 } & { u \\_ { 1 } ^ { 2 } } \\ { 2 } & { 2 v \\_ { 1\
              \ } } & { 1 } & { v \\_ { 1 } } & { 2 v \\_ { 1 } ^ { 2 } } & { 1 }\
              \ & { v \\_ { 1 } ^ { 2 } } \\ { 1 } & { u \\_ { 1 } } & { c } & { c\
              \ u \\_ { 1 } } & { u \\_ { 1 } ^ { 2 } } & { c ^ { 2 } } & { c ^ {\
              \ 2 } u \\_ { 1 } ^ { 2 } } \\ { 1 } & { v \\_ { 1 } } & { c } & { c\
              \ v \\_ { 1 } } & { v \\_ { 1 } ^ { 2 } } & { c ^ { 2 } } & { c ^ {\
              \ 2 } v \\_ { 1 } ^ { 2 } } \\\\end{array} \\\\right\\] } \\\\times\
              \ { \\\\left\\[ \\\\begin{array} { l l l l l l l } { a \\_ { 0 } } &\
              \ { a \\_ { 1 } } & { a \\_ { 2 } } & { a \\_ { 3 } } & { a \\_ { 4\
              \ } } & { a \\_ { 5 } } & { a \\_ { 6 } } \\\\end{array} \\\\right\\\
              ] } ^ { T }\n$$\n\nAfter row reduction, the left matrix is\n\n$$\n\\\
              \\begin{array} { r l r l r l r l } { { 2 } } & { 2 u \\_ { 1 } } & &\
              \ { 1 } & & { u \\_ { 1 } } & & { 2 u \\_ { 1 } ^ { 2 } } & & { 1 }\
              \ & & { u \\_ { 1 } ^ { 2 } } \\ { 0 } & { 2 ( v \\_ { 1 } - u \\_ {\
              \ 1 } ) } & { 0 } & & { v \\_ { 1 } - u \\_ { 1 } } & { 2 ( u \\_ {\
              \ 1 } ^ { 2 } - v \\_ { 1 } ^ { 2 } ) } & { 0 } & & { u \\_ { 1 } ^\
              \ { 2 } - v \\_ { 1 } ^ { 2 } } \\ { 0 } & { 0 } & { 2 c - 1 } & & {\
              \ ( 2 c - 1 ) u \\_ { 1 } } & & { 0 } & { 2 c ^ { 2 } - 1 } & & { (\
              \ 2 c ^ { 2 } - 1 ) u \\_ { 1 } ^ { 2 } } \\ { 0 } & { 0 } & & { 0 }\
              \ & & { ( 2 c - 1 ) ( v \\_ { 1 } - u \\_ { 1 } ) } & & { 0 } & & {\
              \ 0 } & & { ( 2 c ^ { 2 } - 1 ) ( v \\_ { 1 } ^ { 2 } - u \\_ { 1 }\
              \ ^ { 2 } ) } \\\\end{array}\n$$\n\nAs $u \\_ { 1 } \\\\neq v \\_ {\
              \ 1 }$ , the matrix has full rank if $2 c ^ { 2 } - 1 \\\\neq 0$ mod\
              \ $p$ , where $p$ is the prime that defines $\\\\mathbb { F }$ . This\
              \ holds if $2 ^ { - 1 }$ is not in the quadratic residue of $p$ , or\
              \ equivalently $p \\\\not \\\\equiv 1 , 7$ mod 8.⁴ In case $p \\\\equiv\
              \ 1 , 7$ mod 8, we can add a check to both the protocol and the simulator\
              \ to abort if $2 c ^ { 2 } - 1 = 0$ . This does not affect the proof\
              \ of zero knowledge, and only reduces the soundness error by a small\
              \ amount. ⁵\n\nBecause of the full rank of the matrix, the four evaluations\
              \ are linearly independent and uniformly distributed, as $a \\_ { 0\
              \ } , \\\\ldots a \\_ { 6 }$ are chosen randomly. In the ideal world,\
              \ $\\\\boldsymbol { R } ^ { \\* } ( u \\_ { 1 } , c )$ and $\\\\boldsymbol\
              \ { R } ^ { \\* } ( \\\\boldsymbol { v } \\_ { 1 } , \\\\boldsymbol\
              \ { c } )$ are independent and uniformly distributed, and $\\\\dot {\
              \ V } ^ { \\* } ( u ) , \\\\dot { V } ^ { \\* } ( v )$ are randomly\
              \ selected subject to a linear constraint (step 5(c)), which is the\
              \ same as the real world. Therefore, they are indistinguishable in the\
              \ two worlds, which completes the proof.\n\n# 2.4.3 Zero knowledge VPD\n\
              \nIn this section, we present the instantiations of the zkVPD protocol,\
              \ as defined in Definition 2.2.5. For every intermediate layer $i$ ,\
              \ we use the same zkVPD protocol as proposed by Zhang et al. in \\[ZGKPP17a\\\
              ] to commit and open the masking polynomials $g \\_ { i } ( x ) , R\
              \ \\_ { i } ( z \\_ { 1 } , w )$ . In fact, as we show in the previous\
              \ sections, these polynomials are very small $( g \\_ { i }$ is the\
              \ sum of univariate polynomials and $R \\_ { i }$ has 2 variables with\
              \ variable degree 2), the zkVPD protocols become very simple. The complexity\
              \ of KeyGen, Commit, Open, Verify and proof size are all $O ( s \\_\
              \ { i } )$ for $g \\_ { i }$ and are all $O ( 1 )$ for $R \\_ { i }$\
              \ . We omit the full protocols due to space limit.\n\nFor the zkVPD\
              \ used for the input layer, we design a customized protocol based on\
              \ the zkVPD protocol in \\[ZGKPP17a\\]. Recall that at the end of the\
              \ GKR protocol, $\\\\nu$ receives two evaluations of the polynomial\
              \ $\\\\begin{array} { r } { \\\\dot { V } \\_ { d } ( z ) = \\\\tilde\
              \ { V } \\_ { d } ( z ) + Z \\_ { d } ( z ) \\\\sum \\_ { w \\\\in {\
              \ 0 , 1 } } R \\_ { d } ( z \\_ { 1 } , w ) } \\\\end{array}$ at $z\
              \ = \\\\bar { u } ^ { ( d ) }$ and $z = v ^ { ( d ) }$ . In our zero\
              \ knowledge proof protocol, which will be presented in Section 2.4.4,\
              \ $\\\\mathcal { P }$ commits to $\\\\dot { V } \\_ { d } ( z )$ using\
              \ the zkVPD at the beginning, and opens it to the two points selected\
              \ by $\\\\nu$ .\n\nThe protocol in \\[ZGKPP17a\\] works for any polynomial\
              \ with $\\\\ell$ variables and any variable degree, and is particularly\
              \ efficient for multilinear polynomials. We modify the protocol for\
              \ our zero-knowledge proof\n\nConstruction 3. Let $\\\\mathbb { F }$\
              \ be a prime-order finite field. Let $\\\\dot { V } ( \\\\boldsymbol\
              \ { x } ) : \\\\mathbb { F } ^ { \\\\ell } \\\\mathbb { F }$ be an $\\\
              \\ell$ -variate polynomial such\n\nthat $\\\\dot { V } ( x ) = \\\\\
              tilde { V } ( x ) + Z ( x ) \\\\bar { R } ( x \\_ { 1 } ) ,$ , where\
              \ $\\\\tilde { V } ( x )$ is a multilinear polynomial, $\\\\begin{array}\
              \ { r } { Z ( x ) = \\\\prod \\_ { i = 1 } ^ { \\\\ell } \\\\dot { x\
              \ \\_ { i } } ( 1 - x \\_ { i } ) } \\\\end{array}$ and\n\n$R ( x \\\
              _ { 1 } ) = a \\_ { 0 } + a \\_ { 1 } x \\_ { 1 }$ . • $( \\\\mathsf\
              \ { p p } , \\\\mathsf { v p } ) \\\\gets \\\\mathsf { K e y G e n }\
              \ ( 1 ^ { \\\\lambda } , \\\\ell )$ : Select $\\\\alpha , t \\_ { 1\
              \ } , t \\_ { 2 } , \\\\cdot \\\\cdot \\\\cdot , t \\_ { l } , t \\\
              _ { \\\\ell + 1 } \\\\in \\\\mathbb { F }$ uniformaly at random, run\
              \ bp $\\\\mathsf { B i l G e n } ( 1 ^ { \\\\lambda } )$ and compute\
              \ $\\\\mathsf { p } \\\\mathsf { p } = ( \\\\mathsf { b } \\\\mathsf\
              \ { p } , g ^ { \\\\alpha } , g ^ { t \\_ { \\\\ell + 1 } } , g ^ {\
              \ \\\\alpha t \\_ { \\\\ell + 1 } } , \\\\lbrace g ^ { \\\\prod \\_\
              \ { i \\\\in W } t \\_ { i } } , g ^ { \\\\alpha } \\\\rbrace \\\\prod\
              \ \\_ { i \\\\in W } ^ { t \\_ { i } } \\\\rbrace \\_ { W \\\\in \\\\\
              mathcal { W } \\_ { \\\\ell } } )$ , where $w \\_ { \\\\ell }$ is the\
              \ set of all subsets of ${ 1 , \\\\ldots , \\\\ell }$ . Set $\\\\mathsf\
              \ { v p } = ( \\\\mathsf { b p } , g ^ { t \\_ { 1 } } , \\\\ldots ,\
              \ g ^ { t \\_ { \\\\ell + 1 } } , g ^ { \\\\alpha } )$ • $\\\\mathsf\
              \ { c o m } \\\\gets \\\\mathsf { C o m m i t } ( \\\\dot { V } , r\
              \ \\_ { V } , r \\_ { R } , \\\\mathsf { p p } )$ : Compute $c \\_ {\
              \ 1 } = g ^ { \\\\tilde { V } ( t \\_ { 1 } , t \\_ { 2 } , \\\\cdots\
              \ , t \\_ { \\\\ell } ) + r \\_ { V } t \\_ { \\\\ell + 1 } }$ , $c\
              \ \\_ { 2 } = g ^ { \\\\alpha ( \\\\tilde { V } ( t \\_ { 1 } , t \\\
              _ { 2 } , \\\\cdots , t \\_ { \\\\ell } ) + r \\_ { V } t \\_ { \\\\\
              ell + 1 } ) }$ , $c \\_ { 3 } = g ^ { R ( t \\_ { 1 } ) + r \\_ { R\
              \ } t \\_ { \\\\ell + 1 } }$ and $c \\_ { 4 } = g ^ { \\\\alpha ( R\
              \ ( t \\_ { 1 } ) + r \\_ { R } t \\_ { \\\\ell + 1 } ) }$ output the\
              \ commitment com $\\\\mathbf { \\\\boldsymbol { \\\\mathbf { \\\\mathit\
              \ { \\\\Phi } } } } = ( c \\_ { 1 } , c \\_ { 2 } , c \\_ { 3 } , c\
              \ \\_ { 4 } )$ . • ${ \\\\mathsf { a c c e p t } , \\\\mathsf { r e\
              \ j e c t } } \\\\gets { \\\\mathsf { C h e c k C o m m } } ( \\\\mathsf\
              \ { c o m } , \\\\mathsf { v p } ) .$ : Output accept if $e ( c \\_\
              \ { 1 } , g ^ { \\\\alpha } ) = e ( c \\_ { 2 } , g )$ and $e ( c \\\
              _ { 3 } , g ^ { \\\\alpha } ) =$ $e ( c \\_ { 4 } , g )$ . Otherwise,\
              \ output reject. • $( y , \\\\pi ) \\\\gets 0 \\\\mathsf { p e n } (\
              \ \\\\dot { V } , r \\_ { V } , r \\_ { R } , u , \\\\mathsf { p p }\
              \ )$ : Choose $r \\_ { 1 } , \\\\hdots , r \\_ { \\\\ell } \\\\in \\\
              \\mathbb { F }$ at random, and compute polynomials $q \\_ { i }$ such\
              \ that $\\\\begin{array} { c } { { V ( x ) + r \\_ { V } x \\_ { \\\\\
              ell + 1 } + Z ( u ) ( R ( x \\_ { 1 } ) + r \\_ { R } x \\_ { \\\\ell\
              \ + 1 } ) - ( V ( u ) + Z ( u ) R ( u \\_ { 1 } ) ) = } } \\ { { \\\\\
              mathrm { } } } \\ { { \\\\displaystyle \\\\sum \\_ { i = 1 } ^ { \\\\\
              ell } ( x \\_ { i } - u \\_ { i } ) ( q \\_ { i } ( x \\_ { i } , \\\
              \\ldots , x \\_ { \\\\ell } ) + r \\_ { i } x \\_ { \\\\ell + 1 } )\
              \ + x \\_ { \\\\ell + 1 } ( r \\_ { V } + r \\_ { R } Z ( u ) - \\\\\
              displaystyle \\\\sum \\_ { i = 1 } ^ { \\\\ell } r \\_ { i } ( x \\\
              _ { i } - u \\_ { i } ) ) . } } \\\\end{array}$ $\\\\begin{array} {\
              \ l } { { S e t \\\\quad \\\\pi = \\\\qquad \\\\left( { g ^ { q \\_\
              \ { i } ( t \\_ { i } \\\\ldots , t \\_ { \\\\ell } ) + r \\_ { i }\
              \ t \\_ { \\\\ell + 1 } } , g ^ { \\\\alpha ( q \\_ { i } ( t \\_ {\
              \ i } \\\\ldots , t \\_ { \\\\ell } ) + r \\_ { i } t \\_ { \\\\ell\
              \ + 1 } ) } } \\_ { i \\\\in \\[ 1 , \\\\ell \\] } , \\\\quad g ^ {\
              \ r \\_ { V } + r \\_ { R } Z ( u ) - \\\\sum \\_ { i = 1 } ^ { \\\\\
              ell } } \\\\right) , } } \\ { { g ^ { \\\\alpha ( r \\_ { V } + r \\\
              _ { R } Z ( u ) - \\\\sum \\_ { i = 1 } ^ { \\\\ell } r \\_ { i } (\
              \ t \\_ { i } - u \\_ { i } ) ) } ) a n d y = \\\\tilde { V } ( u )\
              \ + Z ( u ) R ( u \\_ { 1 } ) . } } \\\\end{array}$ • ${ \\\\mathsf\
              \ { a c c e p t , r e j e c t } } \\\\gets \\\\mathsf { V e r i f y\
              \ } ( \\\\mathsf { c o m } , u , y , \\\\pi , \\\\mathsf { v p } )$\
              \ : Parse $\\\\pi$ as $( \\\\pi \\_ { i } , \\\\pi \\_ { \\\\alpha i\
              \ } )$ for $i \\\\in \\[ 1 , \\\\ell + 1 \\]$ . Check $e ( \\\\pi \\\
              _ { i } , g ^ { \\\\alpha } ) = e ( \\\\pi \\_ { \\\\alpha i } , g )$\
              \ for $i \\\\in \\[ 1 , \\\\ell + 1 \\]$ . Check $\\\\begin{array} {\
              \ r } { e ( c \\_ { 1 } c \\_ { 3 } ^ { Z ( u ) } / g ^ { y } , g )\
              \ = \\\\prod \\_ { i = 1 } ^ { \\\\ell } e ( \\\\pi \\_ { i } , g ^\
              \ { t \\_ { i } - u \\_ { i } } ) \\\\cdot e ( g ^ { \\\\pi \\_ { \\\
              \\ell + 1 } } , g ^ { t \\_ { \\\\ell + 1 } } ) } \\\\end{array}$ .\
              \ Output accept if all the checks pass, otherwise, output reject.\n\n\
              scheme and preserve the efficiency. Note that though $\\\\dot { V }\
              \ \\_ { d } ( z )$ is a low degree extension of the input, it can be\
              \ decomposed to the sum of $\\\\tilde { V } \\_ { d } ( z )$ , a multilinear\
              \ polynomial, and $\\\\begin{array} { r } { Z \\_ { d } ( z ) \\\\sum\
              \ \\_ { w \\\\in { 0 , 1 } } R \\_ { d } ( z \\_ { 1 } , w ) } \\\\\
              end{array}$ . Moreover, $Z \\_ { d } ( u ^ { ( d ) } )$ and $Z \\_ {\
              \ d } ( v ^ { ( d ) } )$ can be computed directly by $\\\\nu$ . Therefore,\
              \ in our construction, $\\\\mathcal { P }$ commits to $\\\\tilde { V\
              \ } \\_ { d } ( z )$ and $\\\\textstyle \\\\sum \\_ { w \\\\in { 0 ,\
              \ 1 } } R \\_ { d } ( z \\_ { 1 } , w )$ separately, and later opens\
              \ the sum together given $Z \\_ { d } ( u ^ { ( d ) } )$ and $Z \\_\
              \ { d } ( v ^ { ( d ) } )$ , which is naturally supported because of\
              \ the homomorphic property of the commitment. Another optimization is\
              \ that unlike other layers of the circuit, $R \\_ { d } ( z \\_ { 1\
              \ } , w )$ itself is not opened at two points $\\\\mathcal { V }$ does\
              \ not receive $R \\_ { d } ( u ^ { ( d ) } , c ^ { ( d ) } )$ and $R\
              \ \\_ { d } ( v ^ { ( d ) } , c ^ { ( d ) } )$ in Construction 2). Therefore,\
              \ it suffices to set $\\\\dot { V } \\_ { d } ( z ) = \\\\tilde { V\
              \ } \\_ { d } ( z ) + Z \\_ { d } ( z ) R \\_ { d } ( z \\_ { 1 } )$\
              \ , where $R \\_ { d }$ is a univariate linear polynomial. The full\
              \ protocol is presented in Construction 3.\n\nTheorem 2.4.3. Construction\
              \ 3 is a zero-knowledge verifiable polynomial delegation scheme as defined\
              \ by Definition 2.2.5, under Assumption 1 and 2.\n\nThe proof of completeness,\
              \ soundness and zero knowledge is similar to that of the zkVPD protocol\
              \ in \\[ZGKPP17a\\]. We only add an extra univariate linear polynomial\
              \ $R ( x \\_ { 1 } )$ , which does not affect the proof.\n\nWe omit\
              \ the proof due to space limit. Using the same algorithms proposed in\
              \ in \\[ZGKPP18; ZGKPP17a\\], the running time of KeyGen, Commit and\
              \ Open is $O ( 2 ^ { \\\\ell } )$ , Verify takes $O ( \\\\ell )$ time\
              \ and the proof size is $O ( \\\\ell )$ .\n\n# 2.4.4 Putting Everything\
              \ Together\n\nIn this section, we present our zero knowledge argument\
              \ scheme. At a high level, similar to \\[ZGKPP17c; WTSTW18; ZGKPP17a\\\
              ], $\\\\nu$ can use the GKR protocol to verify the correct evaluation\
              \ of a circuit $C$ on input $x$ and a witness $w$ , given an oracle\
              \ access to the evaluation of a polynomial defined by $x , w$ on a random\
              \ point. We instantiate the oracle using the zkVPD protocol. Formally,\
              \ we present the construction in Construction 4, which combines our\
              \ zero knowledge GKR and zkVPD protocols. Similar to the protocols in\
              \ \\[ZGKPP17a; WTSTW18\\], Step 6 and 7 are to check that $\\\\mathcal\
              \ { P }$ indeed uses $x$ as the input to the circuit.\n\nTheorem 2.4.4.\
              \ For an input size n and a finite field F, Construction 4 is a zero\
              \ knowledge argument for the relation\n\n$$\n\\\\begin{array} { r }\
              \ { \\\\mathcal { R } = { ( C , x ; w ) : C \\\\in \\\\mathcal { C }\
              \ \\_ { \\\\mathbb { F } } \\\\wedge \\| x \\| + \\| w \\| \\\\leq n\
              \ \\\\wedge C ( x ; w ) = 1 } , } \\\\end{array}\n$$\n\nas defined in\
              \ Definition 2.2.2, under Assumption $I$ and 2. Moreover, for every\
              \ $( C , x ; w ) \\\\in \\\\mathcal { R }$ , the running time of $\\\
              \\mathcal { P }$ is $O ( \\| C \\| )$ field operations and $O ( n )$\
              \ multiplications in the base group of the bilinear map. The running\
              \ time of $\\\\nu$ is $O ( \\| x \\| + d { \\\\cdot } \\\\log \\| C\
              \ \\| )$ if C is log-space uniform with $d$ layers. $\\\\mathcal { P\
              \ }$ and $\\\\nu$ interact $O ( d \\\\log \\| C \\| )$ rounds and the\
              \ total communication (proof size) is $O ( d \\\\log \\| C \\| )$ .\
              \ In case $d$ is polylog $( \\| C \\| )$ , the protocol is $a$ succinct\
              \ argument.\n\nProof Sketch. The correctness and the soundness follow\
              \ from those of the two building blocks, zero knowl edge GKR and zkVPD,\
              \ by Theorem 2.4.2 and 2.4.3.\n\nTo prove zero knowledge, consider a\
              \ simulator $s$ that calls the simulator $\\\\mathcal { S } \\_ { G\
              \ K R }$ of zero knowledge GKR given in Section 2.4.2 as a subroutine,\
              \ which simulates the partial view up to the input layer. At the input\
              \ layer, the major challenge is that $\\\\boldsymbol { s }$ committed\
              \ to (a randomly chosen) $\\\\dot { V } \\_ { d } ^ { \\* }$ at the\
              \ beginning of the protocol, before knowing the points $\\\\boldsymbol\
              \ { u } ^ { ( d ) } , \\\\boldsymbol { v } ^ { ( d ) }$ to evaluate\
              \ on. If $\\\\boldsymbol { s }$ opens the commitment honestly, with\
              \ high probability the evaluations are not consistent with the last\
              \ message of the GKR (sumcheck in layer $d - 1 )$ ) and a malicious\
              \ $\\\\nu ^ { \\* }$ can distinguish the ideal world from the real world.\
              \ In our proof, we resolve this issue by using the simulator $\\\\mathcal\
              \ { S } \\_ { V P D }$ of our zkVPD protocol. Given the trapdoor trap\
              \ used in KeyGen, $\\\\mathcal { S } \\_ { V P D }$ is able to open\
              \ the commitment to any value in zero knowledge, and in particular it\
              \ opens to those messages that are consistent with the GKR protocol\
              \ in our scheme, which completes the construction of $s$ .\n\nThe complexity\
              \ of our zero knowledge argument scheme follows from our new GKR protocol\
              \ with linear prover time, and the complexity of the zkVPD protocol\
              \ for the input layer analyzed in Section 2.4.3. The masking polynomials\
              \ $g \\_ { i } , R \\_ { i }$ and their commitments and openings introduce\
              \ no asymptotic overhead and are efficient in practice.\n\nRemoving\
              \ interaction. Our construction can be made non-interactive in the random\
              \ oracle model using Fiat– -Shamir heuristic \\[FS86\\]. Though GKR\
              \ protocol is not constant round, recent results \\[BSCS16; CCHLRR18\\\
              ] show that applying Fiat-Shamir only incurs a polynomial soundness\
              \ loss in the number of rounds in GKR. In our implementation, the GKR\
              \ protocol is on a 254-bit prime field matching the bilinear group used\
              \ in the zkVPD. The non-interactive version of our system provides a\
              \ security level of $1 0 0 +$ bits.\n\nConstruction 4. Let $\\\\lambda$\
              \ be the security parameter, $\\\\mathbb { F }$ be a prime field, $n$\
              \ be an upper bound on input size,\n\nand $S$ be an upper bound on circuit\
              \ size. We use $\\\\mathsf { V P D } \\_ { 1 }$ , ${ \\\\mathsf { V\
              \ P D } } \\_ { 2 }$ , ${ \\\\mathsf { V P D } } \\_ { 3 }$ to denote\
              \ the zkVPD protocols for\n\ninput layer, masking polynomials $g \\\
              _ { i }$ and $R \\_ { i }$ described in Construction 2. • $\\\\mathcal\
              \ { G } ( 1 ^ { \\\\lambda } , n , S )$ : run $( \\\\mathsf { p p }\
              \ \\_ { 1 } , \\\\mathsf { v p } \\_ { 1 } ) \\\\gets \\\\mathsf { V\
              \ P D } \\_ { 1 }$ . $\\\\mathsf { K e y G e n } ( 1 ^ { \\\\lambda\
              \ } , \\\\log n )$ , $( \\\\mathsf { p p } \\_ { 2 } , \\\\mathsf {\
              \ v p } \\_ { 2 } ) \\\\gets \\\\mathsf { V P D } \\_ { 2 }$ . $\\\\\
              mathsf { K e y G e n } ( 1 ^ { \\\\lambda } , \\\\log S )$ , $( \\\\\
              mathsf { p p } \\_ { 3 } , \\\\mathsf { v p } \\_ { 3 } ) \\\\gets \\\
              \\mathsf { V P D } \\_ { 3 } . \\\\mathsf { K e y G e n } ( 1 ^ { \\\
              \\lambda } ) .$ . Output $\\\\mathsf { p k } = ( \\\\mathsf { p p }\
              \ \\_ { 1 } , \\\\mathsf { p p } \\_ { 2 } , \\\\mathsf { p p } \\_\
              \ { 3 } )$ and ${ \\\\mathsf { v k } } = ( { \\\\mathsf { v p } } \\\
              _ { 1 } , { \\\\mathsf { v p } } \\_ { 2 } , { \\\\mathsf { v p } }\
              \ \\_ { 3 } )$ . • $\\\\langle \\\\mathcal { P } ( \\\\mathsf { p k\
              \ } , w ) , \\\\mathcal { V } ( \\\\mathsf { v k } ) \\\\rangle ( x\
              \ )$ : Let $C$ be a layered arithmetic circuit over $\\\\mathbb { F\
              \ }$ with $d$ layers, input $x$ and witness $w$ such that $\\| x \\\
              | + \\| w \\| \\\\leq n$ , $\\| C \\| \\\\le S$ and $C ( x ; w ) = 1$\
              \ . Without loss of generality, assume $\\| w \\| / \\| x \\| =$ $2\
              \ ^ { m } - 1$ for some $m \\\\in \\\\mathbb { N }$ . 1. $\\\\mathcal\
              \ { P }$ selects a random bivariate polynomial $R \\_ { d }$ with variable\
              \ degree 2 and commits to the input of $C$ by sending $\\\\mathsf {\
              \ c o m } \\_ { d } \\\\gets \\\\mathsf { V P D } \\_ { 1 }$ .Commit\
              \ $( \\\\dot { V } \\_ { d } , r \\_ { V } , r \\_ { R } , \\\\mathsf\
              \ { p p } \\_ { 1 } )$ to $\\\\nu$ , where $\\\\tilde { V \\_ { d }\
              \ }$ is the multilinear extension of array $( x ; w )$ and $\\\\dot\
              \ { V } \\_ { d } = \\\\tilde { V } \\_ { d } + R \\_ { d }$ 2. $\\\\\
              nu$ runs ${ \\\\mathsf { V P D } } \\_ { 1 }$ .CheckComm $( \\\\mathsf\
              \ { c o m } \\_ { d } , \\\\mathsf { v p } \\_ { 1 } )$ . If it outputs\
              \ reject, $\\\\nu$ aborts and outputs reject. 3. $\\\\mathcal { P }$\
              \ and $\\\\nu$ execute Step 1-5 of the zero knowledge GKR protocol in\
              \ Construction 2, with the zkVPDs instantiated with ${ \\\\mathsf {\
              \ V P D } } \\_ { 2 }$ and ${ \\\\mathsf { V P D } } \\_ { 3 }$ . If\
              \ Construction 2 rejects, $\\\\nu$ outputs reject and aborts. Otherwise,\
              \ by the end of this step, V receives two claims of V˙d at u(d) and\
              \ v(d). 4. $\\\\mathcal { P }$ runs $\\\\begin{array} { r } { y \\_\
              \ { 1 } , \\\\pi \\_ { 1 } ) \\\\qquad \\\\qquad \\\\forall \\\\mathsf\
              \ { P D } \\_ { 1 } . \\\\mathsf { O p e n } ( \\\\dot { V } , r \\\
              _ { V } , r \\_ { R } , u ^ { ( d ) } , \\\\mathsf { p p } \\_ { 1 }\
              \ ) , \\\\qquad ( y \\_ { 2 } , \\\\pi \\_ { 2 } ) } \\\\end{array}$\
              \ ← $\\\\mathsf { V P D } \\_ { 1 } . \\\\mathsf { O p e n } ( \\\\\
              dot { V } , r \\_ { V } , r \\_ { R } , v ^ { ( d ) } , \\\\mathsf {\
              \ p p } \\_ { 1 } )$ and sends $y \\_ { 1 } , \\\\pi \\_ { 1 } , y \\\
              _ { 2 } , \\\\pi \\_ { 2 } t o \\\\mathcal { V }$ $\\\\nu$ . 5. $\\\\\
              nu$ runs Verify $( \\\\mathsf { c o m } \\_ { d } , u ^ { ( d ) } ,\
              \ y \\_ { 1 } , \\\\pi \\_ { 1 } , \\\\mathsf { v p } \\_ { 1 } )$ and\
              \ Verify $( \\\\mathsf { c o m } \\_ { d } , v ^ { ( d ) } , y \\_ {\
              \ 2 } , \\\\pi \\_ { 2 } , \\\\mathsf { v p } \\_ { 1 } )$ and output\
              \ reject $i f$ either check fails. Otherwise, $\\\\nu$ checks $\\\\\
              dot { V } \\_ { d } ( u ^ { ( d ) } ) = y \\_ { 1 }$ and $\\\\dot {\
              \ V } \\_ { d } ( v ^ { ( d ) } ) = y \\_ { 2 }$ , and rejects if either\
              \ fails. 6. $\\\\nu$ computes the multilinear extension of input $x$\
              \ at a random point $r \\_ { x } \\\\in \\\\mathbb { F } ^ { \\\\log\
              \ \\| x \\| }$ and sends $r \\_ { x }$ to $\\\\mathcal { P }$ . 7. $\\\
              \\mathcal { P }$ pads $r \\_ { x }$ to $r \\_ { x } ^ { \\\\prime }\
              \ \\\\in \\\\mathbb { F } ^ { \\\\log \\| x \\| } \\\\times 0 ^ { \\\
              \\log \\| w \\| }$ with $\\\\log \\| w \\|$ 0s and sends $\\\\begin{array}\
              \ { r l } { \\\\mathcal { V } } & { { } ( y \\_ { x } , \\\\pi \\_ {\
              \ x } ) \\\\quad } \\\\end{array}$ $\\\\mathsf { V P D } \\_ { 1 } .\
              \ \\\\mathsf { O p e n } ( \\\\tilde { V } \\_ { d } , r \\_ { V } ,\
              \ r \\_ { R } , r \\_ { x } ^ { \\\\prime } , \\\\mathsf { p p } \\\
              _ { 1 } )$ . $\\\\nu$ checks Verify $( \\\\mathsf { c o m } \\_ { d\
              \ } , r \\_ { x } ^ { \\\\prime } , y \\_ { x } , \\\\pi \\_ { x } ,\
              \ \\\\mathsf { v p } \\_ { 1 } )$ and $y \\_ { x }$ equals the evaluation\
              \ of the multilinear extension on $x$ . $\\\\nu$ outputs reject if the\
              \ checks fail. Otherwise, $\\\\nu$ outputs accept.\n\n# 2.5 Implementation\
              \ and Evaluation\n\nSoftware. We fully implement Libra, our new zero\
              \ knowledge proof system in $\\\\mathrm { C } { + } { + }$ . There are\
              \ around 3000 lines of code for the zkGKR protocol, 1000 lines for the\
              \ zkVPD protocol and 700 lines for circuit generators. Our system provides\
              \ an interface to take a generic layered arithmetic circuit and turn\
              \ it into a zero knowledge proof. We implement a new class for large\
              \ integers named u512, and use it together with the GMP\\[Gnu\\] library\
              \ for large numbers and field arithmetic. We use the ate-pairing\\[Ate\\\
              ] library on a 254-bit elliptic curve for the bilinear map used in zkVPD.\
              \ We plan to open-source our system.\n\nHardware. We run all of the\
              \ experiments on Amazon EC2 c5.9xlarge instances with 70GB of RAM and\
              \ Intel Xeon platinum $8 1 2 4 \\\\mathrm { m }$ CPU with 3GHz virtual\
              \ core. Our current implementation is not parallelized and we only use\
              \ a single CPU core in the experiments. We report the average running\
              \ time of 10 executions. More gate types with no overhead. We first\
              \ present a concrete optimization we developed during the implementation\
              \ to support various types of gates with no extra overhead. In our protocol\
              \ in Section 2.3 and 2.4, we only consider addition and multiplication\
              \ gates, as they are enough to represent all arithmetic circuits. However,\
              \ in practice, the size of the circuit can be reduced significantly\
              \ if we introduce other types of gate. The GKR protocol still works\
              \ with these new gates, but they incur an overhead on the prover time\
              \ for a circuit of the same size. Therefore, in prior work such as \\\
              [WHGSW16; ZGKPP18\\], this is considered as a trade-off.\n\nOur protocol\
              \ supports any gate with fan-in $\\\\leq 2$ and degree $\\\\leq 2$ with\
              \ no overhead on the prover. Recall that in the GKR protocol, the values\
              \ in layer $i$ is represented as a sumcheck of values in layer $i +\
              \ 1$ and the wiring predicates, as shown in Equation 2.2. With a set\
              \ of gate types $\\\\tau$ , we can write the polynomial in the sum as\n\
              \n$$\n\\\\sum \\_ { j \\\\in \\\\mathcal { T } } g \\\\tilde { a } t\
              \ e \\_ { i } ^ { ( j ) } ( g , x , y ) G \\_ { i } ^ { ( j ) } ( \\\
              \\tilde { V } \\_ { i + 1 } ( x ) , \\\\tilde { V } \\_ { i + 1 } (\
              \ x ) ) ,\n$$\n\nwhere $G \\_ { i } ^ { ( j ) } ( \\ v r )$ is the computation\
              \ of gate type $j$ (e.g., for addition gates, $G \\_ { i } ^ { ( j )\
              \ } ( \\\\tilde { V } \\_ { i + 1 } ( x ) , \\\\tilde { V } \\_ { i\
              \ + 1 } ( x ) ) = \\\\tilde { V } \\_ { i + 1 } ( x ) +$ $\\\\tilde\
              \ { V } \\_ { i + 1 } ( x ) )$ . As the gates have fan-in $\\\\leq 2$\
              \ and degree ≤ 2, $G \\_ { i } ^ { ( j ) }$ has up to 2 variables and\
              \ total degree at most 2 for all $j$ . Therefore, each $G \\_ { i }\
              \ ^ { ( j ) }$ can be expressed explicitly as $a \\_ { 0 } + a \\_ {\
              \ 1 } \\\\tilde { V } \\_ { i + 1 } ( x ) + a \\_ { 2 } \\\\tilde {\
              \ V } \\_ { i + 1 } ( y ) + a \\_ { 3 } \\\\tilde { V } \\_ { i + 1\
              \ } ( x ) \\\\tilde { V } \\_ { i + 1 } ( y ) +$ $a \\_ { 4 } \\\\bar\
              \ { \\\\tilde { V } } \\_ { i + 1 } ( x ) ^ { 2 } + a \\_ { 5 } \\\\\
              tilde { V } \\_ { i + 1 } ( \\\\stackrel { \\\\cdot } { y } ) ^ { 2\
              \ }$ , at most 6 nonzero monomials. The prover can then combine all\
              \ the wiring predicates $g \\\\tilde { a } t e \\_ { i } ^ { ( j ) }\
              \ ( g , x , y )$ for the same monomial through a summation. With this\
              \ approach, when generating the proof in Algorithm 4 and 5, the prover\
              \ only allocates one array for each monomial, and initializes all 6\
              \ arrays with one scan through all the gates in Init\\_PhaseOne and\
              \ Init\\_PhaseTwo. In this way, the prover time remains the same regardless\
              \ of the number of gate types.\n\nIn our experiments, useful types of\
              \ gates include subtraction, relay, multiply by constant, $x ( 1 - x\
              \ )$ for binary check, NOT,AND,OR,XOR, etc.\n\n# 2.5.1 Improvements\
              \ on GKR protocols\n\nIn this section, we compare the performace of\
              \ our new GKR protocol with linear prover time with all variants of\
              \ GKR in the literature on different circuits.\n\nMethodology and benchmarks.\
              \ For fair comparisons, we re-implement all of these variants in $\\\
              \\mathrm { C } { + } { + }$ with the same libraries. The variants include:\
              \ (1) $O ( C )$ for regular circuits, proposed in \\[Tha13a\\], where\
              \ the two inputs of a gate can be described by two mapping functions\
              \ with constant size in constant time. See \\[Tha13a\\] for the formal\
              \ definition of regular circuits. (2) $O ( C + C ^ { \\\\prime } \\\\\
              log C ^ { \\\\prime } )$ for data-parallel circuits with a small copy\
              \ of size $C ^ { \\\\prime }$ , proposed in $\\[ \\\\mathrm { W a h\
              \ } + 1 7 \\]$ . (3) $O ( C \\\\log C ^ { \\\\prime } )$ for circuits\
              \ with non-connected different copies of size $C ^ { \\\\prime }$ ,\
              \ proposed in \\[ZGKPP18\\]. (4) $O ( C \\\\log C )$ for arbitrary circuits,\
              \ proposed in \\[CMT12\\].\n\nWe compare our GKR protocol to these variants\
              \ on the benchmarks below:\n\n• Matrix multiplication: $\\\\mathcal\
              \ { P }$ proves to $\\\\nu$ that it knows two matrices whose product\
              \ equals a public matrix. The representation of this function with an\
              \ arithmetic circuit is highly regular⁶. We evaluate on different dimensions\
              \ from $4 \\\\times 4$ to $2 5 6 \\\\times 2 5 6$ and the elements in\
              \ the matrices are 32-bit integers.\n\nTable 2.2: Prover time of our\
              \ linear GKR and previous GKR variants.\n\n|     |     |     |     |\
              \     |     |\n| --- | --- | --- | --- | --- | --- |\n| Matrix multiplication\
              \ | Matrix size | 4x4 | 16x16 | 64x64 | 256x256 |\n| \\[Tha13a\\] |\
              \ 0.0003s | 0.006s | 0.390s | 29.0s |\n| Ours | 0.0004s | 0.014s | 0.788s\
              \ | 50.0s |\n| Image scaling | #pixels | 112x112 | 176x176 | 560x560\
              \ | 1072x1072 |\n| \\[Wah+17\\] | 0.445s | 0.779s | 7.54s | 29.2s |\n\
              | Ours | 0.337s | 1.25s | 19.8s | 79.2s |\n| Image scaling with different\
              \ parameters | #pixels | 112x112 | 176x176 | 560x560 | 1072x1072 |\n\
              | \\[ZGKPP17c\\] | 5.45s | 21.8s | 348s | 1441s |\n| Ours | 0.329s |\
              \ 1.22s | 19.3s | 77.2s |\n| Random circuit | #gates per layer | 28\
              \ | 212 | 216 | 220 |\n| \\[CMT12\\] | 0.008s | 0.179s | 3.79s | 83.1s\
              \ |\n| Ours | 0.002s | 0.039s | 0.635s | 10.8s |\n\n• Image scaling:\
              \ It computes a low-resolution image by scaling from a high-resolution\
              \ image. We use the classic Lanczos re-sampling\\[Tur90\\] method. It\
              \ computes each pixel of the output as the convolution of the input\
              \ with a sliding window and a kernel function defined as: $k ( x ) =\
              \ \\\\operatorname { s i n c } ( x ) / \\\\operatorname { s i n c }\
              \ ( a x )$ , if $- a < x <$ $a ; k ( x ) = 0$ , otherwise, where $a$\
              \ is the scaling parameter and $\\\\mathrm { s i n c } ( x ) = \\\\\
              sin ( x ) / x$ . This function is data parallel, where each sub-circuit\
              \ computes the same function to generate one pixel of the output image.\
              \ We evaluate by fixing the window size as $1 6 \\\\times 1 6$ and increase\
              \ the image size from $1 1 2 \\\\mathrm { x } 1 1 2$ to $1 0 7 2 \\\\\
              mathrm { x } 1 0 7 2$ The pixels are 8-bit integers for greyscale images.\n\
              \n• Image scaling of different parameters: It is the same computation\
              \ as above with different scaling parameters in the kernel function\
              \ for different pixels. The circuit of this function consists of different\
              \ sub-copies. We evaluate it with the same image sizes as above.\n\n\
              • Random circuit: It is randomly generated layered circuit. We randomly\
              \ sample the type of each gate, input value and the wiring patterns.\
              \ We fix the depth as 3 and increase the number of gates per layer from\
              \ $2 ^ { 8 }$ to $2 ^ { 2 0 }$ .\n\nTo be consistent with the next section,\
              \ all the protocols are executed on a 254-bit prime field. This does\
              \ not affect the comparison at all, as all the protocols are in the\
              \ same field. In Table 2.2, we report the prover time of the protocols.\
              \ The proof size and the verification time of all the variants are similar.\n\
              \nResults. As shown in Table 2.2, the performance of our GKR protocol\
              \ is comparable to those special protocols for structured circuits,\
              \ and much better than the state-of-the-art on generic circuits. For\
              \ example, for matrix multiplication, our protocol is slower by $1 .\
              \ 3 – 2 . 4 \\\\times$ , because the protocol in \\[Tha13a\\] writes\
              \ the wiring of matrix multiplication explicitly and does not need to\
              \ compute add˜ and mult ˜ . For image scaling, our protocol is slower\
              \ by $2 . 5 – 4 \\\\times$ . This gap would become even smaller when\
              \ the size of each sub-copy is larger. Here we use a small $1 6 \\\\\
              times 1 6$ block, while the number of copies is 49-4489.\n\nFor image\
              \ scaling with different parameters and generic random circuits, our\
              \ protocol has a speedup of $4 \\\\mathrm { - } 8 \\\\times$ , and the\
              \ speedup will increase with the scale of the circuits, as indicated\
              \ by the complexity.\n\nBesides the speedup on complicated circuits,\
              \ a significant advantage of our new GKR protocol is on the prover interface\
              \ of the system. In prior work such as $\\[ \\\\mathrm { W a h } + 1\
              \ 7$ ; ZGKPP18\\], as the protocols are particularly efficient for structured\
              \ circuits, the circuits must be represented as small copies and the\
              \ numbers of each copy. Even worse, the structure is explored per layer\
              \ of the circuit, making the numbers of each copy potentially different\
              \ in different layers. (E.g., 6 gates may be considered 3 copies with\
              \ 2 gates and 2 copies with 3 gates in two different layers for efficiency\
              \ purposes.) This constraint makes the interface of these systems hard\
              \ to use and generalize. Our result gives a unified solution for arbitrary\
              \ circuits, and it is the main reason that our prover can take the description\
              \ of any layered arithmetic circuit potentially generated by other tools\
              \ like Verilog.\n\n# 2.5.2 Comparing to Other ZKP Schemes\n\nIn this\
              \ section, we show the performance of Libra as a whole and compare it\
              \ with several state-of-the-art zero knowledge proof systems.\n\nMethodology.\
              \ We compare with the following systems: libSNARK \\[BSCTV14c\\], Ligero\\\
              [AHIV17\\], libSTARK\\[BSBHR19\\], Hyrax\\[WTSTW18\\], Bulletproofs\\\
              [BBBPWM18\\] and Aurora \\[BSCRSVW19\\]. See Section 2.1 for more explanations\
              \ of these systems and their asymptotic.\n\n• libSNARK: We use jsnark\
              \ \\[Jsn\\] to write the circuits (rank one constraint system (R1CS)),\
              \ which compiles them to zero knowledge proofs using the libSNARK backend\
              \ \\[Liba\\].\n\n• Ligero: As the system is not open-source, we use\
              \ the same number reported in \\[AHIV17\\] on computing hashes.\n\n\
              • libSTARK: After communications with the authors of \\[BSBHR19\\],\
              \ we obtain numbers for proving the same number of hashes in the 3rd\
              \ benchmark below from the authors. The experiments are executed on\
              \ a server with 512GB of DDR3 RAM (1.6GHz) and 16 cores (2 threads per\
              \ core) at speed of 3.2GHz.\n\n• Hyrax: We use the open-source implementation\
              \ of the system at $\\[ \\\\mathrm { H y r } \\]$ .\n\n• Bulletproofs:\
              \ We use the system re-implemented by \\[WTSTW18\\] at \\[Hyr\\].\n\n\
              • Aurora: As a recently accepted paper, the system is not available\
              \ and we extrapolate its performance using\n\nthe numbers reported in\
              \ the paper \\[BSCRSVW19\\] for circuits with $2 ^ { 1 0 } - 2 ^ { 2\
              \ 0 }$ R1CS constrains.\n\nBenchmarks. We evaluate the systems on three\
              \ benchmarks: matrix multiplication, image scaling and Merkle Tree\\\
              [Mer87\\], which are used in \\[WTSTW18\\]. Matrix multiplication and\
              \ image scaling are the same as explained in Section 2.5.1. In the third\
              \ benchmark, $\\\\mathcal { P }$ proves to $\\\\nu$ that it knows the\
              \ value of the leaves of a Merkle tree\\[Mer87\\] that computes to a\
              \ public root value\\[BEGKN94\\]. We use SHA-256 for the hash function.\
              \ We implement it with a flat circuit where each sub-computation is\
              \ one instance of the hash function. The consistency of the input and\
              \ output of corresponding hashes are then checked by the circuit. There\
              \ are $2 M - 1$ SHA256 invocations for a Merkle tree with $M$ leaves.\
              \ We increase the number of leaves from 16 to 256. We use the SHA-256\
              \ implemented by jsnark \\[Jsn\\] in R1CS format to run libSNARK and\
              \ estimate Aurora, and we use the SHA-256 arithmetic circuit implemented\
              \ by Hyrax to run Hyrax, Bulletproofs and Libra. We only show the performance\
              \ of Ligero and libSTARK on the third benchmark.\n\nWe report the prover\
              \ time, proof size and verification time in Figure 2.1.\n\nProver time.\
              \ As shown in Figure 2.1(a)(b)(c), the prover in Libra is the fastest\
              \ among all systems in all three benchmarks we tested. Ligero is one\
              \ of the best existing ZKP systems on prover time as it is purely based\
              \ on symmetric key operations. Comparing to Ligero, the prover time\
              \ of Libra is $1 . 1 5 \\\\times$ faster on a Merkle tree with 2 leaves\
              \ and $2 \\\\times$ faster with 256 leaves. Comparing to other systems,\
              \ Libra improves the prover time by $3 . 4 - 8 . 9 \\\\times$ vs. Hyrax,\
              \ $7 . 1 - 1 6 . 1 \\\\times$ vs. Aurora, $1 0 . 1 - 1 2 . 4 \\\\times\
              \ \\\\cdot$ vs. libSTARK and $6 5 - 1 6 6 \\\\times$ vs. Bulletproof.\
              \ Libra is also faster than libSNARK on general circuits by $5 - 1 0\
              \ \\\\times$ , as shown in Figure 2.1(a) and 2.1(b). The performance\
              \ of Libra is comparable to libSNARK on Merkle trees in Figure 2.1(c).\
              \ This is because (1) most values in the circuit of SHA256 are binary,\
              \ which is friendly to the prover of libSNARK as the time of exponentiation\
              \ is proportional to the bit-length of the values; (2) The R1CS of SHA256\
              \ is highly optimized by jsnark \\[Jsn\\] and real world products like\
              \ Zcash $\\[ { \\\\mathrm { B e n } } + 1 4 \\]$ . There are only 26,000\
              \ constrains in one hash.\n\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/0caf07c2c196401169b27599596fdea4e9e17f627b349dfc4fdc866b13e0275d.jpg)\n\
              \nFigure 2.1: Comparisons of prover time, proof size and verification\
              \ time between Libra and existing zero-knowledge proof systems.\n\n\
              In the arithmetic circuit used by Libra, there are 60,000 gates with\
              \ 38,000 of them being multiplication gates. Even so, Libra is still\
              \ as fast as libSNARK on a Merkle tree with 2 leaves and $2 \\\\times$\
              \ faster with 256 leaves. We plan to further optimize the implementation\
              \ of SHA256 as an arithmetic circuit in the future.\n\nThe gap between\
              \ Libra and other systems will become bigger as the size of the circuit\
              \ grows, as the prover time in these systems (other than Bulletproof)\
              \ scales quasi-linearly with the circuit size. The evaluations justify\
              \ that the prover time in Libra is both optimal asymptotically, and\
              \ efficient in practice.\n\nVerification time. Figure 2.1(d)(e)(f) show\
              \ the verification time. Our verifier is much slower than libSNARK and\
              \ libSTARK, which runs in $1 . 8 \\\\mathrm { m s }$ and 28-44ms respectively\
              \ in all the benchmarks.\n\nOther than these two systems, the verification\
              \ time of Libra is faster, as it grows sub-linearly with the circuit\
              \ size. In particular, our verification time ranges from $0 . 0 8 -\
              \ 1 . 1 5 \\\\mathrm { s }$ in the benchmarks we consider. In Figure\
              \ 2.1(f), the verification time of Libra is $8 \\\\times$ slower than\
              \ Aurora when $M = 2$ , and $1 5 \\\\times$ faster when $M = 2 5 6$\
              \ . Libra is $2 . 5 \\\\times$ slower than Ligero with $M = 2$ and $4\
              \ \\\\times$ faster with $M = 2 5 6$ . Comparing to Hyrax and Bulletproof,\
              \ our verification is $1 . 2 - 9 \\\\times$ and $2 7 - 9 0 0 \\\\times$\
              \ faster respectively. Again, the gap increases with the scale of the\
              \ circuits as our verification is succinct.\n\nProof size. We report\
              \ the proof size in Figure $2 . 1 ( \\\\mathrm { g } ) ( \\\\mathrm\
              \ { h } ) ( \\\\mathrm { i } )$ . Our proof size is much bigger than\
              \ libSNARK, which is 128 bytes for all circuits, and Bulletproof, which\
              \ ranges in 2-5.5KBs. The proof size in Libra is in the range of 30-60KBs,\
              \ except for the matrix multiplications where it reduces to 5-9KBs.\
              \ This is better than Aurora, Hyrax and libSTARK, which also have poly-logarithmic\
              \ proof size to the circuit. Finally, the proof size in Ligero is $O\
              \ ( { \\\\sqrt { C } } )$ and grows to several megabytes in practice.\n\
              \nSetup time. Among all the systems, only Libra and libSNARK require\
              \ trusted setup. Thanks to the optimization described in the beginning\
              \ of this section, it only takes 202s to generate the public parameters\
              \ in our largest instance with $n \\\\stackrel { \\\\cdot } { = } 2\
              \ ^ { 2 4 }$ . Libra only needs to perform this setup once and it can\
              \ be used for all benchmarks and all circuits with no more inputs. libSNARK\
              \ requires a per-circuit setup. For example, it takes 1027s for the\
              \ Merkle tree with 256 leaves, and takes 210s for $6 4 \\\\times 6 4$\
              \ matrix multiplications.\n\n# 2.5.3 Discussions\n\nIn this section,\
              \ we discuss some potential improvements for Libra.\n\nImproving verification\
              \ time. As shown in the experiments above, the verification time in\
              \ Libra is already fast in practice compared to other systems, yet it\
              \ can be further improved by 1-2 orders of magnitude.\n\nWithin the\
              \ verification of Libra, most of the time (more than $9 5 %$ in the\
              \ evaluations above) is spent on our zkVPD protocols using bilinear\
              \ pairings. In our current protocol, we use the pairing-based zkVPD\
              \ both for the input layer and for the masking polynomials $g \\_ {\
              \ i } , R \\_ { i }$ in each intermediate layer. Although the masking\
              \ polynomials are small, the verification of our zkVPD still requires\
              \ $O ( s \\_ { i } )$ pairings per layer for $g \\_ { i }$ , which is\
              \ asymptotically the same as the input layer. For example, for the SHA256\
              \ circuit with 12 layers, the zkVPD verification of each $g \\_ { i\
              \ }$ is around 46ms, $\\\\frac { 1 } { 1 6 }$ of the total verification\
              \ time.\n\nHowever, there are many zkVPD candidates for these masking\
              \ polynomials. Recall that the size of $g \\_ { i }$ is only $O ( s\
              \ \\_ { i } )$ , logarithmic on the size of the circuit. We could use\
              \ any zkVPD with up to linear commitment size, prover time, proof size\
              \ and verification time while still maintaining the asymptotic complexity\
              \ of Libra. The only property we need is zero knowledge. Therefore,\
              \ we can replace our pairing-based zkVPD with any of the zero knowledge\
              \ proof systems we compare with as a black-box. Ligero and Aurora are\
              \ of particular interest as their verification requires no cryptographic\
              \ operations. If we use the black-box of these two systems for the zkVPD\
              \ of $g \\_ { i } , R \\_ { i }$ , the prover time and proof size would\
              \ be affected minimally, and the verification time would be improved\
              \ by almost $d$ times, as only the zkVPD of the input layer requires\
              \ pairings after the change. This is a 1-2 orders-of-magnitude improvement\
              \ depending on the depth of the circuit. In addition, it also removes\
              \ the trusted setup in the zkVPD for the masking polynomials. We plan\
              \ to integrate this approach into our system when the implementations\
              \ of Ligero and Aurora become available.\n\nRemoving trusted setup.\
              \ After the change above, the only place that requires trusted setup\
              \ is the zkVPD for the input layer. However, replacing our pairing-based\
              \ zkVPD with other systems without trusted setup may affect the succinctness\
              \ of our verification time on structured circuits. For example, using\
              \ Ligero, Bulletproof and Aurora as a black-box would increase the verification\
              \ time to $O ( n )$ , and using Hyrax would increase the proof size\
              \ and verification time to $O ( \\\\sqrt { n } )$ . Using libSTARK may\
              \ keep the same complexity, as polynomial evaluation is a special function\
              \ with short description, but the prover time and memory usage is high\
              \ in STARK as shown in the experiments. Designing an efficient zkVPD\
              \ protocol with logarithmic proof size and verification time without\
              \ trusted setup is left as an interesting future work and we believe\
              \ this paper serves as an important step towards the goal of efficient\
              \ succinct zero knowledge proof without trusted setup.\n\n# Chapter\
              \ 3\n\n# Orion: Zero Knowledge Proof with Linear Prover Time\n\nZero-knowledge\
              \ proof is a powerful cryptographic primitive that has found various\
              \ applications in the real world. However, existing schemes with succinct\
              \ proof size suffer from a high overhead on the proof generation time\
              \ that is super-linear in the size of the statement represented as an\
              \ arithmetic circuit, limiting their efficiency and scalability in practice.\
              \ In this paper, we present Orion, a new zero-knowledge argument system\
              \ that achieves $O ( N )$ prover time of field operations and hash functions\
              \ and $O ( \\\\log ^ { 2 } N )$ proof size. Orion is concretely efficient\
              \ and our implementation shows that the prover time is 3.09s and the\
              \ proof size is 1.5MB for a circuit with $2 ^ { 2 0 }$ multiplication\
              \ gates. The prover time is the fastest among all existing succinct\
              \ proof systems, and the proof size is an order of magnitude smaller\
              \ than a recent scheme proposed in Golovnev et al. 2021.\n\nIn particular,\
              \ we develop two new techniques leading to the efficiency improvement.\
              \ (1) We propose a new algorithm to test whether a random bipartite\
              \ graph is a lossless expander graph or not based on the densest subgraph\
              \ algorithm. It allows us to sample lossless expanders with an overwhelming\
              \ probability. The technique improves the efficiency and/or security\
              \ of all existing zero-knowledge argument schemes with a linear prover\
              \ time. The testing algorithm based on densest subgraph may be of independent\
              \ interest for other applications of expander graphs. (2) We develop\
              \ an efficient proof composition scheme, code switching, to reduce the\
              \ proof size from square root to polylogarithmic in the size of the\
              \ computation. The scheme is built on the encoding circuit of a linear\
              \ code and shows that the witness of a second zero-knowledge argument\
              \ is the same as the message in the linear code. The proof composition\
              \ only introduces a small overhead on the prover time.\n\n# 3.1 Introduction\n\
              \nZero-knowledge proof (ZKP) allows a prover to convince a verifier\
              \ that a statement is valid, without revealing any additional information\
              \ about the prover’s secret witness of the statement. Since it was first\
              \ introduced in the seminal paper by Goldwasser, Micali and Rackoff\
              \ \\[GMR89\\], ZKP has evolved from a purely theoretical interest to\
              \ a concretely efficient cryptographic primitive, leading to many real-world\
              \ applications in practice. It has been widely used in blockchains and\
              \ cryptocurrencies to achieve privacy (Zcash $\\[ \\\\mathrm { B e n\
              \ + } 1 4$ ; Zca\\]) and to improve scalability (zkRollup \\[Zkr\\]).\
              \ More recently, it also found applications in zero-knowledge machine\
              \ learning \\[ZFZS20; LKKO20; LXZ21; FQZDC21; WYXKW21\\], zero-knowledge\
              \ program analysis \\[FDNZ21\\], and zero-knowledge middlebox \\[GAZBW22\\\
              ].\n\nThere are three major efficiency measures in ZKP: the overhead\
              \ of the prover to generate the proof, which is referred to as the prover\
              \ time; the total communication between the prover and the verifier,\
              \ which is called the proof size; and the time to verify the proof,\
              \ which is called the verifier time. Despite its recent progress, the\
              \ efficiency of ZKP is still not good enough for many applications.\
              \ In particular, the prover time is one of the major bottlenecks preventing\
              \ existing ZKP schemes from scaling to large statements. As pointed\
              \ out by Golovnev et al. in \\[GLSTW\\], to prove a statement that can\
              \ be modeled as an arithmetic circuit with $N$ gates, existing schemes\
              \ with succinct proof size either perform a fast Fourier transform (FFT)\
              \ due to the ReedSolomon code encodings or polynomial interpolations,\
              \ or a multi-scalar exponentiation due to the use of discrete-logarithm\
              \ assumptions or bilinear maps, over a vector of size $O ( N )$ . The\
              \ former takes $O ( N \\\\log N )$ field additions and multiplications\
              \ and the latter takes $O ( N \\\\log \\| \\\\mathbb { F } \\| )$ field\
              \ multiplications, where $\\\\left\\| \\\\mathbb { F } \\\\right\\|$\
              \ is the size of the finite field. With the Pippenger’s algorithm \\\
              [Pip76\\], the complexity of the multi-scalar exponentiation can be\
              \ improved to $O ( N \\\\log \\| \\\\mathbb { F } \\| / \\\\log N )$\
              \ , which is still super-linear as $\\\\log \\| \\\\mathbb { F } \\\
              | = \\\\omega ( \\\\log N )$ to ensure security. These operations are\
              \ indeed the dominating cost of the prover time both asymptotically\
              \ and concretely. See Section 3.1.3 for more discussions about existing\
              \ ZKP schemes categorized by the underlying cryptographic techniques.\n\
              \nThe only exceptions in the literature are schemes in \\[BCGGHJ17;\
              \ BCG20; BCL22; GLSTW\\]. Bootle et al. \\[BCGGHJ17\\] proposed the\
              \ first ZKP scheme with a prover time of $O ( N )$ field operations\
              \ and a proof size of $O ( { \\\\sqrt { N } } )$ using a linear-time\
              \ encodable error-correcting code. The proof size is later improved\
              \ to $O ( N ^ { 1 / c } )$ for any constant $c$ via a tensor code in\
              \ \\[BCG20\\], and then to polylog $( N )$ via a generic proof composition\
              \ with a probabilistic checkable proof (PCP) in \\[BCL22\\]. These schemes\
              \ are mainly for theoretical interests and do not have implementations\
              \ with good concrete efficiency. Recently, Golovnev et al. \\[GLSTW\\\
              ] proposed a ZKP scheme based on the techniques in \\[BCG20\\] by instantiating\
              \ the linear-time encodable code with a randomized construction. However,\
              \ the security guarantee (soundness error) is only inverse polynomial\
              \ in the size of the circuit, instead of negligible. Moreover, the proof\
              \ size of the implemented scheme is $O ( { \\\\sqrt { N } } )$ (more\
              \ details are presented in Section 3.1.3). Therefore, the following\
              \ question still remains open:\n\nCan we construct a concretely efficient\
              \ ZKP scheme with $O ( N )$ prover time and polylog $( N )$ proof size?\n\
              \n# 3.1.1 Our Contributions\n\nWe answer the question above positively\
              \ in this paper by proposing a new ZKP scheme. In particular, our contributions\
              \ include:\n\n• First, we propose a random construction of the linear-time\
              \ encodable code that has a constant relative distance with overwhelming\
              \ probability. Such a code was used in all existing linear-time ZKP\
              \ schemes \\[BCGGHJ17; BCG20; BCL22; GLSTW\\] and thus our new construction\
              \ also improves their\n\n|     |     |     |     |     |     |\n| ---\
              \ | --- | --- | --- | --- | --- |\n|  | Prover time | Proof size | Verifier\
              \ time\\* | Soundness | Concrete efficiency |\n| \\[BCGGHJ17\\] | O(N)\
              \ | O(N) | O(N) | negl(N) | x |\n| \\[BCG20\\] | O(N) | O(N1/c) | O(N1/c)\
              \ | negl(N) | x |\n| \\[BCL22\\] | O(N) | polylog(N) | polylog(N) |\
              \ negl(N) | x |\n| \\[GLSTW\\] | O(N) | O(N) | O(N) | O(poly(N) 1 |\
              \ J |\n| our scheme | O(N) | O(log2 N) | O(log2 N) | negl(N) | J |\n\
              \nTable 3.1: Comparison to existing ZKP schemes with linear prover time.\
              \ $N$ is the size of the circuit/R1CS and $c \\\\geq 2$ is a constant.\
              \ \\* The verifier time is achieved in the preprocessing setting. In\
              \ addition, the scheme in \\[GLSTW\\] achieves $O ( { \\\\sqrt { N }\
              \ } )$ verifier for structured circuits in the non-preprocessing setting.\n\
              \nefficiency. The key technique is a new algorithm to test whether a\
              \ random graph is a good expander\n\ngraph based on the densest sub-graph\
              \ algorithm, which may be of independent interest for other applications\
              \ of expander graphs \\[SZT02\\].\n\n• Second, we propose a new reduction\
              \ that achieves a proof size of $O ( \\\\log ^ { 2 } N )$ efficiently.\
              \ Our technique is a proof composition named “code switching” proposed\
              \ in \\[RR20\\]. We develop an efficient instantiation using the encoding\
              \ circuit of the linear-time encodable code, which reduces the proof\
              \ size of the schemes in \\[BCG20; GLSTW\\] from $O ( { \\\\sqrt { N\
              \ } } )$ to $O ( \\\\log ^ { 2 } N )$ with a small overhead on the prover\
              \ time.\n\n• Finally, we implement our new ZKP scheme, Orion, and evaluate\
              \ it experimentally. On a circuit with $2 ^ { 2 0 }$ gates (rank-1-constraint-system\
              \ (R1CS) with $2 ^ { 2 0 }$ constraints), the prover time is 3.09s,\
              \ the proof size is $1 . 5 \\\\mathrm { M B s }$ and the verifier time\
              \ is $7 0 \\\\mathrm { m s }$ . Orion has the fastest prover time among\
              \ all existing ZKP schemes in the literature. The proof size is $6 .\
              \ 5 \\\\times$ smaller than the system in \\[GLSTW\\]. The scheme is\
              \ plausibly post-quantum secure and can be made non-interactive via\
              \ the Fiat-Shamir heuristic \\[FS86\\].\n\nTable 3.1 shows the comparison\
              \ between our scheme and existing schemes with linear prover time and\
              \ succinct proof size.\n\nVerifier time. The verifier time in Table\
              \ 3.1 is achieved in the preprocessing setting (holographic proofs \\\
              [CHMMVW20\\]). As all the schemes do not have a trusted setup, their\
              \ verifier time is $O ( N )$ in the worst case, as the verifier has\
              \ to read the description of the circuit/R1CS. In the preprocessing\
              \ setting, the verifier time becomes sublinear with the commitment of\
              \ an indexer describing the circuit. This is the best that can be achieved,\
              \ and our scheme has a $O ( \\\\log ^ { 2 } N )$ verifier time in this\
              \ setting using the techniques in \\[Set20\\]. In addition, the scheme\
              \ in \\[GLSTW\\] can also achieve a verifier time of $O ( { \\\\sqrt\
              \ { N } } )$ in the non-preprocessing setting if the circuit/R1CS is\
              \ structured, i.e., the description of the circuit can be computed in\
              \ sublinear time. Our scheme has an $O ( { \\\\sqrt { N } } )$ verifier\
              \ in this case, but not $O ( \\\\log ^ { 2 } N )$ . This is because\
              \ the encoding circuit we use in the proof compositing is of size $O\
              \ ( { \\\\sqrt { N } } )$ and is not structured.\n\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/477107db401f537e25c54e2fd809f41c784471114d3c53a60695110d465305a1.jpg)\n\
              \nFigure 3.1: An example of lossless expander. $\\\\begin{array} { r\
              \ } { k = 6 , k ^ { \\\\prime } = 9 , g = 3 , \\\\delta = 1 , \\\\epsilon\
              \ = \\\\frac { 1 } { 6 } } \\\\end{array}$ .\n\n# 3.1.2 Technical Overview\n\
              \nTesting expander graphs via densest sub-graph. All existing ZKP schemes\
              \ with linear prover time and succinct proof size \\[BCGGHJ17; BCG20;\
              \ BCL22; GLSTW\\] use linear-time encodable codes with a constant relative\
              \ distance proposed in \\[Spi96; DI14; GLSTW\\], which in turn all rely\
              \ on the existence of good expander graphs. In a good expander graph,\
              \ any subset of vertices expands to a large number of neighbors. Figure\
              \ 3.1 shows an example of a bipartite graph where any subset of vertices\
              \ on the left of size 2 expands to at least 5 vertices on the right.\
              \ See Section 3.2.1 for formal definitions and constructions. However,\
              \ how to construct such good expanders remain unclear in practice. Explicit\
              \ constructions \\[CRVW02\\] have large hidden constants in the complexity\
              \ and thus are not practical. A random graph tends to have good expansion,\
              \ but the probability that a random graph is not a good expander is\
              \ inverse polynomial in the size of the graph. The code constructed\
              \ from a non-expanding graph does not have a good minimum distance,\
              \ making the ZKP scheme insecure. Therefore, a randomly sampled graph\
              \ is not good for cryptographic applications.\n\nIn this paper, we propose\
              \ a new algorithm to efficiently test whether a random graph is a good\
              \ expander or not. With the new testing algorithm, we are able to re-sample\
              \ the random graph until it passes the test, obtaining a good expander\
              \ with an overwhelming probability and boosting the soundness error\
              \ of the ZKP scheme to be negligible. The testing algorithm is based\
              \ on the densest sub-graph algorithm \\[Gol84\\]. The density of a graph\
              \ $G = ( V , E )$ is defined as the number of edges divided by the number\
              \ of vertices $\\\\frac { \\| E \\| } { \\| V \\| }$ , and the densest\
              \ sub-graph is simply the sub-graph in a graph with the maximum density.\
              \ We observe that a good expander graph tends to have a small maximum\
              \ density. This is because assuming the degree $g$ of each vertex is\
              \ a constant, e.g. $g = 3$ for all vertices on the left in Figure 3.1,\
              \ given any subset of vertices of size $s$ in the graph, the total number\
              \ of edges is fixed as $\\| E \\| = g s$ in the sub-graph defined by\
              \ this subset and its neighbors. For example, any two vertices on the\
              \ left in Figure 3.1 as highlighted always have 6 outgoing edges. Then\
              \ we differentiate two cases:\n\n• In a good expander graph, any subset\
              \ expands to a large number of neighbors, thus the total number of vertices\
              \ in this sub-graph is large. Therefore, the density of any sub-graph\
              \ is small; • In contrast, if the graph is not a good expander, there\
              \ is at least one subset that does not expand. Taking the sub-graph\
              \ defined by this subset and its neighbors, again the number of edges\
              \ is fixed, while the number of vertices is small. Therefore, the density\
              \ of this sub-graph is large, which will be detected by the densest\
              \ subgraph algorithm.\n\nThis observation gives us a way to differentiate\
              \ good expanders. To the best of our knowledge, we are the first to\
              \ make the connection between expander and the densest subgraph problem.\n\
              \nThe real testing algorithm involves random sampling and repeating\
              \ the densest sub-graph algorithm because of additional conditions of\
              \ the expander. The formal algorithm, theorem and proofs are presented\
              \ in Section 3.3.\n\nProof composition via code-switching. With the\
              \ expander graph sampled above and the corresponding linear code, we\
              \ are able to build efficient ZKP schemes following the approaches in\
              \ \\[BCGGHJ17; BCG20; GLSTW\\]. However, the proof size is $O ( N ^\
              \ { 1 / c } )$ instead of $\\\\mathsf { p o l y l o g } ( N )$ . To\
              \ reduce the proof size, a common technique in the literature is proof\
              \ composition. Instead of sending the proof directly to the verifier,\
              \ the prover uses a second ZKP scheme to show that the proof of the\
              \ first ZKP is indeed valid. In particular, in \\[BCGGHJ17; BCG20; GLSTW\\\
              ], the proof consists of several codewords of the linear-time encodable\
              \ code, and the checks can be represented as inner products between\
              \ the messages in the codewords and some public vectors.\n\nUnfortunately,\
              \ we do not have a second ZKP scheme based on the linear-time encodable\
              \ code with a $\\\\mathsf { p o l y l o g } ( N )$ proof size to prove\
              \ inner products. If we had it, we would already be able to build a\
              \ ZKP scheme with polylog $( N )$ proof size in the first place. Instead,\
              \ we rely on the fact that the proof consists of the codewords of the\
              \ linear code and construct the second ZKP scheme as follows. One component\
              \ of the second ZKP scheme is the encoding circuit of the linear-time\
              \ encodable code. It takes the witness of the second ZKP scheme, encodes\
              \ it and outputs several random locations of the codeword. The verifier\
              \ checks that these random locations are the same as the proof of the\
              \ first ZKP scheme, without receiving the entire proof. By the distance\
              \ of the linear-time encodable code, we show that the witness of the\
              \ second ZKP must be the same as the message in the proof of the first\
              \ ZKP with overwhelming probability. After that, the other component\
              \ of the second ZKP checks the inner product relationship modeled as\
              \ an arithmetic circuit. A similar proof composition was also used in\
              \ \\[RR20\\]. We view our approach using the encoding circuit as a variant\
              \ of the proof composition that is efficient in practice, and thus we\
              \ inherit the name “code switching” from \\[RR20\\].\n\nWith this idea,\
              \ we can use any general-purpose ZKP scheme on arithmetic circuits with\
              \ a polylog $( N )$ proof size as the second ZKP scheme in the proof\
              \ composition. The size of this circuit is only $O ( { \\\\sqrt { N\
              \ } } )$ , thus the second ZKP does not introduce any overhead on the\
              \ prover time as long as its prover time is no more than quadratic.\
              \ In our construction, we use the ZKP scheme in \\[ZXZS20\\] as the\
              \ second ZKP. The scheme is based on the interactive oracle proofs (IOP)\
              \ and the witness is encoded using the Reed-Solomon code. Therefore,\
              \ the technique is called code switching. The formal protocols are presented\
              \ in Section 2.4.\n\n# 3.1.3 Related Work\n\nZero-knowledge proof was\
              \ introduced in \\[GMR89\\] and generic constructions based on PCPs\
              \ were proposed by Kilian \\[Kil92\\] and Micali \\[Mic00\\] in the\
              \ early days. Driven by various applications mentioned in the introduction,\
              \ there has been significant progress in efficient ZKP protocols and\
              \ systems. Categorized by their underlying techniques, there are ZKP\
              \ systems based on bilinear maps \\[PHGR13; BSCGTV13; BFRSBW13; BSCTV14a;\
              \ $\\\\mathrm { C o s } { + } 1 5$ ; WSRBW15; FFGKOP16; GKMMM18; MBKM19;\
              \ GWC19a; CHMMVW20; KPPS20\\], MPC-in-the-head \\[GMO16; $\\\\mathrm\
              \ { C h a } { + } 1 7$ ; AHIV17; KKW18\\], IP \\[ZGKPP17d; ZGKPP17b;\\\
              \n\\\nWTSTW18; ZGKPP18; XZZPS19c; Zha+21a\\], discrete logarithm \\\
              [BBBPWM18; BFS20; Set20; SL20\\], interactive oracle proofs (IOP) \\\
              [BSCRSVW19; BSBHR19; ZXZS20; BFHVXZ20; COS20; BDFG20\\], and lattices\
              \ \\[BBCDPGL18; ESLL19; BLNS20; ISW21\\]. As mentioned in the introduction,\
              \ these schemes perform either an FFT (such as schemes based on MPC-in-the-head\
              \ and IOP) or a multi-scalar exponentiation (such as schemes based on\
              \ discrete-log and bilinear pairing), making the complexity of the prover\
              \ time superlinear in the size of the circuit.\n\nWith the techniques\
              \ proposed in \\[XZZPS19c; Zha+21a\\], the prover time of the schemes\
              \ based on the interactive proofs (the GKR protocol \\[GKR08\\]) is\
              \ linear if the size of the input is significantly smaller than the\
              \ size of the circuit. However, the goal of this paper is to make the\
              \ prover time strictly linear without such a requirement, and our polynomial\
              \ commitment scheme can also be plugged into these schemes to improve\
              \ their efficiency.\n\nSchemes with linear prover time. As mentioned\
              \ before, schemes in \\[BCGGHJ17; BCG20; BCL22; GLSTW\\] are the only\
              \ candidates in the literature with linear prover time and succinct\
              \ proof size for arithmetic circuits. They all use linear-time encodable\
              \ codes based on expander graphs and our first contribution applies\
              \ to all of them. Moreover, our ZKP scheme is based on the polynomial\
              \ commitment in \\[GLSTW\\] and the tensor IOP in \\[BCG20\\], and we\
              \ improve the proof size to $O ( \\\\log ^ { 2 } N )$ through a proof\
              \ composition. In fact, the scheme in \\[BCL22\\] also proposes a proof\
              \ composition with the PCP in \\[Mie09\\]. However, the complexity of\
              \ the PCP is polynomial time. That is why the scheme in \\[BCL22\\]\
              \ has to be built on the scheme in \\[BCG20\\] with a proof size of\
              \ $O ( N ^ { 1 / c } )$ and is not concretely efficient, while our scheme\
              \ can be built on top of the efficient scheme in \\[GLSTW\\] with a\
              \ proof size of $O ( { \\\\sqrt { N } } )$ .\n\nFinally, the scheme\
              \ in \\[GLSTW\\] samples a random graph to build the linear-time encodable\
              \ code. The scheme achieves a soundness error of $O \\\\big ( \\\\frac\
              \ { 1 } { \\\\mathsf { p o l y } ( N ) } \\\\big )$ and the authors\
              \ spent great efforts calculating parameters that achieve a concrete\
              \ failure probability of $2 ^ { - 1 0 0 }$ for large circuits in practice\
              \ \\[GLSTW, Claim 2 and Figure 2\\]. Our sampling algorithm provides\
              \ the provable security guarantee of a negligible soundness error for√\
              \ their scheme. Moreover, we improve the proof size from $O ( { \\\\\
              sqrt { N } } )$ to $O ( \\\\log ^ { 2 } N )$ efficiently, solving an\
              \ open problem left in \\[GLSTW\\].\n\nThere are two recent schemes\
              \ that achieve linear prover time for Boolean circuits \\[RR22; HR22\\\
              ]. We mainly focus on arithmetic circuits in this paper, but our techniques\
              \ may also apply to these schemes to obtain efficient instantiations.\n\
              \nSchemes with linear proof size. Recently, there is a line of work\
              \ constructing ZKP based on secure multiparty computation (MPC) techniques\
              \ \\[WYKW20; DIO21; BMRS21; YSWW21\\] and these schemes have demonstrated\
              \ fast prover time in practice. If one treats a block cipher (e.g.,\
              \ AES) as a constant-time operation because of the CPU instruction,\
              \ these schemes indeed have a linear time prover (we are using a similar\
              \ CPU instruction for the hash function SHA-256 in our scheme to achieve\
              \ linear prover time). However, they have linear proof size in the size\
              \ of the circuit, are inherently interactive, and are not publicly verifiable,\
              \ which are not desirable in many applications. We mainly focus on non-interactive\
              \ ZKP with succinct proof size and public verifiability in this paper.\n\
              \nExpander testing. Testing the properties of expander graphs is a deeply\
              \ explored area in computer science. Many works \\[NS07; CS07; GR11\\\
              ] have proposed efficient testing algorithms without accessing the whole\
              \ graph. However, these algorithms do not directly apply to our testing\
              \ of lossless expander. For example, the algorithm in \\[NS07\\] based\
              \ on random walks can differentiate good expanders from graphs that\
              \ are far from expanders, while our scheme can differentiate whether\
              \ a graph is a lossless expander or not with overwhelming probability.\
              \ Of course our algorithm accesses the entire graph, which is fine in\
              \ our application of linear-time encodable code. To the best of our\
              \ knowledge, we are not aware of any testing algorithm with such properties.\n\
              \nThere are also impossibility results on expander testing \\[KS16\\\
              ]. Due to different definitions of expansion, our testing algorithm\
              \ cannot distinguish the cases in \\[KS16, Theorem 1.1\\] and thus it\
              \ does not violate the impossibility results.\n\n# 3.2 Preliminary\n\
              \nWe use $\\[ N \\]$ to denote the set ${ 0 , 1 , 2 , . . . , N - 1\
              \ }$ . $\\\\mathsf { p o l y } ( N )$ means a function upper bounded\
              \ by a polynomial in $N$ with a constant degree . We use $\\\\lambda\
              \ = \\\\omega ( \\\\log N )$ to denote the security parameter, and $\\\
              \\mathsf { n e g l } ( N )$ to denote the negligible function in $N$\
              \ , i.e. $\\\\begin{array} { r } { \\\\mathsf { n e g l } ( N ) \\\\\
              leq \\\\frac { 1 } { \\\\mathsf { p o l y } ( N ) } } \\\\end{array}$\
              \ for all sufficiently large $N$ and any polynomial. Some papers define\
              \ neg $( \\\\lambda )$ as the negligible function. As $\\\\lambda$ is\
              \ a function of $N$ , they are essentially the same and $\\\\mathsf\
              \ { n e g l } ( N ) \\\\leq \\\\frac { 1 } { 2 ^ { \\\\lambda } }$ .\
              \ “PPT” stands for probabilistic polynomial time. $\\\\langle A ( x\
              \ ) , B ( y ) \\\\rangle ( z )$ denotes an interactive protocol between\
              \ algorithms $A , B$ with $x$ as the input of $A , y$ as the input of\
              \ $B$ and $z$ as the common input.\n\n# 3.2.1 Linear-Time Encodable\
              \ Linear Code\n\nDefinition 3.2.1 (Linear Code). A linear error-correcting\
              \ code with message length $k$ and codeword length $n$ is a linear subspace\
              \ $C \\\\in \\\\mathbb { F } ^ { n }$ , such that there exists an injective\
              \ mapping from message to codeword $E \\_ { C } : \\\\mathbb { F } ^\
              \ { k } \\\\to C$ , which is called the encoder of the code. Any linear\
              \ combination of codewords is also a codeword. The rate of the code\
              \ is defined as $\\\\frac { k } { n }$ . The distance between two codewords\
              \ $u , v$ is the hamming distance denoted as $\\\\Delta ( u , v )$ .\
              \ The minimum distance is $d = \\\\mathrm { m i n } \\_ { u , v } \\\
              \\Delta ( u , v )$ . Such a code is denoted as $\\[ n , k , d \\]$ linear\
              \ code, and we also refer to $\\\\frac { d } { n }$ as the relative\
              \ distance of the code.\n\nGeneralized Spielman code. In our construction,\
              \ we use a family of linear codes that can be encoded in linear time\
              \ and has a constant relative distance \\[Spi96; DI14; GLSTW\\]. The\
              \ code was first proposed by Daniel Spielman in \\[Spi96\\] over the\
              \ Boolean alphabet. Druk and Ishai \\[DI14\\] generalized it to a finite\
              \ field $\\\\mathbb { F }$ , and introduced a distance boosting technique\
              \ to achieve the Gilbert-Varshamov bound\\[Gil52; Var57\\]. We only\
              \ use the basic construction over $\\\\mathbb { F }$ without the distance\
              \ boosting, and thus refer to it as the generalized Spielman code in\
              \ this paper. The code relies on the existence of lossless expander\
              \ graphs, which is defined below:\n\nDefinition 3.2.2 (Lossless Expander\
              \ \\[Spi96\\]). Let $G = ( L , R , E )$ be a bipartite graph. $0 < \\\
              \\epsilon < 1$ and $0 < \\\\delta$ be some constants. The vertex set\
              \ consists of $L$ and $R$ , two disjoint subsets, henceforth the left\
              \ and right vertex set. Let $\\\\Gamma ( S )$ be the neighbor set of\
              \ some vertex set $S$ . We say $G$ is an $( k , k ^ { \\\\prime } ;\
              \ g )$ -lossless expander $i f \\\\vert L \\\\vert = k , \\\\vert R\
              \ \\\\vert = k ^ { \\\\prime } = \\\\alpha k$ for some constant $\\\\\
              alpha$ , and the following property hold:\n\n1. Degree: The degree of\
              \ every vertex in $L$ is $g$ .\n\n2. Expansion: $\\| \\\\Gamma ( S )\
              \ \\| \\\\geq ( 1 - \\\\epsilon ) g \\| S \\|$ for every $S \\\\subseteq\
              \ L$ with $\\\\begin{array} { r } { \\| S \\| \\\\le \\\\frac { \\\\\
              delta \\| L \\| } { g } } \\\\end{array}$ .\n\n\nIntuitively speaking,\
              \ a lossless expander has very strong expansion. As the degree of each\
              \ left vertex is $g$ , a set of $\\| S \\|$ left vertices have at most\
              \ $g \\| S \\|$ neighbors, while the second condition requires that\
              \ every set expands to at least $( 1 - \\\\epsilon ) g \\| S \\|$ vertices\
              \ for a small constant $\\\\epsilon$ . Meanwhile, as the right vertext\
              \ set has\n\n$\\| R \\| = \\\\alpha k$ vertices, such an expansion is\
              \ not possible if $\\\\begin{array} { r } { \\| S \\| > \\\\frac { \\\
              \\alpha k } { ( 1 - \\\\epsilon ) g } } \\\\end{array}$ , thus there\
              \ is a condition $\\\\begin{array} { r } { \\| S \\| \\\\le \\\\frac\
              \ { \\\\delta k } { g } } \\\\end{array}$ bounding the size of $S$ .\
              \ An example is shown in Figure 3.1.\n\nConstruction of generalized\
              \ Spielman code. With the lossless expander, we give a brief description\
              \ of the generalized Spielman code. Let $G = ( L , R , E )$ be a lossless\
              \ expander with $\\\\bar { \\| } L \\| = 2 ^ { t } , \\| R \\| = 2 ^\
              \ { \\\\hat { t } - 1 }$ . Let $A \\_ { t }$ be a $2 ^ { t } \\\\times\
              \ 2 ^ { t - \\\\hat { 1 } }$ matrix where $A \\_ { t } \\[ i \\] \\\
              [ j \\] = 1$ if there is an edge $i , j$ in $G$ for $i \\\\in \\[ 2\
              \ ^ { t } \\] , j \\\\in \\[ 2 ^ { t - 1 } \\]$ ; otherwise $A \\_ {\
              \ t } \\[ i \\] \\[ j \\] = 0$ . The generalized Spielman code is constructed\
              \ as follows:\n\n1. Let $E \\_ { C } ^ { t } ( x )$ be the encoder function\
              \ of input length $\\| x \\| = 2 ^ { t }$ , and its output will be a\
              \ codeword of size $2 ^ { t + 2 }$ . We use $E \\_ { C }$ to denote\
              \ the encoder function when length is clear.\n2. If $\\| x \\| \\\\\
              leq n \\_ { 0 }$ then directly output $x$ , for some constant $n \\\
              _ { 0 }$ .\n3. Compute $m \\_ { 1 } = x A \\_ { t }$ . Each entry of\
              \ $m \\_ { 1 }$ can be viewed as a vertex in $R$ , and value of each\
              \ vertex is the summation of its neighbors in $L$ . The length of $m\
              \ \\_ { 1 }$ is $2 ^ { t - 1 }$\n4. Recursively apply the encoder $E\
              \ \\_ { C } ^ { t - 1 }$ on $m \\_ { 1 }$ , let $c \\_ { 1 } = E \\\
              _ { C } ^ { t - 1 } ( m \\_ { 1 } )$ .\n5. Compute $c \\_ { 2 } = c\
              \ \\_ { 1 } A \\_ { t + 1 }$ .\n6. Output $x \\\\odot c \\_ { 1 } \\\
              \\odot c \\_ { 2 }$ as the codeword of size $2 ^ { t + 2 }$ . $\\\\\
              odot$ denotes concatenation.\n\nLemma 3.2.3 (Generalized Spielman code,\
              \ \\[DI14\\]). Given a family of lossless expander, that achieves $(\
              \ 1 -$ $\\\\epsilon ) g \\| S \\|$ expansion with $\\\\begin{array}\
              \ { r } { \\| S \\| \\\\le \\\\frac { \\\\delta \\| L \\| } { g } }\
              \ \\\\end{array}$ , for input size $k$ , the generalized Spielman code\
              \ is a $\\[ 4 k , k , \\\\textstyle { \\\\frac { \\\\delta } { 8 g }\
              \ } k \\]$ linear code over $\\\\mathbb { F }$ .\n\nThe code in \\[GLSTW\\\
              ] is a variant of generalized Spielman code. In their construction,\
              \ random weights are assigned to each edge of lossless expander at line\
              \ 3, 5. The output at line 6 is randomized as $( x \\\\otimes r ) \\\
              \\odot$ $c \\_ { 1 } \\\\odot c \\_ { 2 }$ , where $\\\\otimes$ denotes\
              \ element-wise multiplication and $r$ is a random vector.\n\nDefinition\
              \ 3.2.4 (Tensor code). Let $C$ be a $\\[ n , k , d \\]$ linear code,\
              \ the tensor code $C ^ { \\\\otimes 2 }$ of dimension 2 is the linear\
              \ code in $\\\\mathbb { F } ^ { n ^ { 2 } }$ with message length $k\
              \ ^ { 2 }$ , codeword length $n ^ { 2 }$ , and distance nd. We can view\
              \ the codeword as a $n \\\\times n$ matrix. We define the encoding function\
              \ below:\n\n1. A message of length $k \\\\times k$ is parsed as a $k\
              \ \\\\times k$ matrix. Each row of the matrix is encoded using $E \\\
              _ { C }$ , resulting in a codeword $C \\_ { 1 }$ of size $k \\\\times\
              \ n$ .\n2. Each column of $\\\\mathsf C \\_ { 1 }$ is then encoded again\
              \ using $E \\_ { C }$ . The result ${ \\\\mathsf { C } } \\_ { 2 }$\
              \ of size $n \\\\times n$ is the codeword of the tensor code.\n\n# 3.2.2\
              \ Collision-Resistant Hash Function and Merkle Tree\n\nLet ${ \\\\cal\
              \ H } : { 0 , 1 } ^ { 2 \\\\lambda } { 0 , 1 } ^ { \\\\lambda }$ be\
              \ a hash function. A Merkle Tree is a data structure that allows one\
              \ to commit to $l = 2 ^ { \\\\mathsf { d e p } }$ messages by a single\
              \ hash value $h$ , such that revealing any bit of the message require\
              \ dep $+ 1$ hash values.\n\nA Merkle hash tree is represented by a binary\
              \ tree of depth dep where $l$ messages elements $m \\_ { 1 } , m \\\
              _ { 2 } , . . . , m \\_ { l }$ are assigned to the leaves of the tree.\
              \ The values assigned to internal nodes are computed by hashing the\
              \ value of its two child nodes. To reveal $m \\_ { i }$ , we need to\
              \ reveal $m \\_ { i }$ together with the values on the path from $m\
              \ \\_ { i }$ to the root. We denote the algorithm as follows:\n\n1.\
              \ h ← Merkle.Commit $( m \\_ { 1 } , . . . , m \\_ { l } )$ .\n\n2.\
              \ $( m \\_ { i } , \\\\pi \\_ { \\\\mathrm { i } } ) \\\\gets \\\\mathsf\
              \ { M e r k l e . O p e n } ( m , i )$\n\n\n$$\n{ \\\\mathsf { a c c\
              \ e p t , r e j e c t } } \\\\gets \\\\mathsf { M e r k l e . V e r\
              \ i f y } ( \\\\pi \\_ { \\\\mathrm { i } } , m \\_ { i } , h ) .\n\
              $$\n\nTo achieve zero-knowledge, we requires the hash function to be\
              \ hiding, we formally define hiding as follows:\n\nHiding property The\
              \ hiding property specifies that given any hash output $y$ , it is infeasible\
              \ to find an input $x$ such that $y = H ( x \\| r )$ is satisfied. Note,\
              \ we implicitly assumes for each hash function call on input $x$ , we\
              \ will append a randomness $r$ .\n\n# 3.2.3 Zero-Knowledge Arguments\n\
              \nAn argument system for an NP relation $R$ is a protocol between a\
              \ computationally bounded prover $\\\\mathcal { P }$ and a verifier\
              \ $\\\\nu$ . At the end of the protocol $\\\\nu$ will be convinced that\
              \ there exits a witness $w$ such that $( x , w ) \\\\in R$ for some\
              \ public input $x$ . We focus on arguments of knowledge which require\
              \ the prover know the witness $w$ . We formally define zero-knowledge\
              \ as follows:\n\nDefinition 3.2.5 (View). We denote by View $( \\\\\
              langle \\\\mathcal { P } , \\\\mathcal { V } \\\\rangle ( x ) )$ the\
              \ view of $\\\\nu$ in an interactive protocol with $\\\\mathcal { P\
              \ }$ . Namely, it is the random variable $( r , b \\_ { 1 } , b \\_\
              \ { 2 } , . . . , b \\_ { n } , v \\_ { 1 } , v \\_ { 2 } , . . . ,\
              \ v \\_ { m } )$ where $r$ is $\\\\nu \\_ { s }$ randomness, $b \\_\
              \ { 1 } , . . . , b \\_ { n }$ are messages from $\\\\nu$ to $\\\\mathcal\
              \ { P }$ , and $v \\_ { 1 } , . . . , v \\_ { m }$ are messages from\
              \ $\\\\mathcal { P }$ to $\\\\nu$ .\n\nDefinition 3.2.6. Let $\\\\mathcal\
              \ { R }$ be an NP relation. A tuple of algorithm $( \\\\mathcal { G\
              \ } , \\\\mathcal { P } , \\\\mathcal { V } )$ is a zero-knowledge argument\
              \ of knowledge for $\\\\mathcal { R }$ if the following holds.\n\n•\
              \ Correctness. For every pp output by $\\\\mathcal { G } ( 1 ^ { \\\\\
              lambda } )$ and $( x , w ) \\\\in R ,$\n\n$$\n\\\\begin{array} { r }\
              \ { \\\\mathrm { P r } \\[ \\\\langle \\\\mathcal { P } ( w ) , \\\\\
              mathcal { V } ( \\\\rangle \\\\rangle ( \\\\mathsf { p p } , x ) = \\\
              \\mathsf { a c c e p t } \\] = 1 . } \\\\end{array}\n$$\n\n• Knowledge\
              \ Soundness. For any PPT adversary $\\\\mathcal { P } ^ { \\* }$ , there\
              \ exists a PPT extractor $\\\\varepsilon$ such that for every pp output\
              \ by $\\\\mathcal { G } ( 1 ^ { \\\\lambda } )$ and any $x$ , the following\
              \ probability is negl $( N )$ :\n\n$$\n\\\\operatorname\\* { P r } \\\
              [ \\\\langle \\\\mathcal { P } ^ { \\* } ( \\\\mathfrak { d } ) , \\\
              \\mathcal { V } ( \\\\mathfrak { d } ) \\\\rangle ( \\\\mathsf { p p\
              \ } , x ) = \\\\mathsf { a c c e p t } , ( x , w ) \\\\notin \\\\mathcal\
              \ { R } \\| w \\\\varepsilon ( \\\\mathsf { p p } , x , \\\\mathsf {\
              \ V i e w } ( \\\\langle \\\\mathcal { P } ^ { \\* } ( \\\\mathfrak\
              \ { d } ) , \\\\mathcal { V } ( \\\\mathfrak { d } ) \\\\rangle ( \\\
              \\mathsf { p p } , x ) ) ) \\]\n$$\n\n• Zero knowledge. There exists\
              \ a PPT simulator $\\\\boldsymbol { s }$ such that for any PPT algorithm\
              \ $\\\\nu ^ { \\* }$ , $( x , w ) \\\\in R$ , pp output by $\\\\bar\
              \ { \\\\mathcal { G } } ( 1 ^ { \\\\lambda } )$ , it holds that\n\n\
              $$\n\\\\mathsf { V i e w } ( \\\\langle \\\\mathcal { P } ( w ) , \\\
              \\mathcal { V } ^ { \\* } ( ) \\\\rangle ( x ) ) \\\\approx \\\\mathcal\
              \ { S } ^ { \\\\mathcal { V } ^ { \\* } } ( \\\\mathsf { p p } , x )\n\
              $$\n\nWhere SV $s ^ { \\\\gamma ^ { \\* } } ( x )$ denotes that $s$\
              \ is given oracle accesses to $\\\\nu ^ { \\* }$ ’s random tape.\n\n\
              We say that $( \\\\mathcal { G } , \\\\mathcal { P } , \\\\mathcal {\
              \ V } )$ is $a$ succinct argument system if the total communication\
              \ between $\\\\mathcal { P }$ and $\\\\nu$ (proof size) is pol $y (\
              \ \\\\lambda , \\| x \\| , \\\\log \\| w \\| )$ .\n\nDefinition 3.2.7\
              \ (Arithmetic circuit). An arithmetic circuit C over $\\\\mathbb { F\
              \ }$ and a set of variables $x \\_ { 1 } , . . . , x \\_ { N }$ is $a$\
              \ directed acyclic graph as follows:\n\n1. Each vertex is called a “gate”.\
              \ A gate with in-degree zero is an input gate and is labeled as a variable\
              \ $x \\_ { i }$ or a constant field element in F.\n2. Other gates have\
              \ 2 incoming edges. It calculates the addition or multiplication over\
              \ the two inputs and output the result.\n3. The size of the circuit\
              \ is defined as the number of gates $N$ .\n\n# 3.2.4 Polynomial Commitment\n\
              \nA polynomial commitment consists of three algorithms:\n\n• PC.Commit\
              \ $( \\\\phi ( \\\\cdot ) )$ : the algorithm outputs a commitment $\\\
              \\mathcal { R }$ of the polynomial $\\\\phi ( \\\\cdot )$ .\n\n• $\\\
              \\mathsf { P C . P r o v e } ( \\\\phi , \\\\vec { x } , \\\\mathcal\
              \ { R } )$ : given an evaluation point $\\\\phi ( \\\\vec { x } )$ ,\
              \ the algorithm outputs a tuple $\\\\langle \\\\vec { x } , \\\\phi\
              \ ( \\\\vec { x } ) , \\\\pi \\_ { \\\\vec { x } } \\\\rangle$ , where\
              \ $\\\\pi \\_ { \\\\vec { x } }$ is the proof.\n\n• PC.VerifyEva $(\
              \ \\\\pi \\_ { \\\\vec { x } } , \\\\vec { x } , \\\\phi ( \\\\vec {\
              \ x } ) , \\\\mathcal { R } )$ : given $\\\\pi \\_ { \\\\vec { x } }\
              \ , \\\\vec { x } , \\\\phi ( \\\\vec { x } ) , \\\\mathcal { R }$ ,\
              \ the algorithm checks if $\\\\phi ( \\\\vec { x } )$ is the correct\
              \ evaluation. The algorithm outputs accept or reject.\n\nDefinition\
              \ 3.2.8 ((Multivariate) Polynomial commitment). A polynomial commitment\
              \ scheme has the following properties:\n\n• Correctness. For every polynomial\
              \ $\\\\phi$ and evaluation point $\\\\vec { x }$ , the following probability\
              \ holds:\n\n$$\n\\\\begin{array} { r } { \\\\operatorname\\* { P C }\
              \ . C \\\\mathsf { o m m i t } ( \\\\phi ) \\\\to \\\\mathcal { R }\
              \ } \\ { \\\\operatorname\\* { P C } . \\\\mathsf { P r o v e } ( \\\
              \\phi , \\\\vec { x } , \\\\mathcal { R } ) \\\\to \\\\vec { x } , y\
              \ , \\\\pi } \\ { y = \\\\phi ( \\\\vec { x } ) } \\ { \\\\mathsf {\
              \ P C } . \\\\mathsf { V e r i f y E v a l } ( \\\\pi , \\\\vec { x\
              \ } , y , \\\\mathcal { R } ) \\\\to \\\\mathsf { a c c e p t } } \\\
              \\end{array}\n$$\n\n• Knowledge Soundness. For any PPT adversary $\\\
              \\mathcal { P } ^ { \\* }$ with PC.Commit∗, PC.Prove∗, there exists\
              \ a PPT extractor $\\\\mathcal { E }$ such that the probability below\
              \ is negligible:\n\n$$\n\\\\operatorname\\* { P r } ( \\\\operatorname\\\
              * { P C } \\_ { \\\\mathbf { \\\\Theta } \\\\times \\\\mathbf { \\\\\
              Theta } \\\\times \\\\mathbf { \\\\Theta } ^ { \\* } ( \\\\mathbf {\
              \ \\\\Theta } ^ { \\* } , \\\\vec { x } , \\\\mathcal { R } ^ { \\*\
              \ } ) \\\\to \\\\vec { x } , y ^ { \\* } , \\\\pi ^ { \\* } : \\\\phi\
              \ ^ { \\* } } \\\\mathcal { E } ( \\\\mathcal { R } ^ { \\* } , \\\\\
              vec { x } , \\\\pi ^ { \\* } , y ^ { \\* } ) \\\\land y ^ { \\* } \\\
              \\neq \\\\phi ^ { \\* } ( \\\\vec { x } ) )\n$$\n\n• Zero-knowledge.\
              \ For security parameter $\\\\lambda$ , polynomial $\\\\phi$ , any PPT\
              \ adversary $\\\\mathcal { A }$ , there exists a simulator $\\\\begin{array}\
              \ { r } { \\\\boldsymbol { S } = \\[ S \\_ { 0 } , S \\_ { 1 } \\] }\
              \ \\\\end{array}$ , we consider following two experiments:\n\n|    \
              \ |     |\n| --- | --- |\n|  | Ideal4,s(pp): |\n| Reals,s(pp): | 1\\\
              . RSo(1^,pp) |\n| 1\\. R Commit(pp,) | 2\\. xA(R,pp) |\n| 2\\. xA(R,pp)\
              \ | 3\\. (, y,) SA(, pp), given oracle ac- |\n| 3\\. (x,y,) Prove(o,x,R)\
              \ | cess to y = $(x) |\n| 4\\. bA(r,x,y,R) | 4\\. bA(r,x,y,R) |\n| 5\\\
              . Output b | 5\\. Output b |\n\nFor any PPT adversary $\\\\mathcal {\
              \ A }$ , two experiments are identically distributed:\n\n$$\n\\\\mathrm\
              \ { P r } \\[ \\| \\\\mathsf { R e a l } \\_ { \\\\boldsymbol { A }\
              \ , \\\\boldsymbol { f } } ( \\\\mathsf { p p } ) - \\\\mathsf { I d\
              \ e a l } \\_ { \\\\boldsymbol { A } , \\\\boldsymbol { S } ^ { \\\\\
              boldsymbol { A } } } ( \\\\mathsf { p p } ) \\| = 1 \\] \\\\le \\\\\
              mathsf { n e g l } ( N )\n$$\n\n# 3.3 Testing Algorithm for Lossless\
              \ Expander\n\nAs explained above, the generalized Spielman code relies\
              \ on the existence of lossless expanders. On one hand, there are explicit\
              \ constructions of lossless expanders in the literature \\[CRVW02\\\
              ]. However, there are large hidden constants in the complexity and the\
              \ constructions are not practical. On the other hand, a random bipartite\
              \ graph is a lossless expander with a high probability of $\\\\textstyle\
              \ 1 - O ( { \\\\frac { 1 } { \\\\mathsf { p o l y } ( k ) } } )$ , where\
              \ $k$ is the size of the left vertex set in the bipartite graph. However,\
              \ this is not good enough for cryptographic applications.\n\nIn this\
              \ section, we propose a new approach to sample a lossless expander with\
              \ a negligible failure probability. The key ingredient of our approach\
              \ is a new algorithm to test whether a randomly sampled bipartite graph\
              \ is a lossless expander or not. We begin the section by introducing\
              \ the classical randomized construction of a lossless expander and its\
              \ analysis.\n\n# 3.3.1 Random Construction of Lossless Expander\n\n\
              As defined in Definition 3.2.2, a lossless expander graph is a $g$ -left-regular\
              \ bipartite graph $G = ( L , R , E )$ . Wigderson et al. \\[HLW06, Lemma1.9\\\
              ] showed that a random bipartite graph is a lossless expander with a\
              \ high probability. In particular, we have the following lemma:\n\n\
              Lemma 3.3.1 (\\[HLW06\\]). For fixed constant parameters $g , \\\\delta\
              \ , \\\\alpha , \\\\epsilon ,$ , a random $g$ -left-regular bipartite\
              \ graph is a (k, k′; g)-lossless-expander with probability 1 − O( 1poly(k)\
              \ ).\n\nProof. Let $G = ( L , R , E )$ be a random bipartite graph with\
              \ $k$ vertices on the left and $k ^ { \\\\prime } = O ( k )$ vertices\
              \ on the right, where each left vertex connects to a randomly chosen\
              \ set of $g$ vertices on the right.\n\nLet $s = \\| S \\|$ be the cardinality\
              \ of a left subset of vertices $S \\\\subseteq L$ such that $\\\\begin{array}\
              \ { r } { s \\\\le \\\\frac { \\\\delta k } { g } } \\\\end{array}$\
              \ , and let $t = \\| T \\|$ be the cardinality of a right subset of\
              \ vertices $T \\\\subseteq R$ such that $t \\\\le ( 1 - \\\\epsilon\
              \ ) g s$ . Let $\\\\check { X } \\_ { S , T }$ be an indicator random\
              \ variable for the event that all the edges from $S$ connect to $T$\
              \ . Then for a particular $S$ , if $\\\\Sigma \\_ { T \\\\in R } X \\\
              _ { S , T } = 0$ , then the number of neighboring vertices of $S$ must\
              \ be larger than $( 1 - \\\\epsilon ) g s$ . Otherwise, if there exists\
              \ a $T \\\\in R$ such that $X \\_ { S , T } = 1$ , i.e., all edges from\
              \ $S$ connect to $T$ , the graph is not a lossless expander. As the\
              \ edges are sampled randomly, the probability of this non-expanding\
              \ event is $\\\\big ( \\\\frac { t } { k ^ { ^ { \\\\prime } } } \\\\\
              big ) ^ { s g }$ . Therefore, summing over all $S$ and by the union\
              \ bound, the probability of a non-expanding graph is:\n\n$$\n\\\\begin{array}\
              \ { r l } & { \\\\operatorname\\* { P r } \\[ ( \\\\displaystyle \\\\\
              sum \\_ { S , T } X \\_ { S , T } ) > 0 \\] \\\\leq \\\\displaystyle\
              \ \\\\sum \\_ { S , T } P r \\[ X \\_ { S , T } = 1 \\] = \\\\sum \\\
              _ { S , T } ( \\\\frac { t } { k ^ { \\\\prime } } ) ^ { s g } } \\\
              \ & { \\\\qquad \\\\leq \\\\displaystyle \\\\sum \\_ { s = 2 } ^ { \\\
              \\frac { \\\\delta k } { g } } { \\\\binom { k } { s } } { \\\\binom\
              \ { k ^ { \\\\prime } } { t } } { ( \\\\frac { t } { k ^ { \\\\prime\
              \ } } ) ^ { s g } } \\\\leq \\\\displaystyle \\\\sum \\_ { s = 2 } ^\
              \ { \\\\frac { \\\\delta k } { g } } { \\\\binom { k } { s } } { \\\\\
              binom { k ^ { \\\\prime } } { ( 1 - \\\\epsilon ) g s } } { ( \\\\frac\
              \ { ( 1 - \\\\epsilon ) g s } { k ^ { \\\\prime } } ) ^ { s g } } }\
              \ \\\\end{array}\n$$\n\nUsing the inequality $\\\\textstyle { \\\\binom\
              \ { k } { s } } \\\\leq \\\\left( { \\\\frac { k e } { s } } \\\\right)\
              \ ^ { s }$ , the probability above is\n\n$$\n\\\\begin{array} { r l\
              \ } & { \\\\le \\\\displaystyle \\\\sum \\_ { s = 2 } ^ { \\\\frac {\
              \ \\\\delta x } { g } } ( \\\\frac { k e } { s } ) ^ { s } ( \\\\frac\
              \ { k ^ { \\\\prime } e } { ( 1 - \\\\epsilon ) g s } ) ^ { ( 1 - \\\
              \\epsilon ) g s } ( \\\\frac { ( 1 - \\\\epsilon ) g s } { k ^ { \\\\\
              prime } } ) ^ { s g } } \\ & { = \\\\displaystyle \\\\sum \\_ { s =\
              \ 2 } ^ { \\\\frac { \\\\delta k } { g } } ( \\\\frac { k e } { s }\
              \ ) ^ { s } e ^ { ( 1 - \\\\epsilon ) g s } ( \\\\frac { ( 1 - \\\\\
              epsilon ) g s } { k ^ { \\\\prime } } ) ^ { \\\\epsilon g s } } \\ &\
              \ { = \\\\displaystyle \\\\sum \\_ { s = 2 } ^ { \\\\frac { \\\\delta\
              \ k } { g } } e ^ { ( 1 - \\\\epsilon ) g s + s } \\\\cdot ( \\\\frac\
              \ { k } { s } ) ^ { s } \\\\cdot ( \\\\frac { ( 1 - \\\\epsilon ) g\
              \ s } { k ^ { \\\\prime } } ) ^ { \\\\epsilon g s } } \\\\end{array}\n\
              $$\n\nWhen $s , \\\\epsilon , g$ are constants and $k ^ { \\\\prime\
              \ } = { \\\\cal O } ( k ) , e ^ { ( 1 - \\\\epsilon ) g s + s }$ is\
              \ a constant, $\\\\big ( \\\\frac { k } { s } \\\\big ) ^ { s }$ is\
              \ $O ( { \\\\mathsf { p o l y } } ( k ) )$ , and $\\\\big ( \\\\frac\
              \ { ( 1 - \\\\epsilon ) g s } { k ^ { ' } } \\\\big ) ^ { \\\\epsilon\
              \ g s }$ is $O ( { \\\\frac { 1 } { \\\\mathsf { p o l y } ( k ) } }\
              \ )$ . Therefore, the overall upper bound is at least $O ( { \\\\frac\
              \ { 1 } { \\\\mathsf { p o l y } ( k ) } } )$ .\n\nThe derivation above\
              \ shows that the probability that a random graph is not a lossless expander\
              \ is upperbounded by $O ( { \\\\frac { 1 } { \\\\mathsf { p o l y }\
              \ ( k ) } } )$ , which is not negligible. Furthermore, we show that\
              \ the lower-bound of the nonexpanding probability is also not negligible\
              \ through a simple argument here.\n\nWe focus on the case where $s$\
              \ is a constant. The number of all possible sub-graphs induced by a\
              \ left subset of vertices $S$ is at most $k ^ { \\\\prime s g } = O\
              \ ( \\\\mathsf { p o l y } ( k ) )$ . That is, the size of the entire\
              \ probability space is bounded by a polynomial. The number of non-expanding\
              \ graphs is at least 1 (e.g., all edges from $S$ connect to a single\
              \ vertex in $R$ ). Therefore, the non-expanding probability is at least\
              \ $O ( { \\\\frac { 1 } { \\\\mathsf { p o l y } ( k ) } } )$ .\n\n\
              Lossless expander in \\[GLSTW\\] As explained in Section 3.2.1, in \\\
              [GLSTW\\], the authors extended the gen eralized Spielman code by adding\
              \ random weights to the edges in the bipartite graph. However, the graph\
              \ still needs to be a lossless expander in order to achieve a constant\
              \ relative distance, and the same issue above applies to their construction.\
              \ In particular, as shown by \\[GLSTW, Claim 2\\], the probability of\
              \ not sampling a lossless expander is\n\n$$\n2 ^ { k H ( 1 5 / k ) +\
              \ \\\\alpha k H ( 1 9 . 2 / ( \\\\alpha k ) ) - 1 5 g \\\\log \\\\frac\
              \ { \\\\alpha k } { 1 9 . 2 } } ,\n$$\n\nwhere $H ( x ) = - x \\\\log\
              \ x - ( 1 - x ) \\\\log ( 1 - x )$ . We show that the probability above\
              \ is not negligible. First, for any constant const,\n\n$$\nx H ( \\\\\
              mathrm { c o n s t } / x ) = x ( - \\\\frac { \\\\mathrm { c o n s t\
              \ } } { x } \\\\log \\\\frac { \\\\mathrm { c o n s t } } { x } - (\
              \ 1 - \\\\frac { \\\\mathrm { c o n s t } } { x } ) \\\\log ( \\\\frac\
              \ { x - \\\\mathrm { c o n s t } } { x } ) \\ = ( \\\\mathrm { c o n\
              \ s t } \\\\log ( x ) - \\\\mathrm { c o n s t } \\\\log \\\\mathrm\
              \ { c o n s t } ) + ( 1 - \\\\frac { \\\\mathrm { c o n s t } } { x\
              \ } ) \\\\log ( \\\\frac { x - \\\\mathrm { c o n s t } } { x } ) .\n\
              $$\n\nBy taking the limit, we have $\\\\begin{array} { r } { \\\\operatorname\\\
              * { l i m } \\_ { x \\\\to \\\\infty } x H ( \\\\mathsf { c o n s t\
              \ } / x ) = ( \\\\mathsf { c o n s t } \\\\log ( x ) - \\\\mathsf {\
              \ c o n s t } \\\\log \\\\mathsf { c o n s t } ) + 1 \\\\times 0 . }\
              \ \\\\end{array}$ Therefore, $x { H } ( \\\\mathsf { c o n s t } / x\
              \ ) = O ( \\\\log x )$ . Applying this fact to the equation above, $k\
              \ H ( 1 5 / k ) + \\\\alpha k H ( 1 9 . 2 / ( \\\\alpha k ) ) =$ $O\
              \ ( \\\\log k )$ , and $\\\\begin{array} { r } { - 1 5 g \\\\log { \\\
              \\frac { \\\\alpha k } { 1 9 . 2 } } = - O ( \\\\log k ) } \\\\end{array}$\
              \ . Therefore, $\\\\begin{array} { r } { 2 ^ { k H ( 1 5 / k ) + \\\\\
              alpha k H ( 1 9 . 2 / ( \\\\alpha k ) ) - 1 5 g \\\\log \\\\frac { \\\
              \\alpha k } { 1 9 . 2 } } } \\\\end{array}$ is at least $\\\\begin{array}\
              \ { r } { 2 ^ { - O ( \\\\log k ) } = \\\\frac { 1 } { \\\\mathsf {\
              \ p o l y } ( k ) } } \\\\end{array}$ 1poly(k) . The failure probability\
              \ is similar to the upper bound in Equation 3.1.\n\n# 3.3.2 Algorithm\
              \ based on Densest Sub-graph\n\nTo reduce the non-expanding probability\
              \ of the random construction, we take a closer look at the equations\
              \ above. Equation 3.1 shows that the probability that a random bipartite\
              \ graph is a not lossless expander is upper bounded by $\\\\frac { 1\
              \ } { \\\\mathsf { p o l y } ( k ) }$ . However, we observe that within\
              \ the summation, the probability is actually negligible when $s$ is\
              \ large. In particular, if we decompose the summation in Equation 3.1\
              \ into two sums, one for $2 \\\\leq s \\\\leq \\\\log \\\\log k$ , and\
              \ the other for $s \\\\geq \\\\log \\\\log k$ , the second part is\n\
              \n$$\n\\\\sum \\_ { s = \\\\log \\\\log k } ^ { \\\\frac { \\\\delta\
              \ k } { g } } e ^ { ( 1 - \\\\epsilon ) g s + s } \\\\cdot ( \\\\frac\
              \ { k } { s } ) ^ { s } \\\\cdot ( \\\\frac { ( 1 - \\\\epsilon ) g\
              \ s } { k ^ { ' } } ) ^ { \\\\epsilon g s } .\n$$\n\nLemma 3.3.2. Equation\
              \ 3.2 is negligible if the following conditions are met:\n\n1. $\\\\\
              begin{array} { r } { ( 1 - \\\\epsilon ) \\\\delta + \\\\frac { \\\\\
              delta } { g } + \\\\frac { \\\\delta } { g } \\\\log ( \\\\frac { g\
              \ } { \\\\delta } ) + \\\\log ( \\\\frac { \\\\delta } { \\\\alpha }\
              \ ) \\\\epsilon \\\\delta < - 0 . 0 0 1 , } \\\\end{array}$\n2. $\\\\\
              epsilon d > 2$ .\n\nHere -0.001 is just any small constant that is less\
              \ than 0. We give a proof in Appendix 3.7. To provide an intuition on\
              \ how these parameters are set, we give an example here: $\\\\begin{array}\
              \ { r } { \\\\dot { \\\\boldsymbol { \\\\delta } } = \\\\frac { 1 }\
              \ { 1 1 } , \\\\epsilon = \\\\frac { 7 } { 1 6 } , g = 1 6 , k ^ { \\\
              \\prime } = \\\\frac { 1 } { 2 } k } \\\\end{array}$ . We can verify\
              \ the condition:\n\n1. $\\\\epsilon g = 7 > 2$ .\n2. $\\\\begin{array}\
              \ { r } { ( 1 - \\\\epsilon ) \\\\delta + \\\\frac { \\\\delta } { g\
              \ } + \\\\frac { \\\\delta } { g } \\\\log ( \\\\frac { g } { \\\\delta\
              \ } ) + \\\\log ( \\\\frac { \\\\delta } { \\\\alpha } ) \\\\epsilon\
              \ \\\\delta = - 0 . 0 0 9 < - 0 . 0 0 1 . } \\\\end{array}$\n\nSampling\
              \ lossless expander with negligible failure probability. The observation\
              \ above shows that the non-expanding probability is dominated by small\
              \ sub-graphs with size $2 \\\\leq s \\\\leq \\\\log \\\\log k$ . This\
              \ actually matches our lower bound in Section 3.3.1, as there are only\
              \ polynomially many such sub-graphs and there exist ones that do not\
              \ expand. Therefore, in order to reduce the non-expanding probability,\
              \ we propose a new algorithm that detects small sub-graphs of size $s\
              \ \\\\leq \\\\log \\\\log k$ that do not expand. The algorithm is based\
              \ on the densest sub-graph problem, and we are the first to make the\
              \ connection between the densest sub-graph and the lossless expander.\n\
              \nDefinition 3.3.3 (Densest Sub-graph Problem). Let $G \\ : = \\ : (\
              \ V , E )$ be an undirected graph, and let $S \\ =$ $( E \\_ { S } ,\
              \ V \\_ { S } )$ be a subgraph of $G .$ . The density of $S$ is defined\
              \ to be $\\\\begin{array} { r } { \\\\mathsf { d e n } ( S ) = \\\\\
              frac { E \\_ { S } } { V \\_ { S } } } \\\\end{array}$ . The densest\
              \ sub-graph problem is to find $S$ such that it maximizes den $( S )$\
              \ . We denote the maximum density by $\\\\mathsf { D e n } ( G )$ .\n\
              \nTheorem 3.3.4. \\[Gol84\\] For any graph $G = ( V , E )$ , there is\
              \ a polynomial time algorithm that find the densest sub-graph $G ^ {\
              \ \\\\prime } = ( \\\\boldsymbol { V } ^ { \\\\prime } , \\\\boldsymbol\
              \ { E } ^ { \\\\prime } )$ such that $V ^ { \\\\prime } \\\\subseteq\
              \ V$ and $G ^ { \\\\prime }$ is the sub-graph. And $\\\\frac { \\| \\\
              \\boldsymbol { E ^ { \\\\prime } } \\| } { \\| \\\\boldsymbol { V ^\
              \ { \\\\prime } } \\| }$ is maximized. The running time of the algorithm\
              \ is $O ( \\| V \\| \\| E \\| \\\\log \\| E \\| \\\\log \\| V \\| )$\
              \ .\n\nWe will use this algorithm as a building block of our testing\
              \ algorithm. First, we define a notion of perfect expander, and then\
              \ derive the density of a perfect expander.\n\nDefinition 3.3.5 (Perfect\
              \ expander). Let $G = ( L , R , E )$ be a bipartite graph. We say $G$\
              \ is an $( k ^ { \\* } , k ^ { \\\\prime } ; g )$ - perfect expander\
              \ i $\\\\begin{array} { r } { f \\| L \\| = k ^ { \\* } , \\| R \\|\
              \ = k ^ { \\\\prime } } \\\\end{array}$ , the following property holds\
              \ (where $\\\\Gamma ( S )$ denotes the set of neighbors of a set $S$\
              \ in $G$ ):\n\n1. Degree: every vertex $a \\\\in L$ , it has constant\
              \ degree $g$ .\n\n2. Expansion: $\\| \\\\Gamma ( S ) \\| \\\\geq ( 1\
              \ - \\\\varepsilon ) g \\| S \\|$ for every $S \\\\subseteq L .$ .\n\
              \n\nCompared to lossless expander, the perfect expander does not have\
              \ the upper bound on $\\| S \\|$ in the expansion property. Therefore,\
              \ $k ^ { \\\\prime }$ has to be much larger than $k ^ { \\* }$ , unlike\
              \ the case of lossless expander where $k ^ { \\\\prime } = O ( k )$\
              \ . Now we show that the density of a perfect expander is low:\n\nTheorem\
              \ 3.3.6. If a bipartite graph is a perfect expander, its density is\
              \ at most $\\\\frac { g } { 1 + ( 1 - \\\\epsilon ) g }$ ; otherwise,\
              \ the density of the graph is larger than g1+(1−ϵ)g .\n\nProof. We first\
              \ show that the density of a perfect expander is at most $\\\\frac {\
              \ g } { 1 + ( 1 - \\\\epsilon ) g }$ . For any subset $L ^ { \\\\prime\
              \ } \\\\subseteq L$ , we prove that among all sub-graphs that $L ^ {\
              \ \\\\prime }$ is the left vertex set, the graph induced by $( L ^ {\
              \ \\\\prime } , \\\\Gamma ( L ^ { \\\\prime } ) )$ has the maximum density.\n\
              \nTo see this, suppose $V ^ { \\\\prime } = ( L ^ { \\\\prime } , R\
              \ ^ { \\\\prime } ) , R ^ { \\\\prime } \\\\neq \\\\Gamma ( L ^ { \\\
              \\prime } )$ has density $\\\\frac { \\| \\\\boldsymbol { E ^ { \\\\\
              prime } } \\| } { \\| \\\\boldsymbol { V ^ { \\\\prime } } \\| }$ that\
              \ is the densest sub-graph with $L ^ { \\\\prime }$ as its left vertex\
              \ set.\n\nCase 1: If there exists a vertex $y \\\\in R ^ { \\\\prime\
              \ } , y \\\\notin \\\\Gamma ( L ^ { \\\\prime } )$ , then there is no\
              \ edge between $y$ and $L ^ { \\\\prime }$ . We can increase the density\
              \ by removing y from R′, as \\|E′\\|′ > \\|E′\\|′ . This is a contradiction.\
              \ Therefore, $R ^ { \\\\prime } \\\\subseteq \\\\Gamma ( L ^ { \\\\\
              prime } )$ .\n\nCase 2: If there exists an element $y \\\\in \\\\Gamma\
              \ ( L ^ { \\\\prime } ) , y \\\\notin R ^ { \\\\prime }$ , let $c \\\
              \\geq 1$ be the number of edges between $y$ and $L ^ { \\\\prime }$\
              \ , by adding y to R′, the density becomes \\|E′\\|+c′ > . This is a\
              \ contradiction again and thus $\\\\Gamma ( L ^ { \\\\prime } ) \\\\\
              subseteq R ^ { \\\\prime }$ .\n\nTherefore, we have $\\\\Gamma ( L ^\
              \ { \\\\prime } ) = R ^ { \\\\prime }$ and $V ^ { \\\\prime } = ( L\
              \ ^ { \\\\prime } , \\\\Gamma ( L ^ { \\\\prime } ) )$ maximizes the\
              \ density among all sub-graphs with $L ^ { \\\\prime }$ as the left\
              \ vertex set. Let that sub-graph be $G ^ { \\\\prime }$ . By the expansion\
              \ property of the perfect expander, $\\\\begin{array} { r } { \\\\mathsf\
              \ { d e n } ( G ^ { \\\\prime } ) = \\\\frac { \\| E ^ { \\\\prime }\
              \ \\| } { \\| V ^ { \\\\prime } \\| } \\\\le \\\\frac { \\| L ^ { \\\
              \\prime } \\| g } { \\| L ^ { \\\\prime } \\| + ( 1 - \\\\epsilon )\
              \ g \\| L ^ { \\\\prime } \\| } = \\\\frac { g } { 1 + ( 1 - \\\\epsilon\
              \ ) g } } \\\\end{array}$ . Therefore, the maximum density $\\\\operatorname\
              \ { D e n } ( G ) = \\\\operatorname { m a x } \\_ { L ^ { \\\\prime\
              \ } \\\\subseteq L }$ den(G′) ≤ g1+(1−ϵ)g .\n\nNext, we show that if\
              \ a bipartite graph is not a perfect expander, its density is larger\
              \ than $\\\\frac { g } { 1 + ( 1 - \\\\epsilon ) g }$ . Let $S ^ { \\\
              * }$ be the set such that $\\| \\\\Gamma ( S ^ { \\* } ) \\| < ( 1 -\
              \ \\\\epsilon ) g \\| S ^ { \\* } \\|$ , then the density of the sub-graph\
              \ $G ^ { \\\\prime } = ( V ^ { \\\\prime } = ( S ^ { \\* } , \\\\Gamma\
              \ ( S ^ { \\* } ) ) , E ^ { \\\\prime } )$ \\| E ′ \\| $\\\\begin{array}\
              \ { r } { \\\\frac { \\| \\\\boldsymbol { E } ^ { \\\\prime } \\| }\
              \ { \\| \\\\boldsymbol { V } ^ { \\\\prime } \\| } > \\\\frac { g \\\
              | \\\\boldsymbol { S } ^ { \\* } \\| } { \\| \\\\boldsymbol { S } ^\
              \ { \\* } \\| + ( 1 - \\\\epsilon ) g \\| \\\\boldsymbol { S } ^ { \\\
              * } \\| } = \\\\frac { g } { 1 + ( 1 - \\\\epsilon ) g } } \\\\end{array}$\
              \ , so $\\\\begin{array} { r } { \\\\mathsf { D e n } ( G ) \\\\geq\
              \ \\\\mathsf { d e n } ( G ^ { \\\\prime } ) > \\\\frac { g } { 1 +\
              \ ( 1 - \\\\epsilon ) g } . } \\\\end{array}$ .\n\n# 3.3.3 Testing Random\
              \ Lossless Expander\n\nTheorem 3.3.6 suggests a way to test whether\
              \ a random graph is a lossless expander. As discussed in lemma 3.3.2,\
              \ when $s \\\\geq \\\\log \\\\log k$ , the non-expanding probability\
              \ is negligible. Thus, it suffices to test whether there is a sub-graph\
              \ of size $s \\ < \\ \\\\log \\\\log k$ that does not expand. In particular,\
              \ we are trying to distinguish the following two cases:\n\n# Algorithm\
              \ 8 Distinguisher\n\n1: Let $G = ( L , R , E )$ be the random bipartite\
              \ graph.\n\n2:\n\n3: for $i \\\\in \\[ ( \\\\frac { g } { \\\\delta\
              \ } ) ^ { \\\\log \\\\log k } \\]$ do\n\n4: Sample a random set $L ^\
              \ { \\\\prime }$ , where $\\\\begin{array} { r } { \\| L ^ { \\\\prime\
              \ } \\| = \\\\frac { \\\\delta k } { g } } \\\\end{array}$ .\n\n5: Run\
              \ densest graph algorithm in $\\\\scriptstyle \\[ \\\\mathrm { G o l\
              \ } 8 4 \\]$ on the subgraph induced by $L ^ { \\\\prime }$ : ${ \\\\\
              cal G } ^ { \\* } = $\n\n$( ( L ^ { \\\\prime } , \\\\Gamma ( L ^ {\
              \ \\\\prime } ) ) , E ^ { \\\\prime } )$ to find its densest subgraph.\n\
              \n6: if Den(G∗) > g1+(1−ε)g then\n\n7: return FAIL\n\n8: return SUCC\n\
              \n1. Yes case: For $G = ( L , R , E ) , \\\\forall S \\\\subseteq L\
              \ , \\| S \\| \\\\leq \\\\log \\\\log k $ , we have $\\| \\\\Gamma (\
              \ S ) \\| \\\\geq ( 1 - \\\\epsilon ) g \\| S \\|$ .\n\n2. No case:\
              \ For $G = ( L , R , E )$ , there exists a subset $S ^ { \\* } \\\\\
              subseteq L , \\| S ^ { \\* } \\| \\\\leq \\\\log \\\\log k$ , such that\
              \ $\\| \\\\Gamma ( S ^ { \\* } ) \\| <$ $( 1 - \\\\epsilon ) g \\| S\
              \ \\_ { 0 } \\|$ .\n\n\nTo distinguish these two cases, we cannot directly\
              \ apply the densest sub-graph algorithm on the entire bipartite graph,\
              \ because the expansion property only holds for $\\\\begin{array} {\
              \ r } { \\| S \\| \\\\le \\\\frac { \\\\delta k } { g } } \\\\end{array}$\
              \ by Definition 3.2.2 of the lossless expander. The densest sub-graph\
              \ algorithm would return a large sub-graph with $\\\\vert S \\\\vert\
              \ > { \\\\frac { \\\\delta k } { g } }$ even if it is a lossless expander,\
              \ as the density of the large sub-graph could be larger than $\\\\frac\
              \ { g } { 1 + ( 1 - \\\\epsilon ) g }$ by Theorem 3.3.6.\n\nInstead,\
              \ we randomly sample sub-graphs $G ^ { \\* } = ( ( L ^ { \\\\prime }\
              \ , \\\\Gamma ( L ^ { \\\\prime } ) ) , E ^ { \\\\prime } )$ with $\\\
              \\textstyle { \\\\frac { \\\\delta k } { g } }$ vertexes in the left\
              \ vertex set. If there exists a small non-expanding sub-graph with at\
              \ most $\\\\log \\\\log k$ vertices on the left, the density of this\
              \ small sub-graph is larger than $\\\\frac { g } { 1 + ( 1 - \\\\epsilon\
              \ ) g }$ and the probability of it is in the sub-graph $G ^ { \\* }$\
              \ is at least $\\\\begin{array} { r } { \\\\big ( \\\\frac { \\\\delta\
              \ } { g } \\\\big ) ^ { \\\\mathrm { l o g l o g } k } } \\\\end{array}$\
              \ . Once it is contained in $G ^ { \\\\prime }$ , the densest-sub-graph\
              \ algorithm will output a sub-graph with density larger than $\\\\frac\
              \ { g } { 1 + ( 1 - \\\\epsilon ) }$ . We will sample $G ^ { \\* } \\\
              \ { \\\\frac { g } { \\\\delta } } ^ { \\\\log \\\\log k }$ times to\
              \ amplify the probability. The formal algorithm is presented in Algorithm\
              \ 8.\n\nTheorem 3.3.7 (Distinguisher). Algorithm 8 achieves the following\
              \ properties:\n\n1. If $G$ is a Yes case, then the algorithm will return\
              \ SUCC with probability 1.\n2. If $G$ is a No case, then the algorithm\
              \ will return FAIL with probability at least $1 - { \\\\frac { 1 } {\
              \ e } }$ .\n\nProof. By Theorem 3.3.6, if the random graph is in Yes\
              \ case, then the distinguisher will always return SUCC, since for every\
              \ induced sub-graph $G ^ { \\* }$ , it is a perfect expander. Otherwise,\
              \ if the random graph contains a subset $S \\_ { 0 } \\\\subseteq L\
              \ , \\| S \\_ { 0 } \\| \\\\leq \\\\log \\\\log k$ such that $\\| \\\
              \\Gamma ( S \\_ { 0 } ) \\| < ( 1 - \\\\epsilon ) g \\| S \\_ { 0 }\
              \ \\|$ , then with probability at least $\\\\begin{array} { r } { \\\
              \\big ( \\\\frac { \\\\frac { \\\\delta k } { g } } { k } \\\\big )\
              \ ^ { \\\\mathrm { l o g } \\\\log k } = \\\\big ( \\\\frac { \\\\delta\
              \ } { g } \\\\big ) ^ { \\\\mathrm { l o g } \\\\log k } } \\\\end{array}$\
              \ , $S \\_ { 0 }$ will be a subset of $L ^ { \\\\prime }$ sampled by\
              \ the algorithm. In this case, $L ^ { \\\\prime }$ is not a perfect\
              \ expander graph and by Theorem 3.3.6, $\\\\begin{array} { r } { \\\\\
              mathsf { D e n } ( G ^ { \\* } ) > \\\\frac { g } { 1 + ( 1 - \\\\epsilon\
              \ ) g } } \\\\end{array}$ and the algorithm will return FAIL. Since\
              \ we repeat it $\\\\frac { g } { \\\\delta } ^ { \\\\log \\\\log n }$\
              \ times, the probability that we did not successfully sample $S \\_\
              \ { 0 }$ is $\\\\begin{array} { r } { ( 1 - ( \\\\frac { \\\\delta }\
              \ { g } ) ^ { \\\\log \\\\log k } ) ^ { ( \\\\frac { g } { \\\\delta\
              \ } ) ^ { \\\\log \\\\log k } } } \\\\end{array}$ By the inequality\
              \ (1 − 1n )n ≤ 1e , we have (1 − ( δg )log log k)( gδ )log log k\n\n\
              By repeating the distinguisher $\\\\lambda$ times, we can amplify the\
              \ detection probability of the No case to $\\\\displaystyle { 1 - \\\
              \\frac { 1 } { e ^ { \\\\lambda } } }$ Finally, we re-sample the random\
              \ graph until the distinguisher returns SUCC. The successful probability\
              \ of one sampling is $\\\\textstyle 1 - O ( { \\\\frac { 1 } { \\\\\
              mathsf { p o l y } ( k ) } } )$ , so the expected number of sampling\
              \ is a constant. The algorithm runs $\\\\lambda ( \\\\frac { g } { \\\
              \\delta } ) ^ { \\\\log \\\\log k }$ instances of the densest sub-graph\
              \ algorithm, and each instance involves a graph with at most $\\\\delta\
              \ { \\\\frac { k } { g } }$ vertices and $\\\\delta k$ edges, so the\
              \ total running time is $O ( \\\\lambda ( \\\\frac { g } { \\\\delta\
              \ } ) ^ { \\\\log \\\\log k } k ^ { 2 } \\\\log ^ { 2 } k ) = O ( \\\
              \\lambda \\\\mathsf { p o l y l o g } ( k ) k ^ { 2 } )$ . The same\
              \ algorithm can also apply to the lossless expander graph in \\[GLSTW\\\
              ]. Our sampling algorithm is very efficient in practice. First, it does\
              \ not involve any cryptographic operations and is done once. Second,\
              \ $k = \\\\dot { \\\\sqrt { N } }$ in our protocol of the polynomial\
              \ commitment in the next section, so the complexity is actually quasi-linear\
              \ in the size of the zero-knowledge argument instance. Finally, the\
              \ complexity of the densest sub-graph algorithm in Theorem 3.3.4 is\
              \ for arbitrary graphs. As observed in our experiments, the algorithm\
              \ is faster on random bipartite graphs and we conjecture that there\
              \ is a better complexity analysis, which is left as an interesting future\
              \ work.\n\n# 3.4 Our new Zero-Knowledge Argument\n\nIn this section,\
              \ we present the construction of our zero-knowledge argument scheme.\
              \ Many existing papers show that one can build zero-knowledge arguments\
              \ from polynomial commitments \\[WTSTW18; ZXZS20; CHMMVW20; Set20; GWC19a;\
              \ BFS20; GLSTW\\]. We adopt the same technique and focus on constructing\
              \ a polynomial commitment because of its simplicity and efficiency,\
              \ but our approach can be applied directly to the zero-knowledge arguments\
              \ for R1CS in \\[BCG20; BCL22\\] to improve the prover time and the\
              \ proof size. We start the section by describing the polynomial commitment\
              \ scheme in \\[GLSTW\\] based on the tensor IOP protocol in \\[BCG20\\\
              ] with a proof size of $O ( { \\\\sqrt { N } } )$ .\n\n# 3.4.1 Polynomial\
              \ commitment from tensor query\n\nIn \\[GLSTW\\], Golovnev et al. observed\
              \ that a polynomial evaluation can be expressed as a tensor product.\
              \ Here we only consider multilinear polynomial commitments, which can\
              \ be used to construct zero-knowledge arguments based on the approaches\
              \ in \\[ZGKPP17b; WTSTW18; XZZPS19c; ZXZS20; Set20\\], but our scheme\
              \ can be extended to univariate polynomials. In particular, given a\
              \ multilinear polynomial $\\\\phi$ , its evaluation on input vector\
              \ $x \\_ { 0 } , x \\_ { 1 } , . . . , x \\_ { \\\\log N - 1 }$ is:\n\
              \n$$\n\\\\phi ( x \\_ { 0 } , x \\_ { 1 } , . . . , x \\_ { \\\\log\
              \ N - 1 } ) = \\\\sum \\_ { i \\_ { 0 } = 0 } ^ { 1 } \\\\sum \\_ {\
              \ i \\_ { 1 } = 0 } ^ { 1 } . . . \\\\sum \\_ { i \\_ { \\\\log N -\
              \ 1 } = 0 } ^ { 1 } w \\_ { i \\_ { 0 } i \\_ { 1 } . . . i \\_ { \\\
              \\log N - 1 } } x \\_ { 0 } ^ { i \\_ { 0 } } x \\_ { 1 } ^ { i \\_\
              \ { 1 } } . . . x \\_ { \\\\log N - 1 } ^ { i \\_ { \\\\log N - 1 }\
              \ } .\n$$\n\nTheare $N$ egree of each variable is either 0 monomials\
              \ and coefficients with $\\\\log N$ y the definition ofvariables. We\
              \ let $\\\\begin{array} { r } { i = \\\\sum \\_ { j = 0 } ^ { \\\\log\
              \ N - 1 } \\\\dot { 2 } ^ { j } \\\\dot { i } \\_ { j } } \\\\end{array}$\
              \ nomial,, that is, $i \\_ { 0 } i \\_ { 1 } . . . i \\_ { \\\\mathrm\
              \ { l o g } N - 1 }$ is the binary representation of number i. We use\
              \ w to denote the coefficients where w\\[i\\] = wi0i1...ilog N 1. Similarly\
              \ we define $X \\_ { i } = x \\_ { 0 } ^ { i \\_ { 0 } } x \\_ { 1 }\
              \ ^ { i \\_ { 1 } } . . . x \\_ { \\\\mathrm { l o g } N - 1 } ^ { i\
              \ \\_ { \\\\mathrm { l o g } N - 1 } }$ . Let $k = \\\\sqrt { N }$ $,\
              \ r \\_ { 0 } = { X \\_ { 0 } , X \\_ { 1 } , . . . , X \\_ { k - 1\
              \ } }$ , $r \\_ { 1 } = { X \\_ { 0 \\\\times k } , X \\_ { 1 \\\\times\
              \ k } , X \\_ { 2 \\\\times k } , . . . , X \\_ { ( k - 1 ) \\\\times\
              \ k } }$ . Then we have $X = r \\_ { 0 } \\\\otimes r \\_ { 1 }$ . The\
              \ polynomial evaluation is reduced to a tensor product $\\\\phi ( x\
              \ \\_ { 0 } , x \\_ { 1 } , . . . , \\\\dot { x } \\_ { \\\\mathrm {\
              \ l o g } } N - 1 ) = \\\\left. w , r \\_ { 0 } \\\\otimes r \\_ { 1\
              \ } \\\\right.$ . Using the tensor IOP protocol in \\[BCG20\\], one\
              \ can build a polynomial commitment \\[GLSTW\\] and we present the protocol\
              \ in Protocol 9 for completeness. Here we reuse the notation $k$ as\
              \ it is exactly the message length of the linear code.\n\n|     |  \
              \   |\n| --- | --- |\n| 'rotocol 9 Polynomial commitment from \\[BCG20;\
              \ GLSTW\\] |  |\n|  | Public input: The evaluation point x, parsed as\
              \ a tensor product r = ro O r1; Private input: the polynomial $, the\
              \ coefficient of $ is denoted by w. Let C be the \\[n, k, d\\]-linear\
              \ code, Ec : Fk - F\" be the encoding function, N = k k. If N |\n| \
              \ | is not a perfect square, we can pad it to the next perfect square.\
              \ |\n| 1: function PC.CoMMIr($) | We use a python style notation to\
              \ select the i-th column of a matrix mat\\[:, i\\]. |\n| 2: | Parse\
              \ w as a k k matrix. The prover computes the tensor code encoding C1,\
              \ C2 locally as |\n|  | defined in Definition 3.2.4. Here C is a k n\
              \ matrix and C2 is a n n matrix. |\n| 3: 4: | for i E \\[n\\] do |\n\
              | 5: | Compute the Merkle tree root Root; = Merkle.Commit(C2\\[:, i\\\
              ]). Compute a Merkle tree root R = Merkle.Commit(\\[Rooto, ., Rootn-1\\\
              ]) and output R as |\n| the commitment. |  |\n|  | 6: function PC.PRove($,\
              \ x, R) |\n| 7: | The prover receives a random vector o E F from the\
              \ verifier. |\n| 8: | Co =i0 %o\\[\\]C\\[\\], yo=2 70\\[\\]w\\[i\\]\
              \ |\n| 9: | c= ;2J ro\\[\\]C1\\[i\\] yi==J ro\\[j\\]w\\[\\] |\n| 10:\
              \ | Prover sends c1, y1, Cro, yro to the verifier. |\n| 11: | Verifier\
              \ randomly samples t E \\[n\\] indexes as an array I and send it to\
              \ prover. |\n| 12: | for idx E I do |\n|  |  |\n| 13: | Prover sends\
              \ C1\\[, idx\\] and the Merkle tree proof of Rootdx for C2\\[:, idx\\\
              ] under R to |\n| verifier |  |\n|  | 14: function PC.VERIFYEvAL(z,x,y\
              \ = $(x), R) |\n| 15: | Vidx E I, cn,\\[idx\\] ==(70; C\\[;, idx\\]\
              \ and Ec(yo) == c. |\n|  |  |\n| 16: | Vidx E I, c1 \\[idx\\] ==(ro,\
              \ C1\\[, idx\\]) and Ec(y1) == C1. |\n| 17: | y ==(r1,y1). |\n|  | \
              \ |\n| 18: |  |\n|  | Vidx E I, Ec(Ci\\[:, idx\\]) is consistent with\
              \ Rootidx, and Rootidx's Merkle tree proof is valid. |\n|  |  |\n| \
              \ |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  | \
              \ |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n| 19: |  |\n|  |  |\n|  | \
              \ |\n|  |  |\n|  |  |\n|  |  |\n|  | Output accept if all conditions\
              \ above holds. Otherwise output reject. |\n|  |  |\n|  |  |\n|  |  |\n\
              |  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |\
              \  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n\
              |  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |  |\n|  |\
              \  |\n|  |  |\n\nAs shown in the protocol, to commit to a polynomial,\
              \ PC.Commit parses the coefficients $w$ as a $k \\\\times$ $k$ matrix\
              \ and encodes it using the tensor code with dimension 2 as defined in\
              \ Definition 3.2.4. Then the algorithm constructs a Merkle tree commitment\
              \ for every column $\\\\mathsf C \\_ { 2 } \\[ : , i \\]$ of the $n\
              \ \\\\times n$ codeword ${ \\\\mathsf { C } } \\_ { 2 }$ , and finally\
              \ builds another Merkle tree on top of their roots as the final commitment.\n\
              \nTo answer the tensor query, there are two checks in the protocol:\
              \ a proximity check and a consistency check. The proximity check ensures\
              \ that the matrix in the commitment is indeed close to a codeword of\
              \ the tensor code. The consistency check ensures that $y = \\\\langle\
              \ r \\_ { 0 } \\\\otimes r \\_ { 1 } , w \\\\rangle$ assuming $\\\\\
              mathcal { R }$ is a commitment of a codeword.\n\nProximity check. The\
              \ proximity check has two steps. First, the verifier sends a random\
              \ vector $\\\\gamma \\_ { 0 }$ to the prover, and the prover computes\
              \ the linear combination of all rows of $\\\\mathsf C \\_ { 1 }$ and\
              \ $w$ with $\\\\gamma \\_ { 0 }$ , as in Step 8 in Protocol 9.\n\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/4f82f05e0c91334792635a81bf745aa273bceaf82762ea905286dc3d927a83fd.jpg)\n\
              \nFigure 3.2: An illustration of code switching. The circuit on the\
              \ right for Check 1,2 and Check 3,4 is the same.\n\nBecause of the property\
              \ of a linear code, $c \\_ { \\\\gamma \\_ { 0 } }$ is a codeword with\
              \ message $y \\_ { \\\\gamma \\_ { 0 } }$ , and this step is referred\
              \ to as the “fold” operation in \\[BCG20\\]. Second, the prover shows\
              \ that $c \\_ { \\\\gamma \\_ { 0 } }$ is indeed computed from the committed\
              \ tensor codeword. To do so, the verifier randomly selects $t$ columns\
              \ and the prover opens them with their Merkle tree proofs. The verifier\
              \ checks that the inner product between each column and the random vector\
              \ $\\\\gamma \\_ { 0 }$ is equal to the corresponding element of $c\
              \ \\_ { \\\\gamma \\_ { 0 } }$ (Step 15). As shown in \\[BCGGHJ17; BCG20\\\
              ], if the linear code has a constant relative distance, the committed\
              \ matrix is close to a tensor codeword with overwhelming probability.\n\
              \nConsistency check. The consistency check follows exactly the same\
              \ steps of the proximity check. Instead of using a random vector from\
              \ the verifier, the linear combination is done with $r \\_ { 0 }$ of\
              \ the tensor query $r \\_ { 0 } \\\\otimes r \\_ { 1 }$ Similarly, $c\
              \ \\_ { 1 }$ is a codeword of the linear code with message $y \\_ {\
              \ 1 }$ , and $\\\\phi ( x ) = \\\\langle y \\_ { 1 } , r \\_ { 1 } \\\
              \\rangle$ by the definition of tensor product and polynomial evaluation.\
              \ As shown in \\[BCG20\\], by the check in Step 16, if the committed\
              \ matrix in $\\\\mathcal { R }$ is close to a tensor codeword, then\
              \ $y = \\\\phi ( x )$ with overwhelming probability. In particular,\
              \ there exist an extractor to extract a polynomial $\\\\phi$ from the\
              \ commitment such that $y = \\\\phi ( x )$ .\n\nTheorem 3.4.1 (Polynomial\
              \ commitment \\[BCG20; GLSTW\\]). Protocol 9 is a polynomial commitment\
              \ that is correct and sound as defined in Definition 3.2.8.\n\nEfficiency.\
              \ The prover’s computation is dominated by encoding the tensor code,\
              \ which takes $O ( N )$ time using a linear-time encodable code such\
              \ as the generalized Spielman code. The proof size is $O ( t { \\\\\
              sqrt { N } } )$ , as the prover opens $t$ random columns of size $\\\
              \\sqrt { N }$ to the verifier. The verifier time is also $O ( t { \\\
              \\sqrt { N } } )$ to check the inner products and to encode $t$ columns.\n\
              \n# 3.4.2 Efficient Proof Composition via Code Switching\n\nThe proof\
              \ size of the polynomial commitment in Protocol 9 is √ $O ( { \\\\sqrt\
              \ { N } } )$ (the complexity hides a security parameter $t$ ). There\
              \ are three steps that incur $O ( { \\\\sqrt { N } } )$ proof size in\
              \ Protocol 9: Step 8, 9, and 13. In this section, we present a new protocol\
              \ that reduces the proof size to $O ( \\\\log ^ { 2 } N )$ via the technique\
              \ of proof composition. The idea is to use a second proof system to\
              \ prove that the checks of these three steps are satisfied, without\
              \ sending the proofs of these steps to the verifier directly.\n\nTo\
              \ design the second proof system efficiently, our key observation is\
              \ that the values sent by the prover in these three steps are messages\
              \ of the linear-time encodable code. That is, $y \\_ { \\\\gamma \\\
              _ { 0 } }$ is the message of $c \\_ { \\\\gamma \\_ { 0 } }$ in Step\
              \ 8, $y \\_ { 1 }$ is the message of $c \\_ { 1 }$ in Step 9 and $C\
              \ \\_ { 1 } \\[ : , \\\\mathsf { i d } \\\\times \\]$ is the message\
              \ of $C \\_ { 2 } \\[ : , \\\\mathsf { i d } \\\\times \\]$ for every\
              \ $\\\\mathrm { i d } \\\\times$ in Step 13. Therefore, the second proof\
              \ system takes $y \\_ { \\\\gamma \\_ { 0 } } , y \\_ { 1 }$ and $\\\
              \\mathsf { C } \\_ { 1 } \\[ : , \\\\mathsf { i d } \\\\times \\]$ for\
              \ $\\\\mathsf { i d } \\\\times \\\\in \\ I$ as the witness, and performs\
              \ the following computations:\n\n1. It encodes the witness using the\
              \ encoding circuit of the linear-time encodable code.\n2. It outputs\
              \ a subset of random indices of the codewords chosen by the verifier.\
              \ By checking whether the values of these indices are consistent with\
              \ the commitments by the prover via the Merkle tree, it guarantees that\
              \ the witness is indeed the same as the messages specified above with\
              \ overwhelming probability because of the minimum distance property\
              \ of the code.\n3. Finally, it checks that these messages and their\
              \ codewords satisfy the conditions in line 15, 16 and 17 of Protocol\
              \ 9.\n\nThe idea is illustrated in Figure 3.2, and we formally present\
              \ the statement of the second proof system in Protocol 10. Note that\
              \ $\\\\hat { I }$ is the random set chosen by the verifier in Protocol\
              \ 9, and is only used as a notation for the subscripts in Protocol 10.\
              \ $I$ is the random set chosen by the verifier for the code switching.\
              \ In this way, we switch the message encoded using the linear-time encodable\
              \ code to the witness of the second proof system. In our implementation,\
              \ we are using an IOP-based zero-knowledge argument with the Reed-Solomon\
              \ code, thus this can be viewed as an efficient instantiation of the\
              \ “code switching” technique in \\[RR20\\].\n\nWe apply any zero-knowledge\
              \ argument scheme $\\\\mathcal { Z } \\\\kappa$ on the statement and\
              \ then check the consistency between the output and the Merkle tree\
              \ commitment $\\\\mathcal { R }$ of the codeword of the linear-time\
              \ encodable code. We present the new protocol in Protocol 11 and highlight\
              \ the differences from Protocol 9 in blue. As shown in the protocol,\
              \ instead of sending $c \\_ { 1 } , y \\_ { 1 } , c \\_ { \\\\gamma\
              \ \\_ { 0 } } , y \\_ { \\\\gamma \\_ { 0 } }$ , the prover commits\
              \ to $c \\_ { 1 }$ and $c \\_ { \\\\gamma \\_ { 0 } }$ in Step 8 and\
              \ 9. The codeword ${ \\\\mathsf { C } } \\_ { 2 }$ was already committed\
              \ column-wise in $\\\\mathcal { R }$ . The prover then proves the constraints\
              \ of $c \\_ { 1 } , y \\_ { 1 } , c \\_ { \\\\gamma \\_ { 0 } } , y\
              \ \\_ { \\\\gamma \\_ { 0 } }$ and $\\\\mathsf { C } \\_ { 1 } \\[ :\
              \ , \\\\mathsf { i d } \\\\times \\]$ using the code switching technique\
              \ in Step 13. In this way, we are able to reduce the proof size of Protocol\
              \ 9 to ${ \\\\bar { O } } ( \\\\log ^ { 2 } N )$ .\n\nTheorem 3.4.2.\
              \ Protocol 11 is a polynomial commitment that is correct and sound,\
              \ as defined in Definition 3.2.8 without zero-knowledge property.\n\n\
              The proof is presented in Appendix 3.8.\n\nComplexity of Protocol $\\\
              _ { I I }$ . The prover time remains $O ( N )$ . This is because in\
              \ Step 8 and 9, the prover additionally commits to $c \\_ { 1 } , c\
              \ \\_ { \\\\gamma \\_ { 0 } }$ , which only takes $O ( n ) = O ( { \\\
              \\sqrt { N } } )$ time. In Step 13, the prover invokes another zero-knowledge\
              \ argument on $C \\_ { \\\\mathsf { C S } }$ . $C \\_ { \\\\mathsf {\
              \ C S } }$ consists of $t + 2$ encoding circuits $E \\_ { C }$ of the\
              \ linear-time encodable code and $t { + 2 }$ inner products. In Appendxi\
              \ 3.9, we show that the encoding circuit of the generalized Spielman\
              \ code is of size $O ( k )$ . The circuit to compute an inner product\
              \ is of size $O ( k )$ , thus the overall circuit size is $O ( t \\\\\
              cdot k )$ . By using any zero-knowledge argument scheme with a quasi-linear\
              \ prover time, the prover\n\n# Protocol 10 Code Switching Statement\
              \ $C \\_ { \\\\mathsf { C S } }$\n\n|     |\n| --- |\n| Witness: yo,\
              \ Y1, C1\\[:, idx\\] Vidx E I in Protocol 9. |\n| Public input: %, o,\
              \ 1, y. Public information: I and I chosen by the verifier. |\n| 1:\
              \ Encode cr, := Ec(yo), c := Ec(y1). |\n| 2: for idx E I do |\n| 3:\
              \ Encode C2\\[r, idx\\] := Ec(C1\\[z, idx) |\\\n| 4: for idx E I do\
              \ |\\\n| 5: Check if c. \\[idx\\] == (%o, C1\\[:, idx\\]). > Proximity\
              \ |\\\n| 6: Check if c1\\[idx\\] == (ro, C1\\[z, idx\\]). > Consistency\
              \ |\\\n| 7: Check if (r1, Y1) == y. > Tensor producte |\\\n| 8: for\
              \ 0 j <\\|I\\|do > Encoder check |\\\n| 9: Output c1\\[I\\[j\\]\\],\
              \ cr, \\[I\\[\\]\\]. |\\\n| 10: for idx E I do. |\\\n| 11: Output C2\\\
              [I\\[j\\], idx\\] |\\\n\\\ntime of this step is $O ( t \\\\cdot k \\\
              \\log k )$ . Since $k = \\\\sqrt { N }$ , the prover time is still $O\
              \ ( N )$ dominated by the encoding and the commitment of the $k \\\\\
              times k$ matrix. With the code switching technique, the proof size and\
              \ becomes $O ( t \\\\log ^ { 2 } N )$ .\\\n\\\nSince we apply $\\\\\
              mathcal { Z } \\\\kappa$ in a black-box way, the verification time of\
              \ the protocol will be $O ( { \\\\sqrt { N } } )$ due to the size of\
              \ recursive circuit. However, in the holographic setting with preprocessing,\
              \ the verifier time can be reduced to $O ( \\\\log ^ { 2 } N )$ using\
              \ the techniques in \\[Set20\\]. Note that the code switching circuit\
              \ depends on $I$ randomly selected by the verifier, which is not known\
              \ during preprocessing. ( $\\\\hat { I }$ is also not known, but it\
              \ does not affect the structure of $C \\_ { \\\\mathsf { C S } }$ .)\
              \ Fortunately, we are able to preprocess most of the circuits (Step\
              \ 1-7 in Protocol 10) and the verifier time is $O ( \\\\log ^ { 2 }\
              \ N ) \\\\dot { + } O ( \\| I \\| \\\\cdot \\| \\\\hat { I } \\| ) =\
              \ \\\\dot { O } ( \\\\log ^ { 2 } N )$ in this setting.\\\n\\\n# 3.4.3\
              \ Putting Everything Together\\\n\\\nIn this section, we show how to\
              \ achieve zero-knowledge on top of our new polynomial commitment in\
              \ Protocol 11, and sketch how to build a zero-knowledge argument using\
              \ the polynomial commitment.\\\n\\\nAchieving zero-knowledge. We apply\
              \ a masking technique similar to the one in \\[BCGGHJ17\\]. The codeword\
              \ $\\\\mathsf { C } \\_ { 2 }$ is masked by a codeword MSK of a masking\
              \ polynomial with random coefficients $m$ . We use our proof system\
              \ to prove $y \\_ { w + m } = \\\\langle ( w + m ) , r \\_ { 0 } \\\\\
              otimes r \\_ { 1 } \\\\rangle$ and $y \\_ { m } = \\\\langle m , r \\\
              _ { 0 } \\\\otimes r \\_ { 1 } \\\\rangle$ simultaneously, and the final\
              \ answer of the polynomial evaluation is $y = y \\_ { w + m } - y \\\
              _ { m }$ . We present the protocol in Protocol 12.\\\n\\\nTheorem 3.4.3.\
              \ Protocol 12 is a zero-knowledge polynomial commitment scheme by definition\
              \ 3.2.8.\\\n\\\nWe present the proof in Appendix 3.10.\\\n\\\nZero-knowledge\
              \ argument. Finally, we build our zero-knowledge argument system by\
              \ combining the multivariate polynomial commitment with the sumcheck\
              \ protocol as in \\[Set20; GLSTW\\]. We state the theorem here and refer\
              \ the readers to \\[Set20; GLSTW\\] for the construction and the proof.\\\
              \n\\\n# Protocol 11 Polynomial commitment with code-switching\\\n\\\n\
              Public input: The evaluation point $\\\\vec { x }$ , parsed as a tensor\
              \ product $r = r \\_ { 0 } \\\\otimes r \\_ { 1 }$ ; Private input:\
              \ the polynomial $\\\\phi$ with coefficients $w$ . 1: function COMMIT\
              \ $( \\\\phi )$ 2: Parse $w$ as a $k \\\\times k$ matrix. The prover\
              \ computes the tensor code encoding $\\\\mathsf C \\_ { 1 } , \\\\mathsf\
              \ C \\_ { 2 }$ locally as defined in Definition 3.2.4. 3: for $i \\\\\
              in \\[ n \\]$ do 4: Compute the Merkle tree root ${ \\\\mathsf { R o\
              \ o t } } \\_ { \\\\mathrm { i } } = { \\\\mathsf { M e r k l e . C\
              \ o m m i t } } ( { \\\\mathsf { C } } \\_ { 2 } \\[ : , { \\\\mathsf\
              \ { i } } \\] ) .$ . 5: Compute a Merkle tree root $\\\\mathcal { R\
              \ } =$ Merkle.Commit $( \\[ \\\\mathsf { R o o t } \\_ { 0 } , . . .\
              \ , \\\\mathsf { R o o t } \\_ { \\\\mathsf { n } - 1 } \\] ) ,$ ) and\
              \ output $\\\\mathcal { R }$ as the commitment. 6: function $\\\\mathrm\
              \ { P R O V E } ( \\\\phi , { \\\\vec { x } } , { \\\\mathcal { R }\
              \ } )$ 7: The prover receives a random vector $\\\\gamma \\_ { 0 } \\\
              \\in \\\\mathbb { F } ^ { k }$ from the verifier. 8: $\\\\begin{array}\
              \ { r } { c \\_ { 1 } = \\\\sum \\_ { i = 0 } ^ { k - 1 } r \\_ { 0\
              \ } \\[ i \\] \\\\mathsf { C } \\_ { 1 } \\[ i \\] } \\\\end{array}$\
              \ , $\\\\begin{array} { r } { y \\_ { 1 } = \\\\sum \\_ { i = 0 } ^\
              \ { k - 1 } r \\_ { 0 } \\[ i \\] w \\[ i \\] } \\\\end{array}$ , $\\\
              \\mathcal { R } \\_ { c \\_ { 1 } } = \\\\mathsf { M e r k l e . C o\
              \ m m i t } ( c \\_ { 1 } )$ 9: $\\\\begin{array} { r } { c \\_ { \\\
              \\gamma \\_ { 0 } } = \\\\sum \\_ { i = 0 } ^ { k - 1 } \\\\gamma \\\
              _ { 0 } \\[ i \\] \\\\mathsf C \\_ { 1 } \\[ i \\] , y \\_ { \\\\gamma\
              \ \\_ { 0 } } = \\\\sum \\_ { i = 0 } ^ { k - 1 } \\\\gamma \\_ { 0\
              \ } \\[ i \\] w \\[ i \\] } \\\\end{array}$ , $\\\\mathcal { R } \\\
              _ { \\\\gamma \\_ { 0 } } = \\\\mathsf { M e r k l e . C o m m i t }\
              \ ( c \\_ { \\\\gamma \\_ { 0 } } )$ 10: The prover computes the answer\
              \ $y : = \\\\langle y \\_ { 1 } , r \\_ { 1 } \\\\rangle$ . Prover sends\
              \ $\\\\mathcal { R } \\_ { c \\_ { 1 } } , \\\\mathcal { R } \\_ { \\\
              \\gamma \\_ { 0 } } , y$ to the verifier. 11: The verifier randomly\
              \ samples $t \\\\in \\[ n \\]$ indexes as an array $\\\\hat { I }$ and\
              \ send it to prover. 12: The verifier randomly samples another index\
              \ set $I \\\\subseteq \\[ k \\] , \\| I \\| = t$ and sends it to the\
              \ prover. 13: The prover calls the zero-knowledge argument protocol\
              \ $\\\\mathcal { Z } \\\\boldsymbol { \\ K } . \\\\mathcal { P }$ on\
              \ $C \\_ { \\\\mathsf { C S } }$ . Let $\\\\pi \\_ { z k }$ be the proof\
              \ of the zero-knowledge argument. The prover sends the output of $C\
              \ \\_ { \\\\mathsf { C S } }$ : $\\\\mathsf C \\_ { 2 } \\[ I \\[ j\
              \ \\]$ , idx\\] ∀idx ∈ $\\\\hat { I } , c \\_ { 1 } \\[ I \\[ j \\]\
              \ \\] , c \\_ { \\\\gamma \\_ { 0 } } \\[ I \\[ j \\] \\]$ and $\\\\\
              pi \\_ { z k }$ to the verifier. 14: The prover sends the Merkle tree\
              \ proofs of $\\\\mathsf C \\_ { 2 } \\[ I \\[ j \\]$ , idx\\] $\\\\\
              forall \\\\mathsf { i d } \\\\mathsf { x } \\\\in \\\\hat { I }$ under\
              \ ${ \\\\mathsf { R o o t } } \\_ { \\\\mathsf { i d } \\\\times }$\
              \ . 15: The prover sends the Merkle tree proofs of $\\\\mathsf { R o\
              \ o t } \\_ { \\\\mathsf { i d x } } \\\\forall \\\\mathsf { i d x }\
              \ \\\\in \\\\hat { I }$ under $\\\\mathcal { R }$ . 16: The prover sends\
              \ the Merkle tree proofs of $c \\_ { 1 } \\[ I \\[ j \\] \\] , c \\\
              _ { \\\\gamma \\_ { 0 } } \\[ I \\[ j \\] \\]$ under $\\\\mathcal {\
              \ R } \\_ { c \\_ { 1 } } , \\\\mathcal { R } \\_ { c \\_ { \\\\gamma\
              \ \\_ { 0 } } }$ . 17: function VERIFYEVAL $( \\\\pi \\_ { \\\\vec {\
              \ x } } , \\\\vec { x } , y = \\\\phi ( \\\\vec { x } ) , \\\\mathcal\
              \ { R } )$ 18: The verifier calls the zero-knowledge argument protocol\
              \ $\\\\mathcal { Z } \\\\kappa . \\\\nu$ on $C \\_ { \\\\mathsf { C\
              \ S } }$ . 19: The verifier checks the Merkle tree proofs of $\\\\mathsf\
              \ C \\_ { 2 } \\[ I \\[ j \\] , \\\\mathsf { i d } \\\\mathsf { x }\
              \ \\] \\\\forall \\\\mathsf { i d } \\\\mathsf { x } \\\\in \\\\hat\
              \ { I } .$ . 20: The verifier checks the Merkle tree proofs of $\\\\\
              mathsf { R o o t } \\_ { \\\\mathsf { i d x } } \\\\forall \\\\mathsf\
              \ { i d x } \\\\in \\\\hat { I }$ using $\\\\mathcal { R }$ . 21: The\
              \ verifier checks the Merkle tree proofs of $c \\_ { 1 } \\[ I \\[ j\
              \ \\] \\] , c \\_ { \\\\gamma \\_ { 0 } } \\[ I \\[ j \\] \\]$ using\
              \ $\\\\mathcal { R } \\_ { c \\_ { 1 } } , \\\\mathcal { R } \\_ { c\
              \ \\_ { \\\\gamma \\_ { 0 } } }$ . 22: Output accept if all checks pass.\
              \ Otherwise output reject.\\\n\\\n# Theorem 3.4.4. There exists a zero-knowledge\
              \ argument scheme by definition 3.2.6 with $O ( N )$ prover time, $O\
              \ ( \\\\log ^ { 2 } N )$ proof size and $O ( N )$ verifier time.\\\n\
              \\\nAs we are using the IOP-based scheme in \\[ZXZS20\\] as the second\
              \ zero-knowledge argument in the proof composition, our scheme is an\
              \ IOP with a linear proof size and logarithmic query complexity. The\
              \ scheme can be made non-interactive via the Fiat-Shamir \\[FS86\\]\
              \ heuristic, and has plausible post-quantum security. Following the\
              \ frameworks in \\[CHMMVW20; COS20; Set20; GLSTW\\], our scheme can\
              \ be turned into a holographic proof with a $O ( \\\\log ^ { 2 } N )$\
              \ verifier time in a straight-forward way.\\\n\\\n# Protocol 12 zk-Polynomial\
              \ commitment\\\n\\\nPublic input: The evaluation point $\\\\vec { x\
              \ }$ , parsed as a tensor product $r = r \\_ { 0 } \\\\otimes r \\_\
              \ { 1 }$ ;\\\n\\\nPrivate input: the polynomial $\\\\phi$ with coefficients\
              \ $w$ .\\\n\\\n1: function $\\\\mathbf { Z K C o M M I T } ( \\\\phi\
              \ \\_ { w } )$\\\n\\\n2: The prover randomly samples m ∈ F\\|w\\|.\\\
              \n\\\n3: Output $\\\\mathcal { R } \\_ { w + m } = \\\\mathsf { C O\
              \ M M I T } ( w + m ) , \\\\mathcal { R } \\_ { m } = \\\\mathsf { C\
              \ O M M I T } ( m ) .$ .\\\n\\\n4: function $\\\\mathbf { \\\\Lambda\
              \ } \\_ { \\\\mathbf { Z K P R O V E } } ( \\\\phi , \\\\vec { x } ,\
              \ \\\\mathcal { R } )$\\\n\\\n5: Let $\\\\phi \\_ { m }$ be the masking\
              \ polynomial, $\\\\phi \\_ { w + m }$ be the masked polynomial.\\\n\\\
              \n6: Run $\\\\mathsf { P r o v e } ( \\\\phi \\_ { w + m } , \\\\vec\
              \ { x } , \\\\mathcal { R } \\_ { w + m } )$ . Let the random index\
              \ set used during the protocol be $\\\\hat { I } \\_ { 0 } , I \\_ {\
              \ 0 }$ .\\\n\\\n7: Run $\\\\mathsf { P r o v e } ( \\\\phi \\_ { m }\
              \ , \\\\vec { x } , \\\\mathcal { R } \\_ { m } )$ . In this step, the\
              \ verifier samples the random index set $\\\\hat { I } \\_ { 1 } , I\
              \ \\_ { 1 }$ . used\\\n\\\nduring the protocol such that $\\\\hat {\
              \ I } \\_ { 0 } \\\\cap \\\\hat { I } \\_ { 1 } \\\\stackrel { } { =\
              \ } \\\\varnothing \\\\wedge I \\_ { 0 } \\\\cap I \\_ { 1 } = \\\\\
              varnothing$ .\\\n\\\n8: function $\\\\mathbf { z K } \\\\mathbf { V\
              \ } \\_ { \\\\mathrm { E R I F Y } } ( \\\\pi \\_ { \\\\vec { x } }\
              \ ^ { w + m } , \\\\pi \\_ { \\\\vec { x } } ^ { m } , \\\\vec { x }\
              \ , y \\_ { w + m } , y \\_ { m } , \\\\mathcal { R } \\_ { w + m }\
              \ , \\\\mathcal { R } \\_ { m } )$\\\n\\\n9: The final polynomial evaluation\
              \ $\\\\phi ( \\\\vec { x } )$ should be $y \\_ { w + m } - y \\_ { m\
              \ }$ .\\\n\\\n10: Execute VerifyEval $( \\\\pi \\_ { w + m } , \\\\\
              vec { x } , y \\_ { w + m } , \\\\mathcal { R } \\_ { w + m } )$ .\\\
              \n\\\n11: Execute VerifyEval $( \\\\pi \\_ { m } , \\\\vec { x } , y\
              \ \\_ { m } , \\\\mathcal { R } \\_ { m } )$ .\\\n\\\n12: Output accept\
              \ if all checks above passes, otherwise output reject.\\\n\\\n# 3.5\
              \ Experiments\\\n\\\nWe have implemented our scheme, Orion, and we present\
              \ the evaluations of the system and the comparions to existing ZKP schemes\
              \ in this section.\\\n\\\nSettings and parameters. Our polynomial commitment\
              \ scheme is implemented in $\\\\mathrm { C } { + + }$ with 6000 lines\
              \ of code. The proof composition uses Virgo in \\[ZXZS20\\] and its\
              \ open-source implementation. We combine the polynomial commitment with\
              \ a sumcheck protocol to get our zero-knowledge argument following the\
              \ approach in \\[Set20\\] and we implement our own code for this part.\\\
              \n\\\nExpander graph used in our implementation We use a modified version\
              \ of generalized Spielman code in \\[GLSTW\\]. The code assigns a random\
              \ weight to each edge of the expander graph, achieving a better minimum\
              \ distance. We take a step further and fine-tune the dimensions more\
              \ aggressively. With our testing algorithm, the failure probability\
              \ of the expander sampling remains negligible. There are two types of\
              \ expander graph used in our construction and the parameters are $G\
              \ \\_ { 1 }$ : $\\\\alpha = 0 . 3 3 , \\\\delta = 0 . 6 , \\\\epsilon\
              \ = 0 . 7 8 , g = 6 ; G \\_ { 2 }$ : $\\\\alpha = 0 . 3 3 7 , g = 6\
              \ , \\\\delta = g , \\\\epsilon = 0 . 8 8 .$ .\\\n\\\nParameters of\
              \ our linear code. With expanders above, the final relative distance\
              \ is 0.055. We set the security parameter $\\\\lambda = 1 2 8$ . This\
              \ leads to opening $\\\\begin{array} { r } { t = \\\\frac { - 1 2 8\
              \ } { \\\\log { ( 1 - 0 . 0 5 5 ) } } = 1 5 6 8 } \\\\end{array}$ columns\
              \ and locations in Protocol 11. Hash function and finite field. We use\
              \ the SHA-256 hash function implemented by \\[arm\\]. We use the extension\
              \ field of $\\\\mathrm { G \\\\check { F } ( ( 2 ^ { 6 1 } - 1 ) ^ {\
              \ 2 } ) }$ as our underlying field to be compatible with the zero-knowledge\
              \ argument in \\[ZXZS20\\].\\\n\\\nEnvironment and method. We use an\
              \ AWS m6i-32xlarge instance with Intel(R) Xeon(R) Platinum 8375C CPU\
              \ $\\\\textcircled { a } 2 . 9 0 \\\\mathrm { G H z }$ CPU and 512GB\
              \ memory to execute all of our experiments. However, the largest instance\
              \ in our experiment only utilize 16 GB of memory. All experiments are\
              \ using a single thread except the expander testing algorithm. For each\
              \ data point, we run the experiments 10 times and report the average.\\\
              \n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/9d14223dff2c55a4bc379fc6614c6e2febf10b80c78395f2992b11cd24bd3db4.jpg)\\\
              \n\\\nFigure 3.3: Running time of our expander testing algorithm.\\\n\
              \\\n# 3.5.1 Expander Testing\\\n\\\nWe first show the performance of\
              \ our expander testing algorithm in Section 3.3. We implemented the\
              \ densest sub-graph algorithm in \\[Gol84\\], which uses network-flow\
              \ algorithm as a black-box. In our implementation, we use Dinic’s algorithm\
              \ $\\[ \\\\mathrm { D i n 7 0 } \\]$ , the complexity of which is $O\
              \ ( \\| V \\| ^ { 2 } \\| E \\| )$ on general graphs. However, on random\
              \ bipartite graphs, the Dinic’s algorithm runs significantly faster.\
              \ As observed in our experiments, it scales almost linearly in the size\
              \ of the graph.\\\n\\\nFigure 3.3 shows the running time of the algorithm.\
              \ We vary the size of left vertex set $L$ in the random bipartite graph\
              \ from $2 ^ { 1 2 }$ to $2 ^ { 1 8 }$ , and the size of $R$ is set to\
              \ be $\\| L \\| \\\\times \\\\alpha$ . The implementation uses multi-threading\
              \ utilizing all 128 CPU cores. As shown in the figure, it only takes\
              \ 163 seconds to test whether a random bipartite graph with $\\| L \\\
              | = 2 ^ { 1 5 }$ vertices is a lossless expander with a failure probability\
              \ √ $\\\\mathsf { n e g l } ( N ) = 2 ^ { - 1 2 8 }$ The running time\
              \ almost grows linearly in $\\| L \\|$ . As $k = \\\\sqrt { N }$ in\
              \ our zero-knowledge argument, this is enough for our experiments. As\
              \ the sampling of the lossless expander is done once, our testing algorithm\
              \ is very practical.\\\n\\\n# 3.5.2 Polynomial Commitment\\\n\\\nIn\
              \ this section, we report the performance of our polynomial commitment\
              \ scheme and compare it with the scheme Brakedown in \\[GLSTW\\], which\
              \ is the only implemented polynomial commitment scheme with a linear\
              \ prover time. We use the open-source implementation of Brakedown at\
              \ \\[Wa\\] in the comparison. Our current implementation is for the\
              \ plain version of the polynomial commitment without zero-knowledge,\
              \ which is the same as Brakedown.\\\n\\\nFigure 3.4 shows the performance\
              \ of our polynomial commitment and the polynomial commitment in Brakedown.\
              \ We vary the size of the polynomials from $2 ^ { 1 5 }$ to $2 ^ { 2\
              \ 9 }$ and measure the prover time, the proof size and the verifier\
              \ time. As shown in the figure, our prover time is even slightly faster\
              \ than Brakedown. It only takes 115 seconds for a polynomial with $2\
              \ ^ { 2 7 }$ coefficients, while it is 132 seconds in Brakedown. This\
              \ is because we use more aggressive parameters of the expander code,\
              \ while still achieving 128-bit of security thanks to our expander testing\
              \ algorithm. Moreover, the additional proof composition in our scheme\
              \ involves a second zero-knowledge argument on a circuit of size $O\
              \ ( { \\\\sqrt { N } } )$ . In our experiments, this extra zeroknowledge\
              \ argument takes less than $2 0 %$ of the total prover time, justifying\
              \ that our code switching technique only introduces a small overhead\
              \ on the prover time.\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/965e1d5084fcf28f6535b4a11d906e1d4fbe549c33bca6dd0d190c02c35ad982.jpg)\\\
              \n\\\nFigure 3.4: Performance of polynomial commitments.\\\n\\\nOur\
              \ proof size and verifier time is significantly smaller than Brakedown.\
              \ The proof size is only 6 MBs for a polynomial of size $2 ^ { 2 7 }$\
              \ , $1 6 \\\\times$ smaller than Brakedown. The verifier time is $7\
              \ 0 \\\\mathrm { m s }$ for $N = \\\\dot { 2 } ^ { 2 7 }$ , $3 3 \\\\\
              times$ faster than Brakedown. The result demonstrates the improvement\
              \ of the $O ( \\\\log ^ { 2 } N )$ proof size and verifier time in our\
              \ scheme.\\\n\\\nNote that there is a jump from $N = 2 ^ { 2 1 }$ to\
              \ $N = 2 ^ { 2 3 }$ in the proof size and verifier time. This is because\
              \ in our implementation, instead of directly parsing the coefficients\
              \ into $\\\\sqrt { N } \\\\times \\\\sqrt { N }$ matrix, we optimize\
              \ the dimensions for better performance. When $N \\\\textless 2 ^ {\
              \ 2 3 }$ , it is not meaningful to do code-switching on the columns.\
              \ The prover only does the code-switching on the row (Protocol 11 Step\
              \ 8 and 9), but opens the columns directly. We observe that this gives\
              \ the best prover time and the proof size. When $N \\\\geq 2 ^ { 2 3\
              \ }$ , the prover does the code-switching for both the row and the columns\
              \ (Protocol 11, Step 8–13). Therefore, the proof size and the verifier\
              \ time have a big increase because of the larger column size and the\
              \ additional code-switching protocol.\\\n\\\n# 3.5.3 Zero-knowledge\
              \ Arguments\\\n\\\nFinally, we present the performance of our zero-knowledege\
              \ argument scheme for R1CS as a whole in this section. We focus the\
              \ comparison to existing schemes that work on R1CS and have transparent\
              \ setup and plausible post-quantum security. They include Brakedown\
              \ \\[GLSTW\\], Aurora \\[BSCRSVW19\\] and Ligero \\[AHIV17\\]. We use\
              \ the implementation of Brakedown at \\[Wa\\], and the open-source code\
              \ of Ligero and Aurora at \\[Aur\\] in the experiments.\\\n\\\nWe randomly\
              \ generate the R1CS instances and vary the number of constraints from\
              \ $2 ^ { 1 5 }$ to $2 ^ { 2 0 }$ . As shown in Figure 3.5, Orion has\
              \ the fastest prover among all schemes. It only takes 3.09 seconds to\
              \ generate the proof for $N = 2 ^ { 2 0 }$ . This is slightly faster\
              \ than Brakedown for the same reason as explained in Section 3.5.2.\
              \ It is $2 0 \\\\times$ faster than Ligero and $1 4 2 \\\\times$ faster\
              \ than Aurora because of the linear prover time and the simplified reduction\
              \ via polynomial commitments.\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/edca3c2b17c03a7c3f94ae6d4b977e46833e4b709b62e2b0e2c0740addf08417.jpg)\\\
              \n\\\nFigure 3.5: Performance of zero-knowledge arguments on R1CS.\\\
              \n\\\nThe proof size of Orion is significantly smaller than Brakedown\
              \ and Ligero. It is only $1 . 5 \\\\mathrm { M B }$ for $N =$ $2 ^ {\
              \ 2 0 }$ , $6 . 5 \\\\times$ smaller than Brakedown and $1 2 . 5 \\\\\
              times$ smaller than Ligero. The proof size is even comparable to Aurora,\
              \ which has $O ( \\\\log ^ { 2 } N )$ proof size and uses the Reed-Solomon\
              \ code with a much better minimum distance than our linear code. The\
              \ result justifies the improvement of our code switching.\\\n\\\nWe\
              \ only implemented and compared with the variants of the protocols with\
              \ a linear verifier time. As explained in the introduction, the verifier\
              \ time of all schemes grow linearly with $N$ in the worst case, and\
              \ the comparisons are similar to the prover time. One can reduce the\
              \ verifier time to sublinear in the holographic setting using the techniques\
              \ in \\[CHMMVW20; COS20; Set20\\].\\\n\\\nOther related schemes. There\
              \ are several other existing transparent zero-knowledge argument schemes.\
              \ Hyrax \\[WTSTW18\\], Virgo \\[ZXZS20\\] and Virgo $^ { + + }$ $\\\
              [ Z \\\\mathrm { h a } + 2 1 \\\\mathrm { a } \\]$ work on layered arithmetic\
              \ circuits and STARK \\[BSBHR19\\] works on an algebraic intermediate\
              \ representation that is close to a RAM program. It is hard to compare\
              \ directly to R1CS, but we expect our prover time to be faster than\
              \ these systems for similar computations based on the results shown\
              \ in prior papers \\[ZXZS20; Zha+21a\\]. Spartan and schemes in \\[SL20\\\
              ] are using the same framework of polynomial commitment and sumcheck\
              \ as in our scheme. However, they are based on discrete-log and bilinear\
              \ pairing and thus are not post-quantum secure. As shown in \\[GLSTW\\\
              ], their prover time is slower than Brakedown while the proof size is\
              \ better (tens of KBs). Finally,\\\n\\\nBulletproofs \\[BBBPWM18\\]\
              \ and Supersonic \\[BFS20\\] are based on discrete-log and group of\
              \ unknown order. Their prover time is orders of magnitude slower than\
              \ schemes mentioned above, while providing the smallest proof size (1-2\
              \ KBs) because of the underlying cryptographic techniques.\\\n\\\n#\
              \ 3.6 Appendix\\\n\\\n# 3.7 Proof of Lemma 3.3.2\\\n\\\nProof. When\
              \ $s \\\\geq \\\\log \\\\log k$ , we have following:\\\n\\\n$e ^ { (\
              \ 1 - \\\\epsilon ) g s + s } = e ^ { O ( s ) } = e ^ { c \\_ { 0 }\
              \ s }$ ec0s for some constant c0. $\\\\begin{array} { r } { \\\\big\
              \ ( \\\\frac { ( 1 - \\\\epsilon ) g s } { k ^ { ' } } \\\\big ) ^ {\
              \ \\\\epsilon g s } \\\\le \\\\big ( \\\\frac { g s } { k ^ { ' } }\
              \ \\\\big ) ^ { \\\\epsilon g s } } \\\\end{array}$\\\n\\\nWe take the\
              \ expression in the summation and simplify it:\\\n\\\n$$\\\ne ^ { (\
              \ 1 - \\\\epsilon ) g s + s } \\\\cdot ( \\\\frac { k } { s } ) ^ {\
              \ s } \\\\cdot ( \\\\frac { ( 1 - \\\\epsilon ) g s } { k ^ { ^ { \\\
              \\prime } } } ) ^ { \\\\epsilon g s } \\\\leq e ^ { c \\_ { 0 } s }\
              \ ( \\\\frac { k } { s } ) ^ { s } ( \\\\frac { g s } { k ^ { ^ { \\\
              \\prime } } } ) ^ { \\\\epsilon g s }\\\n$$\\\n\\\nLet $f ( x ) = e\
              \ ^ { c \\_ { 0 } x } ( { \\\\frac { k } { x } } ) ^ { x } ( { \\\\\
              frac { g x } { k ^ { ' } } } ) ^ { \\\\epsilon g x }$ , then its derivative\
              \ $\\\\begin{array} { r } { f ^ { \\\\prime } ( x ) = e ^ { c \\_ {\
              \ 0 } x } ( \\\\frac { k } { x } ) ^ { x } \\\\big ( \\\\frac { g x\
              \ } { k ^ { \\\\prime } } \\\\big ) ^ { \\\\epsilon g x } \\\\cdot (\
              \ c \\_ { 0 } + \\\\epsilon g \\\\log \\\\frac { g x } { k ^ { \\\\\
              prime } } + \\\\epsilon g + \\\\log \\\\frac { k } { x } - 1 ) } \\\\\
              end{array}$ . Let $\\\\begin{array} { r } { g ( x ) = ( c \\_ { 0 }\
              \ + \\\\epsilon g \\\\log \\\\frac { g x } { k ^ { ' } } + \\\\epsilon\
              \ g + \\\\log \\\\frac { k } { x } - 1 ) } \\\\end{array}$ , we know\
              \ that when $x > 2$ , $f ^ { \\\\prime } ( x )$ is positive (negative\
              \ or zero) if and only if $g ( x )$ is positive (negative or zero).\
              \ Taking the derivative of $\\\\begin{array} { r } { g ( x ) , g ^ {\
              \ \\\\prime } ( x ) = \\\\frac { \\\\epsilon g - 1 } { x } > 0 } \\\\\
              end{array}$ so $f ( x )$ is a convex function. Therefore, the maximum\
              \ of $f ( x )$ is $\\\\begin{array} { r } { \\\\operatorname\\* { m\
              \ a x } \\_ { x \\\\in \\[ \\\\log \\\\log k , \\\\frac { \\\\delta\
              \ k } { g } \\] } ( f ( x ) ) = \\\\operatorname\\* { m a x } ( f (\
              \ \\\\log \\\\log k ) , f ( \\\\frac { \\\\delta k } { g } ) ) } \\\\\
              end{array}$ .\\\n\\\nWe then compute these two values at the boundaries:\\\
              \n\\\n$$\\\n\\\\leq \\\\log ^ { c \\_ { 0 } } ( k ) ( \\\\frac { k }\
              \ { \\\\log \\\\log k } ) ^ { \\\\log \\\\log k } ( \\\\frac { \\\\\
              frac { g } { \\\\alpha } \\\\log \\\\log k } { k } ) ^ { 2 \\\\log \\\
              \\log k } = \\\\tilde { O } ( ( \\\\frac { \\\\log \\\\log k } { k }\
              \ ) ^ { \\\\log \\\\log k } ) ,\\\n$$\\\n\\\nwhich is negligible.\\\n\
              \\\n$$\\\n\\\\begin{array} { r l } & { \\\\phantom { = } \\\\textstyle\
              \ e ^ { c \\_ { 0 } \\\\frac { \\\\delta k } { g } } ( \\\\frac { g\
              \ } { \\\\delta } ) ^ { \\\\frac { \\\\delta } { g } } k ( \\\\frac\
              \ { \\\\delta k } { k ^ { \\\\prime } } ) ^ { \\\\epsilon \\\\delta\
              \ k } = \\\\textstyle e ^ { ( \\\\frac { c \\_ { 0 } \\\\delta } { g\
              \ } + \\\\frac { \\\\delta } { g } \\\\log ( \\\\frac { g } { \\\\delta\
              \ } ) ) k + \\\\log ( \\\\frac { \\\\delta } { \\\\delta } ) \\\\epsilon\
              \ \\\\delta k } . } \\ & { \\\\mathrm { \\\\mathrm { l e g l i g i b\
              \ l e ~ i f ~ } } \\\\frac { c \\_ { 0 } \\\\delta } { g } + \\\\frac\
              \ { \\\\delta } { g } \\\\log ( \\\\frac { g } { \\\\delta } ) + \\\\\
              log ( \\\\frac { \\\\delta } { \\\\alpha } ) \\\\epsilon \\\\delta <\
              \ - 0 . 0 1 . \\\\mathrm { \\ T h e r e f o r e , ~ w e ~ s e t } c\
              \ \\_ { 0 } = ( 1 - \\\\epsilon ) g + 1 , \\\\mathrm { a n d } } \\\
              \ & { \\\\frac { c \\_ { 0 } \\\\delta } { g } + \\\\frac { \\\\delta\
              \ } { g } \\\\log ( \\\\frac { g } { \\\\delta } ) + \\\\log ( \\\\\
              frac { \\\\delta } { \\\\alpha } ) \\\\epsilon \\\\delta = ( 1 - \\\\\
              epsilon ) \\\\delta + \\\\frac { \\\\delta } { g } + \\\\frac { \\\\\
              delta } { g } \\\\log ( \\\\frac { g } { \\\\delta } ) + \\\\log ( \\\
              \\frac { \\\\delta } { \\\\alpha } ) \\\\epsilon \\\\delta < - 0 . 0\
              \ 0 1 } \\\\end{array}\\\n$$\\\n\\\nThe reasoning above shows that every\
              \ single value in the summation is negligible as the maximum is negligible,\
              \ and there are linear number of values in the summation, so the summation\
              \ is negligible.\\\n\\\n# 3.8 Proof of Theorem 3.4.2\\\n\\\nProof. Correctness.\
              \ It follows the correctness of Protocol 9, the zero-knowledge argument\
              \ $\\\\mathcal { Z } \\\\kappa$ on $C \\_ { \\\\mathsf { C S } }$ ,\
              \ and the Merkle trees.\\\n\\\nSoundness. By Step 18 of Protocol 11,\
              \ $\\\\mathcal { E }$ first extracts the witness $\\\\boldsymbol { w\
              \ } ^ { \\* } \\\\in \\\\mathbb { F } ^ { ( t + 2 ) k }$ of $\\\\mathcal\
              \ { Z } \\\\kappa$ on $C \\_ { \\\\mathsf { C S } }$ using $\\\\mathcal\
              \ { E } \\_ { \\\\mathcal { Z } \\\\mathcal { K } }$ Parse $w ^ { \\\
              * }$ as $y \\_ { \\\\gamma \\_ { 0 } } ^ { \\* } , y \\_ { 1 } ^ { \\\
              * }$ and $\\\\mathsf { C } \\_ { 1 } ^ { \\* } \\[ : , \\\\mathsf {\
              \ i d } \\\\times \\]$ for $\\\\mathsf { i d } \\\\times \\\\in \\\\\
              hat { I }$ , each of length $k$ . Let $c \\_ { \\\\gamma \\_ { 0 } }\
              \ , c \\_ { 1 }$ and $\\\\mathsf { C } \\_ { 2 } \\[ : , \\\\mathsf\
              \ { i d } \\\\times \\]$ for $\\\\mathsf { i d x } \\\\in \\\\hat {\
              \ I }$ be vectors committed by $\\\\mathcal { P }$ under $\\\\mathcal\
              \ { R } \\_ { \\\\gamma \\_ { 0 } } , \\\\mathcal { R } \\_ { c \\_\
              \ { 1 } }$ , ${ \\\\mathsf { R o o t } } \\_ { \\\\mathsf { i d } \\\
              \\times }$ in Step 8, 9 and 4 in Protocol 11. By the check in Step 21,\
              \ we have\\\n\\\n$$\\\n\\\\operatorname\\* { P r } \\\\left( \\\\Delta\
              \ ( c \\_ { 1 } , E \\_ { C } ( y \\_ { 1 } ^ { \\* } ) ) > \\\\frac\
              \ { d } { 2 } \\\\right) \\\\leq \\\\mathsf { n e g l } ( N ) .\\\n\
              $$\\\n\\\nTo see this, since the minimum distance of the code is $d\
              \ = O ( k )$ , if the vector in $\\\\mathcal { R } \\_ { c \\_ { 1 }\
              \ }$ is at least $\\\\frac { d } { 2 }$ -far from the codeword of $y\
              \ \\_ { 1 } ^ { \\* }$ , then the probability that $c \\_ { 1 }$ and\
              \ $E \\_ { C } ( y \\_ { 1 } ^ { \\* } )$ agrees on any $\\\\operatorname\
              \ { i d } \\\\times$ is $\\\\scriptstyle { \\\\frac { d } { 2 k } }$\
              \ . Therefore, the probability to pass all $t = O ( \\\\lambda )$ checks\
              \ in $I$ in Step 21 is at most $( 1 - \\\\frac { d } { 2 k } ) ^ { t\
              \ }$ , which is $\\\\mathsf { n e g l } ( N )$ . Similarly,\\\n\\\n\
              $$\\\n\\\\operatorname\\* { P r } \\\\left( \\\\Delta ( c \\_ { \\\\\
              gamma \\_ { 0 } } , E \\_ { C } ( y \\_ { \\\\gamma \\_ { 0 } } ^ {\
              \ \\\\ast } ) ) > \\\\frac { d } { 2 } \\\\right) \\\\leq \\\\mathsf\
              \ { n e g l } ( N ) ,\\\n$$\\\n\\\nand\\\n\\\n$$\\\n\\\\operatorname\\\
              * { P r } \\\\left( \\\\Delta ( \\\\mathsf { C } \\_ { 2 } \\[ : , \\\
              \\mathsf { i d x } \\] , E \\_ { C } ( \\\\mathsf { C } \\_ { 1 } ^\
              \ { \\\\ast } \\[ : , \\\\mathsf { i d x } \\] ) ) > \\\\frac { d }\
              \ { 2 } \\\\right) \\\\leq \\\\mathsf { n e g l } ( N ) , \\\\forall\
              \ \\\\mathsf { i d x } \\\\in \\\\hat { I } .\\\n$$\\\n\\\nThis technique\
              \ is exactly the proximity check. Therefore, $y \\_ { \\\\gamma \\_\
              \ { 0 } } ^ { \\* } , y \\_ { 1 } ^ { \\* }$ and $\\\\mathsf { C } \\\
              _ { 1 } ^ { \\* } \\[ : , \\\\mathsf { i d } \\\\times \\]$ for $\\\\\
              mathsf { i d } \\\\times \\\\in \\\\hat { I }$ are indeed the only messages\
              \ within the distance of $\\\\frac { d } { 2 }$ of $c \\_ { \\\\gamma\
              \ \\_ { 0 } } , c \\_ { 1 }$ and $\\\\mathsf { C } \\_ { 2 } \\[ : ,\
              \ \\\\mathsf { i d } \\\\times \\]$ for idx $\\\\in \\\\hat { I }$ respectively,\
              \ except for $\\\\mathsf { n e g l } ( N )$ probability.\\\n\\\nMoreover,\
              \ by the soundness of $\\\\mathcal { Z } \\\\kappa$ on $C \\_ { \\\\\
              mathsf { C S } }$ ,\\\n\\\n$$\\\n\\\\begin{array} { r } { \\\\operatorname\\\
              * { P r } \\\\left( y \\\\neq \\\\langle y \\_ { 1 } ^ { \\\\ast } ,\
              \ r \\_ { 0 } \\\\rangle \\\\right) \\\\le \\\\mathsf { n e g l } (\
              \ N ) , } \\\\end{array}\\\n$$\\\n\\\n$$\\\n\\\\begin{array} { r } {\
              \ \\\\operatorname\\* { P r } \\\\left( E \\_ { C } ( y \\_ { \\\\gamma\
              \ \\_ { 0 } } ^ { \\* } ) \\[ \\\\mathsf { i } \\\\mathsf { d } \\\\\
              mathsf { x } \\] \\\\neq \\\\langle \\\\mathsf { C } \\_ { 1 } ^ { \\\
              * } \\[ : , \\\\mathsf { i } \\\\mathsf { d } \\\\mathsf { x } \\] ,\
              \ \\\\gamma \\_ { 0 } \\\\rangle \\\\right) \\\\leq \\\\mathsf { n e\
              \ g l } ( N ) , \\\\forall \\\\mathsf { i } \\\\mathsf { d } \\\\mathsf\
              \ { x } \\\\in \\\\hat { I } . } \\\\end{array}\\\n$$\\\n\\\nand\\\n\
              \\\n$$\\\n\\\\begin{array} { r } { \\\\operatorname\\* { P r } \\\\\
              big ( E \\_ { C } ( y \\_ { 1 } ^ { \\* } ) \\[ \\\\mathsf { i d x }\
              \ \\] \\\\neq \\\\langle \\\\mathsf { C } \\_ { 1 } ^ { \\* } \\[ :\
              \ , \\\\mathsf { i d x } \\] , r \\_ { 0 } \\\\rangle \\\\big ) \\\\\
              leq \\\\mathsf { n e g l } ( N ) , \\\\forall \\\\mathsf { i d x } \\\
              \\in \\\\hat { I } . } \\\\end{array}\\\n$$\\\n\\\nTherefore, $w = y\
              \ \\_ { 1 } ^ { \\* } , y \\_ { \\\\gamma \\_ { 0 } } ^ { \\* }$ , $(\
              \ \\\\mathsf { C } \\_ { 1 } ^ { \\* } \\[ : , \\\\mathsf { i d } \\\
              \\times \\] \\\\forall \\\\mathsf { i d } \\\\times \\\\in \\\\hat {\
              \ I } )$ , and $E \\_ { C } ( y \\_ { 1 } ^ { \\* } ) , E \\_ { C }\
              \ ( y \\_ { \\\\gamma \\_ { 0 } } ^ { \\* } )$ passes the PC.VerifyEval\
              \ in Protocol 9. By Theorem 3.4.1, $\\\\mathcal { E }$ calls the extractor\
              \ $\\\\mathcal { E } \\_ { P C }$ to extract the coefficients of a polynomial\
              \ $\\\\phi$ such that $\\\\phi ( \\\\vec { x } ) = y$ , where $x = r\
              \ \\_ { 0 } \\\\otimes r \\_ { 1 }$ , except with negligible probability.\
              \ This completes the proof of knowledge soundness.\\\n\\\n# 3.9 Encoding\
              \ circuit\\\n\\\nRecall the construction of generalized Spielman code\
              \ in Preliminary section 3.2.1, we prove the following:\\\n\\\nLemma\
              \ 3.9.1 (Size of the encoder circuit). The size of the encoder circuit\
              \ for input size $k = 2 ^ { t }$ , is at most 8dk. And the circuit depth\
              \ is ${ \\\\cal O } ( \\\\log N )$\\\n\\\nProof. We prove by induction:\\\
              \n\\\n1. If $k \\\\leq n \\_ { 0 }$ , the lemma holds.\\\n\\\n2. Assume\
              \ for all $k ^ { \\* } \\\\leq 2 ^ { t - 1 }$ the lemma holds, we prove\
              \ for $k = 2 ^ { t }$ the lemma holds:\\\n\\\n\\\na) The step $m \\\
              _ { 1 } = x A \\_ { t }$ can be done in $d k$ steps, since $A \\_ {\
              \ t }$ represents an expander graph with dk edges, so $A \\_ { t }$\
              \ is sparse and have only $d k$ non-zeros.\\\n\\\nb) The step $c \\\
              _ { 1 } = E \\_ { C } ^ { t - 1 } ( m \\_ { 1 } )$ costs at most $8\
              \ d \\_ { 2 } ^ { k } = 4 d k$ by induction.\\\n\\\nc) The step $c \\\
              _ { 2 } = c \\_ { 1 } B \\_ { t + 1 }$ costs at most $2 d k$ since $B\
              \ \\_ { t + 1 }$ represents an expander with $2 d k$ edges.\\\n\\\n\
              d) In total the cost is $7 d k \\\\le 8 d k$ .\\\n\\\nThe circuit depth\
              \ is $O ( t ) = O ( \\\\log N )$ from the construction.\\\n\\\n# 3.10\
              \ Proof of Theorem 3.4.3\\\n\\\nProof. The correctness and the soundness\
              \ follow Theorem 3.4.2. Here we give the proof for zero-knowledge. The\
              \ simulator $\\\\boldsymbol { s }$ is constructed in Protocol 13. Next\
              \ we prove that every message sent by the simulator is indistinguishable\
              \ from the real-world execution as follows:\\\n\\\n1. In Step 8, $s$\
              \ directly runs Prove without any modification, so it is indistinguishable\
              \ from the real-world execution.\\\n2. In Step 14, $\\\\boldsymbol {\
              \ s }$ sends two hashes and the result $y$ from the oracle access. by\
              \ the hiding property of the Merkle tree, they are indistinguishable\
              \ from the real-world execution.\\\n3. In Step 15, $s$ calls the simulator\
              \ of $\\\\mathcal { Z } \\\\kappa$ , making $\\\\pi \\_ { \\\\mathcal\
              \ { Z } \\\\mathcal { K } }$ indistinguishable from the real world without\
              \ knowing the witness of the zero-knowledge argument.\\\n4. In Step\
              \ 16, 17, 18, at most $O ( \\| \\\\hat { I } \\_ { 0 } \\| )$ entries\
              \ of the codeword are queried by the verifier, where each entry is a\
              \ combination of the message $w \\_ { S }$ . Since $\\| \\\\hat { I\
              \ } \\_ { 0 } \\| < k$ , these queries are uniformly distributed. The\
              \ same analysis applies to the real-world execution, which also outputs\
              \ uniformly random values.\\\n\\\nNext we need to show that the simulated\
              \ proof actually passes verification. In Protocol 13 step 13, $\\\\\
              boldsymbol { s }$ creates a simulated codeword that only agrees with\
              \ the random codeword $E \\_ { C } ( w + \\\\vec { m } )$ on queried\
              \ points. The simulated codeword $c \\_ { 1 } ^ { \\* }$ and the message\
              \ are computed by solving a set of linear equations. Let $G$ be the\
              \ generator matrix of $E \\_ { C }$ , We have following constraints:\\\
              \n\\\n1 $. \\\\forall i \\\\in I \\_ { 0 } , ( y \\_ { 1 } ^ { \\* }\
              \ G ) \\[ i \\] = = c \\_ { 1 } \\[ i \\] ,$\\\n\\\n2\\. $\\\\langle\
              \ y \\_ { 1 } ^ { \\* } , r \\_ { 1 } \\\\rangle = = y$\\\n\\\nThere\
              \ are $k$ variables in $y \\_ { 1 } ^ { \\* }$ but only $\\\\left\\\
              | I \\_ { 0 } \\\\right\\| + 1$ equations, so $s$ can solve this equation\
              \ using the Gaussian elimination algorithm and get a valid $y \\_ {\
              \ 1 } ^ { \\* }$ , then computes $c \\_ { 1 } ^ { \\* } : = y \\_ {\
              \ 1 } ^ { \\* } G$ or $c \\_ { 1 } ^ { \\* } : = E \\_ { C } ( y \\\
              _ { 1 } ^ { \\* } )$ .\\\n\\\nFinally, the verification of $\\\\mathcal\
              \ { Z } \\\\kappa$ and the three Merkle tree checks in step 16,17, 18\
              \ all pass. The former is because of the the simulator $\\\\mathcal\
              \ { S } \\_ { \\\\mathcal { Z } \\\\mathcal { K } }$ . Step 16, 17 naturally\
              \ passes because ${ \\\\mathsf { C } } \\_ { 2 }$ is consistent with\
              \ $\\\\mathcal { R } \\_ { w \\_ { S } }$ . Step\\\n\\\n# Protocol 13\
              \ Simulators\\\n\\\n1: function $S \\_ { 0 } ( \\\\mathsf { p p } )$\\\
              \n\\\n2: Randomly sample two vectors $w ^ { \\* } , m$ .\\\n\\\n3: Output\
              \ $\\\\mathscr { R } \\_ { w ^ { \\* } + m } : = \\\\mathsf { C O M\
              \ M I T } ( w ^ { \\* } + m ) , \\\\mathscr { R } \\_ { m } : = \\\\\
              mathsf { C O M M I T } ( m ) .$\\\n\\\n4: function $\\\\mathcal { S\
              \ } \\_ { 1 } ^ { \\\\mathcal { A } } ( \\\\vec { x } , \\\\mathsf {\
              \ p p } )$\\\n\\\n5: The simulator receives a random vector $\\\\gamma\
              \ \\_ { 0 } \\\\in \\\\mathbb { F } ^ { k }$ from the verifier.\\\n\\\
              \n6: The simulator reads $A$ ’s random tape to get $\\\\hat { I } \\\
              _ { 0 } , I \\_ { 0 } , \\\\hat { I } \\_ { 1 } , I \\_ { 1 }$ .\\\n\
              \\\n7: The simulator will abort if $\\\\hat { I } \\_ { 0 } \\\\cap\
              \ \\\\hat { I } \\_ { 1 } \\\\stackrel { } { \\\\neq } \\\\varnothing\
              \ \\\\vee \\\\sp { \\\\bullet } I \\_ { 0 } \\\\cap I \\_ { 1 } \\\\\
              neq \\\\varnothing$ .\\\n\\\n8: The simulator runs $\\\\mathsf { P r\
              \ o v e } ( \\\\phi \\_ { m } , \\\\vec { x } , \\\\mathcal { R } \\\
              _ { m } )$ over random tape $I \\_ { 1 } , \\\\hat { I } \\_ { 1 }$\
              \ . Next, the simulator simulates $\\\\mathsf { P r o v e } ( \\\\phi\
              \ \\_ { w + m } , \\\\vec { x } , \\\\mathcal { R } \\_ { w + m } )$\
              \ without knowing the real polynomial $w$ .\\\n\\\n9: The simulator\
              \ makes an oracle query to obtain $y : = \\\\phi \\_ { w } ( \\\\vec\
              \ { x } )$ .\\\n\\\n10: Let $w \\_ { S } : = w ^ { \\\\ast } + m$ ,\
              \ $\\\\mathsf C \\_ { 1 } , \\\\mathsf C \\_ { 2 }$ encodes $w \\_ {\
              \ S }$ .\\\n\\\n11: $\\\\begin{array} { r } { c \\_ { \\\\gamma \\_\
              \ { 0 } } = \\\\sum \\_ { i = 0 } ^ { k - 1 } \\\\gamma \\_ { 0 } \\\
              [ i \\] \\\\mathsf { C } \\_ { 1 } \\[ i \\] } \\\\end{array}$ $\\\\\
              begin{array} { r } { \\\\mathsf { \\\\tilde { \\\\Phi } } \\_ { 1 }\
              \ \\[ i \\] , y \\_ { \\\\gamma \\_ { 0 } } = \\\\sum \\_ { i = 0 }\
              \ ^ { k - 1 } \\\\gamma \\_ { 0 } \\[ i \\] w \\_ { S } \\[ i \\] ,\
              \ \\\\mathcal { R } \\_ { \\\\gamma \\_ { 0 } } = \\\\mathsf { M e r\
              \ k l e } . \\\\mathsf { C o m m i t } ( c \\_ { \\\\gamma \\_ { 0 }\
              \ } ) . } \\\\end{array}$\\\n\\\n12: The simulator computes $\\\\begin{array}\
              \ { r } { c \\_ { 1 } = \\\\sum \\_ { i = 0 } ^ { k - 1 } r \\_ { 0\
              \ } \\[ i \\] \\\\mathsf { C } \\_ { 1 } \\[ i \\] } \\\\end{array}$\\\
              \n\\\n13: The simulator creates $c \\_ { 1 } ^ { \\* } , y \\_ { 1 }\
              \ ^ { \\* }$ , such that $\\\\forall i ~ \\\\in ~ I \\_ { 0 } , c \\\
              _ { 1 } ^ { \\* } \\[ i \\] ~ = = ~ c \\_ { 1 } \\[ i \\]$ , $\\\\langle\
              \ y \\_ { 1 } ^ { \\* } , r \\_ { 1 } \\\\rangle ~ = = ~ y$ , and $E\
              \ \\_ { C } ( y \\_ { 1 } ^ { \\* } ) = = c \\_ { 1 } ^ { \\* }$ , $\\\
              \\mathcal { R } \\_ { c \\_ { 1 } ^ { \\* } } = \\\\mathsf { M e r k\
              \ l e . C o m m i t } ( c \\_ { 1 } ^ { \\* } ) . \\ y \\_ { 1 } ^ {\
              \ \\* }$ can be computed by solving a system of linear equations.\\\n\
              \\\n14: The prover sends $\\\\mathcal { R } \\_ { c \\_ { 1 } ^ { \\\
              * } } , \\\\mathcal { R } \\_ { \\\\gamma \\_ { 0 } } , y$ to the verifier.\\\
              \n\\\n15: The prover calls the zero-knowledge argument protocol simulator\
              \ $\\\\mathcal { Z } \\\\kappa . s$ on $C \\_ { \\\\mathsf { C S } }$\
              \ . Let $\\\\pi \\_ { z k }$ be the proof of the zero-knowledge argument.\
              \ The prover sends the output of $C \\_ { \\\\mathsf { C S } } \\\\\
              colon \\\\mathsf C \\_ { 2 } \\[ I \\_ { 0 } \\[ j \\] , \\\\mathsf\
              \ { i d } \\\\mathsf { x } \\]$ $\\\\forall \\\\mathsf { i d } \\\\\
              bar { \\\\mathbf { x } } \\\\in \\\\hat { I } \\_ { 0 } , c \\_ { 1\
              \ } \\[ I \\_ { 0 } \\[ j \\] \\] , c \\_ { \\\\gamma \\_ { 0 } } \\\
              [ I \\_ { 0 } \\[ j \\] \\]$ and $\\\\pi \\_ { z k }$ to the verifier.\\\
              \n\\\n16: The prover sends the Merkle tree proofs of $\\\\mathsf C \\\
              _ { 2 } \\[ I \\_ { 0 } \\[ j \\] , \\\\mathsf { i d } \\\\mathsf {\
              \ x } \\] \\\\mathsf { \\ y i d } \\\\mathsf { x } \\\\in \\\\hat {\
              \ I } \\_ { 0 }$ under ${ \\\\mathsf { R o o t } } \\_ { \\\\mathsf\
              \ { i d } \\\\times }$ .\\\n\\\n17: The prover sends the Merkle tree\
              \ proofs of $\\\\mathsf { R o o t } \\_ { \\\\mathsf { i d x } } \\\\\
              forall \\\\mathsf { i d } \\\\times \\\\in \\\\hat { I } \\_ { 0 }$\
              \ under $\\\\mathcal { R } \\_ { w \\_ { s } }$ .\\\n\\\n18: The prover\
              \ sends the Merkle tree proofs of $c \\_ { 1 } \\[ I \\_ { 0 } \\[ j\
              \ \\] \\] , c \\_ { \\\\gamma \\_ { 0 } } \\[ I \\_ { 0 } \\[ j \\]\
              \ \\]$ under $\\\\mathcal { R } \\_ { c \\_ { 1 } ^ { \\* } } , \\\\\
              mathcal { R } \\_ { c \\_ { \\\\gamma \\_ { 0 } } }$\\\n\\\n18 will\
              \ pass because $c \\_ { 1 } ^ { \\* }$ is constructed to agree with\
              \ $c \\_ { 1 }$ on index set $I \\_ { 0 }$ . Therefore, all the checks\
              \ in the verification are satisfied.\\\n\\\n# Chapter 4\\\n\\\n# Pianist:\
              \ Scalable zkRollups via Fully Distributed Zero-Knowledge Proofs\\\n\
              \\\nIn the past decade, blockchains have seen various financial and\
              \ technological innovations, with cryptocurrencies reaching a market\
              \ cap of over 1 trillion dollars. However, scalability is one of the\
              \ key issues hindering the deployment of blockchains in many applications.\
              \ To improve the throughput of the transactions, zkRollups and zkEVM\
              \ techniques using the cryptographic primitive of zero-knowledge proofs\
              \ (ZKPs) have been proposed and many companies are adopting these technologies\
              \ in the layer-2 solutions. However, in these technologies, the proof\
              \ generation of the ZKP is the bottleneck and the companies have to\
              \ deploy powerful machines with TBs of memory to batch a large number\
              \ of transactions in a ZKP.\\\n\\\nIn this work, we improve the scalability\
              \ of these techniques by proposing new schemes of fully distributed\
              \ ZKPs. Our schemes can improve the efficiency and the scalability of\
              \ ZKPs using multiple machines, while the communication among the machines\
              \ is minimal. With our schemes, the ZKP generation can be distributed\
              \ to multiple participants in a model similar to the mining pools. Our\
              \ protocols are based on Plonk, an efficient zero-knowledge proof system\
              \ with a universal trusted setup. The first protocol is for data-parallel\
              \ circuits. For computation of $M$ sub-circuits of size $T$ each, using\
              \ $M$ machines, the prover time is $O ( T \\\\log T + M \\\\log M )$\
              \ , while the prover time of the original Plonk on a single machine\
              \ is $O ( M T \\\\log ( M T ) )$ . Our protocol incurs only $O ( 1 )$\
              \ communication per machine, and the proof size and verifier time are\
              \ both $O ( 1 )$ , the same as the original Plonk. Moreover, we show\
              \ that with minor modifications, our second protocol can support general\
              \ circuits with arbitrary connections while preserving the same proving,\
              \ verifying, and communication complexity.\\\n\\\nWe implement Pianist\
              \ (Plonk vIA uNlimited dISTribution), a fully distributed ZKP system\
              \ using our protocols. Pianist can generate the proof for 8192 transactions\
              \ in 313 seconds on 64 machines. This improves the scalability of the\
              \ Plonk scheme by $6 4 \\\\times$ . The communication per machine is\
              \ only $2 . 1 \\ \\\\mathrm { K B }$ , regardless of the number of machines\
              \ and the size of the circuit. The proof size is $2 . 2 \\\\mathrm {\
              \ K B }$ and the verifier time is $3 . 5 \\\\mathrm { { m s } }$ . We\
              \ further show that Pianist has similar improvements for general circuits.\
              \ On a randomly generated circuit with $2 ^ { 2 5 }$ gates, it only\
              \ takes 5s to generate the proof using 32 machines, $2 4 . 2 \\\\times$\
              \ faster than Plonk on a single machine.\\\n\\\n# 4.1 Introduction\\\
              \n\\\nBlockchain technology has paved the way for innovative services\
              \ such as decentralized finance, NFTs, and GameFi. The cryptocurrency\
              \ market has experienced significant growth, surpassing 1 trillion USD\
              \ in value since Bitcoin’s inception 13 years ago \\[Coi\\]. Techniques\
              \ like zkRollups and zkEVM have been proposed to boost blockchain efficiency\
              \ and bridge the transaction throughput gap between digital and traditional\
              \ scenarios. Implementing zkRollups could potentially increase transaction\
              \ throughput by over 100 times, as estimated by Vitalik Buterin \\[Vit\\\
              ]. Numerous companies have incorporated these techniques into their\
              \ products, including zkSync \\[Zks\\], Starkware \\[Sta\\], Hermez\
              \ \\[Her\\], Aztec \\[Azt\\], Scroll \\[Scr\\], and others.\\\n\\\n\
              zkRollups and zkEVM rely on zero-knowledge proofs (ZKPs), a cryptographic\
              \ primitive that allows a prover to convince a verifier the correctness\
              \ of computations. More specifically, they use Zero-Knowledge Succinct\
              \ Non-interactive Argument of Knowledge (ZK-SNARK) systems, which ensures\
              \ that the proof size is significantly smaller than the size of computation\
              \ and enables faster validation. By utilizing ZKPs, a single server\
              \ can validate multiple transactions, compute state transitions, and\
              \ generate a proof that is posted on the blockchain. Instead of re-executing\
              \ all transactions, nodes can verify transactions and smart contracts\
              \ by checking the proof and updating their status. This approach greatly\
              \ increases the transaction throughput of the blockchain.\\\n\\\nHowever,\
              \ the proof generation remains a significant bottleneck for existing\
              \ ZKP schemes when applied to large-scale statements such as zkRollups\
              \ and zkEVM. For instance, our experiments show that the Plonk system\
              \ \\[GWC19b\\], a widely-used ZKP protocol in the industry, can only\
              \ scale to a circuit with $2 ^ { 2 5 }$ gates on a machine with $2 0\
              \ 0 \\\\mathrm { G B }$ of memory. As a result, companies like Starkware\
              \ \\[Sta\\] and Scroll \\[Scr\\] must deploy powerful clusters with\
              \ terabytes of memory to generate proofs for zkRollups and zkEVM. In\
              \ this paper, we tackle this issue by proposing fully distributed ZKP\
              \ schemes that enhance both efficiency and scalability through distributed\
              \ proof generation across multiple machines. Crucially, our schemes\
              \ require minimal communication among machines, with each machine only\
              \ exchanging a constant number of values with the master machine. This\
              \ approach allows us to distribute ZKP generation in zkRollups and zkEVM\
              \ among multiple participants, in a similar model to existing mining\
              \ pools. More transactions can be batched into a single ZKP within a\
              \ fixed period, without necessitating participants to stay online and\
              \ communicate with each other with high overhead. Participants can potentially\
              \ share the reward for generating the ZKP, akin to miners in current\
              \ proof-of-work blockchains. Furthermore, our scheme can be generalized\
              \ to create proofs for arbitrary general circuits, leading us to the\
              \ name “fully distributed ZKPs”.\\\n\\\nOur distributed schemes are\
              \ built upon Plonk \\[GWC19b\\]. Instead of using univariate polynomials\
              \ to represent the constraints of a computation, we devise a protocol\
              \ based on a bivariate constraint system. First, we claim that this\
              \ protocol can cater to data-parallel circuits, allowing each machine\
              \ to generate the witness for its corresponding sub-circuit. Second,\
              \ we further generalize it to compute proofs for general circuits with\
              \ aribitrary connections, assuming the witness has already been distributed\
              \ among the machines. In both cases, our schemes demonstrate that the\
              \ efficiency and scalability can be improved by a factor of $M$ using\
              \ $M$ machines, the proof size remains $O ( 1 )$ , and the communication\
              \ complexity per machine is only $O ( 1 )$ .\\\n\\\nOur contributions.\
              \ We have the following contributions:\\\n\\\n• We propose two fully\
              \ distributed ZKP protocols for data-parallel circuits and general circuits,\
              \ respectively. To construct the schemes, we first propose a distributed\
              \ polynomial interactive oracle proof (polynomial IOP) and then combine\
              \ it with a polynomial commitment scheme (PCS) that is distributively\
              \ computable as well. The polynomial IOP is a bivariate variant of Plonk’s\
              \ \\[GWC19b\\] constraint system. To “compile” both IOP schemes by polynomial\
              \ commitments, we use the bivariate variant of the KZG \\[PST13\\] scheme\
              \ and demonstrate that it is distributively computable. The use of the\
              \ Lagrange polynomial in our scheme is inspired by a sub-scheme in Caulk\
              \ \\[ZBKMNS22\\].\\\n\\\n• We further show that our protocols are robust\
              \ in the presence of malicious machines. We formalize the notion as\
              \ Robust Collaborative Proving Scheme (RCPS), for the collaborative\
              \ generation of proofs among sub-provers in a malicious environment.\
              \ In this setting, the master node is able to verify partial proofs\
              \ and messages received from other machines before aggregating them\
              \ to compute the final proof. We show that our protocols are robust\
              \ under this definition with an additional step of verification. This\
              \ property is crucial for the applications of distributed zkRollups\
              \ and zkEVM to exclude malicious participants without ruining the distributed\
              \ proof generation.\\\n\\\n• We implement the fully distributed ZKP\
              \ system, Pianist, for both data-parallel and general circuits. For\
              \ the data-parallel version, we report experimental results for the\
              \ blockchain application of zkRollups. Utilizing rollup circuits generated\
              \ by the Circom compiler \\[Cira\\], we show that Pianist can scale\
              \ to 8192 transactions on 64 machines with a prover time of 313 seconds.\
              \ In comparison, the original Plonk scheme can only scale to 32 transactions\
              \ with a prover time of 95 seconds on a single machine. The communication\
              \ between each machine and the master machine is only 2144 bytes, and\
              \ the proof size is 2208 bytes. We observe similar improvements for\
              \ general circuits. On a circuit of size $2 ^ { 2 5 }$ , it only takes\
              \ 5s to generate the proof using 32 machines, which is $2 4 . 2 \\\\\
              times$ faster than Plonk on a single machine, with 2336 Bytes communication\
              \ and 2816 Bytes proof size.\\\n\\\nOrganization of the paper. We review\
              \ the related work in Section 4.1.1 and present the preliminaries in\
              \ Section 4.2. To explain our protocols, we first introduce our distributed\
              \ polynomial IOP schemes in Section 4.3 for data-parallel circuits and\
              \ general circuits. Then in Section 4.4, we present a bivariate variant\
              \ of the polynomial commitment in \\[KZG; PST13\\] to compile our polynomial\
              \ IOP schemes to SNARKs. In Section 4.5, we formalize the notion of\
              \ robust collaborative proving scheme (RCPS) and show that our scheme\
              \ is able to detect malicious machines. We showcase the performance\
              \ of our system in Section 4.6, and present additional discussions in\
              \ Section 4.7.\\\n\\\n# 4.1.1 Related works\\\n\\\nZero-knowledge proofs\
              \ (ZKP) were first introduced by Goldwasser, Micali, and Rackoff in\
              \ their seminal paper \\[GMR\\]. Driven by real-world applications such\
              \ as blockchains $\\[ { \\\\mathrm { B e n } } + 1 4$ ; KMSWP; Xie+22\\\
              ], there has been a rapid development of efficient zkSNARK systems in\
              \ recent years \\[PHGR13; BSCTV14c; Gro16; WTSTW18; ZGKPP17a; BSBHR19;\
              \ BBBPWM18; AHIV17; BSCRSVW19; XZZPS19c; CHMMVW20; GWC19b; Set20; ZXZS20;\
              \ Zha+21b\\]. Despite such progress, it remains challenging to scale\
              \ ZKP protocols to large statements due to their high overhead on the\
              \ prover running time and memory usage.\\\n\\\nDistributed ZKPs. To\
              \ scale existing ZKP protocols to large-scale circuits, distributed\
              \ algorithms provide a promising direction. Wu et al. proposed the first\
              \ distributed zero-knowledge proof protocol called DIZK in \\[WZCPS18\\\
              ]. DIZK scales the pairing-based zkSNARK in \\[Gro16\\] to handle circuits\
              \ that are 100 times larger on 128 machines compared to a single machine.\
              \ However, DIZK incurs a high communication cost that is linear in the\
              \ total size of the circuit among different machines because the scheme\
              \ runs a distributed number theoretic transformation (NTT) algorithm\
              \ among the machines using the Map-Reduce framework. Additionally, the\
              \ recent work of zkBridge $\\[ \\\\mathrm { X i e } + 2 2 \\]$ proposed\
              \ deVirgo, a distributed ZKP protocol based on the ZKP scheme in \\\
              [ZXZS20\\], to build bridges between two blockchains using ZKPs. The\
              \ protocol achieves linear improvement on both the prover time and scalability\
              \ in the number of machines. However, deVirgo also incurs a linear communication\
              \ cost among the machines, and the proof size grows with the number\
              \ of machines. This seems inevitable due to the use of the FRI protocol\
              \ in \\[BSBHR18\\] with Merkle trees \\[Mer87\\]. By contrast, our schemes\
              \ offer optimal linear scalability in prover time and minimal communication\
              \ among distributed machines simultaneously. We provide comparisons\
              \ in Table 4.1.\\\n\\\nPCD and IVC Proof-Carrying Data (PCD \\[CT10;\
              \ BCCT13\\]) is a cryptographic technique that breaks down computation\
              \ into a sequence of steps. In each step, the prover convinces the verifier\
              \ not only of the current step’s correctness but also of all previous\
              \ steps. It is an alternative solution for data-parallel circuits when\
              \ memory is limited. There are generally two ways to achieve PCD: one\
              \ is from succinct verification, and the other is from accumulation.\
              \ In the succinct verification approach, for each step, the prover generates\
              \ a proof for the current step computation and verification for the\
              \ proof generated from the previous step, as seen in\\[BCCT13; BSCTV14b;\
              \ COS20\\], etc. The accumulation approach postpones and accumulates\
              \ the verification of SNARK proofs (or some expensive part of it) at\
              \ each recursion step and proves it all at once at the last step, as\
              \ demonstrated in \\[BCMS20; Hal; BCLMS20; KST22; KS22\\], etc. Although\
              \ there is no direct correspondence for general circuits, some of these\
              \ techniques, including but not limited to \\[KST22; KS22\\], claim\
              \ to achieve Incremental Verifiable Computation (IVC). IVC focuses on\
              \ dividing longrunning computations into stages that can be verified\
              \ incrementally. For instance, Nova \\[KST22\\] supports proof generation\
              \ when the computation involves a nondeterministic function $f$ and\
              \ the result of $f ^ { n } ( z \\_ { 0 } )$ . These techniques are widely\
              \ employed in various applications, however, we identify several drawbacks\
              \ when compared to our proposed solution. See details in Section 4.7.\\\
              \n\\\nDistributed computation from proof aggregation Similar to our\
              \ approach, aPlonk \\[ABST22\\] is a distributed solution based on Plonk\
              \ that requires prover nodes to share the same Fiat-Shamir randomness,\
              \ necessitating synchronization several times during the proving process.\
              \ In their scheme, they propose a multipolynomial commitment to combine\
              \ parties’ polynomial commitments and attest to the batch opening using\
              \ a generalized Inner-Product Argument (IPA) from \\[BMV19\\]. Additionally,\
              \ they delegate the verification of the constraint system through all\
              \ evaluations to the prover. We also include the discussion for their\
              \ protocol in Section 4.7.\\\n\\\n|     |     |     |     |     |\\\n\
              | --- | --- | --- | --- | --- |\\\n| Scheme | P, time | Comm. | \\|\\\
              |& V time | Robust |\\\n| DIZK \\[WZCPS18\\] | O(T log2 T) | O(N) |\
              \ 0(1) | x |\\\n| deVirgo \\[Xie+22\\] | O(T log T) | O(N) | O(log2\
              \ N) | x |\\\n| Pianist | O(T log T) | O(M) | 0(1) | J |\\\n\\\nTable\
              \ 4.1: Comparisons of our schemes to existing distributed ZKP protocols\
              \ given $M$ distributed machines on the circuit with $M$ sub-circuits\
              \ and total $N$ gates, where each sub-circuit has $\\\\begin{array}\
              \ { r } { T = \\\\frac { N } { M } } \\\\end{array}$ gates. $\\\\mathcal\
              \ { P } \\_ { i }$ time denotes the prover time per machine, Comm. denotes\
              \ the total communication among machines, $\\| \\\\pi \\|$ denotes the\
              \ proof size, and $\\\\nu$ time denotes the verifier time.\\\n\\\n#\
              \ 4.2 Preliminaries\\\n\\\nOur construction follows the framework proposed\
              \ in \\[BFS20\\] and achieves SNARK by first compiling a public-coin\
              \ Polynomial IOP into a doubly-efficient public-coin interactive argument\
              \ of knowledge using a polynomial commitment scheme. Subsequently, the\
              \ non-interactive property is achieved through the FiatShamir transform.\
              \ We present the notations and corresponding definitions below\\\n\\\
              \n# 4.2.1 Notations\\\n\\\nIn our distributed setting, the size of the\
              \ entire circuit is $N$ , and there are $M$ machines (or users acting\
              \ as sub-provers) participating in this protocol. Consequently, each\
              \ party is responsible for generating a proof for a sub-circuit of size\
              \ $\\\\begin{array} { r } { T = \\\\frac { N } { M } } \\\\end{array}$\
              \ .\\\n\\\nWe use bivariate polynomials to help construct the constraint\
              \ system in the scheme. In our constraint system, for the $i$ -th party,\
              \ it holds its local witness vector ${ \\\\vec { a } \\_ { i } = ( a\
              \ \\_ { i , 0 } , a \\_ { i , 1 } , \\\\ldots , a \\_ { i , T - 1 }\
              \ ) }$ . We can transform this witness vector into a univariate polynomial\
              \ $\\\\begin{array} { r } { a \\_ { i } ( X ) = \\\\sum \\_ { j = 0\
              \ } ^ { T - 1 } a \\_ { i , j } L \\_ { j } ( X ) } \\\\end{array}$\
              \ , where $L \\_ { j } ( X )$ is the Lagrange polynomial defined from\
              \ the $T$ -th roots of unity, with the close-form $\\\\begin{array}\
              \ { r } { L \\_ { j } ( X ) = \\\\frac { \\\\omega \\_ { X } ^ { j }\
              \ } { T } \\\\cdot \\\\frac { X ^ { T } - 1 } { X - \\\\omega \\_ {\
              \ X } ^ { j } } } \\\\end{array}$ . Furthermore, we aggregate the witness\
              \ polynomial from all parties as a bivariate polynomial $\\\\begin{array}\
              \ { r } { A ( Y , X ) = \\\\sum \\_ { i = 0 } ^ { M - 1 } a \\_ { i\
              \ } ( X ) R \\_ { i } ( Y ) } \\\\end{array}$ , $\\\\begin{array} {\
              \ r } { R \\_ { i } ( Y ) = \\\\frac { \\\\omega \\_ { Y } ^ { i } }\
              \ { M } \\\\cdot \\\\frac { Y ^ { M } - 1 } { Y - \\\\omega \\_ { Y\
              \ } ^ { i } } } \\\\end{array}$ $R \\_ { i } ( Y )$ $M$\\\n\\\nUnless\
              \ specifically stated, for polynomials, we use lowercase letters such\
              \ as ate polynomial storing local information, and uppercase letters\
              \ $A , B , C$ to denote the bivariate polynomial aggregating information\
              \ throughout the entire circuit. In addition, we use lowercase letters\
              \ $x , y$ to denote a specific assignment or evaluation for the polynomial,\
              \ and uppercase letters $X , Y$ to denote unassigned variables.\\\n\\\
              \n# 4.2.2 Interactive Argument\\\n\\\nDefinition 4.2.1 (Interactive\
              \ Argument). We say that $\\\\mathsf { A R G } = ( \\\\mathscr { G }\
              \ , \\\\mathscr { P } , \\\\mathscr { V } )$ is an interactive argument\
              \ of knowledge for a relation $\\\\mathcal { R }$ if it satisfies the\
              \ following completeness and knowledge properties.\\\n\\\n• Completeness:\
              \ For every adversary $\\\\mathcal { A }$\\\n\\\n$$\\\n\\\\operatorname\\\
              * { P r } \\[ { \\\\big ( } \\\\mathbf { { p p , x , w } } , \\\\mathbf\
              \ { \\\\mathcal { V } ( p p , x ) } { \\\\big \\\\rangle } = 1 : ( \\\
              \\mathbf { x , w } ) { \\\\mathcal { G } ( 1 ^ { \\\\lambda } ) }\\\n\
              $$\\\n\\\n• Witness-extended emulation: ARG has witness-extended emulation\
              \ with knowledge error $\\\\kappa$ if there exists an expected polynomial-time\
              \ algorithm $\\\\mathcal { E }$ such that for every polynomial-size\
              \ adversary $\\\\mathcal { A }$ it\\\n\\\nholds that\\\n\\\n$$\\\n\\\
              \\begin{array} { r l } & { \\\\operatorname\\* { P r } \\[ \\\\mathcal\
              \ { A } ( \\\\mathfrak { a u x } , \\\\mathfrak { t r } ) = 1 : ( \\\
              \\mathfrak { x } , \\\\mathfrak { a u x } ) \\\\mathcal { A } ( \\\\\
              mathfrak { p p } ) } \\ & { \\\\qquad \\\\mathrm { t r } \\\\langle\
              \ \\\\mathcal { A } ( \\\\mathfrak { a u x } ) , \\\\mathcal { V } (\
              \ \\\\mathfrak { p p } , \\\\mathfrak { x } ) \\\\rangle \\] } \\ &\
              \ { - \\\\operatorname\\* { P r } \\[ a n \\\\mathcal { A } ( \\\\mathfrak\
              \ { a u x } , \\\\mathfrak { t r } ) = 1 \\\\quad \\\\mathfrak { p p\
              \ } \\\\mathcal { G } ( 1 ^ { \\\\lambda } ) } \\ & { \\\\qquad t n\
              \ e n \\\\alpha i t \\\\mathfrak { t r } i s a c e p t i n g : ( \\\\\
              mathfrak { x } , \\\\mathfrak { a u x } ) \\\\mathcal { A } ( \\\\mathfrak\
              \ { p p } ) } \\ & { \\\\qquad t h e n ( \\\\mathfrak { x } , \\\\mathfrak\
              \ { w } ) \\\\in \\\\mathcal { R } \\\\quad ( \\\\mathfrak { t r } ,\
              \ \\\\mathfrak { w } ) \\\\mathcal { E } ^ { A ( \\\\mathfrak { a u\
              \ x } ) } ( \\\\mathfrak { p p } , \\\\mathfrak { x } ) \\] \\| \\\\\
              leq \\\\kappa ( \\\\lambda ) } \\\\end{array}\\\n$$\\\n\\\nAbove $\\\
              \\mathcal { E }$ has oracle access to (the next-message functions of)\
              \ $\\\\mathcal { A } ( \\\\mathsf { a u x } )$ .\\\n\\\nIf the interactive\
              \ argument of knowledge protocol ARG is public-coin, is has been shown\
              \ that by the Fiat-Shamir transform \\[FS86\\], we can derive a non-interactive\
              \ argument of knowledge from ARG. If the scheme further satisfies the\
              \ following property:\\\n\\\n• Succinctness. The proof size is $\\|\
              \ \\\\pi \\| = \\\\mathsf { p o l y } ( \\\\lambda , \\\\log \\| C \\\
              | )$ and the verification time is poly $( \\\\lambda , \\| \\\\mathbb\
              \ { x } \\| , \\\\log \\| C \\| )$ ,\\\n\\\nthen it is a Succinct Non-interactive\
              \ Argument of Knowledge (SNARK).\\\n\\\nFor the applications of zkRollups\
              \ and zkEVM, we only need a SNARK that is complete, sound, and succinct.\
              \ Our constructions can be made zero-knowledge via known transformations\
              \ with random masks and we omit the details in this paper.\\\n\\\n#\
              \ 4.2.3 Polynomial Interactive Oracle Proof\\\n\\\nDefinition 4.2.2\
              \ (Public-coin Polynomial Interactive Oracle Proof \\[BFS20\\]). Let\
              \ $\\\\mathcal { R }$ be a binary relation and $\\\\mathbb { F }$ be\
              \ a finite field. Let $X = ( X \\_ { 1 } , \\\\ldots , X \\_ { \\\\\
              mu } )$ be a vector of $\\\\mu$ indeterminates. A $( \\\\mu , d )$ Polynomial\
              \ IOP for $\\\\mathcal { R }$ over $\\\\mathbb { F }$ with soundness\
              \ error ϵ and knowledge error $\\\\delta$ consists of two stateful PPT\
              \ algorithms, the prover $\\\\mathcal { P }$ , and the verifier $\\\\\
              nu$ , that satisfy the following requirements:\\\n\\\n• Protocol syntax.\
              \ For each $i$ -th round there is a prover state $\\\\mathsf { s t }\
              \ \\_ { i } ^ { \\\\mathcal { P } }$ and a verifier state $\\\\mathsf\
              \ { s t } \\_ { i } ^ { \\\\mathcal { V } }$ . For any common input\
              \ $x$ and $\\\\mathcal { R }$ witness $w$ , at round $O$ the states\
              \ are $\\\\mathsf { s t } \\_ { 0 } ^ { \\\\mathcal { P } } = ( x ,\
              \ w )$ and $\\\\mathsf { s t } \\_ { 0 } ^ { \\\\mathcal { V } } = x$\
              \ . In the $i$ -th round (starting at $i = 1$ ) the prover outputs a\
              \ single proof oracle $\\\\mathcal { P } ( \\\\mathfrak { s t } \\_\
              \ { i - 1 } ^ { \\\\mathcal { P } } ) \\\\to \\\\pi \\_ { i } .$ , which\
              \ is $a$ polynomial $\\\\pi \\_ { i } ( X ) \\\\in \\\\mathbb { F }\
              \ \\[ X \\]$ . The verifier deterministically computes the query matrix\
              \ $\\\\boldsymbol { i } \\\\in \\\\mathbb { F } ^ { \\\\mu \\\\times\
              \ \\\\ell }$ from its state and a string of public random bits $\\\\\
              mathsf { c o i n s } \\_ { i } \\\\gets { 0 , 1 } ^ { \\* }$ , i.e,\
              \ $\\\\mathcal { V } ( \\\\mathsf { s t } \\_ { i - 1 } ^ { \\\\mathcal\
              \ { V } } , \\\\mathsf { c o i n s } \\_ { i } ) \\\\to \\\\Sigma \\\
              _ { i }$ . This query matrix is interpreted as a list of $\\\\ell$ points\
              \ in $\\\\mathbb { F } ^ { \\\\mu }$ denoted $( \\\\sigma \\_ { i ,\
              \ 1 } , \\\\ldots , \\\\sigma \\_ { i , \\\\ell } )$ . The oracle $\\\
              \\pi \\_ { i }$ is queried on all points in this list, producing the\
              \ response vector $( \\\\pi \\_ { i } ( \\\\sigma \\_ { i , 1 } ) ,\
              \ \\\\ldots , \\\\pi \\_ { \\\\ell } ( \\\\sigma \\_ { i , \\\\ell }\
              \ ) ) = a \\_ { i } \\\\in \\\\mathbb { F } ^ { 1 \\\\times \\\\ell\
              \ }$ . The updated prover state is $\\\\mathsf { s t } \\_ { i } ^ {\
              \ \\\\mathcal { P } } \\\\gets ( \\\\mathsf { s t } \\_ { i - 1 } ^\
              \ { P } ) , \\\\Sigma \\_ { i } )$ and verifier state is $\\\\mathsf\
              \ { s t } \\_ { i } ^ { V } \\\\gets ( \\\\mathsf { s t } \\_ { i -\
              \ 1 } ^ { \\\\nu } , \\\\Sigma \\_ { i } , a \\_ { i } )$ . Finally,\
              \ $\\\\mathcal { V } ( \\\\mathsf { s t } \\_ { t } ^ { \\\\mathcal\
              \ { V } } )$ returns 1 or 0.\\\n\\\n(Extensions: multiple and prior\
              \ round oracles; various arity. The syntax can be naturally extended\
              \ such that multiple oracles are sent in the $i$ -th round; that the\
              \ verifier may query oracles sent in the $i$ -th round or earlier; or\
              \ that some of the oracles are polynomials in fewer variables than $\\\
              \\mu$ .)\\\n\\\nFurthermore, a Polynomial IOP is stateless if for each\
              \ $i \\\\in \\[ t \\] , \\\\mathcal { V } ( \\\\mathfrak { s t } \\\
              _ { i - 1 } ^ { \\\\mathcal { V } } , \\\\mathsf { c o i n } \\\\mathsf\
              \ { s } \\_ { i } ) = \\\\mathcal { V } ( i , \\\\mathsf { c o i n }\
              \ \\\\mathsf { s } \\_ { i } ) .$\\\n\\\n# 4.2.4 Polynomial Commitment\
              \ Scheme (PCS)\\\n\\\nDefinition 4.2.3 (Polynomial commitment scheme\
              \ (PCS)). A Polynomial commitment scheme $\\\\Gamma$ is a tuple $\\\\\
              Gamma = ( { \\\\sf K e y G e n }$ , Commit, Open, Verify) of PPT algorithms\
              \ where:\\\n\\\n• $\\\\mathsf { K e y G e n } ( 1 ^ { \\\\lambda } ,\
              \ { \\\\mathcal F } ) \\\\to \\\\mathsf { p p }$ generates public parameters\
              \ pp;\\\n\\\n• Commit $( f , \\\\mathsf { p p } ) \\\\to \\\\mathsf\
              \ { c o m } \\_ { f }$ takes a secret polynomial $f ( \\\\mathbf { X\
              \ } )$ where ${ X = ( X \\_ { 0 } , \\\\dots , X \\_ { \\\\mu - 1 }\
              \ ) }$ and outputs a public commitment ${ \\\\mathsf { c o m } } \\\
              _ { f }$ ;\\\n\\\n• Op $\\\\mathsf { \\\\Omega } \\\\mathsf { n } (\
              \ \\\\mathsf { c o m } \\_ { f } , \\\\mathsf { x } , \\\\mathsf { p\
              \ p } ) \\\\to ( z , \\\\pi \\_ { f } )$ evaluates the polynomial $y\
              \ = f ( \\\\mathbf { X } )$ on a point x and generate a proof $\\\\\
              pi \\_ { f }$ ;\\\n\\\n• Verify $( \\\\mathsf { c o m } \\_ { f } ,\
              \ \\\\mathbf { x } , z , \\\\pi \\_ { f } , \\\\mathsf { p p } ) \\\\\
              to b \\\\in { 1 , 0 }$ is a protocol between the prover $\\\\mathcal\
              \ { P }$ and verifier $\\\\nu$ , verifying whether $f ( \\\\mathbf {\
              \ x } )$ is $z$ through pp, ${ \\\\mathsf { c o m } } \\_ { f }$ and\
              \ $\\\\pi \\_ { f }$ ;\\\n\\\nwhich satisfies the following properties:\\\
              \n\\\n• Completeness. For any polynomial $f \\\\in { \\\\mathcal { F\
              \ } }$ and $\\\\mathbf { x } \\\\in \\\\mathbb { F } ^ { \\\\mu }$ ,\
              \ the following probability is 1.\\\n\\\n$$\\\n\\\\begin{array} { r\
              \ } { \\\\mathrm { p p } \\\\mathsf { K e y G e n } ( 1 ^ { \\\\lambda\
              \ } , \\\\mathcal { F } ) } \\ { \\\\mathrm { P r } \\[ \\\\mathsf {\
              \ V e r i f y } ( \\\\mathsf { c o m } \\_ { f } , \\\\mathbf { x }\
              \ , z , \\\\pi \\_ { h } , \\\\mathsf { p p } ) = 1 : \\\\mathsf { c\
              \ o m } \\_ { f } \\\\mathsf { C o m m i t } ( f , \\\\mathsf { p p\
              \ } ) \\] } \\ { ( z , \\\\pi \\_ { f } ) \\\\mathsf { O p e n } ( f\
              \ , \\\\mathbf { x } , \\\\mathsf { p p } ) \\] } \\\\end{array}\\\n\
              $$\\\n\\\n• Knowledge soundness. For any PPT adversary $\\\\mathcal\
              \ { P } ^ { \\* }$ , there exists a PPT extractor $\\\\mathcal { E }$\
              \ with access to ${ \\\\mathcal { P } } ^ { \\* } { \\\\boldsymbol {\
              \ \\\\mathbf { \\\\mathit { s } } } }$ messages during the protocol,\
              \ the following probability is negl $( \\\\lambda )$ .\\\n\\\n$$\\\n\
              \\\\begin{array} { r l } { \\\\mathrm { P r } } & { \\\\overset { \\\
              \\mathsf { V e r i f y } ( \\\\mathsf { c o m } ^ { \\* } , \\\\mathbf\
              \ { x } ^ { \\* } , z ^ { \\* } , \\\\boldsymbol { \\\\pi } ^ { \\*\
              \ } , \\\\mathsf { p p } ) = 1 } { \\\\mathsf { P p } } \\\\overset\
              \ { } { \\\\sim } \\\\mathsf { K e y G e n } ( 1 ^ { \\\\lambda } ,\
              \ \\\\mathcal { F } ) } \\ { \\\\quad \\\\wedge \\\\mathsf { c o m }\
              \ ^ { \\* } = \\\\mathsf { C o m m i t } ( f ^ { \\* } , \\\\mathsf\
              \ { p p } ) : ( z ^ { \\* } , \\\\mathbf { x } ^ { \\* } ) \\\\mathcal\
              \ { P } ^ { \\* } ( 1 ^ { \\\\lambda } , \\\\mathsf { p p } ) } \\ {\
              \ \\\\wedge f ^ { \\* } ( \\\\mathbf { x } ^ { \\* } ) \\\\neq z ^ {\
              \ \\* } } & { ( c o m ^ { \\* } , \\\\boldsymbol { \\\\pi } ^ { \\*\
              \ } ) \\\\mathcal { P } ^ { \\* } ( 1 ^ { \\\\lambda } , \\\\mathsf\
              \ { p p } ) } \\ & { f ^ { \\* } \\\\mathcal { E } ^ { \\\\mathcal {\
              \ P } ^ { \\* } ( \\\\cdot ) } ( 1 ^ { \\\\lambda } , \\\\mathsf { p\
              \ p } ) } \\\\end{array}\\\n$$\\\n\\\nIt is worth noting that in \\\
              [BFS20\\], although they demonstrate that if the polynomial commitment\
              \ protocol satisfies witness-extended emulation, the compiled interactive\
              \ argument also inherits this knowledge property. However, they also\
              \ point out that it has been proven in \\[Lin01\\] that every knowledge\
              \ sound protocol satisfies witness-extended emulation as well.\\\n\\\
              \n# 4.3 Constraint System And Distributed Polynomial IOP Protocol\\\n\
              \\\nIn this and the following sections, we demonstrate how to construct\
              \ our distributively computable SNARK for data-parallel circuits (which\
              \ accommodate various sub-circuits) and arbitrary general circuits.\
              \ In both settings, we distribute the input and computation across $M$\
              \ machines, each capable of evaluating one subcircuit $C \\_ { i }$\
              \ of size $\\\\begin{array} { r } { T = \\\\frac { N } { M } } \\\\\
              end{array}$ locally. In this section, we first present the constraint\
              \ system, and then design an IOP protocol proving the constraints. We\
              \ prove that our IOP protocol has knowledge soundness and can be transformed\
              \ into a distributed double-efficient interactive argument of knowledge\
              \ after compiling with a distributive computable bivariate PCS. In the\
              \ next section, we will instantiate our protocol with bivariate KZG\
              \ and provide a detailed analysis of proving time, verification time,\
              \ proof size, and communication complexity.\\\n\\\nBefore diving into\
              \ the details, we first explain our intuition. We opt for the distributed\
              \ system to avoid the substantial overhead introduced by recursive proof\
              \ (see Section 4.7 for a detailed discussion). PCDand-IVC-based solutions\
              \ rely on recursive proofs because they handle each sub-circuit in a\
              \ separate proof waiting to be aggregated. Instead, we treat all sub-circuits\
              \ as a whole and exploit the succinctness of SNARK, resulting in a small\
              \ proof size and verification time. However, DIZK \\[WZCPS18\\] shows\
              \ that directly applying distribution techniques to the original univariate\
              \ SNARK system leads to linear communication costs due to the significantly\
              \ interleaving network required to run the NTT algorithm. Taking both\
              \ hazards into account, we propose a solution leveraging bivariate polynomial\
              \ constraints to both ”split” the NTT instances, avoiding substantial\
              \ communication, and ”combine” the proof for each sub-circuit as a whole,\
              \ eliminating the need for expensive aggregation costs. The details\
              \ are as follows.\\\n\\\n# 4.3.1 Arithmetic Constraint System for Each\
              \ Party\\\n\\\nOur constraint system inherits the original Plonk \\\
              [GWC19b\\]. The original Plonk works for a fan-in-two arithmetic circuit,\
              \ where each gate takes at most two inputs. In Plonk, the left input,\
              \ the right input, and the output of each gate are encoded by three\
              \ univariate polynomials respectively. The verifier can check the computation\
              \ of each gate by a polynomial equation, which we refer to as the gate\
              \ constraint. Additionally, the verifier also checks that the input\
              \ and output of the gates are connected correctly as defined by the\
              \ structure of the circuit, which we refer to as the copy constraint.\\\
              \n\\\nGate Constraint For the $i$ -th party, let $a \\_ { i , j } ,\
              \ b \\_ { i , j }$ and $o \\_ { i , j }$ be the left input, right input,\
              \ and output of gate $j$ of the sub-circuit $C \\_ { i }$ , for $j =\
              \ 0 , \\\\ldots , T - 1$ . We define a polynomials $\\\\begin{array}\
              \ { r } { a \\_ { i } ( X ) = \\\\sum \\_ { j = 0 } ^ { T - 1 } a \\\
              _ { i , j } L \\_ { j } ( X ) } \\\\end{array}$ where ${ L \\_ { j }\
              \ ( X ) } \\_ { j }$ is the Lagrange polynomials defined from the $T$\
              \ -th roots of unity. The coefficient representation of $a \\_ { i }\
              \ ( X )$ can be computed using polynomial interpolation and the complexity\
              \ is $O ( T \\\\log T )$ via NTT algorithm. Similarly, we define polynomials\
              \ $b \\_ { i } ( X )$ and $o \\_ { i } ( X )$ using $\\\\left( b \\\
              _ { i , j } \\\\right) \\_ { j }$ and $\\\\left( o \\_ { i , j } \\\\\
              right) \\_ { j }$ . If gate $j$ is an addition gate, then $a \\_ { i\
              \ , j } + b \\_ { i , j } = o \\_ { i , j }$ , and thus $a \\_ { i }\
              \ ( \\\\omega \\_ { X } ^ { j } ) + b \\_ { i } ( \\\\omega \\_ { X\
              \ } ^ { j } ) = o \\_ { i } ( \\\\omega \\_ { X } ^ { j } )$ ; if gate\
              \ $j$ is a multiplication gate, then $a \\_ { i j } \\\\cdot b \\_ {\
              \ i j } = o \\_ { i j }$ , and thus $a \\_ { i } ( \\\\omega \\_ { X\
              \ } ^ { j } ) \\\\cdot b \\_ { i } ( \\\\omega \\_ { X } ^ { j } ) =\
              \ o \\_ { i } ( \\\\omega \\_ { X } ^ { j } )$ . Following the design\
              \ of Plonk, we can write the relationship of all gates as one polynomial\
              \ in Equation 4.1.\\\n\\\n$$\\\n\\\\begin{array} { c } { { g \\_ { i\
              \ } ( X ) : = q \\_ { a , i } ( X ) a \\_ { i } ( X ) + q \\_ { b ,\
              \ i } ( X ) b \\_ { i } ( X ) + q \\_ { o , i } ( X ) o \\_ { i } (\
              \ X ) } } \\ { { { } } } \\ { { + q \\_ { a b , i } ( X ) a \\_ { i\
              \ } ( X ) b \\_ { i } ( X ) + q \\_ { c , i } ( X ) = 0 . } } \\\\end{array}\\\
              \n$$\\\n\\\nHere the polynomials $q \\_ { a , i } ( X ) , q \\_ { b\
              \ , i } ( X ) , q \\_ { o , i } ( X ) , q \\_ { a b , i } ( X ) , q\
              \ \\_ { c , i } ( X ) :$ are defined by the structure of $C \\_ { i\
              \ }$ satisfying\\\n\\\n• Addition gate: $q \\_ { a , i } ( \\\\omega\
              \ \\_ { X } ^ { j } ) = 1 , q \\_ { b , i } ( \\\\omega \\_ { X } ^\
              \ { j } ) = 1 , q \\_ { o , i } ( \\\\omega \\_ { X } ^ { j } ) = -\
              \ 1 , q \\_ { a b , i } ( \\\\omega \\_ { X } ^ { j } ) = 0 , q \\_\
              \ { c , i } ( \\\\omega \\_ { X } ^ { j } ) = 0 .$ • Multiplication\
              \ gate: $q \\_ { a , i } ( \\\\omega \\_ { X } ^ { j } ) = 0 , q \\\
              _ { b , i } ( \\\\omega \\_ { X } ^ { j } ) = 0 , q \\_ { o , i } (\
              \ \\\\omega \\_ { X } ^ { j } ) = - 1 , q \\_ { a b , i } ( \\\\omega\
              \ \\_ { X } ^ { j } ) = 1 , q \\_ { c , i } ( \\\\omega \\_ { X } ^\
              \ { j } ) = 0 .$ • Public input: $q \\_ { a , i } ( \\\\omega \\_ {\
              \ X } ^ { j } ) = 0$ , $q \\_ { b , i } ( \\\\omega \\_ { X } ^ { j\
              \ } ) = 0$ , $q \\_ { o , i } ( \\\\omega \\_ { X } ^ { j } ) = - 1$\
              \ , $q \\_ { a b , i } ( \\\\omega \\_ { X } ^ { j } ) = 0$ , $q \\\
              _ { c , i } ( \\\\omega \\_ { X } ^ { j } ) = \\\\mathsf { i n } \\\
              _ { i , j }$ if the $j$ -th gate in $C \\_ { i }$ is a public input\
              \ gate with the value of $\\\\mathsf { i n } \\_ { i , j }$ .\\\n\\\n\
              In this way, the correct evaluation of the circuit is equivalent to\
              \ Equation 4.1 being 0 for all $X \\\\in \\\\Omega \\_ { X }$ , where\
              \ $\\\\Omega \\_ { X }$ denotes the set $\\\\left{ \\\\omega \\_ { X\
              \ } ^ { 0 } , \\\\cdots , \\\\omega \\_ { X } ^ { T - 1 } \\\\right}$\\\
              \n\\\nCopy Constraint In addition to checking the gate constraint, the\
              \ verifier also needs to check that the connections of wires are correct\
              \ as defined by the circuit. In particular, there are redundancies in\
              \ the vectors $a \\_ { i , j } , b \\_ { i , j }$ and $o \\_ { i , j\
              \ }$ , since the output of one gate is the input of other gates in the\
              \ circuit. The method used in Plonk is derived from a product argument,\
              \ which can show that if a set of values ${ f \\_ { i } } \\_ { i \\\
              \\in \\\\mathbb { Z } }$ are identical, then the following two sets\
              \ are equal:\\\n\\\n$$\\\n{ ( f \\_ { i } , i ) } \\_ { i \\\\in \\\\\
              mathcal { T } } = { ( f \\_ { i } , \\\\sigma ( i ) ) } \\_ { i \\\\\
              in \\\\mathcal { T } }\\\n$$\\\n\\\nwhere $\\\\sigma$ defines a cycle\
              \ connecting all indexes. The protocol reduces the argument to 2 polynomial\
              \ equations.\\\n\\\nThe details of the permutation argument is as follows:\
              \ $\\\\forall X \\\\in \\\\Omega \\_ { X } , a \\_ { i } ( \\\\sigma\
              \ \\_ { i } ( X ) ) = a \\_ { i } ^ { \\\\prime } ( X )$ , where $a\
              \ \\_ { i } ( X )$ and $a \\_ { i } ^ { \\\\prime } ( X )$ are two univariate\
              \ polynomials in $\\\\mathbb { F }$ and $\\\\sigma \\_ { i }$ is a public\
              \ permutation from $\\\\Omega \\_ { X }$ to $\\\\Omega \\_ { X }$ .\
              \ Particularly, in the protocol checking the consistency of $a \\_ {\
              \ i } ( X ) , b \\_ { i } ( X ) , o \\_ { i } ( X )$ in the gate constraint,\
              \ given two random points $\\\\eta , \\\\gamma \\\\in \\\\mathbb { F\
              \ }$ from the verifier, the prover defines the running product polynomial\
              \ $z \\_ { i } ( X )$ on $\\\\mathbb { F }$ defined as follows:\\\n\\\
              \n$$\\\n\\\\begin{array} { r } { z \\_ { i } ( \\\\omega \\_ { X } ^\
              \ { j } ) : = \\\\prod \\_ { k = 0 } ^ { j - 1 } \\\\frac { f \\_ {\
              \ i } ( \\\\omega \\_ { X } ^ { k } ) } { f \\_ { i } ^ { \\\\prime\
              \ } ( \\\\omega \\_ { X } ^ { k } ) } } \\\\end{array}\\\n$$\\\n\\\n\
              where for simplicity, the notation of $f \\_ { i } ( X )$ and $f \\\
              _ { i } ^ { \\\\prime } ( X )$ are used to indicate\\\n\\\n$$\\\n\\\\\
              begin{array} { r l } & { f \\_ { i } ( X ) : = ( a \\_ { i } ( X ) +\
              \ \\\\eta \\\\sigma \\_ { a , i } ( X ) + \\\\gamma ) ( b \\_ { i }\
              \ ( X ) + \\\\eta \\\\sigma \\_ { b , i } ( X ) + \\\\gamma ) } \\ &\
              \ { \\\\qquad ( o \\_ { i } ( X ) + \\\\eta \\\\sigma \\_ { c , i }\
              \ ( X ) + \\\\gamma ) , } \\ & { f \\_ { i } ^ { \\\\prime } ( X ) :\
              \ = ( a \\_ { i } ( X ) + \\\\eta k \\_ { a } X + \\\\gamma ) ( b \\\
              _ { i } ( X ) + \\\\eta k \\_ { b } X + \\\\gamma ) } \\ & { \\\\qquad\
              \ ( o \\_ { i } ( X ) + \\\\eta k \\_ { o } X + \\\\gamma ) , } \\\\\
              end{array}\\\n$$\\\n\\\nwhere $k \\_ { a } = 1$ , $k \\_ { b }$ is any\
              \ quadratic non-residue, and $k \\_ { o }$ is a quadratic non-residue\
              \ not contained in $k \\_ { b } \\\\Omega \\_ { X }$ . The $j$ -th cell\
              \ in $a \\_ { i }$ , $b \\_ { i }$ , $c \\_ { i }$ is denoted by $\\\
              \\omega \\_ { X } ^ { j } , k \\_ { 1 } \\\\omega \\_ { X } ^ { j }\
              \ , k \\_ { 2 } \\\\omega \\_ { X } ^ { j }$ , respectively, and $\\\
              \\sigma \\_ { a , i } ( \\\\omega \\_ { X } ^ { j } )$ denotes the destination\
              \ that the $j$ -th cell in $a \\_ { i }$ is mapped to $( \\\\sigma \\\
              _ { b , i }$ and $\\\\sigma \\_ { c , i }$ are defined similarly). The\
              \ goal of the permutation argument is $\\\\begin{array} { r } { \\\\\
              Pi \\_ { k = 0 } ^ { T - 1 } \\\\frac { f \\_ { i } ( \\\\omega \\_\
              \ { X } ^ { k } ) } { f \\_ { i } ^ { \\\\prime } ( \\\\omega \\_ {\
              \ X } ^ { k } ) } = 1 } \\\\end{array}$\\\n\\\n$$\\\n\\\\begin{array}\
              \ { r l } & { p \\_ { i , 0 } ( X ) : = L \\_ { 0 } ( X ) ( z \\_ {\
              \ i } ( X ) - 1 ) } \\ & { p \\_ { i , 1 } ( X ) : = z \\_ { i } ( X\
              \ ) f \\_ { i } ( X ) - z \\_ { i } ( \\\\omega \\_ { X } X ) f \\_\
              \ { i } ^ { \\\\prime } ( X ) } \\\\end{array}\\\n$$\\\n\\\nwhich equals\
              \ 0 when $X \\\\in \\\\Omega \\_ { X }$ .\\\n\\\nFinally, since the\
              \ constraints $g \\_ { i } ( X ) , p \\_ { i , 0 } ( X )$ and $p \\\
              _ { i , 1 } ( X )$ all equal 0 when $X \\\\in \\\\Omega \\_ { X }$ ,\
              \ then given a random challenge $\\\\lambda$ from the verifier, there\
              \ must exist a quotient polynomial $h \\_ { i } ( X )$ satisfying\\\n\
              \\\n$$\\\ng \\_ { i } ( X ) + \\\\lambda p \\_ { i , 0 } ( X ) + \\\\\
              lambda ^ { 2 } p \\_ { i , 1 } ( X ) = V \\_ { X } ( X ) h \\_ { i }\
              \ ( X ) ,\\\n$$\\\n\\\nwhere $V \\_ { X } ( X ) = X ^ { T } - 1$ .\\\
              \n\\\nPolynomial IOP protocol for Plonk. In the original Plonk, the\
              \ IOP process sends oracles to the verifier in three rounds. Suppose\
              \ the verifier knows the structure of the circuit and have oracles of\
              \ $\\\\left{ q \\_ { { a , b , o , a b , c } } ( X ) , \\\\sigma \\\
              _ { { a , b , o } } ( X ) \\\\right}$ . In the first round, the prover\
              \ sends the polynomial oracles for $a ( X ) , b ( X ) , o ( X )$ . In\
              \ the second round, after receiving random challenge $\\\\eta , \\\\\
              gamma$ from the verifier, the prover constructs the oracle $z ( X )$\
              \ for the verifier. In the remaining round, with the randomness $\\\\\
              lambda$ from the verifier, the prover computes the quotient polynomial\
              \ $h ( X )$ and sends its oracle to the verifier. After having access\
              \ to all the oracles, the verifier queries them on a random point $X\
              \ = \\\\alpha$ and an extra point $X = \\\\omega \\_ { X } \\\\cdot\
              \ \\\\alpha$ for $z ( X )$ . With the evaluation, the verifier can verify\
              \ all the constraints.\\\n\\\n# 4.3.2 Constraint System for Data-parallel\
              \ Circuit\\\n\\\nIn this section, we show how to aggregate the polynomials\
              \ from all separated sub-circuits into a single bivariate polynomial\
              \ and remain the constraint structure. Inheriting the general-purpose\
              \ arithmetic constraints from Plonk, it is clear that we not only have\
              \ a constraint system proving data-parallel circuits but also for a\
              \ more general case: we allow the sub-circuits to be different.\\\n\\\
              \nIntuitively, we can use the powers of another variable $Y$ to randomly\
              \ combine the polynomials from different parties. For example $\\\\\
              begin{array} { r } { \\\\dot { A ( Y , X ) } = \\\\sum \\_ { i = 0 }\
              \ ^ { M - 1 } Y ^ { i } a \\_ { i } ( X ) } \\\\end{array}$ , where\
              \ $a \\_ { i } ( X )$ is hold by the $i$ -th party. However, when we\
              \ leverage this formula in the polynomial formula, such as $\\\\begin{array}\
              \ { r } { \\\\left( \\\\sum \\_ { i = 0 } ^ { M - 1 } Y ^ { i } a \\\
              _ { i } ( X ) \\\\right) \\\\left( \\\\sum \\_ { i = 0 } ^ { M - 1 }\
              \ Y ^ { i } b \\_ { i } ( X ) \\\\right) - } \\\\end{array}$ $\\\\textstyle\
              \ \\\\left( \\\\sum \\_ { i = 0 } ^ { M - 1 } Y ^ { i } c \\_ { i }\
              \ ( X ) \\\\right)$ , the cross-terms with the form $Y ^ { i } a \\\
              _ { i } ( X ) \\\\cdot Y ^ { j } b \\_ { j } ( X )$ for $i \\\\neq j$\
              \ in the expansion will be very annoying. To avoid the cross-term, instead,\
              \ we combine the polynomials with Lagrange polynomials $R \\_ { i }\
              \ ( Y )$ . This idea is inspired by a sub-scheme in the recent work\
              \ Caulk \\[ZBKMNS22\\]. In particular, for each univariate polynomial\
              \ in Equation 4.1, Equation 4.4, Equation 4.5 and Equation 4.6, i.e.,\
              \ $s \\_ { i } \\\\in { q \\_ { a , i } , q \\_ { b , i } , q \\_ {\
              \ o , i } , q \\_ { a b , i } , q \\_ { c , i } , \\\\sigma \\_ { a\
              \ , i } , \\\\sigma \\_ { b , i } , \\\\sigma \\_ { o , i } , a \\_\
              \ { i } , b \\_ { i } , o \\_ { i } , z \\_ { i } , h \\_ { i } }$ ,\
              \ we define a bivariate polynomial as\\\n\\\n$$\\\n\\\\begin{array}\
              \ { r } { S ( Y , X ) = \\\\sum \\_ { i = 0 } ^ { M - 1 } R \\_ { i\
              \ } ( Y ) s \\_ { i } ( X ) . } \\\\end{array}\\\n$$\\\n\\\nThen we\
              \ have an aggregated gate constraint:\\\n\\\n$$\\\n\\\\begin{array}\
              \ { l } { { G ( Y , X ) : = Q \\_ { a } ( Y , X ) A ( Y , X ) + Q \\\
              _ { b } ( Y , X ) B ( Y , X ) } } \\ { { \\ \\ \\\\qquad + Q \\_ { a\
              \ b } ( Y , X ) A ( Y , X ) B ( Y , X ) } } \\ { { \\ \\\\qquad + Q\
              \ \\_ { o } ( Y , X ) O ( Y , X ) + Q \\_ { c } ( Y , X ) } } \\ { {\
              \ P \\_ { 0 } ( Y , X ) : = L \\_ { 0 } ( X ) ( Z ( Y , X ) - 1 ) }\
              \ } \\ { { P \\_ { 1 } ( Y , X ) : = Z ( Y , X ) \\\\displaystyle \\\
              \\prod \\_ { S \\\\in { A , B , O } \\\\atop S \\\\in { A , B , O }\
              \ } ( S ( Y , X ) + \\\\eta \\\\sigma \\_ { a } ( Y , X ) + \\\\gamma\
              \ ) } } \\ { { \\ \\\\qquad - Z ( Y , \\\\omega \\_ { X } X ) \\\\displaystyle\
              \ \\\\prod \\_ { S \\\\in { A , B , O } } ( S ( Y , X ) + \\\\eta k\
              \ \\_ { s } X + \\\\gamma ) } } \\\\end{array}\\\n$$\\\n\\\nThen after\
              \ transforming Equation 4.6, we have\\\n\\\n$$\\\nG ( Y , X ) + \\\\\
              lambda P \\_ { 0 } ( Y , X ) + \\\\lambda ^ { 2 } P \\_ { 1 } ( Y ,\
              \ X ) - V \\_ { X } ( X ) H \\_ { X } ( Y , X )\\\n$$\\\n\\\nwhich equals\
              \ 0 for all $Y \\\\in \\\\Omega \\_ { Y }$ . It is no hard to see that\
              \ this is equivalent to Equation 4.6 holds for all $i \\\\in \\[ M \\\
              ]$ , because by the definition of the Lagrange polynomial $R \\_ { i\
              \ } ( Y )$ , there is only one non-zero term $g \\_ { i } ( X )$ , $p\
              \ \\_ { i , 0 } ( X )$ and $p \\_ { i , 1 } ( X )$ in Equation 4.6 when\
              \ $Y = \\\\omega \\_ { Y } ^ { i }$ . Therefore, evaluating Equation\
              \ 4.11 at $Y = \\\\omega \\_ { Y } ^ { i }$ is exactly the same as Equation\
              \ 4.6 for $C \\_ { i }$ .\\\n\\\nFinally, to check Equation 4.11 vanishes\
              \ on $Y \\\\in \\\\Omega \\_ { Y }$ , we compute $H \\_ { Y } ( Y ,\
              \ X )$ such that\\\n\\\n$$\\\n\\\\begin{array} { l } { G ( Y , X ) +\
              \ \\\\lambda P \\_ { 0 } ( Y , X ) + \\\\lambda ^ { 2 } P \\_ { 1 }\
              \ ( Y , X ) - V \\_ { X } ( X ) H \\_ { X } ( Y , X ) } \\ { \\ = V\
              \ \\_ { Y } ( Y ) H \\_ { Y } ( Y , X ) } \\\\end{array}\\\n$$\\\n\\\
              \nwhere $V \\_ { Y } ( Y ) = Y ^ { M } - 1$ . This concludes the bivariate\
              \ constraint system in our solution.\\\n\\\nA sketch of the distributed\
              \ IOP for the previous system. In Protocol 3, we introduce the polynomial\
              \ IOP protocol for the previous constraint system (excluding the orange\
              \ characters). From this protocol, we observe that, aside from sending\
              \ and assisting the verifier with querying the polynomial oracles, the\
              \ prover only needs to distributively maintain each oracle. We will\
              \ later prove that this property is sufficient to construct a distributed\
              \ SNARK proof generation. We also observe that this property trivially\
              \ holds for all polynomials except $H \\_ { Y } ( Y , X )$ . To circumvent\
              \ this obstacle, the prover receives an opening point $\\\\alpha$ from\
              \ the verifier and only sends the univariate oracle $H \\_ { Y } ( Y\
              \ , \\\\alpha )$ . We claim that after this modification, the protocol\
              \ remains knowledge-sound and can be distributively computed. For simplicity,\
              \ we provide the strict proof in Section 4.3.4 after explaining the\
              \ system for general circuits.\\\n\\\nRemark 4.3.1. For the witness\
              \ generation, since all sub-circuits are separated, each party can generate\
              \ its witness locally.\\\n\\\nRemark 4.3.2. Although we assume the sub-circuits\
              \ are independent of each other, it is easy to observe that if we introduce\
              \ custom gates and rotation along with the variable $Y$ , then we can\
              \ support some simple connections among different sub-circuits. In addition,\
              \ we can also introduce local lookup arguments in our constraint system.\
              \ Further discussion on custom gates and lookup arguments are in Section\
              \ 4.7.\\\n\\\n# 4.3.3 Constraint System for General Circuit\\\n\\\n\
              In this section, we show the great potential of our system by generalizing\
              \ it to generate proofs for arbitrary\\\n\\\ncircuits. Recall that in\
              \ the original Plonk, it leverages $\\\\sigma \\_ { a } ( X )$ , $\\\
              \\sigma \\_ { b } ( X )$ , and $\\\\sigma \\_ { c } ( X )$ to navigate\
              \ the next wire\\\n\\\nin the circuit with equal value, and computes\
              \ the running product polynomial $z ( X )$ as a helper polynomial $\\\
              \\begin{array} { r } { \\\\Pi \\_ { k = 0 } ^ { j - 1 } \\\\frac { f\
              \ ( \\\\omega \\_ { X } ^ { k } ) } { f ^ { \\\\prime } ( \\\\omega\
              \ \\_ { X } ^ { k } ) } = 1 } \\\\end{array}$\\\n\\\nand how to construct\
              \ the product proof through the whole circuit.\\\n\\\nSince we need\
              \ to indicate which sub-circuit the next wire locates, we define ${\
              \ ( \\\\sigma \\_ { Y , s , i } ( X ) , \\\\sigma \\_ { X , s , i }\
              \ ( X ) ) } \\_ { s \\\\in { a , b , o } }$ as: if for the $i$ -th party,\
              \ for the $j$ -th entry in the polynomial $s$ is mapped to the $i ^\
              \ { \\\\prime }$ -th party, $j ^ { \\\\prime }$ -th entry in the polynomial\
              \ $s ^ { \\\\prime }$ polynomial, then $\\\\left( \\\\sigma \\_ { Y\
              \ , s , i } ( \\\\omega \\_ { X } ^ { j } ) , \\\\sigma \\_ { X , s\
              \ , i } ( \\\\omega \\_ { X } ^ { j } ) \\\\right) = \\\\left( \\\\\
              omega \\_ { Y } ^ { i ^ { \\\\prime } } , k \\_ { s ^ { \\\\prime }\
              \ } \\\\omega \\_ { X } ^ { j ^ { \\\\prime } } \\\\right)$ Therefore,\
              \ we need to prove that\\\n\\\n$$\\\n\\\\prod \\_ { i = 0 } ^ { M -\
              \ 1 } \\\\prod \\_ { j = 0 } ^ { T - 1 } { \\\\frac { f \\_ { i } (\
              \ \\\\omega \\_ { X } ^ { j } ) } { f \\_ { i } ^ { \\\\prime } ( \\\
              \\omega \\_ { X } ^ { j } ) } } = 1\\\n$$\\\n\\\nwhere\\\n\\\n$$\\\n\
              \\\\begin{array} { c } { { f \\_ { i } ( X ) : = ( a \\_ { i } ( X )\
              \ + \\\\eta \\_ { Y } \\\\sigma \\_ { Y , a , i } ( X ) + \\\\eta \\\
              _ { X } \\\\sigma \\_ { X , a , i } ( X ) + \\\\gamma ) } } \\ { { \\\
              \ \\\\qquad ( b \\_ { i } ( X ) + \\\\eta \\_ { Y } \\\\sigma \\_ {\
              \ Y , b , i } ( X ) + \\\\eta \\_ { X } \\\\sigma \\_ { X , b , i }\
              \ ( X ) + \\\\gamma ) } } \\ { { \\ \\\\qquad ( o \\_ { i } ( X ) +\
              \ \\\\eta \\_ { Y } \\\\sigma \\_ { Y , o , i } ( X ) + \\\\eta \\_\
              \ { X } \\\\sigma \\_ { X , o , i } ( X ) + \\\\gamma ) } } \\ { { f\
              \ \\_ { i } ^ { \\\\prime } ( X ) : = ( a \\_ { i } ( X ) + \\\\eta\
              \ \\_ { Y } Y + \\\\eta \\_ { X } X + \\\\gamma ) } } \\ { { \\ \\\\\
              qquad ( b \\_ { i } ( X ) + \\\\eta \\_ { Y } Y + \\\\eta \\_ { X }\
              \ k \\_ { 1 } X + \\\\gamma ) } } \\ { { \\ \\\\qquad ( o \\_ { i }\
              \ ( X ) + \\\\eta \\_ { Y } Y + \\\\eta \\_ { X } k \\_ { 2 } X + \\\
              \\gamma ) } } \\\\end{array}\\\n$$\\\n\\\nThen we show how to construct\
              \ the constraints for the product argument. Similarly, each party remains\
              \ the running product zi(X), however for the one after the last entry,\
              \ z∗i = zi(ωT −1X ) fiω − X \x01f′ωT −1\x01 i X no longer equals 1.\
              \ Therefore, comparing with Equation 4.4 and Equation 4.5, we have the\
              \ following constraints instead:\\\n\\\n$$\\\n\\\\begin{array} { r l\
              \ } & { p \\_ { i , 0 } ( X ) : = L \\_ { 0 } ( X ) ( z \\_ { i } (\
              \ X ) - 1 ) } \\ & { p \\_ { i , 1 } ( X ) : = ( 1 - L \\_ { T - 1 }\
              \ ( X ) ) } \\ & { \\\\qquad \\\\cdot \\\\left( z \\_ { i } ( X ) f\
              \ \\_ { i } ( X ) - z \\_ { i } ( \\\\omega \\_ { X } X ) f \\_ { i\
              \ } ^ { \\\\prime } ( X ) \\\\right) } \\\\end{array}\\\n$$\\\n\\\n\
              After constructing $z \\_ { i }$ , each party will send the product\
              \ of their slices $z \\_ { i } ^ { \\* }$ to the master node, which\
              \ then generates another helper polynomial $W ( X )$ to denote the running\
              \ product through $\\\\left( z \\_ { 0 } ^ { \\\\ast } , \\\\dots ,\
              \ z \\_ { M - 1 } ^ { \\\\ast } \\\\right)$ . Therefore, we have two\
              \ more constraints that for $0 \\\\leq i < M$ :\\\n\\\n$$\\\n\\\\begin{array}\
              \ { r l } & { ~ p \\_ { i , 2 } : = w \\_ { 0 } - 1 \\\\mathrm { ~ w\
              \ h i c h ~ i s ~ 0 ~ f o r ~ a l l ~ } i } \\ & { p \\_ { i , 3 } (\
              \ X ) : = L \\_ { N - 1 } ( X ) } \\ & { ~ \\\\cdot \\\\left( w \\_\
              \ { i } z \\_ { i } ( X ) f \\_ { i } ( X ) - w \\_ { ( i + 1 ) % M\
              \ } f \\_ { i } ^ { \\\\prime } ( X ) \\\\right) } \\\\end{array}\\\n\
              $$\\\n\\\nTherefore we compute $h \\_ { i } ( X )$ and $H \\_ { X }\
              \ ( Y , X )$ through the following equation instead:\\\n\\\n$$\\\n\\\
              \\begin{array} { c } { { h \\_ { i } ( X ) = \\\\displaystyle \\\\frac\
              \ { g \\_ { i } ( X ) + \\\\lambda p \\_ { i , 0 } + \\\\lambda ^ {\
              \ 2 } p \\_ { i , 1 } + \\\\lambda ^ { 4 } p \\_ { i , 3 } } { { X }\
              \ ^ { T } - 1 } } } \\ { { { } } } \\ { { { \\\\displaystyle H \\_ {\
              \ X } ( Y , X ) = \\\\sum \\_ { i = 0 } ^ { M - 1 } R \\_ { i } ( Y\
              \ ) h \\_ { i } ( X ) } } } \\\\end{array}\\\n$$\\\n\\\nFinally, by\
              \ multiplying polynomials with $R \\_ { i } ( Y )$ , the permutation\
              \ argument becomes\\\n\\\n$$\\\n\\\\begin{array} { r l } & { P \\_ {\
              \ 0 } ( Y , X ) : = L \\_ { 0 } ( X ) ( Z ( Y , X ) - 1 ) } \\ & { P\
              \ \\_ { 1 } ( Y , X ) : = ( 1 - L \\_ { N - 1 } ( X ) ) } \\ & { \\\\\
              qquad \\\\cdot \\\\left( Z ( Y , X ) F ( Y , X ) - Z ( Y , \\\\omega\
              \ \\_ { X } X ) F ^ { \\\\prime } ( Y , X ) \\\\right) } \\ & { \\\\\
              qquad P \\_ { 2 } ( Y ) : = R \\_ { 0 } ( Y ) ( W ( Y ) - 1 ) } \\ &\
              \ { p \\_ { 3 } ( Y , X ) : = L \\_ { N - 1 } ( X ) } \\ & { \\\\qquad\
              \ \\\\cdot \\\\left( W ( Y ) Z ( Y , X ) F ( Y , X ) - W ( \\\\omega\
              \ \\_ { Y } Y ) F ^ { \\\\prime } ( Y , X ) \\\\right) } \\\\end{array}\\\
              \n$$\\\n\\\nwhere $F ( Y , X )$ and $F ^ { \\\\prime } ( Y , X )$ are\
              \ just notations to denote\\\n\\\n$$\\\n\\\\begin{array} { l } { { \\\
              \\displaystyle F ( Y , X ) : = \\\\prod \\_ { S \\\\in { A , B , O }\
              \ } ( S ( Y , X ) + \\\\eta \\_ { Y } \\\\sigma \\_ { Y , s } ( Y ,\
              \ X ) } } \\ { { \\\\displaystyle \\\\qquad + \\\\eta \\_ { X } \\\\\
              sigma \\_ { X , s } ( Y , X ) + \\\\gamma ) } } \\ { { \\\\displaystyle\
              \ F ^ { \\\\prime } ( Y , X ) : = \\\\prod \\_ { S \\\\in { A , B ,\
              \ O } } ( S ( Y , X ) + \\\\eta \\_ { Y } Y + \\\\eta \\_ { X } k \\\
              _ { s } X + \\\\gamma ) } } \\\\end{array}\\\n$$\\\n\\\nBy combining\
              \ with the same gate constraint as for data-parallel circuits, we finally\
              \ have the equation to define $H \\_ { Y } ( Y , X )$ , which concludes\
              \ our constraint system for general circuits.\\\n\\\n$$\\\n\\\\begin{array}\
              \ { l } { { G ( Y , X ) + \\\\lambda P \\_ { 0 } ( Y , X ) + \\\\lambda\
              \ ^ { 2 } P \\_ { 1 } ( Y , X ) + \\\\lambda ^ { 3 } P \\_ { 2 } ( Y\
              \ ) } } \\ { { \\ + \\\\lambda ^ { 4 } P \\_ { 3 } ( Y , X ) = V \\\
              _ { X } ( Y , X ) H \\_ { X } ( Y , X ) + V \\_ { Y } ( Y ) H \\_ {\
              \ Y } ( Y , X ) } } \\\\end{array}\\\n$$\\\n\\\n# 4.3.4 Distributedly\
              \ Computable Polynomial IOP Protocol\\\n\\\nWe present our polynomial\
              \ IOP protocol in Protocol 3. The text in orange denotes the additional\
              \ steps for general circuits. We have the following theorem:\\\n\\\n\
              Theorem 4.3.3. Protocol 3 is a polynomial IOP protocol for $\\\\mathcal\
              \ { R }$ with negligible knowledge error.\\\n\\\nThe proof is in Appendix\
              \ 4.8.\\\n\\\nTheorem 4.3.4. Protocol 3 is a Polynomial IOP protocol\
              \ that can be compiled into a distributedly computable double efficient\
              \ non-interactive proof that has witness-extended emulation, using a\
              \ distributed computable PCS, with only a constant increase in communication\
              \ and $O ( N \\\\log T + M \\\\log M )$ additional proving time compared\
              \ to the PCS used.\\\n\\\nProof. We prove the theorem as follows:\\\n\
              \\\nSecurity. In \\[BFS20\\], they provide a detailed proof demonstrating\
              \ that if the polynomial commitment scheme $\\\\Gamma$ has witness-extended\
              \ emulation, and if the $t$ -round Polynomial IOP for a relation $\\\
              \\mathcal { R }$ has negligible knowledge error, an interactive argument\
              \ for $\\\\mathcal { R }$ with witness-extended emulation exists.\\\n\
              \\\nWe present a sketch of the proof: for an arbitrary adversary prover\
              \ $\\\\mathcal { P } ^ { \\\\mathsf { I P } }$ for the $\\\\mathrm {\
              \ I P }$ scheme, we can construct an adversary prover $\\\\mathcal {\
              \ P } ^ { \\\\mathsf { I O P } }$ . With DKZG that guarantees witness-extended\
              \ emulation, it enables ${ \\\\mathcal { P } } ^ { \\* } \\| { \\\\\
              mathsf { O P } }$ to simulate the transcript with ${ \\\\mathcal { P\
              \ } } ^ { \\* } \\| { \\\\mathsf { P } }$ to extract polynomials. After\
              \ sending the oracles to $\\\\mathcal { V } \\| \\\\mathsf { O P }$\
              \ and receiving challenges, ${ \\\\mathcal { P } } \\_ { { \\\\mathsf\
              \ { I O P } } }$ can rewind the transcript with $\\\\mathcal { P } \\\
              _ { \\| \\\\mathsf { P } }$ to insert the same randomness from $\\\\\
              mathcal { V } \\_ { \\\\mathsf { I O P } }$ . Consequently, due to the\
              \ knowledge soundness of PCS, the reduction succeeds with high probability.\
              \ Then from the knowledge soundness proven in Theorem 4.3.3, an upper\
              \ bound of the knowledge error for the $\\\\mathrm { I P }$ protocol\
              \ is achieved.\\\n\\\nWe kindly refer to \\[BFS20\\] for the complete\
              \ proof.\\\n\\\nEfficiency. To analyze the extra communication, for\
              \ all polynomials except $H \\_ { Y } ( Y , X )$ and $W ( Y )$ , it\
              \ is divided into slices and stored in each party. Then with a PCS which\
              \ can generate commitments and proofs in this scenario, we can handle\
              \ all oracle constructions and queries to those polynomials. As for\
              \ $W ( Y )$ , it is computed by $\\\\mathcal { P } \\_ { 0 }$ from $z\
              \ \\_ { i } ^ { \\* }$ received from the $i$ -th parties. Therefore,\
              \ it can be easily computed from constant message exchange between each\
              \ node to the master. While the difficulty occurs when computing $H\
              \ \\_ { Y } ( Y , X )$ , instead of computing the full description,\
              \ $\\\\mathcal { P } \\_ { 0 }$ only deals with it after receiving the\
              \ first opening coordinate $X = \\\\alpha$ and computes $H \\_ { Y ,\
              \ \\\\alpha } ( Y ) = H \\_ { Y } ( Y , \\\\alpha )$ . Therefore, for\
              \ $0 \\\\leq i < M$ , $\\\\mathcal { P } \\_ { i }$ sends $s \\_ { i\
              \ } ( \\\\alpha )$ for $s \\\\in { q \\_ { a } , q \\_ { b } , q \\\
              _ { o } , q \\_ { a b } , q \\_ { c } , a , b , c , z , h \\_ { x }\
              \ }$ and recover the corresponding polynomial $S ( Y , \\\\alpha )$\
              \ , $\\\\mathcal { P } \\_ { 0 }$ can compute $G ( Y , \\\\alpha )$\
              \ , $P \\_ { { 0 , 1 , 2 , 3 } } ( Y , \\\\alpha )$ and compute $H \\\
              _ { Y , \\\\alpha } ( Y )$ according to Equation 4.23. Additionally\
              \ considering the distribution of random challenges, the compiled polynomial\
              \ IOP protocol only has a constant number of more communication than\
              \ PCS.\\\n\\\nAs for the proving time, it requires at most $O ( T \\\
              \\log T )$ together to compute $z \\_ { i } ( X ) , h \\_ { i } ( X\
              \ )$ for each party and $O ( M \\\\log M )$ for $\\\\mathcal { P } \\\
              _ { 0 }$ to compute $W ( Y )$ and $H \\_ { Y , \\\\alpha } ( Y )$ ,\
              \ the extra proving time is up to $O ( T \\\\log T +$ $M \\\\log M )$\
              \ for a single machine and $O ( N \\\\log T + M \\\\log M )$ in total.\\\
              \n\\\nProtocol 3 (Polynomial IOP for Data-parallel and General Circuits).\
              \ Suppose the circuit struc\\\n\\\nture is known by $\\\\mathcal { P\
              \ }$ and $\\\\nu$ , therefore, $\\\\nu$ knows the following oracles:\
              \ $\\\\begin{array} { r l } & { { Q \\_ { a } ( Y , X ) , Q \\_ { b\
              \ } ( Y , X ) , Q \\_ { o } ( Y , X ) , Q \\_ { a b } ( Y , X ) , Q\
              \ \\_ { c } ( X ) } . } \\ & { \\\\cdot \\\\left{ \\\\sigma \\_ { Y\
              \ , a } ( Y , X ) , \\\\sigma \\_ { Y , b } ( Y , X ) , \\\\sigma \\\
              _ { Y , o } ( Y , X ) , \\\\sigma \\_ { X , a } ( Y , X ) , \\\\sigma\
              \ \\_ { X , b } ( Y , X ) , \\\\sigma \\_ { X , o } ( Y , X ) \\\\right}\
              \ . } \\\\end{array}$\\\n\\\nWhen generating proof for a new instance,\
              \ $\\\\mathcal { P }$ and $\\\\nu$ go through the following rounds:\
              \ 1. $\\\\mathcal { P }$ sends the oracles of ${ A ( Y , X ) , B ( Y\
              \ , X ) , C ( Y , X ) } \\\\mathrm { ~ t o ~ } \\\\mathcal { V } .$\
              \ 2. After receiving $, \\\\eta \\_ { X } , \\\\gamma$ from $\\\\nu$\
              \ , $\\\\mathcal { P }$ sends the oracle of $Z ( Y , X )$ and $W ( Y\
              \ )$ to $\\\\nu$ . 3. After receiving $\\\\lambda$ from $\\\\nu$ , $\\\
              \\mathcal { P }$ computes HX(Y, X) PM−1i=0 Ri(Y ) gi(X)+λpi,0(X)+λ2pi,1(X)+λ4pi,3(X)\
              \ and sends the oracle to V . 4. After $\\\\begin{array} { r l } { \\\
              \\mathrm { r e c e i v i n g } \\\\qquad \\\\alpha \\\\qquad \\\\mathrm\
              \ { f r o m } \\\\qquad \\\\mathcal { V } , \\\\qquad \\\\mathcal {\
              \ P } \\\\qquad \\\\mathrm { c o m p u t e s } \\\\qquad H \\_ { Y ,\
              \ \\\\alpha } ( Y ) } & { { } = \\\\mathrm { i n d } \\\\mathrm { f\
              \ r o m } \\\\qquad \\\\mathrm { i n d } \\\\mathrm { f r o m } } \\\
              \ { \\\\frac { \\\\lambda P \\_ { 0 } ( Y , \\\\alpha ) + \\\\lambda\
              \ ^ { 2 } P \\_ { 1 } ( Y , \\\\alpha ) + \\\\lambda ^ { 3 } P \\_ {\
              \ 2 } ( Y ) + \\\\lambda ^ { 4 } P \\_ { 3 } ( Y , \\\\alpha ) - ( \\\
              \\alpha ^ { T } - 1 ) H \\_ { X } ( Y , \\\\alpha ) } { Y ^ { M } -\
              \ 1 } \\\\mathrm { a n d ~ s e n d s ~ t h e ~ o r a c l e ~ t o ~ }\
              \ \\\\mathcal { V } . } \\\\end{array}$ 5. $\\\\nu$ queries all oracles\
              \ on $X = \\\\alpha , Y = \\\\beta$ and assign the evaluations to the\
              \ corresponding polynomials in Equation 4.12 or Equation 4.23. If this\
              \ equation holds, then $\\\\nu$ output 1, otherwise 0.\\\n\\\n# 4.4\
              \ Fully Distributed SNARK\\\n\\\nIn Theorem 4.3.4, we show that with\
              \ a distributed PCS, we can build a fully distributed double-efficient\
              \ interactive argument of knowledge protocol from distributed polynomial\
              \ IOP. In this section, we instantiate Theorem 4.3.4 by a distributed\
              \ bivariate KZG.\\\n\\\n# 4.4.1 Distributed KZG\\\n\\\nIn this section,\
              \ we present a distributedly computable PCS based on a bivariate variant\
              \ the KZG scheme in \\[KZG; PST13\\].\\\n\\\nIn our distributed setting,\
              \ the total size of the polynomial is $N$ , and there are $M$ machines\
              \ of $\\\\mathcal { P } \\_ { 0 } , \\\\cdots , \\\\mathcal { P } \\\
              _ { M - 1 }$ with part of the polynomial on each machine of size $T\
              \ = N / M$ . The goal of the fully distributed polynomial commitments\
              \ is to accelerate the prover time by $B$ times while keeping the communication\
              \ complexity among the machine’s minimum. Moreover, both the proof size\
              \ and the verifier time should remain the same as the original polynomial\
              \ commitment schemes. We present the distributed protocol in Protocol\
              \ 4.\\\n\\\nTheorem 4.4.1. Given polynomial $f ( Y , X ) \\\\in \\\\\
              mathbb { F } ^ { M } \\\\times \\\\mathbb { F } ^ { \\\\frac { N } {\
              \ M } }$ , Protocol $^ { 4 }$ is PCS satisfying completeness and knowledge\
              \ soundness. The total proving computation consists of $O ( N )$ group\
              \ operations, while $\\\\begin{array} { l } { \\\\displaystyle { { \\\
              \\cal O } \\\\left( \\\\frac { N } { M } \\\\right) } } \\\\end{array}$\
              \ group operations for each node and $\\\\begin{array} { r } { O \\\\\
              left( \\\\frac { N } { M } + M \\\\right) } \\\\end{array}$ group operations\
              \ for the master node. The total commu\\\n\\\nProtocol 4 (Distributed\
              \ Bivariate Polynomial Commitment). Suppose $\\\\mathcal { P }$ has\
              \ $M$ machines of\\\n\\\n$\\\\mathcal { P } \\_ { 0 } , \\\\cdots ,\
              \ \\\\mathcal { P } \\_ { M - 1 }$ and suppose $\\\\mathcal { P } \\\
              _ { 0 }$ is the master node. Given the bivariate polynomial $f ( Y ,\
              \ X ) \\\\quad = \\\\quad$\\\n\\\n$\\\\begin{array} { r } { \\\\sum\
              \ \\_ { i = 0 } ^ { M - 1 } f \\_ { i , j } R \\_ { i } ( Y ) L \\_\
              \ { j } ( X ) } \\\\end{array}$ , each machine holds $\\\\begin{array}\
              \ { r } { f \\_ { i } ( X ) = \\\\sum \\_ { j = 0 } ^ { T - 1 } f \\\
              _ { i , j } L \\_ { j } ( X ) } \\\\end{array}$ The protocol proceeds\
              \ as follows.\\\n\\\n• $\\\\begin{array} { r } { \\\\mathsf { D K Z\
              \ G . K e y G e n } ( \\\\mathbb { 1 } ^ { \\\\lambda } , M , T ) \\\
              \\mathrm { ~ : ~ G e n e r a t e ~ \\ p p ~ = ~ } \\\\left( g , g ^\
              \ { \\\\tau \\_ { X } } , g ^ { \\\\tau \\_ { Y } } , ( U \\_ { i ,\
              \ j } ) \\_ { 0 \\\\le i < M , } = \\\\left( g ^ { R \\_ { i } ( \\\\\
              tau \\_ { Y } ) L \\_ { j } ( \\\\tau \\_ { X } ) } \\\\right) ^ { -\
              \ 1 } \\\\right) } \\\\end{array}$ 0≤i<M, 0≤j<T with trapdoor $\\\\\
              tau \\_ { Y }$ and $\\\\tau \\_ { X }$ . Let $\\\\mathcal { P } , \\\
              \\mathcal { V }$ hold pp.\\\n\\\n• DKZG.Commit $( f , \\\\mathsf { p\
              \ p } )$ : In the commitment phase, each $\\\\mathcal { P } \\_ { i\
              \ }$ computes the commitment $\\\\begin{array} { r l } { \\\\mathsf\
              \ { c o m } \\_ { f \\_ { i } } } & { { } = } \\\\end{array}$ $\\\\\
              textstyle \\\\prod \\_ { j = 0 } ^ { T - 1 } U \\_ { i , j } ^ { f \\\
              _ { i , j } }$ and sends it to $\\\\mathcal { P } \\_ { 0 }$ , where\
              \ $f \\_ { i , j }$ is the $j$ -th entry in the evaluation representation\
              \ of $f \\_ { i } ( X )$ . After receiving commitments from others,\
              \ $\\\\mathcal { P } \\_ { 0 }$ computes $\\\\begin{array} { r } { {\
              \ \\\\mathsf { c o m } } \\_ { f } = \\\\prod \\_ { i = 0 } ^ { M -\
              \ 1 } { \\\\mathsf { c o m } } \\_ { f \\_ { i } } } \\\\end{array}$\
              \ .\\\n\\\n• $\\\\mathsf { . } \\\\mathsf { D K Z G . O p e n } ( f\
              \ , \\\\beta , \\\\alpha , \\\\mathsf { p p } ) :$ : 1. Each $\\\\mathcal\
              \ { P } \\_ { i }$ computes $f \\_ { i } ( \\\\alpha )$ and $\\\\begin{array}\
              \ { r } { q \\_ { 0 } ^ { ( i ) } ( X ) = \\\\frac { f \\_ { i } ( X\
              \ ) - f \\_ { i } ( \\\\alpha ) } { X - \\\\alpha } } \\\\end{array}$\
              \ . $\\\\mathcal { P } \\_ { i }$ computes $\\\\pi \\_ { 0 } ^ { ( i\
              \ ) } = g ^ { R \\_ { i } ( \\\\tau \\_ { Y } ) q \\_ { 0 } ^ { ( i\
              \ ) } ( \\\\tau \\_ { X } ) }$ using the public parameters and sends\
              \ $f \\_ { i } ( \\\\alpha ) , \\\\pi \\_ { 0 } ^ { ( i ) }$ to $\\\\\
              mathcal { P } \\_ { 0 }$ . 2. After receiving $\\\\left{ \\\\left( f\
              \ \\_ { i } ( \\\\alpha ) , \\\\pi \\_ { 0 } ^ { ( i ) } \\\\right)\
              \ \\\\right} \\_ { 0 \\\\leq i < M } , { \\\\mathcal { P } } \\_ { 0\
              \ }$ computes $\\\\begin{array} { r } { \\\\pi \\_ { 0 } = \\\\prod\
              \ \\_ { i = 0 } ^ { M - 1 } \\\\pi \\_ { 0 } ^ { ( i ) } } \\\\end{array}$\
              \ , and also recover $f ( Y , \\\\alpha ) =$ $\\\\begin{array} { r }\
              \ { \\\\sum \\_ { i = 0 } ^ { M - 1 } R \\_ { i } ( Y ) f \\_ { i }\
              \ ( \\\\alpha ) . } \\\\end{array}$ 3. $\\\\mathcal { P } \\_ { 0 }$\
              \ computes $f ( \\\\beta , \\\\alpha )$ and $\\\\begin{array} { r }\
              \ { q \\_ { 1 } ( Y ) ~ = ~ \\\\frac { f ( Y , \\\\alpha ) - f ( \\\\\
              beta , \\\\alpha ) } { Y - \\\\beta } } \\\\end{array}$ . $\\\\mathcal\
              \ { P } \\_ { 0 }$ computes $\\\\pi \\_ { 1 } = g ^ { q \\_ { 1 } (\
              \ \\\\tau \\_ { Y } ) }$ and sends $z =$ $f ( \\\\beta , \\\\alpha )$\
              \ and $\\\\pi \\_ { f } = ( \\\\pi \\_ { 0 } , \\\\pi \\_ { 1 } )$ to\
              \ $\\\\nu$ .\\\n\\\n• DKZG.Verify $( \\\\mathsf { c o m } \\_ { f }\
              \ , \\\\beta , \\\\alpha , z , \\\\pi \\_ { f } , \\\\mathsf { p p }\
              \ )$ : $\\\\nu$ parses $\\\\begin{array} { c c c } { { \\\\pi \\_ {\
              \ f } } } & { { = } } & { { \\\\left( \\\\pi \\_ { 0 } , \\\\pi \\_\
              \ { 1 } \\\\right) } } \\\\end{array}$ , and checks if $\\\\begin{array}\
              \ { l l } { e \\\\left( { \\\\mathsf { c o m } } \\_ { f } / g ^ { z\
              \ } , g \\\\right) } & { \\\\stackrel { ? } { = } } \\\\end{array}$\
              \ $e \\\\left( \\\\pi \\_ { 0 } , g ^ { \\\\tau \\_ { X } - \\\\alpha\
              \ } \\\\right) e \\\\left( \\\\bar { \\\\pi \\_ { 1 } } , g ^ { \\\\\
              tau \\_ { Y } - \\\\beta } \\\\right)$ . It outputs 1 if the check passes,\
              \ and 0 otherwise.\\\n\\\nnication between $\\\\mathcal { P } \\_ {\
              \ i }$ and $\\\\mathcal { P } \\_ { 0 }$ is $O ( 1 )$ . The commitment\
              \ and proof size are both $O ( 1 )$ group elements. The verification\
              \ cost is $O ( 1 )$ group operations.\\\n\\\nProof. We prove the theorm\
              \ as follows:\\\n\\\nFor security. We kindly refer to \\[ZGKPP17d\\\
              ] for a full proof of the knowledge soundness for the multivariate KZG\
              \ protocol.\\\n\\\nFor efficiency. For the proving complexity, to commit\
              \ the polynomial $f ( Y , X )$ , each prover node $\\\\mathcal { P }\
              \ \\_ { i }$ need to compute ${ \\\\mathsf { c o m } } \\_ { f \\_ {\
              \ i } }$ , which costs $\\\\begin{array} { r } { \\\\mathrm { ~ { ~\
              \ \\\\cal ~ O ~ } ~ } ( \\\\frac { N } { M } ) } \\\\end{array}$ group\
              \ operations, and the master prover products them up in $O ( M )$ group\
              \ operations. To open the polynomial on a point $( \\\\beta , \\\\alpha\
              \ )$ , each node needs to evaluate $f \\_ { i } ( \\\\alpha )$ and compute\
              \ $\\\\pi \\_ { 0 } ^ { ( i ) }$ , from which the master node derives\
              \ $f ( Y , \\\\alpha )$ , and $\\\\pi \\_ { 0 }$ , with the same number\
              \ of group operations as computing the commitment. Finally $P \\_ {\
              \ 0 }$ computes $\\\\pi \\_ { 1 }$ in $O ( M )$ group operations. For\
              \ the communication, $\\\\mathcal { P } \\_ { i }$ only sends ${ \\\\\
              mathsf { c o m } } \\_ { f \\_ { i } }$ , $f \\_ { i } ( \\\\alpha )$\
              \ and $\\\\pi \\_ { 0 } ^ { ( i ) }$ to $\\\\mathcal { P } \\_ { 0 }$\
              \ , and receives random challenge $\\\\alpha$ from $\\\\mathcal { P\
              \ } \\_ { 0 }$ , thus the communication complexity is constant. It is\
              \ easy to observe that the proof size and verification time are both\
              \ constant.\\\n\\\n# 4.4.2 Using DKZG to Compile Protocol 3\\\n\\\n\
              We show our full instantiation in Protocol 5. From this protocol, we\
              \ have the following theorem for general circuits, which implies the\
              \ security and efficiency of the data-parallel setting.\\\n\\\nTheorem\
              \ 4.4.2. Given a general circuit $C$ with $N$ gates, Protocol 5 is a\
              \ double-efficient public-coin interactive argument of knowledge protocol\
              \ with witness-extended emulation for the relation of $C ( \\\\mathbb\
              \ { x } ; \\\\mathbb { w } ) = 1$ when splitting $C$ into $M$ parts\
              \ $( C \\_ { 0 } , \\\\dots , C \\_ { M - 1 } )$ each with $\\\\begin{array}\
              \ { r } { T = \\\\frac { N } { M } } \\\\end{array}$ gates. The total\
              \ proving computation consists of $O ( N \\\\log T + M \\\\log M )$\
              \ field operations and $O ( N )$ group operations, with each $\\\\mathcal\
              \ { P } \\_ { i }$ computes $O ( T \\\\log T )$ field operations and\
              \ $O ( T )$ group operations, while $\\\\mathcal { P } \\_ { 0 }$ computes\
              \ $O ( T \\\\log T + M \\\\log M )$ field operations plus $O ( M + T\
              \ )$ group operations. The communication is $O ( 1 )$ per machine. The\
              \ final proof size is $O ( 1 )$ . The verification cost is $O ( 1 )$\
              \ given the access to the commitments of the public polynomials defined\
              \ by the circuit in the preprocessing model.\\\n\\\nProof. We prove\
              \ the theorem as follows:\\\n\\\nFor security. Following the security\
              \ proof in Theorem 4.3.4, by combining the knowledge soundness of DKZG\
              \ in Theorem 4.4.1 and polynomial IOP in Theorem 4.3.3, we prove that\
              \ Protocol 5 is a double efficient public-coin interactive argument\
              \ of knowledge protocol with negligible knowledge error.\\\n\\\nFor\
              \ efficiency. The complexity for the efficiency is directly implied\
              \ by Theorem 4.3.4 and Theorem 4.4.1.\\\n\\\nSince Protocol 5 operates\
              \ in the public-coin setting, it can be transformed into a SNARK protocol\
              \ using the Fiat-Shamir transform.\\\n\\\n# 4.5 Robust Collaborative\
              \ Proving System\\\n\\\nIn the previous sections, we propose a distributed\
              \ ZKP protocol that divides the proving computation across multiple\
              \ machines and generates a constant-size proof, with constant communication\
              \ and minimal overhead in terms of proving and verification time compared\
              \ to prior work. In this section, we introduce the definition of the\
              \ Robust Collaborative Proving System (RCPS) scheme and then propose\
              \ a scheme in Protocol 5, demonstrating the potential of our protocol\
              \ in a malicious environment where each prover node might sabotage the\
              \ entire proof by intentionally generating a bad proof.\\\n\\\nDefinition\
              \ 4.5.1 (Robust Collaborative Proving System (RCPS)). Suppose for the\
              \ computation $C$ , we define a system for $M$ participants to be Robust\
              \ Collaborative Proving System (RCPS) and has the following functionalities:\\\
              \n\\\n$\\\\bullet \\\\mathsf { S e t u p } ( 1 ^ { \\\\lambda } ) \\\
              \\mathsf { p p }$\\\n\\\n• SplitCircuit $( C , M ) \\\\to { \\\\mathcal\
              \ { C } } = ( C \\_ { 0 } , \\\\dots , C \\_ { M - 1 } )$ • MasterKeyGen\
              \ $( { \\\\mathcal { C } } , M , { \\\\mathsf { p p } } ) \\\\to ( {\
              \ \\\\mathsf { m p k } } , { \\\\mathsf { v k } } )$ . • ${ \\\\mathsf\
              \ { K e y G e n } } \\_ { i } \\\\left( C \\_ { i } , { \\\\mathsf {\
              \ m p k } } \\\\right) \\\\to { \\\\mathsf { p k } } \\_ { i } .$ .\\\
              \n\\\n• SplitWitness $( C , \\\\mathfrak { x } ) \\\\to ( \\\\mathbb\
              \ { w } \\_ { 0 } , \\\\mathfrak { . . . } , \\\\mathbb { w } \\_ {\
              \ M - 1 } ) .$ $\\\\mathsf { C o P r o v e } \\_ { i } ^ { ( \\\\mathcal\
              \ { P } \\_ { 0 } ) } \\\\left( \\\\mathsf { p k } \\_ { i } , \\\\\
              mathrm { x } \\_ { i } \\\\in \\\\mathbb { x } , \\\\mathrm { w } \\\
              _ { i } \\\\right) \\\\to \\\\pi \\_ { 0 } ^ { ( i ) }$\\\n\\\n$\\\\\
              begin{array} { r l } & { \\\\mathsf { \\\\Gamma } ^ { \\\\mathsf { T\
              \ e s t } \\_ { i } } \\\\left( \\\\mathbb { x } \\_ { i } , \\\\pi\
              \ \\_ { 0 } ^ { ( i ) } , \\\\mathsf { m p k } \\\\right) \\\\to b \\\
              _ { i } \\\\in { 1 , 0 } } \\ & { } \\ & { \\\\mathsf { M e r g e }\
              \ \\\\left( \\\\left( b \\_ { 0 } , \\\\ldots , b \\_ { M - 1 } \\\\\
              right) , \\\\left( \\\\pi \\_ { 0 } ^ { ( 0 ) } , \\\\ldots , \\\\pi\
              \ \\_ { 0 } ^ { ( M - 1 ) } \\\\right) \\\\right) \\\\to \\\\pi . }\
              \ \\\\end{array}$ • Verify $( \\\\mathbb { x } , \\\\pi , \\\\mathbb\
              \ { v } \\\\mathbf { k } ) { 1 , 0 }$\\\n\\\nIt satisfies the following\
              \ properties: completeness, witness-extended emulation, partial correctness,\
              \ and partial witness-extended emulation. Because the verifier’s view\
              \ is identical to an interactive argument, we directly inherit the definition\
              \ of the completeness, witness-extended emulation in Definition 4.2.1\
              \ and only present the definition of partial correctness and witness-extended\
              \ emulation:\\\n\\\n• Partial correctness. Given pp and the circuit\
              \ partition for $C$ , for each $0 \\\\leq i < M$ , if $C \\_ { i } (\
              \ \\\\mathbb { x } \\_ { i } ; \\\\mathbb { w } \\_ { i } ) = 1$ and\
              \ $\\\\pi \\_ { 0 } ^ { ( i ) } = \\\\mathsf { C o P r o v e } \\_ {\
              \ i } ^ { ( \\\\mathcal { P } \\_ { 0 } ) } \\\\left( \\\\mathsf { p\
              \ k } \\_ { i } , \\\\mathbb { x } \\_ { i } \\\\in \\\\mathbb { x }\
              \ , \\\\mathbb { w } \\_ { i } \\\\right)$ , then\\\n\\\n$$\\\n\\\\\
              begin{array} { r } { \\\\mathrm { P r } \\\\left\\[ \\\\mathsf { T e\
              \ s t } \\_ { i } \\\\left( \\\\mathbb { x } \\_ { i } , \\\\pi \\_\
              \ { 0 } ^ { ( i ) } , \\\\mathsf { m p k } \\\\right) = 1 \\\\right\\\
              ] = 1 . } \\\\end{array}\\\n$$\\\n\\\n• Partial witness-extended emulation.\
              \ With a valid pp, a circuit partition $\\\\mathcal { C }$ for $C$ ,\
              \ with $\\| { \\\\mathcal { C } } \\| = M$ , and mpk ← MasterKeyGen\
              \ $( { \\\\mathcal { C } } , M , { \\\\mathsf { p p } } )$ , an RCPS\
              \ has partial witness-extended emulation if that: for each $0 \\\\leq\
              \ i < M$ , and any PPT adversary $A \\_ { i }$ , there exists a PPT\
              \ extractor $\\\\mathcal { E } \\_ { i }$ with access to $A \\_ { i\
              \ }$ ’s messages during the protocol such that $( \\\\mathbb { x } \\\
              _ { i } , \\\\mathsf { a u x } \\_ { i } ) \\\\gets \\\\mathcal { A\
              \ } \\_ { i } ( \\\\mathsf { m p k } )$ , $( \\\\mathbb { w } \\_ {\
              \ i } , \\\\mathsf { t r } \\_ { i } ) \\\\gets \\\\mathcal { E } \\\
              _ { i } ^ { \\\\mathcal { A } \\_ { i } ( \\\\mathsf { a u x } \\_ {\
              \ i } ) } ( \\\\mathbb { x } \\_ { i } , \\\\mathsf { m p k } )$ , and\\\
              \n\\\n$$\\\n\\\\begin{array} { r l } & { \\\\mathrm { \\| P r } \\\\\
              left\\[ \\\\mathcal { A } \\_ { i } ( \\\\mathsf { a u x } \\_ { i }\
              \ ; \\\\mathsf { t r } \\_ { i } ) = 1 \\\\wedge \\\\mathsf { t r }\
              \ i s a c c e p t i n g \\\\Rightarrow C \\_ { i } ( \\\\mathtt { x\
              \ } \\_ { i } , \\\\mathtt { w } \\_ { i } ) = 1 \\\\right\\] } \\ &\
              \ { - \\\\mathrm { \\\\normalfont ~ P r } \\\\left\\[ \\\\mathcal {\
              \ A } \\_ { i } ( \\\\mathsf { a u x } \\_ { i } ; \\\\mathsf { t r\
              \ } \\_ { i } ) = 1 \\\\right\\] \\| \\\\leq \\\\mathsf { n e g } \\\
              | ( \\\\boldsymbol \\\\lambda ) } \\\\end{array}\\\n$$\\\n\\\nWe further\
              \ show that with additional verification, our protocol for data-parallel\
              \ circuits is an RCPS. The full protocol is presented in Protocol 5\
              \ and after receiving the partial proofs and messages from $P \\_ {\
              \ i }$ , $P \\_ { 0 }$ performs the checks at the end of Step 4). In\
              \ this way, the protocol is secure in the presence of malicious machines.\
              \ $P \\_ { 0 }$ can identify the cheating party and exclude her from\
              \ the final proof.\\\n\\\nTheorem 4.5.2. For a data-parallel circuit\
              \ $C$ consisting of $M$ independent sub-circuits, Protocol 5 is an RCPS\
              \ with completeness, witness-extended emulation, partial correctness,\
              \ and partial witness-extended emulation.\\\n\\\nPlease refer to the\
              \ proof in Appendix 4.9.\\\n\\\n# 4.6 Experiments\\\n\\\nWe have implemented\
              \ the fully distributed ZKP system, Pianist and we present the implementation\
              \ details and evaluation results in this section.\\\n\\\nSoftware and\
              \ hardware. Our implementation is based on the Gnark \\[Gna\\] library\
              \ written by Golang. Our scheme is implemented using $3 7 0 0 +$ lines\
              \ of code in Go. The bilinear map is instantiated using a BN254 curve.\
              \ It provides around 100 bits of security and the pairing instruction\
              \ is supported in Solidity, the programming language of Ethereum smart\
              \ contracts. The experiments were executed on AWS m6i.16xlarge machines\
              \ with 64 vCPUs and 256 GiB memory. We used the multi-threading enabled\
              \ by the Gnark library. We opened 2–64 machines over the two regions\
              \ of California and Oregon.\\\n\\\nDesign of the experiments. The goal\
              \ of the experiments is to evaluate and demonstrate the following three\
              \ advantages of Pianist:\\\n\\\n1. Linear scalability: we measure the\
              \ running time and memory usage and demonstrate that Pianist has linear\
              \ scalability in the number of machines. The running time decreases\
              \ linearly as the machine number grows. The maximum size of the circuit\
              \ supported by the system grows linearly with the number of machines.\\\
              \n2. Minimum communication and synchronization: we measure the communication\
              \ between the machines to demonstrate that Pianist only incurs $O (\
              \ 1 )$ communication per machine in $O ( 1 )$ round.\\\n3. Constant\
              \ proof size and verifier time: we report the proof size and the verifier\
              \ time and show that they remain small in practice.\\\n\\\nThese three\
              \ properties are critical for blockchain applications where with our\
              \ new system, users can contribute to ZKP generations in these applications\
              \ in a model similar to mining pools.\\\n\\\n# 4.6.1 Evaluations of\
              \ Pianist for zkRollups\\\n\\\nWe first present the performance of Pianist\
              \ on data-parallel circuits in the application of zkRollups. We use\
              \ the rollup circuit by Polygon Hermez \\[Her\\]. The circuit is compiled\
              \ using Circom \\[Cira\\] and the output format is the rank-1-constraint-system\
              \ (R1CS). As Pianist and the original Plonk do not support R1CS directly,\
              \ we further compile the R1CS to Gnark’s Plonk constraint. The number\
              \ of R1CS constraints is about 86k per transaction and the final Plonk\
              \ circuit we use in our experiments is about $6 6 0 \\\\mathrm { k }$\
              \ per transaction. This transformation introduces a big overhead compared\
              \ to manually designed circuits. In practice, the size of the Plonk\
              \ circuit can be reduced significantly with special gates and lookup\
              \ arguments. For example, Scroll \\[Scr\\] designed more than 2000 custom\
              \ gates for the zkEVM circuit. Unfortunately, we could not find any\
              \ opensource code of the Plonk circuit for zkRollups (even with custom\
              \ gates). However, the big overhead of the transformation does not defeat\
              \ the purpose of our experiments. No matter how many transactions can\
              \ be supported on a single machine, we show that Pianist can scale it\
              \ to $M$ times more using $M$ machines with small communication.\\\n\
              \\\nProver time. We run our distributed proof generation on 2-64 machines\
              \ and Figure 4.1 shows the result. The $x$ -axis is the number of transactions\
              \ to batch in the zkRollups and the $y$ -axis is the prover time. We\
              \ report the prover time of each $\\\\mathcal { P } \\_ { i }$ in our\
              \ scheme and the running time of the original Plonk scheme on a single\
              \ machine as a baseline. We introduced additional optimizations to Plonk\
              \ on a single machine to improve the memory usage, and the performance\
              \ shown in all of our experiments are based on the optimized version.\
              \ We run each case to the maximum number of transactions until the machines\
              \ run out of memory. As shown in the figure, with 64 machines, Pianist\
              \ can prove up to 8192 transactions in 313s, while the original Plonk\
              \ can only scale to 32 transactions with a prover time of 95s. The number\
              \ of transactions and thus the maximum circuit size scales linearly\
              \ in the number of machines. Moreover, given a fixed number of transactions,\
              \ the prover time is accelerated by the number of machines. For example,\
              \ it only takes 17.5s to prove 32 transactions using 4 machines, $5\
              \ . 4 \\\\times$ faster than on a single machine. In addition, the additional\
              \ time on $P \\_ { 0 }$ to generate the final proof is only 2-16ms in\
              \ all of our experiments, which is extremely fast compared to the prover\
              \ time of each machine.\\\n\\\nConstant communication, proof size, and\
              \ verifier time. In our experiments, each machine only sends 1984 bytes\
              \ of messages for data-parallel circuits (or 2080 for general circuits)\
              \ in 4 rounds to the master node and receives 160 bytes for data-parallel\
              \ (or 256 for general) circuits from the master node, regardless of\
              \ the total number of machines. Because of this, the bandwidth and the\
              \ network delay of the machines do not affect the results at all. This\
              \ feature enables large-scale zkRollups with the help of users globally\
              \ in a model similar to a mining pool, as the nodes do not have to stay\
              \ online and deal with massive communication with other nodes in a Map-Reduce\
              \ framework as in \\[WZCPS18\\]. The proof size is $2 7 \\\\mathbb {\
              \ G } \\_ { 1 }$ (or 34 for general circuits) and 15 (or 20 for general\
              \ circuits) $\\\\mathbb { F }$ elements (2208 bytes or 2816 for general\
              \ circuits) and the verifier time is $3 . 5 \\\\mathrm { m s }$ in all\
              \ cases regardless of the number of transactions. Compared to the original\
              \ Plonk, we use bivariate polynomials, which increase the proof size\
              \ by 18 (or 25 for general circuits) $\\\\mathbb { G } \\_ { 1 }$ ,\
              \ 7 (or 12 for general circuits) $\\\\mathbb { F }$ elements, and the\
              \ verifier time by two pairings.\\\n\\\n# 4.6.2 Evaluations on General\
              \ Circuits\\\n\\\nIn this section, we further demonstrate that Pianist\
              \ supports the distributed proof generation of general circuits with\
              \ arbitrary connections. We vary the total size of the circuit from\
              \ $2 ^ { 2 1 }$ to $2 ^ { \\\\bar { 2 } 5 }$ , and randomly sample the\
              \ type and the connection of each gate. The circuit is evaluated and\
              \ the witness is distributed evenly to multiple machines. In practice,\
              \ the memory usage of the circuit evaluation is not the bottleneck and\
              \ the evaluation of the entire circuit can be executed on each machine\
              \ individually.\\\n\\\nProver time. In Figure 4.2, the $x$ -axis is\
              \ the number of machines and the $y \\\\cdot$ -axis is the prover time\
              \ of each machine $P \\_ { i }$ . As shown in the Figure, the running\
              \ time is decreasing with the number of machines. In particular, for\
              \ a random circuit of size $\\\\bar { 2 } ^ { 2 5 }$ , it takes 121s\
              \ to generate the proof using Plonk on a single machine (with our optimizations),\
              \ while it takes 76.9s on 2 machines in Pianist, $1 . 5 7 \\\\times$\
              \ faster than Plonk. It is further reduced to 5s using 32 machines,\
              \ which is $2 4 . 2 \\\\times$ faster than Plonk.\\\n\\\nIn addition,\
              \ Table 4.2 shows the additional time on $P \\_ { 0 }$ to merge proofs\
              \ and messages from $P \\_ { i } \\\\mathbf { s }$ . As shown in the\
              \ table, this step only takes several milliseconds in all instances.\\\
              \n\\\nOverhead vs. Plonk To show that the overhead of proving time between\
              \ Pianist and Plonk, we illustrate the case with the same circuit size\
              \ as $2 ^ { 2 1 }$ per instance in Figure 4.4. From this result, we\
              \ show that the overhead of Pianist is negligible.\\\n\\\nMemory usage.\
              \ Figure 4.3 shows the memory usage of the machines. As shown in the\
              \ figure, in Pianist, the memory usage on each machine decreases with\
              \ the number of machines. For example, for a circuit of size $2 ^ {\
              \ 2 4 }$ , it takes $7 0 . 7 \\\\mathrm { G B }$ of memory to run the\
              \ original protocol on a single machine, while it only takes 31.7GB\
              \ on each machine to run Pianist using two machines. It is further improved\
              \ to 1.92GB using 32 machines, which is $3 6 . 8 \\\\times$ smaller\
              \ than Plonk. The improvement is critical for zkRollups and zkEVM as\
              \ the memory consumption of existing ZKP systems is large. Pianist is\
              \ able to increase the scalability of these schemes linearly in the\
              \ number of machines, thus batching more transactions in one ZKP with\
              \ the help of the fully distributed proof generations.\\\n\\\nCommunication,\
              \ proof size, and verifier time. Similar to the case of data-parallel\
              \ circuits, they all remain $O ( 1 )$ for general circuits. In particular,\
              \ the communication is 2336 bytes per machine, the proof size is 2816\
              \ bytes and the verifier time is $3 \\\\mathrm { m s }$ .\\\n\\\nTable\
              \ 4.2: Extra time to merge proofs on $\\\\mathcal { P } \\_ { 0 }$\\\
              \n\\\n|     |     |     |     |\\\n| --- | --- | --- | --- |\\\n| Circuit\
              \ Size | 8 Nodes | 16 Nodes | 32 Nodes |\\\n| 221 | 2.764 ms | 3.576ms\
              \ | 4.629ms |\\\n| 222 | 2.975 ms | 3.666ms | 4.800ms |\\\n| 223 | 3.073\
              \ ms | 3.687ms | 5.009ms |\\\n| 224 | 3.120 ms | 3.692ms | 5.705ms |\\\
              \n\\\n# 4.7 Discussions\\\n\\\nComparison with PCD and IVC As highlighted\
              \ in Section 4.1.1, Proof-Carrying Data (PCD)\\[CT10; BCCT13\\] generates\
              \ a proof at each step for newly received transactions. To ensure the\
              \ correctness of previous proofs, there are two approaches: either aggregating\
              \ a recursive proof for the previous succinct verification circuits\
              \ in the current proof\\[BCCT13; BSCTV14b; COS20\\], or merging each\
              \ proof into an accumulator and verifying them all at once \\[BCMS20;\
              \ Hal; BCLMS20; KST22; KS22\\]. By using either the aggregated verification\
              \ circuit or the accumulator, the prover does not need to store the\
              \ entire circuit, making these methods suitable alternatives when memory\
              \ is limited.\\\n\\\nNonetheless, these techniques share some common\
              \ drawbacks. First, they all utilize recursive proofs, which depend\
              \ on the assumption that the random oracle (RO) used in the Fiat-Shamir\
              \ transform can be efficiently instantiated. Second, their proofs are\
              \ generated sequentially, potentially imposing an upper bound on TPS.\
              \ Third, either the succinct verification aggregation or the accumulator\
              \ demands extra effort from the prover, which will at least increase\
              \ linearly as the number of steps grows, resulting in reduced practical\
              \ performance. Our work, on the other hand, avoids these issues since\
              \ we do not employ recursive proofs.\\\n\\\nWe also mentioned Incremental\
              \ Verifiable Computation (IVC) for incrementally verifying stages of\
              \ longrun computation, such as Nova \\[KST22\\] and SuperNova \\[KS22\\\
              ]. While Nova and SuperNova are suitable for real-world applications\
              \ like zkRollups and zkEVM, they expose the output of each stage, which\
              \ cannot guarantee a zero-knowledge property throughout the entire process.\
              \ We argue that our work not only supports general circuits, offering\
              \ a more powerful computation model but can also achieve zero-knowledge\
              \ properties using common techniques.\\\n\\\nComparison with aPlonk\
              \ \\[ABST22\\] In Section 4.1.1, we mentioned an alternative solution,\
              \ aPlonk, which is based on Plonk and generalized IPA under the same\
              \ settings (distributed, shared Fiat-Shamir randomness) as our approach.\
              \ However, due to the use of IPA, their final verification cost is logarithmic\
              \ with respect to the number of parties. Additionally, they only propose\
              \ a solution for data-parallel circuits and their solution involves\
              \ recursive proofs. In contrast, our proof does not require recursive\
              \ circuits, our verification cost is independent of the number of parties,\
              \ and our approach is more flexible when generalizing to circuits with\
              \ connections and general circuits. Consequently, our solution delivers\
              \ better performance, both theoretically and practically.\\\n\\\nCustom\
              \ gates. A key advantage of the Plonk scheme lies in its support for\
              \ custom gates. Users can define their own gate constraints, differing\
              \ from Equation 4.1, by altering term forms and introducing rotations.\
              \ Custom gates may increase the degree and total number of terms in\
              \ Equation 4.1, but typically reduce the overall gate count in the circuit,\
              \ leading to significant improvements in prover time in practice. As\
              \ mentioned earlier, Scroll \\[Scr\\] designed over 2000 custom gates\
              \ to enhance Plonk’s performance in their zkEVM implementation. Our\
              \ new schemes are fully compatible with custom gates by following the\
              \ outline introduced in Section 4.3.\\\n\\\nAdditionally, as mentioned\
              \ in Section 4.3, rotations can be introduced for the variable $Y$ ,\
              \ and simple, regular connections among different sub-circuits can be\
              \ established based on the data-parallel setting. For instance, in a\
              \ zkEVM context, if we treat a block of instructions as a sub-circuit,\
              \ we can define the constraint $S \\_ { \\\\mathsf { p c } } ( X ) f\
              \ \\_ { \\\\mathsf { p c } } ( Y , X ) + \\\\Delta = S \\_ { \\\\mathsf\
              \ { p c } } ( X ) f \\_ { \\\\mathsf { p c } } ( \\\\omega \\_ { Y }\
              \ Y , X )$ to represent the program counter change between the previous\
              \ and current blocks, where $S \\_ { \\\\mathsf { p c } } ( X )$ serves\
              \ as a selector to indicate the row recording the program counter.\\\
              \n\\\nLookup arguments. Lookup arguments play a crucial role in the\
              \ implementation of zkRollups and zkEVM, as they help construct proofs\
              \ for RAM and chiplet computations. Since these lookup arguments are\
              \ compiled into polynomial equations, we assert that they are compatible\
              \ with our system. We can identify two primary use cases for lookup\
              \ arguments:\\\n\\\n1. Lookup arguments with local tables. In this scenario,\
              \ each sub-circuit possesses its own lookup arguments, independent of\
              \ other sub-circuits. This setup is well-suited for situations where\
              \ each machine runs a program with its local memory, for example.\\\n\
              \\\n2. Lookup arguments with global tables. This configuration allows\
              \ applications to define global lookup tables, such as range tables\
              \ or chiplet computing. We argue that, by leveraging the latest lookup\
              \ argument research \\[Hab22; EFG22\\] based on logarithmic derivatives,\
              \ this can be easily implemented. These protocols eliminate the need\
              \ for cumbersome permutations of input and table vectors, requiring\
              \ only the counting of occurrences and the execution of a sumcheck protocol.\
              \ Furthermore, by employing rotation on the variable $Y$ , global tables\
              \ can be distributed across different machines, thus reducing the workload\
              \ for the master node.\\\n\\\n\\\nProtocol 5 (Distributedly Computable\
              \ Double-efficient Public-coin Interactive Argument of Knowledge). $\\\
              \\mathcal { P }$ is a prover with $M$ machines of $\\\\mathcal { P }\
              \ \\_ { 0 } , \\\\cdots , \\\\mathcal { P } \\_ { M - 1 }$ , with master\
              \ node $\\\\mathcal { P } \\_ { 0 }$ . Given a fan-in two arithmetic\
              \ circuit $C$ of size $N$ with $M$ sub-circuits, each of size $T = N\
              \ / M$ . $\\\\mathcal { P }$ wants to convince $\\\\nu$ that $C \\_\
              \ { i } \\\\left( \\\\mathbb { x } ^ { ( i ) } ; \\\\mathbb { w } ^\
              \ { ( i ) } \\\\right) = 1$ for all $i \\\\in \\[ M \\]$ , where $\\\
              \\mathbf { \\\\boldsymbol { \\\\mathrm { x } } } ^ { ( i ) }$ is the\
              \ public input and $\\\\mathbb { w } ^ { ( i ) }$ is the witness of\
              \ $C \\_ { i }$ . Each $\\\\mathcal { P } \\_ { i }$ holds the sub-circuit\
              \ $C \\_ { i }$ .\\\n\\\n• Key generation and preprocessing procedure:\
              \ Let $\\\\begin{array} { c c l } { { ( { \\\\sf p } { \\\\sf k } }\
              \ } & { { = } } & { { \\\\left{ { \\\\sf p } { \\\\sf k } \\_ { i }\
              \ \\\\right} \\_ { 0 \\\\leq i < M } , { \\\\sf v } { \\\\sf k } ) }\
              \ } \\\\end{array}$ . Run ${ \\\\mathsf { D K Z G . K e y G e n } (\
              \ 1 \\\\mathsf { \\\\Sigma } ^ { \\\\lambda } , M , T ) }$ and generate\
              \ g, $g ^ { \\\\tau \\_ { X } }$ , $\\\\begin{array} { r c l r } { g\
              \ ^ { \\\\tau \\_ { Y } } , \\\\textbf { U } } & { = } & { ( \\\\mathbf\
              \ { U \\_ { i } } ) \\_ { 0 \\\\leq i < M } = \\ \\\\left( g ^ { R \\\
              _ { i } ( \\\\tau \\_ { Y } ) L \\_ { j } ( \\\\tau \\_ { X } ) } \\\
              \\right) \\_ { 0 \\\\leq i < M } , } \\\\end{array}$ )\x110 i<M , and\
              \ derive V = $\\\\begin{array} { l l l } { \\\\mathbf { V } } & { =\
              \ } & { \\\\left( g ^ { R \\_ { i } ( \\\\tau \\_ { Y } ) } \\\\right)\
              \ \\_ { 0 \\\\leq i < M } } \\\\end{array}$ Compute commitments ${ \\\
              \\mathsf { c o m } } \\_ { S }$ for each of the following polynomial\
              \ set $ { \\\\mathcal { S } } \\_ { \\\\mathsf { p p } }$ : $\\\\begin{array}\
              \ { r l r } { S \\_ { \\\\mathsf { p p } } ^ { - - \\\\sigma ^ { \\\
              * } } } & { = } & { { Q \\_ { a } ( Y , X ) , Q \\_ { b } ( Y , X )\
              \ , Q \\_ { o } ( Y , X ) , Q \\_ { a b } ( Y , X ) , Q \\_ { c } (\
              \ Y , X ) , } \\\\end{array}$ σY,a(Y, X), σY,b(Y, X), σY,o(Y, X),σX,a(Y,\
              \ X), σX,b(Y, X), σX,o(Y, X)} Let $s \\_ { i } ( X )$ be defined by\
              \ $S ( Y , X )$ $=$ $\\\\sum \\_ { i = 0 } ^ { M - 1 } R \\_ { i } (\
              \ Y ) s \\_ { i } ( X )$ , we define pk0 \x10V, U0, {s0(X)}S∈Spp $\\\
              \\begin{array} { r l r } { \\\\mathsf { p } \\\\mathsf { k } \\_ { i\
              \ } } & { { } \\ = \\ } & { \\\\Big ( \\\\mathbf { U } \\_ { i } , {\
              \ s \\_ { i } ( X ) } \\_ { S \\\\in \\\\mathcal { S } \\_ { \\\\mathsf\
              \ { p p } } } \\\\Big ) } \\\\end{array}$ vk $=$ $\\\\left( g ^ { \\\
              \\tau \\_ { X } } , g ^ { \\\\tau \\_ { Y } } , { \\\\mathsf { c o m\
              \ } \\_ { S } } \\_ { S \\\\in { \\\\cal S } \\_ { \\\\mathsf { p p\
              \ } } } \\\\right)$\\\n\\\n# • Proving procedure:\\\n\\\n1. Each $\\\
              \\mathcal { P } \\_ { i }$ evaluates $C \\_ { i }$ and defines polynomials\
              \ $a \\_ { i } ( X )$ , $b \\_ { i } ( X )$ , $o \\_ { i } ( X )$ .\
              \ $\\\\mathcal { P }$ invokes the distributed algorithm Commit in Protocol\
              \ 4 to obtain ${ \\\\mathsf { c o m } } \\_ { A }$ , $\\\\mathsf { c\
              \ o m } \\_ { B }$ , ${ \\\\mathsf { c o m } } \\_ { O }$ as commitments\
              \ of $A ( Y , X ) , B ( Y , X ) , O ( Y , X )$ and sends them to $\\\
              \\nu$ .\\\n\\\n2. er re com ivinutes $\\\\eta \\_ { Y } , \\\\eta \\\
              _ { X }$ $\\\\gamma$ from Then $\\\\nu$ eachinvo $\\\\mathcal { P }\
              \ \\_ { i }$ computes the Com $z \\_ { i } ( X )$ , and sends the last\
              \ entryorithm in Protocol 4 to o $\\\\cdot$ $\\\\mathcal { P } \\_ {\
              \ 0 }$ rom whichand sends $\\\\mathcal { P } \\_ { 0 }$ $\\\\begin{array}\
              \ { r } { W ( Y ) = \\\\sum \\_ { i = 0 } ^ { M - 1 } w \\_ { i } R\
              \ \\_ { i } ( Y ) } \\\\end{array}$ $\\\\mathcal { P }$ $\\\\mathsf\
              \ { c o m } \\_ { Z } ,$ $\\\\nu$\\\n\\\n3. After receiving $\\\\lambda$\
              \ from $\\\\nu$ , $\\\\mathcal { P } \\_ { 0 }$ shares it to $\\\\mathcal\
              \ { P } \\_ { i }$ . Each $\\\\mathcal { P } \\_ { i }$ computes $h\
              \ \\_ { i } ( X )$ according to Equation 4.6 or Equation 4.18. Then,\
              \ $\\\\mathcal { P }$ invokes algorithm Commit in Protocol 4 to obtain\
              \ comH = $\\\\mathsf { c o m } \\_ { H \\_ { X } } = \\\\left{ \\\\\
              mathsf { c o m } \\_ { H \\_ { X , 0 } } , \\\\mathsf { c o m } \\_\
              \ { H \\_ { X , 1 } } , \\\\mathsf { c o m } \\_ { H \\_ { X , 2 } }\
              \ , \\\\mathsf { c o m } \\_ { H \\_ { X , 3 } } \\\\right}$ as commitments\
              \ of $\\\\begin{array} { r } { H \\_ { X } ( Y , X ) = \\\\sum \\_ {\
              \ i = 0 } ^ { M - 1 } R \\_ { i } ( Y ) h \\_ { i } ( X ) } \\\\end{array}$\
              \ , and sends them to $\\\\nu$ . The form of $\\\\mathsf { c o m } \\\
              _ { H \\_ { X } }$ due to the fact that $H \\_ { X } ( Y , X )$ has\
              \ degree $3 T - 2$ $\\\\cdot$ $X$\\\n\\\n4. After receiving the random\
              \ point $\\_ \\\\alpha$ from $\\\\nu$ , $\\\\mathcal { P } \\_ { 0 }$\
              \ sends $\\_ \\\\alpha$ to each $\\\\mathcal { P } \\_ { i }$ . We define\
              \ $S \\_ { \\\\mathrm { w i t } } = { A , B , O , Z }$ Then $\\\\mathcal\
              \ { P }$ process the following computation:\\\n\\\n\\\n– for each polynomial\
              \ $S \\\\in S \\_ { \\\\mathsf { p p } } \\\\cup S \\_ { \\\\mathsf\
              \ { w i t } }$ , run Step 1 & 2 in DKZG.Open function, computing $S\
              \ ( Y , \\\\alpha )$ and the first entry of $\\\\pi \\_ { S }$ as $\\\
              \\pi \\_ { S } \\[ 0 \\]$ .\\\n\\\n– Furthermore, $\\\\mathcal { P }\
              \ \\_ { 0 }$ also recovers $Z ( Y , \\\\omega \\_ { X } \\\\cdot \\\\\
              alpha )$ and $\\\\pi \\_ { Z } ^ { \\\\prime }$ \\[0\\] when running\
              \ DKZG.Open for opening $Z ( Y , X )$ on $X = \\\\omega \\_ { X } \\\
              \\cdot \\\\alpha$ .\\\n\\\n– With all ${ S ( Y , \\\\alpha ) } \\_ {\
              \ S \\\\in { \\\\cal S } \\_ { \\\\mathrm { w i t } } \\\\cup { \\\\\
              cal S } \\_ { \\\\mathsf { p p } } }$ and $Z ( Y , \\\\omega \\_ { X\
              \ } \\\\alpha )$ , $\\\\mathcal { P }$ computes $H \\_ { Y , \\\\alpha\
              \ } ( Y )$ according to Equation 4.12 or Equation 4.23 and the univariate\
              \ commitment $\\\\mathsf { c o m } \\_ { H \\_ { Y } } ~ = ~ \\\\left{\
              \ \\\\mathsf { c o m } \\_ { H \\_ { Y , 0 } } , \\\\mathsf { c o m\
              \ } \\_ { H \\_ { Y , 1 } } , \\\\mathsf { c o m } \\_ { H \\_ { Y ,\
              \ 2 } } \\\\qquad \\\\right}$ as commitments of $H \\_ { Y } ( Y , X\
              \ ) \\ =$ $\\\\sum \\_ { i = 0 } ^ { M - 1 } h \\_ { y , \\\\alpha ,\
              \ i } R \\_ { i } ( Y )$ , and sends them to $\\\\nu$ . The degree of\
              \ $H \\_ { Y , \\\\alpha } ( Y )$ has degree $3 T - 2$ or $\\\\cdot$\
              \ with respect to $Y$ .\\\n\\\n– Finally, $\\\\mathcal { P }$ sends\
              \ ${ \\\\pi \\_ { S } \\[ 0 \\] } \\_ { S \\\\in { \\\\cal S } \\_ {\
              \ \\\\mathrm { w i t } } \\\\cup { \\\\cal S } \\_ { \\\\mathsf { p\
              \ p } } } \\\\cup \\\\left{ \\\\pi \\_ { Z } ^ { \\\\prime } \\[ 0 \\\
              ] , \\\\mathsf { c o m } \\_ { h \\_ { Y } } \\\\right} \\\\mathrm {\
              \ t o } \\\\mathcal { V } .$\\\n\\\nIn the malicious setting: $\\\\\
              mathcal { P } \\_ { i }$ for $i \\\\neq 0$ might be dishonest, $\\\\\
              mathcal { P } \\_ { 0 }$ needs to check whether the other nodes have\
              \ sent malicious proof. Since $\\\\mathcal { P } \\_ { 0 }$ has received\
              \ the commitments $\\\\left( \\\\mathsf { c o m } \\_ { s \\_ { i }\
              \ } \\\\right) \\_ { 0 \\\\leq i < M }$ for each $s \\\\in S \\_ { \\\
              \\mathrm { w i t } } \\\\cup \\\\left{ h \\_ { X , 0 } , h \\_ { X ,\
              \ 1 } , h \\_ { X , 2 } \\\\right. \\\\qquad \\\\left. \\\\begin{array}\
              \ { r l r l } \\\\end{array} \\\\right}$ and $\\\\cdot$ when distributively\
              \ committing polynomials, and the corresponding evaluations ${ s \\\
              _ { i } ( \\\\alpha ) }$ and opening proof $\\\\left{ \\\\pi \\_ { 0\
              \ , s } ^ { \\\\left( i \\\\right) } \\\\right}$ when distributively\
              \ opening the polynomials with $\\_ \\\\alpha$ , $\\\\mathcal { P }\
              \ \\_ { 0 }$ can verify Equation 4.1, Equation 4.14, Equation 4.15,\
              \ Equation 4.16, Equation 4.17 with evaluations and the following paring\
              \ check: $e ( \\\\mathsf { c o m } \\_ { s \\_ { i } } / g ^ { s \\\
              _ { i } ( \\\\alpha ) } , g ) \\\\overset { ? } { = } e ( \\\\pi \\\
              _ { 0 , s } ^ { ( i ) } , g ^ { \\\\tau \\_ { X } - \\\\alpha } )$ If\
              \ for some $i ^ { \\* }$ , the check doesn’t pass, $\\\\mathcal { P\
              \ } \\_ { 0 }$ discards all messages sent from $\\\\mathcal { P } \\\
              _ { i } { \\* }$ and replaces them with dummy messages.\\\n\\\n5. After\
              \ receiving $\\\\beta$ from $\\\\nu$ , $\\\\mathcal { P }$ executes\
              \ Step 3 in the Open algorithm in Protocol 4 to compute the evaluations\
              \ on $S ( \\\\beta , \\\\alpha )$ and $\\\\pi \\_ { S } \\[ 1 \\]$ for\
              \ $S \\\\in S \\_ { \\\\mathsf { w i t } } \\\\cup S \\_ { \\\\mathsf\
              \ { p p } }$ and $Z ( \\\\beta , \\\\omega \\_ { X } \\\\alpha )$ ,\
              \ $H \\_ { X } ( \\\\beta , \\\\alpha )$ . $\\\\mathcal { P }$ also\
              \ computes $H \\_ { Y } ( \\\\beta ) , \\\\pi \\_ { H \\_ { Y } }$ and\
              \ $W ( \\\\beta ) , \\\\pi \\_ { W }$ . In the end, $\\\\mathcal { P\
              \ }$ sends all the evaluations and proofs to $\\\\nu$ .\\\n\\\n• Verification\
              \ procedure: $\\\\nu$ verifies the following steps:\\\n\\\n1. $\\\\\
              nu$ verifies the evaluation and proof $S ( \\\\beta , \\\\alpha ) ,\
              \ \\\\pi \\_ { S }$ for $S \\\\in S \\_ { \\\\mathrm { w i t } } \\\\\
              cup S \\_ { \\\\mathsf { p p } } \\\\cup { Z ( Y , \\\\omega \\_ { X\
              \ } X ) , H \\_ { X } ( Y , X ) }$ , together with $H \\_ { Y } ( \\\
              \\beta )$ , $\\\\cdot$ with corresponding proofs by invoking the Verify\
              \ algorithm in Protocol 4.\\\n2. With the evaluations, $\\\\nu$ verifies\
              \ the gate constraint Equation 4.8.\\\n3. With the evaluations, $\\\\\
              nu$ verifies the copy constraints according to Equation 4.9, Equation\
              \ 4.10, or Equation 4.19, Equation 4.20, Equation 4.21, Equation 4.22.\\\
              \n\\\nIf all checks pass, $\\\\nu$ outputs 1; otherwise $\\\\nu$ outputs\
              \ 0.\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/c7214df7ee6acdd7569f29c3fc2a2de6b28a8854cb38bef5ad37e6fd6e00c65f.jpg)\\\
              \n\\\nFigure 4.1: Prover time of Pianist for zkRollups transaction verification.\\\
              \n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/68aa061333bd1fb5832b365ea91f0d8da8fbf0c809022807e8589a6b1d57f761.jpg)\\\
              \n\\\nFigure 4.2: Prover time of random circuits\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/e74a442ff1479c68b46e98b751d622c6557ca61819574b7bd3534905217a4858.jpg)\\\
              \n\\\nFigure 4.3: Memory consumption of random circuit\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/ab665ddecd09d3ca7cb6663ff9493282085ce7185eed0e39a29f691e750ea3de.jpg)\\\
              \n\\\nFigure 4.4: Comparison between the prover time of a single node\
              \ in Pianist and Plonk for sub-circuit with the same size\\\n\\\n# 4.8\
              \ Proof of Theorem 4.3.3\\\n\\\nTheorem 4.3.3. Protocol 3 is a Polynomial\
              \ IOP protocol with negligible knowledge error.\\\n\\\nProof. For simplicity,\
              \ we only prove the theorem in the general-circuit setting. We assume\
              \ the adversary $\\\\mathcal { P } ^ { \\* }$ has unbounded power. At\
              \ the beginning, both $\\\\mathcal { P } ^ { \\* }$ and $\\\\nu$ hold\
              \ the following precomputed polynomial set $\\\\mathcal { S } \\_ {\
              \ \\\\mathsf { p p } }$ :\\\n\\\n$$\\\n\\\\begin{array} { r l } & {\
              \ { Q \\_ { a } ( Y , X ) , Q \\_ { b } ( Y , X ) , Q \\_ { o } ( Y\
              \ , X ) , Q \\_ { a b } ( Y , X ) , Q \\_ { c } ( Y , X ) } } \\ & {\
              \ { \\\\sigma \\_ { Y , a } ( Y , X ) , \\\\sigma \\_ { Y , b } ( Y\
              \ , X ) , \\\\sigma \\_ { Y , o } ( Y , X ) \\\\sigma \\_ { X , a }\
              \ ( Y , X ) , \\\\sigma \\_ { X , b } ( Y , X ) , \\\\sigma \\_ { X\
              \ , o } ( Y , X ) } } \\\\end{array}\\\n$$\\\n\\\nWith arbitrary invalid\
              \ witness $\\\\mathbf { a } ^ { \\* } , \\\\mathbf { b } ^ { \\* } ,\
              \ \\\\mathbf { o } ^ { \\* } \\\\in \\\\mathbb { F } ^ { M \\\\times\
              \ T }$ generated by $\\\\mathcal { P } ^ { \\* }$ , the possibility\
              \ that $\\\\nu$ outputs 1 is negiligible.\\\n\\\n1. For each $\\\\mathbf\
              \ { f } \\\\in { \\\\mathbf { a } ^ { \\* } , \\\\mathbf { b } ^ { \\\
              * } , \\\\mathbf { o } ^ { \\* } }$ , $\\\\mathcal { P } ^ { \\* }$\
              \ define the polynomial $\\\\begin{array} { r } { F ( Y , X ) = \\\\\
              sum \\_ { i = 0 } ^ { M - 1 } \\\\sum \\_ { j = 0 } ^ { T - 1 } f \\\
              _ { i , j } L \\_ { j } ( X ) R \\_ { i } ( Y ) = } \\\\end{array}$\
              \ $\\\\begin{array} { r } { \\\\sum \\_ { i = 0 } ^ { M - 1 } f \\_\
              \ { i , j } L \\_ { j } ( X ) , Z ^ { \\* } ( Y , X ) } \\\\end{array}$\
              \ and $W ^ { \\* } ( Y )$ are derived from the witnesses.\\\n\\\n2.\
              \ In the round after $\\\\nu$ sends $\\\\beta$ to $\\\\mathcal { P }\
              \ ^ { \\* }$ , which is the last round, $\\\\nu$ queries all oracles\
              \ in $\\\\mathcal { S } \\_ { \\\\mathsf { p p } }$ and $S \\_ { \\\\\
              mathrm { w i t } } =$ ${ A ^ { \\* } ( Y , X ) , B ^ { \\* } ( Y , X\
              \ ) , O ^ { \\* } ( Y , X ) , Z ^ { \\* } ( Y , X ) , W ^ { \\* } (\
              \ Y ) }$ with random challenge $\\\\alpha$ and $\\\\beta$ and verifies\
              \ the Equation 4.23. Since $\\\\nu$ has received all oracles before\
              \ sending $\\\\beta$ to $\\\\mathcal { P }$ , by the Schwartz-Zipple\
              \ Lemma \\[Sch80; Zip79\\], it implies that there exists $\\\\begin{array}\
              \ { r } { Q \\_ { 0 } ( Y ) : = G \\_ { \\\\alpha } ( Y ) \\\\stackrel\
              \ { \\\\cdot } { + } \\\\sum \\_ { i = 0 } ^ { 3 } \\\\lambda ^ { i\
              \ + 1 } P \\_ { i , \\\\alpha } ( Y ) - \\\\left( \\\\alpha ^ { T }\
              \ - 1 \\\\right) H \\_ { X } ( Y , \\\\alpha ) } \\\\end{array}$ where\\\
              \n\\\n\\\n$$\\\n\\\\begin{array} { r l } & { G \\_ { \\\\alpha } ( Y\
              \ ) : = \\\\bar { G } \\_ { \\\\alpha } ( Y , \\\\alpha ) A ^ { \\\\\
              alpha } ( Y , \\\\alpha ) + \\\\bar { Q } \\_ { \\\\alpha } ( Y , \\\
              \\alpha ) B ^ { \\\\alpha } ( Y , \\\\alpha ) } \\ & { \\\\qquad + \\\
              \\bar { Q } \\_ { \\\\alpha } ( Y , \\\\alpha ) A ^ { \\\\alpha } (\
              \ Y , \\\\alpha ) B ^ { \\\\alpha } ( Y , \\\\alpha ) } \\ & { \\\\\
              qquad + \\\\bar { Q } \\_ { \\\\alpha } ( Y , \\\\alpha ) A ^ { \\\\\
              alpha } ( Y , \\\\alpha ) + \\\\bar { Q } \\_ { \\\\alpha } ( Y , \\\
              \\alpha ) } \\ & { \\\\qquad + \\\\bar { Q } \\_ { \\\\alpha } ( Y ,\
              \ \\\\alpha ) ( \\\\sigma ^ { \\\\alpha } ( Y , \\\\alpha ) + \\\\bar\
              \ { Q } \\_ { \\\\alpha } ( Y , \\\\alpha ) } \\ & { F \\_ { \\\\alpha\
              \ } ( Y ) : = \\\\bar { \\\\alpha } \\_ { 1 } ( 1 - \\\\bar { Z } \\\
              _ { \\\\alpha } ( Y , \\\\alpha ) ) - 1 } \\ & { \\\\qquad \\\\quad\
              \ + \\\\bar { Z } ^ { \\\\alpha } ( Y , \\\\alpha ) F \\_ { \\\\alpha\
              \ } ( Y ) - \\\\bar { Z } \\_ { \\\\alpha , \\\\alpha } ( Y ) F \\_\
              \ { \\\\alpha } ^ { \\\\alpha } ( Y ) } \\ & { F \\_ { \\\\alpha } (\
              \ Y ) : = \\\\bar { B } \\_ { \\\\alpha } ( Y ) ( W ^ { \\\\alpha }\
              \ ( Y ) ) - \\\\bar { Z } \\_ { \\\\alpha } ( Y , \\\\alpha ) F \\_\
              \ { \\\\alpha } ( Y ) } \\ & { \\\\qquad \\\\quad - \\\\bar { W } ^\
              \ { \\\\alpha } ( \\\\sigma ^ { \\\\alpha } ( Y ) ) \\\\bar { W } ^\
              \ { \\\\alpha } ( Y ) } \\ & { F \\_ { \\\\alpha } ( Y ) : = \\\\bar\
              \ { W } \\ : ( \\\\bar { W } ^ { \\\\alpha } ( Y ) ) \\ : \\\\bar {\
              \ F } \\_ { \\\\alpha } ( Y ) } \\ & { \\\\qquad \\\\quad - \\\\bar\
              \ { W } ^ { \\\\alpha } ( \\\\sigma ^ { \\\\alpha } ( Y , \\\\alpha\
              \ ) + \\\\bar { W } \\ : \\\\bar { \\\\sigma } \\_ { \\\\alpha } ( Y\
              \ , \\\\alpha ) ) } \\ & { \\\\qquad \\\\quad \\\\times ( \\\\bar {\
              \ A } \\_ { \\\\alpha } ( Y , \\\\alpha ) \\ : \\\\bar { F } \\_ { \\\
              \\alpha } ( Y , \\\\alpha ) + \\\\bar { Y } ) } \\ & F \\_ { \\\\alpha\
              \ } ^ { \\\\alpha } ( Y ) : = \\ : \\ : \\\\prod ^ { \\\\alpha } \\\
              \ : ( \\\\bar { B } ( X , \\\\alpha ) + \\\\bar { \\\\sigma } \\_ {\
              \ \\\\alpha } ( Y , \\ \\\\end{array}\\\n$$\\\n\\\nsuch that\\\n\\\n\
              $$\\\nQ \\_ { 0 } ( Y ) = \\\\left( Y ^ { M } - 1 \\\\right) H \\_ {\
              \ Y , \\\\alpha } ( Y )\\\n$$\\\n\\\nwhich means, for $0 \\\\leq i <\
              \ M , Q ( \\\\omega \\_ { Y } ^ { i } ) = 0$ . From the form of $F \\\
              \\in { A ^ { \\* } , B ^ { \\* } , O ^ { \\* } , Z ^ { \\* } , H \\\
              _ { X } }$ , $\\\\begin{array} { r } { F ( Y , X ) = \\\\sum \\_ { i\
              \ = 0 } ^ { M - 1 } f \\_ { i } ( X ) R \\_ { i } ( Y ) } \\\\end{array}$\
              \ and $\\\\begin{array} { r } { W ^ { \\* } ( Y ) = \\\\sum \\_ { i\
              \ = 0 } ^ { M - 1 } w \\_ { i } ^ { \\* } R \\_ { i } ( Y ) } \\\\end{array}$\
              \ , we know that for $0 \\\\leq i < M$\\\n\\\nafter assigning the value\
              \ $a \\_ { i } ^ { \\* } ( \\\\alpha ) , b \\_ { i } ^ { \\* } ( \\\\\
              alpha ) , o \\_ { i } ^ { \\* } ( \\\\alpha ) , z \\_ { i } ^ { \\*\
              \ } ( \\\\alpha ) , z \\_ { i } ^ { \\* } ( \\\\omega \\_ { X } \\\\\
              alpha )$ and $w \\_ { i }$ to the corresponding polynomials of $Y$ in\
              \ Equation 4.24, we will derive $q \\_ { 0 , i } = Q \\_ { 0 } ( \\\\\
              omega \\_ { Y } ^ { i } ) = 0$ .\\\n\\\n# In the following rounds, we\
              \ go through the proof for $0 \\\\leq i < M$ .\\\n\\\n3. In the round\
              \ after $\\\\nu$ sends $\\\\alpha$ to $\\\\mathcal { P }$ . Since $\\\
              \\nu ^ { \\* }$ has oracles for all polynomials, before sending $\\\\\
              alpha$ to $\\\\mathcal { P } ^ { \\* }$ , which is equivalent to have\
              \ oracles of $s \\_ { i } ( X ) \\\\in ( a \\_ { i } ^ { \\* } ( X )\
              \ , b \\_ { i } ^ { \\* } ( X ) , c \\_ { i } ^ { \\* } ( X ) , z \\\
              _ { i } ^ { \\* } ( X ) , h \\_ { X , i } ( X ) )$ since $s \\_ { i\
              \ } ( r ) = S ( \\\\omega \\_ { Y } ^ { i } , r )$ . In addition, $\\\
              \\nu$ has the oracle $W ( Y )$ from which he can query $w \\_ { i }\
              \ = W ( \\\\omega \\_ { Y } ^ { i } )$ . Again from the Schwartz-Zipple\
              \ Lemma, there exists $q \\_ { i } ( X ) : = g \\_ { i } ( X ) + \\\\\
              lambda p \\_ { i , 0 } ( X ) + \\\\lambda ^ { 2 } p \\_ { i , 1 } (\
              \ X ) + \\\\lambda ^ { 4 } p \\_ { i , 3 } ( X )$ , where\\\n\\\n$$\\\
              \n\\\\begin{array} { r l } & { g \\_ { i } ( X ) : = q \\_ { a , i }\
              \ ( X ) a \\_ { i } ^ { \\* } ( X ) + q \\_ { b , i } ( X ) b \\_ {\
              \ i } ^ { \\* } ( X ) + q \\_ { c , i } ( X ) } \\ & { \\\\qquad + q\
              \ \\_ { a , i } ( X ) a \\_ { i } ^ { \\* } ( X ) b \\_ { i } ^ { \\\
              * } ( X ) + q \\_ { a , i } ( X ) \\\\sigma \\_ { i } ^ { \\* } ( X\
              \ ) } \\ & { p \\_ { 0 , i } ( X ) : = L \\_ { 0 } ( X ) \\\\left( z\
              \ \\_ { i } ^ { \\* } ( X ) - 1 \\\\right) } \\ & { p \\_ { 1 , i }\
              \ ( X ) : = \\\\left( 1 - L \\_ { \\\\mathrm { N } - 1 } ( X ) \\\\\
              right) } \\ & { \\\\qquad \\\\cdot \\\\left( z \\_ { i } ^ { \\* } (\
              \ X ) f \\_ { i } ( X ) - z \\_ { i } ^ { \\* } ( x \\_ { X } ) f \\\
              _ { i } ^ { \\* } ( X ) \\\\right) } \\ & { p \\_ { 3 , i } ( X ) :\
              \ = L \\_ { \\\\mathrm { N } - 1 } ( X ) \\\\left( w \\_ { i } z \\\
              _ { i } ^ { \\* } ( X ) f \\_ { i } ( X ) - w \\_ { i + 1 } f \\_ {\
              \ i } ^ { \\\\prime } ( X ) \\\\right) } \\ & { f \\_ { i } ( X ) :\
              \ = \\\\displaystyle \\\\prod \\_ { \\\\mathbf { x } \\\\in { \\\\mathbf\
              \ { x } ^ { \\* } , \\\\mathbf { x } ^ { \\\\prime } } } \\\\left( s\
              \ \\_ { i } ( X ) + \\\\eta \\_ { \\\\mathrm { Y } } \\\\omega \\_ {\
              \ i } ^ { \\* } \\\\right) } \\ & { \\\\qquad \\\\quad + \\\\eta \\\
              _ { \\\\mathrm { Y } } \\\\alpha \\_ { \\\\mathbf { x } , i } ( X )\
              \ + \\\\gamma ) } \\ & { f \\_ { i } ^ { \\\\prime } ( X ) : = \\\\\
              displaystyle \\\\prod \\_ { \\\\mathbf { x } \\\\in { \\\\mathbf { x\
              \ } ^ { \\\\prime } , \\\\mathbf { x } ^ { \\\\prime } } } \\\\left(\
              \ s \\_ { i } ( X ) + \\\\eta \\_ { \\\\mathrm { Y } } \\\\omega \\\
              _ { i } ^ { \\* } \\\\right) } \\ & { \\\\qquad \\\\quad + \\\\eta \\\
              _ { \\\\mathrm { Y } } \\\\left( s \\_ { i } ( X ) + \\\\eta \\_ { \\\
              \\mathrm { Y } } \\\\omega \\_ { \\\\mathbf { Y } } ^ { \\* } + \\\\\
              eta \\_ { \\\\mathrm { Y } } k \\_ { i } x + \\\\gamma \\\\right) }\
              \ \\ & \\\\qquad \\\\quad \\\\leq a ^ { \\* } \\\\times \\ \\\\end{array}\\\
              \n$$\\\n\\\nsuch that\\\n\\\n$$\\\nq \\_ { i } ( X ) = \\\\left( X ^\
              \ { T } - 1 \\\\right) h \\_ { X , i } ( X )\\\n$$\\\n\\\nwhich means,\
              \ for $0 \\\\leq i < M$ , $Q ( \\\\omega \\_ { Y } ^ { i } ) = 0$ .\
              \ From the form of $f \\\\in \\\\left{ a ^ { \\* } , b ^ { \\* } , o\
              \ ^ { \\* } , z ^ { \\* } , h \\_ { X } \\\\right}$ , $f \\_ { i } (\
              \ Y , X ) =$ $\\\\textstyle \\\\sum \\_ { j = 0 } ^ { T - 1 } f \\_\
              \ { i , j } L \\_ { j } ( X )$ , we know that for $0 \\\\leq j < T$\
              \ after assigning the value $a \\_ { i , j } ^ { \\* } , b \\_ { i ,\
              \ j } ^ { \\* } , o \\_ { i , j } ^ { \\* } , z \\_ { i , j } ^ { \\\
              * } , z \\_ { i , j + 1 } ^ { \\* }$ to the corresponding polynomials\
              \ of $X$ in Equation 4.26, we will derive $q \\_ { i , j } = q \\_ {\
              \ i } ( \\\\omega \\_ { X } ^ { j } ) = 0$ .\\\n\\\n4. In the round\
              \ after $\\\\nu$ sends $\\\\gamma$ to $\\\\mathcal { P } ^ { \\* }$\
              \ , since $\\\\nu ^ { \\* }$ has received oracles $\\\\left( a \\_ {\
              \ i } ^ { \\* } ( X ) , b \\_ { i } ^ { \\* } ( X ) , c \\_ { i } ^\
              \ { \\* } ( X ) , z \\_ { i } ^ { \\* } ( X ) , w \\_ { i } ^ { \\*\
              \ } , w \\_ { i + 1 } ^ { \\* } \\\\right)$ before sending $\\\\lambda$\
              \ to $\\\\mathcal { P }$ , from Schwartz-Zipple Lemma, it implies for\
              \ each $0 \\\\leq j < T$ , $g \\_ { i } ( \\\\omega \\_ { X } ^ { j\
              \ } ) = p \\_ { 0 , i } ( \\\\omega \\_ { X } ^ { j } ) = p \\_ { 1\
              \ , i } ( \\\\omega \\_ { X } ^ { j } ) = p \\_ { 2 , i } ( \\\\omega\
              \ \\_ { X } ^ { j } ) = 0 .$\\\n\\\nAfter combine the claims for $0\
              \ \\\\leq i < M$ , it implies $( { \\\\bf a } ^ { \\* } , { \\\\bf b\
              \ } ^ { \\* } , { \\\\bf c } ^ { \\* } ) \\\\in ( \\\\mathbb { F } ^\
              \ { M \\\\times T } , \\\\mathbb { F } ^ { M \\\\times T } , \\\\mathbb\
              \ { F } ^ { M \\\\times T } )$ is a valid witness for gate constraints.\
              \ From the constraints related to $Z$ and $W$ , suppose $( \\\\sigma\
              \ \\_ { Y , i , j } , \\\\sigma \\_ { X , i , j } )$ correctly describe\
              \ the permutation cycles similar to the permutation cycles in Plonk,\
              \ we prove the argument that\\\n\\\n$$\\\n\\\\left{ \\\\begin{array}\
              \ { l } { \\\\left( a \\_ { i , j } , \\\\sigma \\_ { Y , a , i , j\
              \ } , \\\\sigma \\_ { X , a , i , j } \\\\right) } \\ { \\\\left( b\
              \ \\_ { i , j } , \\\\sigma \\_ { Y , b , i , j } , \\\\sigma \\_ {\
              \ X , b , i , j } \\\\right) } \\ { \\\\left( o \\_ { i , j } , \\\\\
              sigma \\_ { Y , o , i , j } , \\\\sigma \\_ { X , o , i , j } \\\\right)\
              \ } \\\\end{array} \\\\right} = \\\\left{ \\\\begin{array} { l } { \\\
              \\left( a \\_ { i , j } , \\\\omega \\_ { Y } ^ { i } , k \\_ { a }\
              \ \\\\omega \\_ { X } ^ { j } \\\\right) } \\ { \\\\left( b \\_ { i\
              \ , j } , \\\\omega \\_ { Y } ^ { i } , k \\_ { b } \\\\omega \\_ {\
              \ X } ^ { j } \\\\right) } \\ { \\\\left( o \\_ { i , j } , \\\\omega\
              \ \\_ { Y } ^ { i } , k \\_ { o } \\\\omega \\_ { X } ^ { j } \\\\right)\
              \ } \\\\end{array} \\\\right}\\\n$$\\\n\\\nTherefore, $( { \\\\bf a\
              \ } ^ { \\* } , { \\\\bf b } ^ { \\* } , { \\\\bf c } ^ { \\* } ) \\\
              \\in ( \\\\mathbb { F } ^ { M \\\\times T } , \\\\mathbb { F } ^ { M\
              \ \\\\times T } , \\\\mathbb { F } ^ { M \\\\times T } )$ also satisfies\
              \ the copy constraints which is equivalent to the copy constraints in\
              \ original Plonk. The possibility P∗ successfully cheats V is bounded\
              \ by 5M+5T +O(1)\\|F\\| .\\\n\\\n# 4.9 Proof of Theorem 4.5.2\\\n\\\n\
              Theorem 4.5.2. For a data-parallel circuit $C$ consisting of $M$ independent\
              \ sub-circuits, Protocol 5 is an RCPS with completeness, witness-extended\
              \ emulation, partial correctness, and partial witness-extended emulation.\\\
              \n\\\nProof. We prove this theorem by first utilizing Protocol 5 in\
              \ a data-parallel setting to implement RCPS and subsequently demonstrating\
              \ that the instantiation possesses the witness-extended emulation property.\\\
              \n\\\nImplementation. We implement the functionalities in Definition\
              \ 4.5.1 as follows:\\\n\\\n• Setup $\\\\left( 1 ^ { \\\\lambda } \\\\\
              right) \\\\to { \\\\mathsf { p p } }$ : run $\\\\mathsf { D K Z G .\
              \ K e y G e n } ( 1 ^ { \\\\lambda } , M \\_ { \\\\mathsf { m a x }\
              \ } , T \\_ { \\\\mathsf { m a x } } )$ and generate all bases needed\
              \ for creating and verifying polynomial commitments.\\\n\\\n• SplitCircuit\
              \ $( C , M ) \\\\to \\\\mathcal { C } = ( C \\_ { 0 } , \\\\dots , C\
              \ \\_ { M - 1 } )$ : split $C$ into $M$ independent sub-circuits, denoted\
              \ as $C \\_ { 0 } , \\\\dots , C \\_ { M - 1 }$ .\\\n\\\n• MasterKeyGen\
              \ $( { \\\\mathcal { C } } , M , { \\\\mathsf { p p } } ) \\\\to ( {\
              \ \\\\mathsf { m p k } } , { \\\\mathsf { v k } } )$ : call DKZG.Commit\
              \ $( S , { \\\\mathsf { p p } } )$ to compute $\\\\left{ \\\\left( \\\
              \\mathsf { c o m } \\_ { S } , \\\\mathsf { c o m } \\_ { s \\_ { i\
              \ } } \\\\right) \\\\right} \\_ { s \\\\in { \\\\cal S } \\_ { \\\\\
              mathsf { p p } } }$ . We define $\\\\mathsf { m p k } = \\\\left( \\\
              \\mathsf { c o m } \\_ { s \\_ { i } } \\\\right) \\_ { 0 \\\\leq i\
              \ < S \\_ { \\\\mathsf { p p } } } ,$ . Set vk as in the key generation\
              \ and preprocessing procedure from Protocol 5.\\\n\\\n• $\\\\mathsf\
              \ { K e y G e n } \\_ { i } \\\\left( C \\_ { i } , \\\\mathsf { m p\
              \ k } \\\\right) \\\\to \\\\mathsf { p k } \\_ { i }$ : generate ${\
              \ \\\\mathsf { p k } } \\_ { i }$ for $\\\\mathcal { P } \\_ { i }$\
              \ following the key generation and preprocessing procedure in Protocol\
              \ 5.\\\n\\\n• SplitWitness $( C , \\\\mathfrak { x } ) \\\\to ( \\\\\
              mathbb { w } \\_ { 0 } , \\\\dots , \\\\mathbb { w } \\_ { M - 1 } )$\
              \ : each prover $\\\\mathcal { P } \\_ { i }$ holds the witness $\\\\\
              mathbb { W } \\_ { i }$ in $C \\_ { i }$ .\\\n\\\n• ${ \\\\mathsf {\
              \ C o P r o v e } } \\_ { i } ^ { ( { \\\\mathcal { P } } \\_ { 0 }\
              \ ) } ( { \\\\mathsf { p k } } \\_ { i } , { \\\\mathrm { x } } \\_\
              \ { i } \\\\in { \\\\mathbb { x } } , { \\\\mathrm { w } } \\_ { i }\
              \ ) \\\\pi \\_ { 0 } ^ { ( i ) }$ : execute the proving procedure between\
              \ $\\\\mathcal { P } \\_ { 0 }$ and other nodes in Protocol 5 from Step\
              \ 1 to Step 4, collecting all messages from $\\\\mathcal { P } \\_ {\
              \ i }$ as $\\\\pi \\_ { 0 } ^ { ( i ) }$ .\\\n\\\n• $\\\\mathsf { T\
              \ e s t } \\_ { i } \\\\left( \\\\mathbb { x } \\_ { i } , \\\\pi \\\
              _ { 0 } ^ { ( i ) } , \\\\mathsf { m p k } \\\\right) \\\\to b \\_ {\
              \ i } \\\\in { 1 , 0 }$ : $\\\\mathcal { P } \\_ { 0 }$ performs the\
              \ checking procedure, as shown in the malicious setting in Protocol\
              \ 5. If all checks pass, output 1; otherwise, output 0.\\\n\\\n• Merge\
              \ $\\\\left( \\\\left( b \\_ { 0 } , \\\\dots , b \\_ { M - 1 } \\\\\
              right) , \\\\left( \\\\pi \\_ { 0 } ^ { ( 0 ) } , \\\\dots , \\\\pi\
              \ \\_ { 0 } ^ { ( M - 1 ) } \\\\right) \\\\right) \\\\to \\\\pi$ : $\\\
              \\mathcal { P } \\_ { 0 }$ replaces $\\\\pi \\_ { 0 } ^ { ( i ) }$ with\
              \ a dummy proof if $b \\_ { i } = 0$ , and run Step 5 in Protocol 5\
              \ to generate the proof $\\\\pi$ .\\\n\\\n• Verify $( \\\\mathbb { x\
              \ } , \\\\pi , \\\\mathbb { v } \\\\mathbf { k } ) { 1 , 0 }$ : $\\\\\
              nu$ runs the verification procedure in Protocol 5.\\\n\\\nCompleteness\
              \ and witness-extended emulation properties are inherited from Protocol\
              \ 5 as proven in Theorem 4.4.2. Partial correctness is straightforward.\
              \ Consequently, we only need to prove that the given implementation\
              \ possesses witness-extended emulation. We note that the underlying\
              \ polynomial IOP is derived from the constraints in Equation 4.1, Equation\
              \ 4.4, and Equation 4.5, compiled with a variant of KZG protocol. As\
              \ a result, we follow the same framework used in the proof for Theorem\
              \ 4.3.4.\\\n\\\nThe knowledge error in the IOP. By replacing $\\\\nu$\
              \ with $\\\\mathcal { P } \\_ { 0 }$ , we claim that the second part\
              \ of the proof in Appendix 4.8, which argues for $0 \\\\leq i < M$ ,\
              \ provides evidence of the knowledge error in this implementation.\\\
              \n\\\nThe knowledge soundness of PCS. We observe that the PCS scheme\
              \ between $\\\\mathcal { P } \\_ { i }$ and $\\\\mathcal { P } \\_ {\
              \ 0 }$ is a variant of the KZG protocol, with $\\\\mathsf { p } \\\\\
              mathsf { p } = \\\\left( g ^ { R \\_ { i } ( \\\\tau \\_ { Y } ) L \\\
              _ { j } ( \\\\tau \\_ { X } ) } \\\\right) \\\\mathsf { 0 } \\\\leq\
              \ j < T$ instead of $\\\\left( g ^ { L \\_ { i } ( \\\\tau \\_ { X }\
              \ ) } \\\\right)$ for the standard KZG protocol with pp in the Lagrange\
              \ basis. To prove the knowledge soundness of the KZG variant, we proceed\
              \ as follows:\\\n\\\nassuming $\\\\mathsf { p } \\\\mathsf { p } = \\\
              \\left( g ^ { L \\_ { j } ( \\\\tau \\_ { X } ) } \\\\right) \\\\mathsf\
              \ { 0 } \\\\leq j < T$ , the adversary $\\\\mathcal { A }$ for the KZG\
              \ protocol generates $z ^ { \\* } , \\\\mathbf { x } ^ { \\* } , \\\\\
              mathsf { c o m } ^ { \\* } , \\\\pi ^ { \\* }$ . Then, $\\\\mathcal\
              \ { A }$ creates $\\\\mathsf { p } \\\\mathsf { p } ^ { \\\\prime }\
              \ = \\\\left( g ^ { R \\_ { i } ( \\\\tau \\_ { Y } ) L \\_ { J } (\
              \ \\\\tau \\_ { X } ) } \\\\right)$ for the KZG variant using a randomly\
              \ sampled $\\\\tau \\_ { Y }$ . If an extractor $\\\\mathcal { E } ^\
              \ { \\\\mathcal { A } ^ { \\\\prime } ( \\\\cdot ) } ( 1 ^ { \\\\lambda\
              \ } , \\\\mathsf { p p } ^ { \\\\prime } )$ can successfully compute\
              \ $f ^ { \\* }$ such that $f ^ { \\* } ( \\\\mathbf { x } ^ { \\* }\
              \ ) = z ^ { \\* }$ , we can construct $\\\\mathcal { E } ^ { \\\\mathcal\
              \ { A } ( \\\\cdot ) } ( 1 ^ { \\\\lambda } , \\\\mathsf { p p } )$\
              \ by invoking $\\\\mathcal { E } ^ { \\\\prime }$ and returning $f ^\
              \ { \\* }$ . Therefore, we proved that the KZG variant also has knowledge\
              \ soundness.\\\n\\\n# Chapter 5\\\n\\\n# zkBridge: Trustless Cross-chain\
              \ Bridges Made Practical\\\n\\\nBlockchains have seen growing traction\
              \ with cryptocurrencies reaching a market cap of over 1 trillion dollars,\
              \ major institution investors taking interests, and global impacts on\
              \ governments, businesses, and individuals. Also growing significantly\
              \ is the heterogeneity of the ecosystem where a variety of blockchains\
              \ co-exist. Cross-chain bridge is a necessary building block in this\
              \ multi-chain ecosystem. Existing solutions, however, either suffer\
              \ from performance issues or rely on trust assumptions of committees\
              \ that significantly lower the security. Recurring attacks against bridges\
              \ have cost users more than 1.5 billion USD. In this paper, we introduce\
              \ zkBridge, an efficient cross-chain bridge that guarantees strong security\
              \ without external trust assumptions. With succinct proofs, zkBridge\
              \ not only guarantees correctness, but also significantly reduces on-chain\
              \ verification cost. We propose novel succinct proof protocols that\
              \ are orders-of-magnitude faster than existing solutions for workload\
              \ in zkBridge. With a modular design, zkBridge enables a broad spectrum\
              \ of use cases and capabilities, including message passing, token transferring,\
              \ and other computational logic operating on state changes from different\
              \ chains. To demonstrate the practicality of zkBridge, we implemented\
              \ a prototype bridge from Cosmos to Ethereum, a particularly challenging\
              \ direction that involves large proof circuits that existing systems\
              \ cannot efficiently handle. Our evaluation shows that zkBridge achieves\
              \ practical performance: proof generation takes less than 20 seconds,\
              \ while verifying proofs on-chain costs less than 230K gas. For completeness,\
              \ we also implemented and evaluated the direction from Ethereum to other\
              \ EVM-compatible chains (such as BSC) which involve smaller circuits\
              \ and incurs much less overhead.\\\n\\\nThis work was previously published\
              \ in $\\[ Z \\\\mathrm { h a } + 2 1 \\\\mathrm { a } \\]$ .\\\n\\\n\
              # 5.1 Introduction\\\n\\\nSince the debut of Bitcoin, blockchains have\
              \ evolved to an expansive ecosystem of various applications and communities.\
              \ Cryptocurrencies like Bitcoin and Ethereum are gaining rapid traction\
              \ with the market cap reaching over a trillion USD \\[Coi\\] and institutional\
              \ investors \\[Ham22; Win21\\] taking interests. Decentralized Finance\
              \ (DeFi) demonstrates that blockchains can enable finance instruments\
              \ that are otherwise impossible (e.g., flash loans \\[QZLG21\\]). More\
              \ recently, digital artists \\[Bee\\] and content creators \\[You\\\
              ] resort to blockchains for transparent and accountable circulation\
              \ of their works.\\\n\\\nAlso growing significantly is the heterogeneity\
              \ of the ecosystem. A wide range of blockchains have been proposed and\
              \ deployed, ranging from ones leveraging computation (e.g., in Proof-of-Work\
              \ \\[Nak08\\]), to economic incentives (e.g., in Proof-of-Stake \\[GHMVZ17;\
              \ BLMR14; KRDO17; DGKR17; BPS16\\]), and various other resources such\
              \ as storage \\[RD16; Fil; DFKP15; ABFG14\\], and even time \\[Int\\\
              ]. While it is rather unclear that one blockchain dominates others in\
              \ all aspects, these protocols employ different techniques and achieve\
              \ different security guarantees and performance. It has thus been envisioned\
              \ that (e.g., in \\[Amu; Mul; But\\]) the ecosystem will grow to a multi-chain\
              \ future where various protocols co-exist, and developers and users\
              \ can choose the best blockchain based on their preferences, the cost,\
              \ and the offered amenities.\\\n\\\nA central challenge in the multi-chain\
              \ universe is how to enable secure cross-chain bridges through which\
              \ applications on different blockchains can communicate. An ecosystem\
              \ with efficient and inexpensive bridges will enable assets held on\
              \ one chain to effortlessly participate in marketplaces hosted on other\
              \ chains. In effect, an efficient system of bridges will do for blockchains\
              \ what the Internet did for siloed communication networks.\\\n\\\nThe\
              \ core functionality of a bridge between blockchains $\\\\mathcal {\
              \ C } \\_ { 1 }$ and $\\\\mathcal { C } \\_ { 2 }$ is to prove to applications\
              \ on $\\\\mathcal { C } \\_ { 2 }$ that a certain event took place on\
              \ $\\\\mathcal { C } \\_ { 1 }$ , and vice versa. We use a generic notion\
              \ of a bridge, namely one that can perform multiple functions: message\
              \ passing, asset transfers, etc. In our modular design, the bridge itself\
              \ neither involves nor is restricted to any application-specific logic.\\\
              \n\\\nThe problem. While cross-chain bridges have been built in practice\
              \ \\[Rai; Polb; Lay; Axe\\], existing solutions either suffer from poor\
              \ performance, or rely on central parties.\\\n\\\nThe operation of the\
              \ bridge depends on the consensus protocols of both chains. If $\\\\\
              mathcal { C } \\_ { 1 }$ runs Proof-ofWork, a natural idea is to use\
              \ a light client protocol (e.g., SPV \\[Nak08\\]). Specifically, a smart\
              \ contract on $\\\\mathcal { C } \\_ { 2 }$ , denoted by $S { \\\\mathcal\
              \ { C } } \\_ { 2 }$ , will keep track of block headers of $\\\\mathcal\
              \ { C } \\_ { 1 }$ , based on which transaction inclusion (and other\
              \ events) can be verified with Merkle proofs. This approach, however,\
              \ incurs a significant computation and storage overhead, since $S {\
              \ \\\\mathcal { C } } \\_ { 2 }$ needs to verify all block headers and\
              \ keep a long and ever-growing list of them. For non-PoW chains, the\
              \ verification can be even more expensive. For example, for a bridge\
              \ between a Proofof-Stake chain (like Cosmos) and Ethereum, verifying\
              \ a single block header on Ethereum would cost about 64 million gas\
              \ \\[Nea\\] (about $$ 6300$ at time of writing), which is prohibitively\
              \ high.\\\n\\\nCurrently, as an efficient alternative, many bridge protocols\
              \ (PolyNetwork, Wormhole, Ronin, etc.) resort to a committee-based approach:\
              \ a committee of validators are entrusted to sign off on state transfers.\
              \ In these systems, the security boils down to, e.g., the honest majority\
              \ assumption. This is problematic for two reasons. First, the extra\
              \ trust assumption in the committee means the bridged asset is not as\
              \ secure as native ones, complicating the security analysis of downstream\
              \ applications. Second, relying on a small committee can lead to single\
              \ point failures. Indeed, in a recent exploit of the Ronin bridge \\\
              [Ron\\], the attackers were able to obtain five of the nine validator\
              \ keys, through which they stole 624 million USD, making it the largest\
              \ attack in the history of DeFi by Apr 2022¹. Even the second and third\
              \ largest attacks are also against bridges $$ 6110$ was stolen from\
              \ PolyNetwork \\[Pola\\] and $$ 3260$ was stolen from Wormhole \\[Wora\\\
              ]), and key compromise was suspected in the PolyNetwork attack.\\\n\\\
              \nOur approach. We present zkBridge to enable an efficient cross-chain\
              \ bridge without trusting a centralized committee. The main idea is\
              \ to leverage zk-SNARK, which are succinct non-interactive proofs (arguments)\
              \ of knowledge \\[WTSTW18; XZZPS19b; $Z \\\\mathrm { h a } + 2 1 \\\\\
              mathrm { a }$ ; BSBHR19; BSCTV14c; AHIV17; BSCRSVW19; COS20; CHMMVW20;\
              \ ZGKPP17d; ZGKPP18; BBBPWM18; GWC19b; Set20\\]. A zk-SNARK enables\
              \ a prover to efficiently convince $S { \\\\mathcal { C } } \\_ { 2\
              \ }$ that a certain state transition took place on $\\\\mathcal { C\
              \ } \\_ { 1 }$ . To do so, $S { \\\\mathcal { C } } \\_ { 2 }$ will\
              \ keep track of a digest $D$ of the latest tip of $\\\\mathcal { C }\
              \ \\_ { 1 }$ . To sync $S { \\\\mathcal { C } } \\_ { 2 }$ with new\
              \ blocks in $\\\\mathcal { C } \\_ { 1 }$ , anyone can generate and\
              \ submit a zk-SNARK that proves to $S { \\\\mathcal { C } } \\_ { 2\
              \ }$ that the tip of $\\\\mathcal { C } \\_ { 1 }$ has advanced from\
              \ $D$ to $D ^ { \\\\prime }$ .\\\n\\\nThis design offers three benefits.\
              \ First, the soundness property of a zk-SNARK ensures the security of\
              \ the bridge. Thus, we do not need additional security requirements\
              \ beyond the security of the underlying blockchains. In particular zkBridge\
              \ does not rely on a committee for security. Second, with a purpose-built\
              \ zk-SNARK, $\\\\mathcal { C } \\_ { 2 }$ can verify a state transition\
              \ of $\\\\mathcal { C } \\_ { 1 }$ far more efficiently than encoding\
              \ the consensus logic of $\\\\mathcal { C } \\_ { 1 }$ in $S { \\\\\
              mathcal { C } } \\_ { 2 }$ . In this way, as an example for zkBridge\
              \ from Cosmos to Ethereum, we reduce the proof verification cost from\
              \ $\\\\sim 8 0 M$ gas to less than $2 3 0 K$ gas on $\\\\mathcal { C\
              \ } \\_ { 2 }$ . The storage overhead of the bridge is reduced to constant.\
              \ Third, by separating the bridge from application-specific logic, zkBridge\
              \ makes it easy to enable additional applications on top of the bridge.\\\
              \n\\\nTechnical challenges. To prove correctness of a given computation\
              \ outcome using a zk-SNARK, one first needs to express the computation\
              \ as an arithmetic circuit. While zk-SNARK verification is fast (logarithmic\
              \ in the size of the circuit or even constant), proof generation time\
              \ is at least linear, and in practice can be prohibitively expensive.\
              \ Moreover, components used by real-world blockchains are not easily\
              \ expressed as an arithmetic circuit. For example, the widely used EdDSA\
              \ digital signature scheme is very efficient to verify on a CPU, but\
              \ is expensive to express as an arithmetic circuit, requiring more than\
              \ 2 million gates \\[Cirb\\]. In a cross-chain bridge, each state transition\
              \ could require the verification of hundreds of signatures depending\
              \ on the chains, making it prohibitively expensive to generate the required\
              \ zk-SNARK proof. In order to make zkBridge practical, we must reduce\
              \ proof generation time.\\\n\\\nTo this end, we propose two novel ideas.\
              \ First, we observe that the circuits used by cross-chain bridges are\
              \ data-parallel, in that they contain multiple identical copies of a\
              \ smaller sub-circuit. Specifically, the circuit for verifying $N$ digital\
              \ signatures contains $N$ copies of the signature verification sub-circuit.\
              \ To leverage the data-parallelism, we propose deVirgo, a novel distributed\
              \ zero-knowledge proofs protocol based on Virgo \\[ZXZS20\\]. deVirgo\
              \ enjoys perfect linear scalability, namely, the proof generation time\
              \ can be reduced by a factor of $M$ if the generation is distributed\
              \ over $M$ machines. The protocol is of independent interest and might\
              \ be useful in other scenarios. Other proof systems can be similarly\
              \ parallelized \\[WZCPS18\\].\\\n\\\nWhile deVirgo significantly reduces\
              \ the proof generation time, verifying deVirgo proofs on chain, especially\
              \ for the billion-gate circuits in zkBridge, can be expensive for smart\
              \ contracts where computational resources are extremely limited. To\
              \ compress the proof size and the verification cost, we recursively\
              \ prove the correctness of a (potentially large) deVirgo proof using\
              \ a classic zk-SNARK due to Groth \\[Gro16\\], hereafter denoted Groth16.\
              \ The Groth16 prover outputs constant-size proofs that are fast to verify\
              \ by a smart contract on an EVM blockchain. We stress that one cannot\
              \ use Groth16 to generate the entire zkBridge proof because the circuits\
              \ needed in zkBridge are too large for a Groth16 prover. Instead, our\
              \ approach of compressing a deVirgo proof using Groth16 gives the best\
              \ of both worlds: a fast deVirgo parallel prover for the bulk of the\
              \ proof, where the resulting proof is compressed into a succinct Groth16\
              \ proof that is fast to verify. We elaborate on this technique in Section\
              \ 5.5. This approach to compressing long proofs is also being adopted\
              \ in commercial zk-SNARK systems such as \\[Pold; Polc; Ris\\].\\\n\\\
              \nImplementation and evaluation. To demonstrate the practicality of\
              \ zkBridge, we implement an end-toend prototype of zkBridge from Cosmos\
              \ to Ethereum, given it is among the most challenging directions as\
              \ it involves large circuits for correctness proofs. Our implementation\
              \ includes the protocols of deVirgo and recursive proof with Groth16,\
              \ and the transaction relay application. The experiments show that our\
              \ system achieves practical performance. deVirgo can generate a block\
              \ header relay proof within 20s, which is more than $1 0 0 \\\\mathrm\
              \ { x }$ faster than the original Virgo system with a single machine.\
              \ Additionally, the on-chain verification cost decreases from ${ \\\\\
              sim } 8 0 \\\\mathbf { M }$ gas (direct signature verification) to less\
              \ than 230K gas, due to the recursive proofs. In addition, as a prototype\
              \ example, we also implement zkBridge from Ethereum to other EVM-compatible\
              \ chains such as BSC, which involves smaller circuits for proof generation\
              \ and incurs much less overhead.\\\n\\\n# 5.1.1 Our contribution\\\n\
              \\\nIn this paper, we make the following contributions:\\\n\\\n• In\
              \ this paper, we propose zkBridge, a trustless, efficient, and secure\
              \ cross-chain bridge whose security relies on succinct proofs (cryptographic\
              \ assumptions) rather than a committee (external trust assumptions).\
              \ Compared with existing cross-chain bridge projects in the wild, zkBridge\
              \ is the first solution that achieves the following properties at the\
              \ same time.\\\n\\\n– Trustless and Secure: The correctness of block\
              \ headers on remote blockchains is proven by zkSNARKs, and thus no external\
              \ trust assumptions are introduced. Indeed, as long as the connected\
              \ blockchains and the underlying light-client protocols are secure,\
              \ and there exists at least one honest node in the block header relay\
              \ network, zkBridge is secure.\\\n\\\n– Permissionless and Decentralized:\
              \ Any node can freely join the network to relay block headers, generate\
              \ proofs, and claim the rewards. Due to the elimination of the commonly-used\
              \ central or Proof-of-Stake style committee for block header validation,\
              \ zkBridge also enjoys better decentralization.\\\n\\\n– Extensible:\
              \ Smart contracts using zkBridge enjoy maximum flexibility because they\
              \ can invoke the updater contract to retrieve verified block headers,\
              \ and then perform their application-specific verification and functionality\
              \ (e.g., verifying transaction inclusion through auxiliary Merkle proofs).\
              \ By separating the bridge from application-specific logic, zkBridge\
              \ makes it easy to develop applications on top of the bridge.\\\n\\\n\
              – Universal: The block header relay network and the underlying proof\
              \ scheme in zkBridge is universal – Efficient: With our highly optimized\
              \ recursive proof scheme, block headers can be relayed within a short\
              \ time (usually tens of seconds for proof generation), and the relayed\
              \ information can be quickly finalized as soon as the proof is verified,\
              \ thus supporting fast and flexible bridging of information.\\\n\\\n\
              In summary, zkBridge is a huge leap towards building a secure, trustless\
              \ foundation for blockchain interoperability.\\\n\\\n• We propose a\
              \ novel 2-layer recursive proof system, which is of independent interest,\
              \ as the underlying zkSNARK protocol to achieve both reasonable proof\
              \ generation time and on-chain verification cost. Through the coordination\
              \ of deVirgo and Groth16, we achieve a desirable balance between efficiency\
              \ and cost.\\\n\\\n– For the first layer, aiming at prompt proof generation,\
              \ we introduce deVirgo, a distributed version of Virgo proof system.\
              \ deVirgo combines distributed sumcheck and distributed polynomial commitment\
              \ to achieve optimal parallelism, through which the proof generation\
              \ phase is much more accelerated by running on distributed machines.\
              \ deVirgo is more than $1 0 0 \\\\mathrm { x }$ faster than Virgo for\
              \ the workload in zkBridge.\\\n\\\n– For the second layer, aiming at\
              \ acceptable on-chain verification cost, we use Groth16 to recursively\
              \ prove that the previously generated proof by deVirgo indeed proves\
              \ the validity of the corresponding remote block headers. Through the\
              \ second layer, the verification gas cost is reduced from an estimated\
              \ $\\\\sim 8 0 M$ to less than $2 3 0 K$ , making on-chain verification\
              \ practical.\\\n\\\n• We implement an end-to-end prototype of zkBridge\
              \ and evaluate its performance in two scenarios: from Cosmos to Ethereum\
              \ (which is the main focus since it involves large proof circuits that\
              \ existing systems cannot efficiently handle), and from Ethereum to\
              \ other EVM-compatible chains (which in comparison involves much smaller\
              \ circuits). The experiment results show that zkBridge achieves practical\
              \ performance and is the first practical cross-chain bridge that achieves\
              \ cryptographic assurance of correctness.\\\n\\\n# 5.2 Background\\\n\
              \\\nIn this section we cover the preliminaries, essential background\
              \ on blockchains, and zero-knowledge proofs.\\\n\\\n# 5.2.1 Notations\\\
              \n\\\nLet $\\\\mathbb { F }$ be a finite field and $\\\\lambda$ be a\
              \ security parameter. We use $f ( ) , h ( )$ for polynomials, $x , y$\
              \ for single variables, bold letters $\\\\mathbf { x }$ , y for vectors\
              \ of variables. Both $\\\\mathbf { x } \\[ i \\]$ and $x \\_ { i }$\
              \ denote the $i$ -th element in $\\\\mathbf { x }$ . For $\\\\mathbf\
              \ { x }$ , we use notation $\\\\mathbf { x } \\[ i : k \\]$ to denote\
              \ slices of vector $\\\\mathbf { x }$ , namely $\\\\mathbf { x } \\\
              [ i : k \\] = ( x \\_ { i } , x \\_ { i + 1 } , \\\\cdot \\\\cdot \\\
              \\cdot , x \\_ { k } )$ . We use i to denote the vector of the binary\
              \ representation of some integer $i$ .\\\n\\\nMerkle Tree. Merkle tree\
              \ \\[Mer87\\] is a data structure widely used to build commitments to\
              \ vectors because of its simplicity and efficiency. The prover time\
              \ is linear in the size of the vector while the verifier time and proof\
              \ size are logarithmic in the size of the vector. Given a vector of\
              \ ${ \\\\bf x } = ( x \\_ { 0 } , \\\\cdots , x \\_ { N - 1 } )$ , it\
              \ consists of three algorithms:\\\n\\\n$$\\\n\\\\begin{array} { r l\
              \ } & { \\\\bullet \\ \\\\mathsf { r t } \\\\mathsf { M T . C o m m\
              \ i t } ( \\\\mathbf { x } ) } \\ & { \\\\bullet \\ ( \\\\mathbf { x\
              \ } \\[ i \\] , \\\\pi \\_ { i } ) \\\\mathsf { M T . O p e n } ( \\\
              \\mathbf { x } , i ) } \\ & { \\\\bullet \\ { 1 , 0 } \\\\mathsf { M\
              \ T . V e r i f y } ( \\\\pi \\_ { i } , \\\\mathbf { x } \\[ i \\]\
              \ , \\\\mathsf { r t } ) . } \\\\end{array}\\\n$$\\\n\\\n# 5.2.2 Blockchains\\\
              \n\\\nA blockchain is a distributed protocol where a group of nodes\
              \ collectively maintains a ledger which consists of an ordered list\
              \ of blocks. A block blk is a data-structure that stores a header blkH\
              \ and a list of transactions, denoted by $\\\\mathsf { b } \\| \\\\\
              mathsf { k } = \\\\left{ \\\\mathsf { b } \\| \\\\mathsf { k } \\\\\
              mathsf { H } ; \\\\mathsf { t } \\\\mathsf { r } \\\\mathsf { x } \\\
              _ { 1 } , \\\\ldots , \\\\mathsf { t } \\\\mathsf { r } \\\\mathsf {\
              \ x } \\_ { t } \\\\right}$ . A block header contains metadata about\
              \ the block, including a pointer to the previous block, a compact representation\
              \ of the transactions (typically a Merkle tree root), validity proofs\
              \ such as solutions to cryptopuzzles in Proof-of-Work systems or validator\
              \ signatures in Proofof-Stake ones.\\\n\\\nSecurity of blockchains.\
              \ The security of blockchains has been studied extensively. Suppose\
              \ the ledger in party $i$ ’s local view is $\\\\mathsf { L O G } \\\
              _ { i } ^ { r } = \\[ \\\\mathsf { b l k } \\_ { 1 } , \\\\mathsf {\
              \ b l k } \\_ { 2 } , \\\\ldots , \\\\mathsf { b l k } \\_ { r } \\\
              ]$ where $r$ is the height. For any $2 \\\\leq k \\\\leq r$ and the\
              \ $k$ -th block $\\\\mathsf { b } \\| \\\\mathsf { k } \\_ { k }$ ,\
              \ $\\\\mathsf { b l k } \\_ { k } . \\\\mathsf { p t r } = \\\\mathsf\
              \ { b l k H } \\_ { k - 1 }$ , so every single block is linked to the\
              \ previous one. For the purpose of this paper, we care about two (informal)\
              \ properties:\\\n\\\n1. Consistency: For any honest nodes $i$ and $j$\
              \ , and for any rounds of $r \\_ { 0 }$ and $r \\_ { 1 }$ , it must\
              \ be satisfied that either $\\\\mathsf { L O G } \\_ { i } ^ { r \\\
              _ { 0 } }$ is a prefix of $\\\\mathsf { L O G } \\_ { j } ^ { r \\_\
              \ { 1 } }$ or vice versa.\\\n2. Liveness: If an honest node receives\
              \ some transaction trx at some round $r$ , then trx will be included\
              \ into the blockchain of all honest nodes eventually.\\\n\\\nSmart contracts\
              \ and gas. In addition to reaching consensus over the content of the\
              \ ledger, many blockchains support expressive user-defined programs\
              \ called smart contracts, which are stateful programs with state persisted\
              \ on a blockchain. Without loss of generality, smart contract states\
              \ can be viewed a key-value store (and often implemented as such.) Users\
              \ send transactions to interact with a smart contract, and potentially\
              \ alter its state.\\\n\\\nA key limitation of existing smart contract\
              \ platforms is that computation and storage are scarce resources and\
              \ can be considerably expensive. Typically smart contract platforms\
              \ such as Ethereum charge a fee (sometimes called gas) for every step\
              \ of computation. For instance, EdDSA signatures are extremely cheap\
              \ to verify (a performant CPU can verify 71000 of them in a second \\\
              [BDLSY12\\]), but verifying a single EdDSA signature on Ethereum costs\
              \ about 500K gas, which is about $$ 49$ at the time of writing. Storage\
              \ is also expensive on Ethereum. Storing 1KB of data costs about $0\
              \ . 0 3 2 \\\\mathrm { E T H }$ , which can be converted to approximately\
              \ $$ 90$ at the time of writing. This limitation is not unique to Ethereum\
              \ but rather a reflection of the low capacity of permissionless blockchains\
              \ in general. Therefore reducing on-chain computation and storage overhead\
              \ is one of the key goals.\\\n\\\n# 5.2.3 Light client protocol\\\n\\\
              \nIn a blockchain network, there are full nodes as well as light ones.\
              \ Full nodes store the entire history of the blockchain and verify all\
              \ transactions in addition to verifying block headers. Light clients,\
              \ on the other hand, only store the headers, and therefore can only\
              \ verify a subset of correctness properties.\\\n\\\nThe workings of\
              \ light clients depend on the underlying consensus protocol. The original\
              \ Bitcoin paper contains a light client protocol (SPV \\[Nak08\\]) that\
              \ uses Merkle proofs to enable a light client who only stores recent\
              \ headers to verify transaction inclusion. A number of improvements\
              \ have been proposed ever since. For instance, in Proof-of-Stake, typically\
              \ a light client needs to verify account balances in the whole blockchain\
              \ history (or up to a snapshot), and considers the risk of long range\
              \ attacks. For BFT-based consensus, a light client needs to verify validator\
              \ signatures and keeps track of validator rotation. We refer readers\
              \ to \\[CBC21\\] for a survey.\\\n\\\nTo abstract consensus-specific\
              \ details away, we use\\\n\\\n$$\\\n\\\\mathsf { L i g h t C C } ( \\\
              \\mathsf { L C S } \\_ { r - 1 } , \\\\mathsf { b l k H } \\_ { r -\
              \ 1 } , \\\\mathsf { b l k H } \\_ { r } ) \\\\to { \\\\mathsf { t r\
              \ u e } , \\\\mathsf { f a l s e } }\\\n$$\\\n\\\nto denote the block\
              \ validation rule of a light client: given a new block header ${ \\\\\
              mathsf { b } } \\| { \\\\mathsf { k } } { \\\\mathsf { H } } \\_ { r\
              \ }$ , LightCC determines if the header represents a valid next block\
              \ after ${ \\\\sf b } \\| { \\\\sf k } { \\\\sf H } \\_ { r - 1 }$ given\
              \ its current state ${ \\\\mathsf { L } } { \\\\mathsf { C } } { \\\\\
              mathsf { S } } \\_ { r - 1 }$ . We define the required properties of\
              \ a light client protocol as follows:\\\n\\\nDefinition 5.2.1 (Light\
              \ client protocol). A light client protocol enables a node to synchronize\
              \ the block headers of the state of the blockchain. Suppose all block\
              \ headers in party i’s local view is $\\\\mathsf { L O G } H \\_ { i\
              \ } ^ { r } \\ =$ $\\[ \\\\mathsf { b } \\| \\\\mathsf { k } \\\\mathsf\
              \ { H } \\_ { 1 } , \\\\mathsf { b } \\| \\\\mathsf { k } \\\\mathsf\
              \ { H } \\_ { 2 } , . . . , \\\\mathsf { b } \\| \\\\mathsf { k } \\\
              \\mathsf { H } \\_ { r } \\]$ , the light client protocol satisfies\
              \ following properties:\\\n\\\n1. Succinctness: For each state update,\
              \ the light client protocol only takes $O ( 1 )$ time to synchronize\
              \ the state.\\\n2. Liveness: If an honest full node receives some transaction\
              \ trx at some round $r$ , then trx must be included into the blockchain\
              \ eventually. A light client protocol will eventually include a block\
              \ header ${ \\\\mathsf { b } } \\| { \\\\mathsf { k } } { \\\\mathsf\
              \ { H } } \\_ { i }$ such that the corresponding block includes the\
              \ transaction trx.\\\n3. Consistency: For any honest nodes $i$ and $j$\
              \ , and for any rounds of $r \\_ { 0 }$ and $r \\_ { 1 }$ , it must\
              \ be satisfied that either $\\\\mathsf { L O G } H \\_ { i } ^ { r \\\
              _ { 0 } }$ is a prefix of $\\\\mathsf { L O G } H \\_ { j } ^ { r \\\
              _ { 1 } }$ or vice versa.\\\n\\\n# 5.2.4 Zero-knowledge proofs\\\n\\\
              \nAn argument system for an NP relationship $\\\\mathcal { R }$ is a\
              \ protocol between a computationally-bounded prover $\\\\mathcal { P\
              \ }$ and a verifier $\\\\nu$ . At the end of the protocol, $\\\\nu$\
              \ is convinced by $\\\\mathcal { P }$ that there exists a witness w\
              \ such that $( \\\\mathbf { x } ; \\\\mathbf { w } ) \\\\in \\\\mathcal\
              \ { R }$ for some input $\\\\mathbf { x }$ . We use $\\\\mathcal { G\
              \ }$ to represent the generation phase of the public parameters pp.\
              \ Formally, consider the definition below, where we assume $\\\\mathcal\
              \ { R }$ is known to $\\\\mathcal { P }$ and $\\\\nu$ .\\\n\\\nDefinition\
              \ 5.2.2. Let $\\\\lambda$ be a security parameter and $\\\\mathcal {\
              \ R }$ be an NP relation. A tuple of algorithm $( \\\\mathcal { G }\
              \ , \\\\mathcal { P } , \\\\mathcal { V } )$ is a zero-knowledge argument\
              \ of knowledge for $\\\\mathcal { R }$ if the following holds.\\\n\\\
              \n• Completeness. For every pp output by $\\\\mathcal { G } ( 1 ^ {\
              \ \\\\lambda } )$ , $( \\\\mathbf { x } ; \\\\mathbf { w } ) \\\\in\
              \ \\\\mathcal { R }$ and $\\\\pi \\\\mathcal { P } ( \\\\mathbf { x\
              \ } , \\\\mathbf { w } , \\\\mathsf { p p } ) ,$ ,\\\n\\\n$$\\\n\\\\\
              operatorname\\* { P r } \\[ \\\\mathcal { V } ( \\\\mathbf { x } , \\\
              \\pi , \\\\mathsf { p p } ) = 1 \\] = 1\\\n$$\\\n\\\n• Knowledge Soundness.\
              \ For any PPT prover $\\\\mathcal { P } ^ { \\* }$ , there exists a\
              \ PPT extractor $\\\\mathcal { E }$ such that for any auxiliary string\
              \ $\\\\mathbf { z }$ , ${ \\\\mathsf { p p } } { \\\\mathcal { G } }\
              \ ( 1 ^ { \\\\lambda } )$ , $\\\\pi ^ { \\* } \\\\gets \\\\mathcal {\
              \ P } ^ { \\* } ( \\\\mathbf { x } , \\\\mathbf { z } , \\\\mathsf {\
              \ p p } )$ , $w \\\\gets \\\\mathcal { E } ^ { \\\\mathcal { P } ^ {\
              \ \\\\ast } ( \\\\cdot ) } ( \\\\mathbf { x } , \\\\mathbf { z } , \\\
              \\mathsf { p p } )$ , and\\\n\\\n$$\\\n\\\\operatorname\\* { P r } \\\
              [ ( \\\\mathbf { x } ; \\\\mathbf { w } ) \\\\notin \\\\mathcal { R\
              \ } \\\\land \\\\mathcal { V } ( \\\\mathbf { x } , \\\\pi ^ { \\* }\
              \ , \\\\mathsf { p p } ) = 1 \\] \\\\le \\\\mathsf { n e g l } ( \\\\\
              lambda ) ,\\\n$$\\\n\\\nwhere $\\\\varepsilon ^ { \\\\mathcal { P }\
              \ ^ { \\\\ast } ( \\\\cdot ) }$ represents that $\\\\mathcal { E }$\
              \ can rewind $\\\\mathcal { P } ^ { \\* }$ ,\\\n\\\n• Zero knowledge.\
              \ There exists a PPT simulator $s$ such that for any PPT algorithm $\\\
              \\nu ^ { \\* }$ , $( \\\\mathbf { x } ; \\\\mathbf { w } ) \\\\in \\\
              \\mathcal { R }$ , pp output by $\\\\bar { \\\\mathcal { G } } ( 1 ^\
              \ { \\\\lambda } )$ , it holds that\\\n\\\n$$\\\n\\\\mathsf { V i e\
              \ w } ( \\\\mathcal { V } ^ { \\* } ( \\\\mathsf { p p } , { \\\\mathbf\
              \ { x } } ) ) \\\\approx \\\\mathcal { S } ^ { \\\\mathcal { V } ^ {\
              \ \\* } } ( { \\\\mathbf { x } } ) ,\\\n$$\\\n\\\nwhere View $\\\\mathcal\
              \ { V } ^ { \\* } ( \\\\mathsf { p p } , \\\\mathbf { x } ) ,$ ) denotes\
              \ the view that the verifier sees during the execution of the interactive\
              \ process with $\\\\mathcal { P }$ , $\\\\boldsymbol { s } ^ { \\\\\
              nu ^ { \\* } } ( \\\\mathbf { x } )$ denotes the view generated by $s$\
              \ given input $\\\\mathbf { x }$ and transcript of $\\\\nu ^ { \\* }$\
              \ , and $\\\\approx$ denotes two perfectly indistinguishable distributions.\\\
              \n\\\nWe say that $( \\\\mathcal { G } , \\\\mathcal { P } , \\\\mathcal\
              \ { V } )$ is a succinct argument system² if the total communication\
              \ (proof size) between $\\\\mathcal { P }$ and $\\\\nu$ , as well as\
              \ $\\\\nu$ ’s running time, are poly $\\\\left( \\\\lambda , \\| \\\\\
              mathbf { x } \\| , \\\\log \\| \\\\mathcal { R } \\| \\\\right)$ , where\
              \ $\\| \\\\mathcal { R } \\|$ is the size of the circuit that computes\
              \ $\\\\mathcal { R }$ as a function of $\\\\lambda$ .\\\n\\\n# 5.3 zkBridge\
              \ Protocol\\\n\\\nAt a high level, a smart contract is a stateful program\
              \ with states persisted on a blockchain. A bridge like zkBridge is a\
              \ service that enables smart contracts on different blockchains to transfer\
              \ states from one chain to another in a secure and verifiable fashion.\\\
              \n\\\nBelow we first explain the design of zkBridge and its workflow\
              \ through an example, then we specify the protocol in more detail. For\
              \ ease of exposition, we focus on one direction of the bridge, but the\
              \ operation of the opposite direction is symmetric.\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/ec9053a4daf57667d734c2f652044d848eb7254b5902a5a2a4787578e6646e6b.jpg)\\\
              \n\\\nFigure 5.1: The design of zkBridge illustrated with the example\
              \ of cross-chain token transfer. The components in shade belongs to\
              \ zkBridge. For clarity we only show one direction of the bridge and\
              \ the opposite direction is symmetric.\\\n\\\n# 5.3.1 Overview of zkBridge\
              \ design\\\n\\\nTo make it easy for different applications to integrate\
              \ with zkBridge, we adopt a modular design where we separate application-specific\
              \ logic (e.g., verifying smart contract states) from the core bridge\
              \ functionality (i.e., relaying block headers).\\\n\\\nFigure 5.1 shows\
              \ the architecture and workflow of zkBridge. The core bridge functionality\
              \ is provided by a block header relay network (trusted only for liveness)\
              \ that relays block headers of $\\\\mathcal { C } \\_ { 1 }$ along with\
              \ correctness proofs, and an updater contract on $\\\\mathcal { C }\
              \ \\_ { 2 }$ that verifies and accepts proofs submitted by relay nodes.\
              \ The updater contract maintains a list of recent block headers, and\
              \ updates it properly after verifying proofs submitted by relay nodes;\
              \ it exposes a simple and application-agnostic API, from which application\
              \ smart contracts can obtain the latest block headers of the sender\
              \ blockchain and build application-specific logic on top of it.\\\n\\\
              \nApplications relying on zkBridge will typically deploy a pair of contracts,\
              \ a sender contract and a receiver contract on $\\\\mathcal { C } \\\
              _ { 1 }$ and $\\\\mathcal { C } \\_ { 2 }$ , respectively. We refer\
              \ to them collectively as application contracts or relying contracts.\
              \ The receiver contract can call the updater contract to obtain block\
              \ headers of $\\\\mathcal { C } \\_ { 1 }$ , based on which they can\
              \ perform application specific tasks. Depending on the application,\
              \ receiver contracts might also need a user or a third party to provide\
              \ application-specific proofs, such as Merkle proofs for smart contract\
              \ states.\\\n\\\nAs an example, Fig. 5.1 shows the workflow of cross-chain\
              \ token transfer, a common use case of bridges, facilitated by zkBridge.\
              \ Suppose a user $\\\\mathcal { U }$ wants to trade assets (tokens)\
              \ she owns on blockchain $\\\\mathcal { C } \\_ { 1 }$ in an exchange\
              \ residing on another blockchain $\\\\mathcal { C } \\_ { 2 }$ (presumably\
              \ because $\\\\mathcal { C } \\_ { 2 }$ charges lower fees or has better\
              \ liquidity), she needs to move her funds from $\\\\mathcal { C } \\\
              _ { 1 }$ to $\\\\mathcal { C } \\_ { 2 }$ . A pair of smart contracts\
              \ $\\\\mathcal { S } \\\\mathcal { C } \\_ { \\\\mathrm { l o c k }\
              \ }$ and ${ \\\\mathcal { S C } } \\_ { \\\\mathrm { m i n t } }$ are\
              \ deployed on blockchains $\\\\mathcal { C } \\_ { 1 }$ and $\\\\mathcal\
              \ { C } \\_ { 2 }$ respectively. To move the funds, the user locks $$\
              \ 0$ tokens in $\\\\mathcal { S } \\\\mathcal { C } \\_ { \\\\mathrm\
              \ { l o c k } }$ (step $\\\\textcircled{1}$ in Fig. 5.1) and then requests\
              \ $$ 5$ tokens to be issued by ${ \\\\mathcal { S C } } \\_ { \\\\operatorname\\\
              * { m i n t } }$ . To ensure solvency, ${ \\\\mathcal { S C } } \\_\
              \ { \\\\mathrm { m i n t } }$ should only issue new tokens if and only\
              \ if the user has locked tokens on $\\\\mathcal { C } \\_ { 1 }$ . This\
              \ requires ${ \\\\mathcal { S C } } \\_ { \\\\operatorname\\* { m i\
              \ n t } }$ to read the states of $\\\\mathcal { S } \\\\mathcal { C\
              \ } \\_ { \\\\mathrm { l o c k } }$ (the balance of $\\\\mathcal { U\
              \ }$ , updated in step $\\\\textcircled{2}$ ) from a different blockchain,\
              \ which it cannot do directly. zkBridge enables this by relaying the\
              \ block headers of $\\\\mathcal { C } \\_ { 1 }$ to $\\\\mathcal { C\
              \ } \\_ { 2 }$ along with proofs (step $\\\\textcircled{3}$ and $\\\\\
              textcircled{4}$ ). ${ \\\\mathcal { S C } } \\_ { \\\\mathrm { m i n\
              \ t } }$ can retrieve the block headers from the smart contract frontend\
              \ (the updater contract), check that the balance of user $\\\\mathcal\
              \ { U }$ is indeed $$ 5$ (step $\\\\textcircled{5}$ ), and only then\
              \ mint $$ 5$ tokens (Step $\\\\textcircled{6}$ ).\\\n\\\nBesides cross-chain\
              \ token transfer, zkBridge can also enable various other applications\
              \ such as crosschain collateralized loans, general message passing,\
              \ etc. We present three use cases in Section 5.3.3.\\\n\\\n# 5.3.2 Protocol\
              \ detail\\\n\\\nHaving presented the overview, in this section, we specify\
              \ the protocol in more detail.\\\n\\\n# Security and system model\\\n\
              \\\nFor the purpose of modeling bridges, we model a blockchain $\\\\\
              mathcal { C }$ as a block-number-indexed key-value store, denoted as\
              \ $\\\\mathcal { C } \\[ t \\] : \\\\mathcal { K } \\\\mathcal { V }$\
              \ where $t$ is the block number, $\\\\kappa$ and $\\\\nu$ are key and\
              \ value spaces respectively. In Ethereum, for example, $\\\\mathcal\
              \ { V } = \\\\left{ 0 , 1 \\\\right} ^ { 2 5 6 }$ and keys are the concatenation\
              \ of a smart contract identifier $\\\\mathcal { S C }$ and a per-smart-contract\
              \ storage address $K$ . For a given contract $\\\\mathcal { S C }$ ,\
              \ we denote the value stored at address $K$ at block number $t$ as $S\
              \ C \\[ t , K \\]$ , and we call $\\\\mathit { S C } \\[ t , \\\\cdot\
              \ \\]$ the state of $\\\\mathcal { S C }$ at block number $t$ . Again,\
              \ for ease of exposition, we focus on the direction from $\\\\mathcal\
              \ { S } \\\\mathcal { C } \\_ { 1 }$ to $S { \\\\mathcal { C } } \\\
              _ { 2 }$ , denoted as $B \\\\mathcal { R } \\[ S \\\\mathcal { C } \\\
              _ { 1 } S \\\\mathcal { C } \\_ { 2 } \\]$ .\\\n\\\nFunctional and security\
              \ goals. We require the bridge $B \\\\mathcal { R } \\[ S \\\\mathcal\
              \ { C } \\_ { 1 } S \\\\mathcal { C } \\_ { 2 } \\]$ to reflect states\
              \ of $\\\\mathcal { S } \\\\mathcal { C } \\_ { 1 }$ correctly and timely:\\\
              \n\\\n1. Correctness: For all $t , K , S { \\\\mathcal { C } } \\_ {\
              \ 2 }$ accepts a wrong state $V \\\\neq S { \\\\mathcal { C } } \\_\
              \ { 1 } \\[ t , K \\]$ with negligible probability.\\\n\\\n2. Liveness:\
              \ Suppose $S { \\\\mathcal { C } } \\_ { 2 }$ needs to verify $\\\\\
              mathcal { S } \\\\mathcal { C } \\_ { 1 }$ ’s state at $( t , K )$ ,\
              \ the bridge will provide necessary information eventually.\\\n\\\n\\\
              \nSecurity assumptions. For correctness, zkBridge does not introduce\
              \ extra trust assumptions besides those made by the underlying blockchains.\
              \ Namely, we assume both the sender blockchain and the receiver blockchain\
              \ are consistent and live (Section 5.2), and the sender chain has a\
              \ light client protocol to enable fast block header verification. For\
              \ both properties, we assume there is at least one honest node in the\
              \ relay network, and that the zk-SNARK used is sound.\\\n\\\n# Construction\
              \ of zkBridge\\\n\\\nAs described in Section 5.3, a bridge $B \\\\mathcal\
              \ { R } \\[ S \\\\mathcal { C } \\_ { 1 } S \\\\mathcal { C } \\_ {\
              \ 2 } \\]$ consists of three components: a block header relay network,\
              \ a updater contract, and one or more application contracts. Below we\
              \ specify the protocols for each component.\\\n\\\nBlock header relay\
              \ network. We present the formal protocol of block header relay network\
              \ in Protocol 14\\\n\\\n# Protocol 14 Block header relay network\\\n\
              \\\nprocedure RELAYNEXTHEADER(LCSr−1, blkHr−1) Contact $k$ different\
              \ full nodes to get the block headers following ${ \\\\sf b } \\| {\
              \ \\\\sf k } { \\\\sf H } \\_ { r - 1 }$ , namely ${ \\\\mathsf { b\
              \ } } \\| { \\\\mathsf { k } } { \\\\mathsf { H } } \\_ { r }$ . Generate\
              \ a ZKP $\\\\pi$ proving\\\n\\\n$$\\\n\\\\mathsf { L i g h t C C } (\
              \ \\\\mathsf { L C S } \\_ { r - 1 } , \\\\mathsf { b } \\| \\\\mathsf\
              \ { k } \\\\mathsf { H } \\_ { r - 1 } , \\\\mathsf { b } \\| \\\\mathsf\
              \ { k } \\\\mathsf { H } \\_ { r } ) \\\\to \\\\mathsf { t r u e } .\\\
              \n$$\\\n\\\nSend $( \\\\pi , \\\\mathsf { b } \\| \\\\mathsf { k } \\\
              \\mathsf { H } \\_ { r } , \\\\mathsf { b } \\| \\\\mathsf { k } \\\\\
              mathsf { H } \\_ { r - 1 } )$ to the updater contract.\\\n\\\nNodes\
              \ in the block header relay network run RelayNextHeader with the current\
              \ state of the updater contract ${ \\\\mathsf { L C S } } \\_ { r -\
              \ 1 }$ , ${ \\\\mathsf { b } } \\| { \\\\mathsf { k } } { \\\\mathsf\
              \ { H } } \\_ { r - 1 } )$ as input. The exact definition of ${ \\\\\
              mathsf { L } } { \\\\mathsf { C } } { \\\\mathsf { S } } \\_ { r - 1\
              \ }$ is specific to light client protocols (see \\[CBC21\\] for a survey).\
              \ The relay node then connects to full nodes in $\\\\mathcal { C } \\\
              _ { 1 }$ and gets the block header ${ \\\\mathsf { b } } \\| { \\\\\
              mathsf { k } } { \\\\mathsf { H } } \\_ { r }$ following ${ \\\\sf b\
              \ } \\| { \\\\sf k } { \\\\sf H } \\_ { r - 1 }$ . The relay node generates\
              \ a ZKP $\\\\pi$ showing the correctness of ${ \\\\mathsf { b } } \\\
              | { \\\\mathsf { k } } { \\\\mathsf { H } } \\_ { r }$ , by essentially\
              \ proving that ${ \\\\mathsf { b } } \\| { \\\\mathsf { k } } { \\\\\
              mathsf { H } } \\_ { r }$ is accepted by a light client of $\\\\mathcal\
              \ { C } \\_ { 1 }$ after block ${ \\\\sf b } \\| { \\\\sf k } { \\\\\
              sf H } \\_ { r - 1 }$ . It then sends $( \\\\pi , \\\\mathsf { b l k\
              \ } \\\\mathsf { H } \\_ { r } )$ to the updater contract on $\\\\mathcal\
              \ { C } \\_ { 2 }$ . To avoid the wasted proof time due to collision\
              \ (note that when multiple relay nodes send at the same time, only one\
              \ proof can be accepted), relay nodes can coordinate using standard\
              \ techniques (e.g., to send in a round robin fashion). While any zero-knowledge\
              \ proofs protocol could be used, our highly optimized one will be presented\
              \ later in Section 5.4.\\\n\\\nTo incentivize block header relay nodes,\
              \ provers may be rewarded with fees after validating their proofs. We\
              \ leave incentive design for future work. A prerequisite of any incentive\
              \ scheme is unstealability \\[SCPTZ21\\], i.e., the guarantee that malicious\
              \ nodes cannot steal others’ proofs. To this end, provers will embed\
              \ their identifiers (public keys) in proofs, e.g., as input to the hash\
              \ function in the Fiat-Shamir heuristic \\[FS86\\].\\\n\\\nWe note that\
              \ this design relies on the security of the light client verifier of\
              \ the sender chain. For example, the light client verifier must reject\
              \ a valid block header that may eventually become orphaned and not part\
              \ of the sender chain.\\\n\\\nThe updater contract. The protocol for\
              \ the updater contract is specified in Protocol 15.\\\n\\\nThe updater\
              \ contract maintains the light client’s internal state including a list\
              \ of block headers of $\\\\mathcal { C } \\_ { 1 }$ in headerDAG. It\
              \ has two publicly exposed functions. The HeaderUpdate function can\
              \ be invoked by any block header relay node, providing supposedly the\
              \ next block header and a proof as input. If the proof verifies against\
              \ the current light client state LCS and ${ \\\\sf b } \\| { \\\\sf\
              \ k } { \\\\sf H } \\_ { r - 1 }$ , the contract will do further light-client\
              \ checks, and then the state will be updated accordingly. Since the\
              \ caller of this function must pay a fee, DoS attacks are naturally\
              \ prevented.\\\n\\\nThe GetHeader function can be called by receiver\
              \ contracts to get the block header at height $t$ . Receiver contracts\
              \ can use the obtained block header to finish application-specific verification,\
              \ potentially with the help of a user or some third party.\\\n\\\nApplication\
              \ contracts. zkBridge has a modular design in that the updater contract\
              \ is application-agnostic. Therefore in $B \\\\mathcal { R } \\[ S \\\
              \\mathcal { C } \\_ { 1 } S \\\\mathcal { C } \\_ { 2 } \\]$ , it is\
              \ up to the application contracts $\\\\mathcal { S } \\\\mathcal { C\
              \ } \\_ { 1 }$ and $S { \\\\mathcal { C } } \\_ { 2 }$ to decide what\
              \ the information to bridge is. Generally, proving that $S \\\\mathcal\
              \ { C } \\_ { 1 } \\[ t , K \\] = V$ is straightforward: $S { \\\\mathcal\
              \ { C } } \\_ { 2 }$ can request for a Merkle proof for the leaf of\
              \ the state Trie Tree (at block number $t$ ) corresponding to address\
              \ $K$ . The receiver contract can obtain ${ \\\\mathsf { b } } \\| {\
              \ \\\\mathsf { k } } { \\\\mathsf { H } } \\_ { t }$ from the updater\
              \ contract by calling the function GetHeader $( t )$ . Then it can verify\
              \ $S \\\\mathcal { C } \\_ { 1 } \\[ t , K \\] = V$ against the Merkle\
              \ root in ${ \\\\mathsf { b } } \\| { \\\\mathsf { k } } { \\\\mathsf\
              \ { H } } \\_ { t }$ . Required Merkle proofs are application-specific,\
              \ and are typically provided by the users of $S { \\\\mathcal { C }\
              \ } \\_ { 2 }$ , some third party, or the developer/maintainer of $S\
              \ { \\\\mathcal { C } } \\_ { 2 }$ .\\\n\\\n|     |     |\\\n| --- |\
              \ --- |\\\n| headerDAG := 0 LCS := 1 | \\> DAG of headers > light client\
              \ state |\\\n| procedure HEADERUPDATE(r, b\\|kH,, b\\|kHr-1) |  |\\\n\
              | if bIkHr-1 headerDAG then return False |  |\\\n| if verifies against\
              \ LCS, blkH,-1, blkH, then | \\> skip if parent block is not in the\
              \ DAG |\\\n| Update LCS according to the light client protocol.. | \
              \ |\\\n| Insert blkH, into headerDAG. |  |\\\n| procedure GETHEADER(t)\
              \ if t headerDAG then | \\> t is a unique identifier to a block header\
              \ |\\\n| return |  |\\\n| else | \\> tell the caller to wait |\\\n|\
              \ return headerDAG\\[t\\], LCS |  |\\\n|  | \\> The LCS will help users\
              \ to determine if t is on a fork. |\\\n\\\nSecurity arguments. The security\
              \ of zkBridge is stated in the following theorem.\\\n\\\nTheorem 5.3.1.\
              \ The bridge $B \\\\mathcal { R } \\[ S \\\\mathcal { C } \\_ { 1 }\
              \ S \\\\mathcal { C } \\_ { 2 } \\]$ implemented by protocols 14 and\
              \ 15 satisfies both consistency and liveness, assuming the following\
              \ holds:\\\n\\\n1. there is at least one honest node in the block header\
              \ relay network;\\\n\\\n2. the sender chain is consistent and live;\\\
              \n\\\n3. the sender chain has a light-client verifier as in Def. 5.2.1;\
              \ and\\\n\\\n4. the succinct proof system is sound.\\\n\\\n\\\nProof\
              \ (sketch). To prove the consistency of DAG, we first need to convert\
              \ the DAG into a list of blocks to match the definition of blockchain\
              \ consistency. We define an algorithm Longest : $\\\\mathsf { D A G\
              \ } \\\\to \\\\mathsf { I }$ List such that given a DAG, the algorithm\
              \ will output a list MainChain representing the main chain. For example,\
              \ if the sender chain is Ethereum, the algorithm Longest will first\
              \ calculate the path with the maximum total difficulty in the DAG represented\
              \ by L, and then output MainChain $\\\\therefore = \\\\mathsf { L }\
              \ \\[ : - K \\]$ . Here $K$ is a security parameter. By assumption 1\
              \ and 2, there will be an honest node in our system running either a\
              \ full node or a light node, which will be consistent with the sender\
              \ chain. Also, according to assumption 1, at least one prover node is\
              \ honestly proving the light client execution. By assumption 4 that\
              \ the proof system is sound, the updater contract will correctly verify\
              \ the light-client state. We argue that the updater contract is correctly\
              \ running the light-client protocol. Therefore, by the consistency of\
              \ the light-client protocol, MainChain will be consistent with any other\
              \ honest node.\\\n\\\nThe liveness of our protocol directly follows\
              \ from the liveness of $\\\\mathcal { C } \\_ { 1 }$ and its light client\
              \ protocol.\\\n\\\n# 5.3.3 Application use cases\\\n\\\nIn this section,\
              \ we present three examples of applications that zkBridge can support.\\\
              \n\\\nTransaction inclusion: a building block. A common building block\
              \ of cross-chain applications is to verify transaction inclusion on\
              \ another blockchain. Specifically, the goal is to enable a receiver\
              \ contract $S { \\\\mathcal { C } } \\_ { 2 }$ on $\\\\mathcal { C }\
              \ \\_ { 2 }$ to verify that a given transaction trx has been included\
              \ in a block $B \\_ { t }$ on $\\\\mathcal { C } \\_ { 1 }$ at height\
              \ $t$ . To do so, the receiver contract $S { \\\\mathcal { C } } \\\
              _ { 2 }$ needs a user or a third-party service to provide the Merkle\
              \ proof for trx in $B \\_ { t }$ . Then, $S { \\\\mathcal { C } } \\\
              _ { 2 }$ will call the updater contract to retrieve the block header\
              \ of $\\\\mathcal { C } \\_ { 1 }$ at height $t$ , and then verify the\
              \ provided Merkle proof against the Merkle root contained in the header.\\\
              \n\\\nNext, we will present three use cases that extend the building\
              \ block above.\\\n\\\n1. Message passing and data sharing. Cross-chain\
              \ message passing is another common building block useful for, e.g.,\
              \ sharing off-chain data cross blockchains.\\\n\\\nMessage passing can\
              \ be realized as a simple extension of transaction inclusion, by embedding\
              \ the message in a transaction. Specifically, to pass a message $m$\
              \ from $\\\\mathcal { C } \\_ { 1 }$ to $\\\\mathcal { C } \\_ { 2 }$\
              \ , a user can embed $m$ in a transaction $\\\\mathrm { t r } \\\\mathsf\
              \ { x } \\_ { m }$ , send $\\\\mathrm { t r } \\\\mathsf { x } \\_ {\
              \ m }$ to $\\\\mathcal { C } \\_ { 1 }$ , and then execute the above\
              \ transaction inclusion proof.\\\n\\\n2. Cross-chain assets transfer/swap.\
              \ Bridging native assets is a common use case with growing demand. In\
              \ this application, users can stake a certain amount of token $T \\\
              _ { A }$ on the sender blockchain $\\\\mathcal { C } \\_ { 1 }$ , and\
              \ get the same amount of token $T \\_ { A }$ (for native assets transfer\
              \ if eligible) or a certain amount of token $T \\_ { B }$ of approximately\
              \ the same value (for native assets swap) on the receiver blockchain\
              \ $\\\\mathcal { C } \\_ { 2 }$ . With the help of the transaction inclusion\
              \ proof, native assets transfer/swap can be achieved, as illustrated\
              \ at a high level in Section 5.3.1. Here we specify the protocol in\
              \ more detail.\\\n\\\nTo set up, the developers will deploy a lock contract\
              \ $\\\\mathcal { S } \\\\mathcal { C } \\_ { \\\\mathrm { l o c k }\
              \ }$ on $\\\\mathcal { C } \\_ { 1 }$ and a mint contract ${ \\\\mathcal\
              \ { S C } } \\_ { \\\\operatorname\\* { m i n t } }$ on $\\\\mathcal\
              \ { C } \\_ { 2 }$ . For a user who wants to exchange $n \\_ { A }$\
              \ of token $T \\_ { A }$ for an equal value in token $T \\_ { B }$ ,\
              \ she will first send a transaction $\\\\mathrm { t r } \\\\mathsf {\
              \ x } \\_ { \\\\mathrm { l o c k } }$ that transfers $n \\_ { A }$ of\
              \ token $T \\_ { A }$ to $\\\\mathcal { S } \\\\mathcal { C } \\_ {\
              \ \\\\mathrm { l o c k } }$ , along with an address $a d d r \\_ { C\
              \ \\_ { 2 } }$ to receive token $T \\_ { B }$ on $\\\\mathcal { C }\
              \ \\_ { 2 }$ . After $\\\\mathrm { t r } \\\\mathsf { x } \\_ { \\\\\
              mathrm { l o c k } }$ is confirmed in a block $B$ , the user will send\
              \ a transaction $\\\\mathrm { { t r } \\\\times \\_ { \\\\mathrm { {\
              \ m i n t } } } }$ to ${ \\\\mathcal { S C } } \\_ { \\\\mathrm { m\
              \ i n t } }$ , including sufficient information to verify the inclusion\
              \ of $\\\\mathrm { t r } \\\\mathsf { x } \\_ { \\\\mathrm { l o c k\
              \ } }$ . Based on information in $\\\\mathrm { { t r } \\\\times \\\
              _ { \\\\mathrm { { m i n t } } } }$ , ${ \\\\mathcal { S C } } \\_ {\
              \ \\\\mathrm { m i n t } }$ will verify that $\\\\mathrm { t r } \\\\\
              mathsf { x } \\_ { \\\\mathrm { l o c k } }$ has been included on C1,\
              \ and transfer the corresponding TB tokens to the address addrC specified\
              \ in trxlock. Finally, ${ \\\\mathcal { S C } } \\_ { \\\\mathrm { m\
              \ i n t } }$ will mark $\\\\mathrm { t r } \\\\mathsf { x } \\_ { \\\
              \\mathrm { l o c k } }$ as minted to conclude the transfer.\\\n\\\n\
              3. Interoperations for NFTs. In the application of Non-fungible Token\
              \ (NFT) interoperations, users always lock/stake the NFT on the sender\
              \ blockchain, and get minted NFT or NFT derivatives on the receiver\
              \ blockchain. By designing the NFT derivatives, the cross-chain protocol\
              \ can separate the ownership and utility of an NFT on two blockchain\
              \ systems, thus supporting locking the ownership of the NFT on the sender\
              \ blockchain and getting the utility on the receiver blockchain.\\\n\
              \\\n# 5.3.4 Efficient Proof Systems for zkBridge\\\n\\\nThe most computationally\
              \ demanding part of zkBridge is the zero-knowledge proofs generation\
              \ that relay nodes must do for every block. So far we have abstracted\
              \ away the detail of proof generation, which we will address in Sections\
              \ 5.4 and 5.5. Here, we present an overview of our solution.\\\n\\\n\
              For Proof-of-Stake chains, the proofs involve verifying hundreds of\
              \ signatures. A major source of over head is field transformation between\
              \ different elliptic curves when the sender and receiver chains use\
              \ different cryptography implementation, which is quite common in practice.\
              \ For example, Cosmos uses EdDSA on Curve25519 whereas Ethereum natively\
              \ supports a different curve BN254. The circuit for verifying a single\
              \ Cosmos signature in the field supported by Ethereum involves around\
              \ 2 million gates, thus verifying a block (typically containing 32 signatures)\
              \ will involve over 64 million gates, which is too big for existing\
              \ zero-knowledge proofs schemes.\\\n\\\nTo make zkBridge practical,\
              \ we propose two ideas.\\\n\\\nReducing proof time with deVirgo We observe\
              \ that the ZKP circuit for verifying multiple signatures is composed\
              \ of multiple copies of one sub-circuit. Our first idea is to take advantage\
              \ of this special structure and distribute proof generation across multiple\
              \ servers. We propose a novel distributed ZKP protocol dubbed deVirgo,\
              \ which carefully parallelizes the Virgo \\[ZXZS20\\] protocol, one\
              \ of the fastest ZKP systems (in terms of prover time) without a trusted\
              \ setup. With deVirgo, we can accelerate proof generation in zkBridge\
              \ with perfect linear scalability. We will dive into the detail of deVirgo\
              \ in Section 5.4.\\\n\\\nReducing on-chain cost by recursive verification.\
              \ While verifying deVirgo proofs on ordinary CPUs is very efficient,\
              \ on-chain verification is still costly. To further reduce the on-chain\
              \ verification cost (computation and storage), we use recursive verification:\
              \ the prover recursively proves the correctness of a (potentially large)\
              \ Virgo proof using a smart-contract-friendly zero-knowledge protocol\
              \ to get a small and verifierefficient proof. At a high level, we trade\
              \ slightly increased proof generation time for much reduced on-chain\
              \ verification cost: the proof size reduces from $2 0 0 { + } \\\\mathrm\
              \ { K B }$ to 131 bytes, and the required computation reduces from infeasible\
              \ amount of gas to 210K gas. We will present more detail of recursive\
              \ verification in Section 5.5.\\\n\\\n# 5.4 Distributed proof generation\\\
              \n\\\nAs observed previously, the opportunity for fast prover time stems\
              \ from the fact that the circuit for verifying $N$ signatures consists\
              \ of $N$ copies of identical sub-circuits. This type of circuits is\
              \ called data-parallel \\[Tha15\\]. The advantage of data-parallel circuits\
              \ is that there is no connection among different sub-copies. Therefore,\
              \ each copy can be handled separately. We consider accelerating the\
              \ proof generation on such huge circuits by dealing with each sub-circuit\
              \ in parallel. In this section, we propose a distributed zk-SNARK protocol\
              \ on data-parallel circuits.\\\n\\\nThere are many zero knowledge proofs\
              \ protocols \\[ZXZS20; XZZPS19b; Set20; WTSTW18; BSCTV14c; BSCRSVW19;\
              \ AHIV17; BSBHR19; Zha $+ 2 1 \\\\mathbf { a }$ ; GWC19b; COS20\\] supporting\
              \ our computation. We choose Virgo as the underlying ZKP protocols for\
              \ two reasons: 1. Virgo does not need a trusted setup and is plausibly\
              \ post-quantum secure. 2. Virgo is one of the fastest protocols with\
              \ succinct verification time and succinct proof size for problems in\
              \ large scale. We present a new distributed version of Virgo for data-parallel\
              \ arithmetic circuits achieving optimal scalability without any overhead\
              \ on the proof size. Specifically, our protocol of deVirgo on data-parallel\
              \ circuits with $N$ copies using $N$ parallel machines is $N$ times\
              \ faster than the original Virgo while the proof size remains the same.\
              \ Our scheme is of independent interest and is possible to be used in\
              \ other Virgo-based systems to improve the efficiency.\\\n\\\nWe provide\
              \ the overall description of deVirgo as follows. Suppose the prover\
              \ has $N$ machines in total, labeled from $\\\\mathcal { P } \\_ { 0\
              \ }$ to $\\\\mathcal { P } \\_ { N - 1 }$ . Assume $\\\\mathcal { P\
              \ } \\_ { 0 }$ is the master node while other machines are ordinary\
              \ nodes. Assume $\\\\nu$ is the verifier. Given a data-parallel arithmetic\
              \ circuit consisting of $N$ identical structures, the naïve algorithm\
              \ of the distributed Virgo is to assign each sub-circuit to a separate\
              \ node. Then each node runs Virgo to generate the proof separately.\
              \ The concatenation of $N$ proofs is the final proof. Unfortunately,\
              \ the proof size in this naive algorithm scales linearly in the number\
              \ of sub-circuits, which can be prohibitively large for data-parallel\
              \ circuits with many sub-copies. To address the problem, our approach\
              \ removes the additional factor of $N$ in the proof size by aggregating\
              \ messages and proofs among distributed machines. Specifically, the\
              \ original protocol of Virgo consists of two major building blocks.\
              \ One is the GKR protocol \\[GKR15\\], which consists of $d$ sumcheck\
              \ protocols \\[LFKN92\\] for a circuit of depth $d$ . The other is the\
              \ polynomial commitment (PC) scheme. We design distributed schemes for\
              \ each of the sumcheck and the polynomial commitment (PC). In our distributed\
              \ sumcheck protocol, a master node $\\\\mathcal { P } \\_ { 0 }$ aggregates\
              \ messages from all machines, then sends the aggregated message to $\\\
              \\nu$ in every round, instead of sending messages from all machines\
              \ directly to $\\\\nu$ . Our protocol for distributed sumcheck has exactly\
              \ the same proof size as the original sumcheck protocol, thus saving\
              \ a factor $N$ over the naïve distributed protocol. Additionally, in\
              \ our distributed PC protocol, we optimize the commitment phase and\
              \ make $\\\\mathcal { P } \\_ { 0 }$ aggregate $N$ commitments into\
              \ one instead of sending $N$ commitments directly to $\\\\nu$ . During\
              \ the opening phase, the proof can also be aggregated, which improves\
              \ the proof size by a logarithmic factor in the size of the polynomial.\\\
              \n\\\nWe present preliminaries in Section 5.4.1, the detail of the distributed\
              \ sumcheck protocol in Section 5.4.2 and the detail of the distributed\
              \ PC protocol in Section 5.4.3. We combine them all together to build\
              \ deVirgo in Section 5.4.4.\\\n\\\n# 5.4.1 Preliminaries\\\n\\\nMulti-linear\
              \ extension/polynomial. Let $V : { 0 , 1 } ^ { \\\\ell } \\ \\ \\\\\
              mathbb { F }$ be a function. The multi-linear extension/polynomial of\
              \ $V$ is the unique polynomial $\\\\tilde { V } : \\\\mathbb { F } ^\
              \ { \\\\ell } \\\\to \\\\mathbb { F }$ such that $\\\\tilde { V } (\
              \ \\\\mathbf { x } ) = V ( \\\\mathbf { x } )$ for all $\\\\mathbf {\
              \ x } \\\\in { 0 , 1 } ^ { \\\\ell }$ . $\\\\tilde { V }$ can be expressed\
              \ as:\\\n\\\n$$\\\n\\\\begin{array} { r } { \\\\tilde { V } ( \\\\mathbf\
              \ { x } ) = \\\\sum \\_ { \\\\mathbf { b } \\\\in { 0 , 1 } ^ { \\\\\
              ell } } \\\\prod \\_ { i = 1 } ^ { \\\\ell } ( ( 1 - x \\_ { i } ) (\
              \ 1 - b \\_ { i } ) + x \\_ { i } b \\_ { i } ) ) \\\\cdot V ( \\\\\
              mathbf { b } ) , } \\\\end{array}\\\n$$\\\n\\\nwhere $b \\_ { i }$ is\
              \ $i$ -th bit of $\\\\mathbf { b }$ .\\\n\\\nIdentity function. Let\
              \ $\\\\beta : { 0 , 1 } ^ { \\\\ell } \\\\times { 0 , 1 } ^ { \\\\ell\
              \ } \\\\to { 0 , 1 }$ be the identity function such that $\\\\beta (\
              \ \\\\mathbf { x } , \\\\mathbf { y } ) = 1$ if $\\\\mathbf x = \\\\\
              mathbf y$ , and $\\\\beta ( \\\\mathbf { x } , \\\\mathbf { y } ) =\
              \ 0$ otherwise. Suppose $\\\\beta$ is the multilinear extension of $\\\
              \\beta$ . Then $\\\\beta$ can be expressed as: $\\\\begin{array} { r\
              \ } { \\\\beta ( \\\\mathbf { x } , \\\\mathbf { y } ) = \\\\prod \\\
              _ { i = 1 } ^ { \\\\ell } ( ( 1 - x \\_ { i } ) ( 1 - y \\_ { i } )\
              \ + x \\_ { i } y \\_ { i } ) } \\\\end{array}$ .\\\n\\\n# 5.4.2 Distributed\
              \ sumcheck\\\n\\\nBackground: the sumcheck protocol. The sumcheck problem\
              \ is to sum a multivariate polynomial $f :$ $\\\\mathbb { F } ^ { \\\
              \\ell } \\\\to \\\\mathbb { F }$ over all binary inputs: $\\\\begin{array}\
              \ { r } { \\\\sum \\_ { b \\_ { 1 } , \\\\cdots , b \\_ { \\\\ell }\
              \ \\\\in { 0 , 1 } } f ( b \\_ { 1 } , \\\\cdots , b \\_ { \\\\ell }\
              \ ) } \\\\end{array}$ . The sumcheck protocol allows the prover $\\\\\
              mathcal { P }$ to convince the verifier $\\\\nu$ that the summation\
              \ is $H$ via a sequence of interactions, and the formal protocol is\
              \ presented in Protocol 8.\\\n\\\nThe high-level idea of the sumcheck\
              \ protocol is to divide the verification into $\\\\ell$ rounds. In each\
              \ round, the prover only sends a univariate polynomial to the verifier.\
              \ The verifier checks the correctness of the polynomial by a single\
              \ equation. Then this variable will be replaced by a random point sampled\
              \ by the verifier. As there are totally $\\\\ell$ variables in $f$ ,\
              \ after $\\\\ell$ rounds, the claim about the summation will be reduced\
              \ to a claim about $f$ on a random vector r. Given the oracle access\
              \ to $f$ on a random vector, the verifier can check the last claim.\\\
              \n\\\nThe GKR protocol. We follow the convention in prior works of GKR\
              \ protocols \\[CMT12; Tha13b; ZGKPP17d; XZZPS19b; ZXZS20\\]. We denote\
              \ the number of gates in the $i$ -th layer as $S \\_ { i }$ and let\
              \ $s \\_ { i } =$\\\n\\\nProtocol 8 (Sumcheck). The protocol proceeds\
              \ in $\\\\ell$ rounds.\\\n\\\n• In the first round, $\\\\mathcal { P\
              \ }$ sends a univariate polynomial\\\n\\\n$$\\\nf \\_ { 1 } ( x \\_\
              \ { 1 } ) \\\\stackrel { d e f } { = } \\\\displaystyle \\\\sum \\_\
              \ { b \\_ { 2 } , \\\\ldots , b \\_ { \\\\ell } \\\\in { 0 , 1 } } f\
              \ ( x \\_ { 1 } , b \\_ { 2 } , \\\\ldots , b \\_ { \\\\ell } ) ,\\\n\
              $$\\\n\\\n$\\\\nu$ checks $H = f \\_ { 1 } ( 0 ) + f \\_ { 1 } ( 1 )$\
              \ . Then $\\\\nu$ sends a random challenge $r \\_ { 1 } \\\\in \\\\\
              mathbb { F }$ to $\\\\mathcal { P }$ .\\\n\\\n• In the $i$ -th round,\
              \ where $2 \\\\leq i \\\\leq \\\\ell - 1 , \\\\mathcal { P }$ sends\
              \ a univariate polynomial\\\n\\\n$$\\\nf \\_ { i } ( x \\_ { i } ) \\\
              \\stackrel { d e f } { = } \\\\sum \\_ { b \\_ { i + 1 } , \\\\ldots\
              \ , b \\_ { \\\\ell } \\\\in { 0 , 1 } } f ( r \\_ { 1 } , \\\\ldots\
              \ , r \\_ { i - 1 } , x \\_ { i } , b \\_ { i + 1 } , \\\\ldots , b\
              \ \\_ { \\\\ell } ) ,\\\n$$\\\n\\\n$\\\\nu$ checks $f \\_ { i - 1 }\
              \ ( r \\_ { i - 1 } ) = f \\_ { i } ( 0 ) + f \\_ { i } ( 1 )$ , and\
              \ sends a random challenge $r \\_ { i } \\\\in \\\\mathbb { F }$ to\
              \ $\\\\mathcal { P }$ .\\\n\\\n• In the $\\\\ell$ -th round, $\\\\mathcal\
              \ { P }$ sends a univariate polynomial\\\n\\\n$$\\\n\\\\begin{array}\
              \ { r } { f \\_ { \\\\ell } ( x \\_ { \\\\ell } ) \\\\overset { d e\
              \ f } { = } f ( r \\_ { 1 } , r \\_ { 2 } , \\\\ldots , r \\_ { l -\
              \ 1 } , x \\_ { \\\\ell } ) , } \\\\end{array}\\\n$$\\\n\\\n$\\\\nu$\
              \ checks $f \\_ { \\\\ell - 1 } ( r \\_ { \\\\ell - 1 } ) = f \\_ {\
              \ \\\\ell } ( 0 ) + f \\_ { \\\\ell } ( 1 )$ . The verifier generates\
              \ a random challenge $r \\_ { \\\\ell } ~ \\\\in$ $\\\\mathbb { F }$\
              \ . Given oracle access to an evaluation $f ( r \\_ { 1 } , r \\_ {\
              \ 2 } , \\\\ldots , r \\_ { \\\\ell } )$ of $f , \\\\nu$ will accept\
              \ if and only if $f \\_ { \\\\ell } ( r \\_ { \\\\ell } ) = f ( r \\\
              _ { 1 } , r \\_ { 2 } , \\\\ldots , r \\_ { \\\\ell } )$ . The oracle\
              \ access can be instantiated by PC.\\\n\\\n$\\\\lceil \\\\log S \\_\
              \ { i } \\\\rceil$ . (For simplicity, we assume $S \\_ { i }$ is a power\
              \ of 2, and we can pad the layer with dummy gates otherwise.) We then\
              \ define a function $V \\_ { i } : { 0 , 1 } ^ { s \\_ { i } } \\\\\
              to \\\\mathbb { F }$ that takes a binary string $\\\\mathbf { b } \\\
              \\in { 0 , 1 } ^ { s \\_ { i } }$ and returns the output of gate $\\\
              \\mathbf { b }$ in layer $i$ , where $\\\\mathbf { b }$ is called the\
              \ gate label. With this definition, $V \\_ { 0 }$ corresponds to the\
              \ output of the circuit, and $V \\_ { d }$ corresponds to the input\
              \ layer. Finally, we define two additional functions $a d d \\_ { i\
              \ } , \\\\bar { m } u l t \\_ { i } : { 0 , 1 } ^ { s \\_ { i - 1 }\
              \ + 2 s \\_ { i } } { 0 , 1 }$ , referred to as wiring predicates in\
              \ the literature. $a d d \\_ { i }$ $( m u l t \\_ { i } )$ takes one\
              \ gate label $\\\\mathbf { z } \\\\in { 0 , 1 } ^ { s \\_ { i - 1 }\
              \ }$ in layer $i - 1$ and two gate labels $\\\\mathbf { x } , \\\\mathbf\
              \ { y } \\\\in { 0 , 1 } ^ { s \\_ { i } }$ in layer $i$ , and outputs\
              \ 1 if and only if gate $\\\\mathbf { z }$ is an addition (multiplication)\
              \ gate that takes the output of gate $\\\\mathbf x , \\\\mathbf y$ as\
              \ input. With these definitions, for any $\\\\mathbf { z } \\\\in {\
              \ 0 , 1 } ^ { s \\_ { i } }$ , $V \\_ { i }$ can be written as:\\\n\\\
              \n$$\\\n\\\\begin{array} { r } { V \\_ { i } ( \\\\mathbf { z } ) =\
              \ \\\\sum \\_ { \\\\mathbf { x } , \\\\mathbf { y } \\\\in { 0 , 1 }\
              \ ^ { s \\_ { i + 1 } } } ( a d d \\_ { i + 1 } ( \\\\mathbf { z } ,\
              \ \\\\mathbf { x } , \\\\mathbf { y } ) ( V \\_ { i + 1 } ( \\\\mathbf\
              \ { x } ) + V \\_ { i + 1 } ( \\\\mathbf { y } ) ) } \\ { + m u l t\
              \ \\_ { i + 1 } ( \\\\mathbf { z } , \\\\mathbf { x } , \\\\mathbf {\
              \ y } ) V \\_ { i + 1 } ( \\\\mathbf { x } ) V \\_ { i + 1 } ( \\\\\
              mathbf { y } ) ) } \\\\end{array}\\\n$$\\\n\\\nIn the equation above,\
              \ $V \\_ { i }$ is expressed as a summation, so $\\\\nu$ can use the\
              \ sumcheck protocol to check that it is computed correctly. As the sumcheck\
              \ protocol operates on polynomials defined on $\\\\mathbb { F }$ , we\
              \ rewrite the\\\n\\\nequation with their multi-linear extensions:\\\n\
              \\\n$$\\\n\\\\begin{array} { r l } & { \\\\tilde { V } \\_ { i } ( \\\
              \\mathbf { g } ) = \\\\sum \\_ { \\\\mathbf { x } , \\\\mathbf { y }\
              \ \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } h \\_ { i } ( \\\\mathbf\
              \ { g } , \\\\mathbf { x } , \\\\mathbf { y } ) } \\ & { \\\\qquad =\
              \ \\\\sum \\_ { \\\\mathbf { x } , \\\\mathbf { y } \\\\in { 0 , 1 }\
              \ ^ { s \\_ { i + 1 } } } ( a \\\\tilde { d } d \\_ { i + 1 } ( \\\\\
              mathbf { g } , \\\\mathbf { x } , \\\\mathbf { y } ) ( \\\\tilde { V\
              \ } \\_ { i + 1 } ( \\\\mathbf { x } ) + \\\\tilde { V } \\_ { i + 1\
              \ } ( \\\\mathbf { y } ) ) } \\ & { \\\\qquad + m \\\\tilde { u } l\
              \ t \\_ { i + 1 } ( \\\\mathbf { g } , \\\\mathbf { x } , \\\\mathbf\
              \ { y } ) \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf { x } ) \\\\tilde\
              \ { V } \\_ { i + 1 } ( \\\\mathbf { y } ) ) , } \\\\end{array}\\\n\
              $$\\\n\\\nwhere $\\\\mathbf { g } \\\\in \\\\mathbb { F } ^ { s \\_\
              \ { i } }$ is a random vector.\\\n\\\nWith Equation 5.2, the GKR protocol\
              \ proceeds as following. The prover $\\\\mathcal { P }$ first sends\
              \ the claimed output of the circuit to $\\\\nu$ . From the claimed output,\
              \ $\\\\nu$ defines polynomial $\\\\tilde { V } \\_ { 0 }$ and computes\
              \ $\\\\tilde { V } \\_ { 0 } ( \\\\mathbf { g } )$ for a random $\\\\\
              mathbf { g } \\\\in \\\\mathbb { F } ^ { s \\_ { 0 } }$ . $\\\\nu$ and\
              \ $\\\\mathcal { P }$ then invoke a sumcheck protocol on Equation 5.2\
              \ with $i = 0$ . As described in Protocol 8, at the end of the sumcheck,\
              \ $\\\\nu$ needs an oracle access to $h \\_ { i } ( \\\\mathbf { g }\
              \ , \\\\mathbf { u } , \\\\mathbf { v } )$ , where $\\\\mathbf { u }\
              \ , \\\\mathbf { v }$ are randomly selected in $\\\\mathbb { F } ^ {\
              \ s \\_ { i + 1 } }$ . To compute $h \\_ { i } ( \\\\mathbf { g } ,\
              \ \\\\mathbf { u } , \\\\mathbf { v } )$ , $\\\\nu$ computes $a \\\\\
              tilde { d } d \\_ { i + 1 } ( \\\\mathbf { g } , \\\\mathbf { u } ,\
              \ \\\\mathbf { v } )$ and $\\\\tilde { m u l t } \\_ { i + 1 } ( \\\\\
              mathbf { g } , \\\\mathbf { u } , \\\\mathbf { v } )$ locally (they\
              \ only depend on the wiring pattern of the circuit, not on the values),\
              \ asks $\\\\mathcal { P }$ to send $\\\\tilde { V } \\_ { 1 } ( \\\\\
              mathbf { u } )$ and $\\\\tilde { V } \\_ { 1 } ( \\\\mathbf { v } )$\
              \ and computes $h \\_ { i } ( \\\\mathbf { g } , \\\\mathbf { u } ,\
              \ \\\\mathbf { v } )$ to complete the sumcheck protocol. In this way,\
              \ $\\\\nu$ and $\\\\mathcal { P }$ reduce a claim about the output to\
              \ two claims about values in layer 1. $\\\\nu$ and $\\\\mathcal { P\
              \ }$ could invoke two sumcheck protocols on $\\\\tilde { V } \\_ { 1\
              \ } ( \\\\mathbf { u } )$ and $\\\\tilde { V } \\_ { 1 } ( \\\\mathbf\
              \ { \\\\bar { v } } )$ recursively to layers above, but the number of\
              \ the sumcheck protocols would increase exponentially.\\\n\\\nOne way\
              \ to combine two claims $\\\\tilde { V } \\_ { i } ( { \\\\mathbf {\
              \ u } } )$ and $\\\\tilde { V } \\_ { i } ( { \\\\bf { v } } )$ is using\
              \ random linear combinations, as proposed in \\[CFS17; WTSTW18\\]. Upon\
              \ receiving the two claims $\\\\tilde { V } \\_ { i } ( { \\\\mathbf\
              \ { u } } )$ and $\\\\tilde { V } \\_ { i } ( { \\\\bf { v } } )$ ,\
              \ $\\\\nu$ selects $\\\\alpha \\_ { i , 1 } , \\\\alpha \\_ { i , 2\
              \ } \\\\in \\\\mathbb { F }$ randomly and computes $\\\\alpha \\_ {\
              \ i , 1 } \\\\tilde { V } \\_ { i } ( { \\\\mathbf { u } } ) + \\\\\
              tilde { \\\\alpha } \\_ { i , 2 } \\\\tilde { V } \\_ { i } ( { \\\\\
              mathbf { v } } )$ . Based on Equation 5.2, this random linear combination\
              \ can be written as\\\n\\\n$$\\\n\\\\begin{array} { r l } & { \\\\quad\
              \ \\\\alpha \\_ { i , 1 } \\\\tilde { V } \\_ { i } ( \\\\mathbf { u\
              \ } ) + \\\\alpha \\_ { i , 2 } \\\\tilde { V } \\_ { i } ( \\\\mathbf\
              \ { v } ) } \\ & { = \\\\alpha \\_ { i , 1 } \\\\quad \\\\quad } \\\
              \ & { \\\\quad \\\\quad \\\\quad \\\\quad \\\\times \\\\mathbf { y }\
              \ \\\\in { 0 , 1 } ^ { s } \\\\dot { s } + 1 \\\\dot { a } d \\_ { i\
              \ + 1 } ( \\\\mathbf { u } , \\\\mathbf { x } , \\\\mathbf { y } ) (\
              \ \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf { x } ) + \\\\tilde { V\
              \ } \\_ { i + 1 } ( \\\\mathbf { y } ) ) } \\ & { \\\\quad + m \\\\\
              tilde { u } t t \\_ { i + 1 } ( \\\\mathbf { u } , \\\\mathbf { x }\
              \ , \\\\mathbf { y } ) \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf {\
              \ x } ) \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf { y } ) } \\ & {\
              \ \\\\quad + \\\\alpha \\_ { i , 2 } \\\\quad \\\\quad \\\\quad \\\\\
              quad \\\\quad \\\\quad \\\\times \\\\underline { { a } } \\\\dot { d\
              \ } d \\_ { i + 1 } ( \\\\mathbf { v } , \\\\mathbf { x } , \\\\mathbf\
              \ { y } ) ( \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf { x } ) + \\\\\
              tilde { V } \\_ { i + 1 } ( \\\\mathbf { y } ) ) } \\ & { \\\\quad \\\
              \\quad \\\\quad \\\\quad \\\\quad \\\\times \\\\mathbf { y } \\\\in\
              \ { 0 , 1 } ^ { s } \\\\dot { s } + 1 } \\ & { \\\\quad \\\\quad \\\\\
              quad \\\\quad \\\\quad \\\\times \\\\mathbf { y } \\\\in { 1 , 1 } ^\
              \ { s } \\\\mathbf { x } , \\\\mathbf { y } \\\\tilde { V } \\_ { i\
              \ + 1 } ( \\\\mathbf { x } ) \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf\
              \ { y } ) } \\ & { = \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\
              \\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad\
              \ \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\\
              quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad\
              \ \\\\quad \\\\quad \\\\quad \\\\quad } \\ & \\\\quad \\\\quad \\\\\
              quad \\\\quad \\\\quad \\\\quad \\\\times \\\\mathbf { y } \\\\in {\
              \ 0 , 1 } ^ { s } \\\\dot { s } d \\\\bar { d } d \\_ { i + 1 } ( \\\
              \\mathbf { u } , \\\\mathbf { x } , \\\\mathbf { y } ) + \\\\alpha \\\
              _ { i , 2 } \\\\tilde { a } d \\_ { d + 1 } ( \\\\mathbf { v } , \\\\\
              mathbf { x } , \\\\mathbf { y } ) ) ( \\\\tilde { V } \\_ { i + 1 }\
              \ ( \\ \\\\end{array}\\\n$$\\\n\\\n$\\\\nu$ and $\\\\mathcal { P }$\
              \ then execute the sumcheck protocol on Equation 5.3 instead of Equation\
              \ 5.2. At the end of the sumcheck protocol, $\\\\nu$ still receives\
              \ two claims about $\\\\tilde { V } \\_ { i + 1 }$ , computes their\
              \ random linear combination and proceeds to the layer above recursively\
              \ until the input layer. The formal GKR protocol is presented in Protocol\
              \ 9.\\\n\\\nComplexity of the sumcheck protocol in GKR protocol. For\
              \ simplicity in the complexity analysis, we define the sumcheck equation\
              \ in GKR protocol as\\\n\\\n$$\\\n\\\\tilde { V } \\_ { i } ( \\\\mathbf\
              \ { g } ) = \\\\sum \\_ { \\\\mathbf { x } \\\\in { 0 , 1 } ^ { \\\\\
              ell } } f ( \\\\mathbf { x } , \\\\tilde { V } \\_ { i + 1 } ( \\\\\
              mathbf { x } ) ) ,\\\n$$\\\n\\\nProtocol 9 (GKR). Let $\\\\mathbb {\
              \ F }$ be a finite field. Let $C$ : $\\\\mathbb { F } ^ { m } \\\\to\
              \ \\\\mathbb { F } ^ { k }$ be a $d$ -depth layered arithmetic circuit.\
              \ $\\\\mathcal { P }$ wants to convince that $C ( \\\\mathbf { x } )\
              \ = \\\\mathbf { 1 }$ where $\\\\mathbf { x }$ is the input from $\\\
              \\nu$ , and 1 is the output. Without loss of generality, assume $m$\
              \ and $k$ are both powers of 2 and we can pad them if not.\\\n\\\n1.\
              \ $\\\\nu$ chooses a random $\\\\mathbf { g } \\\\in \\\\mathbb { F\
              \ } ^ { s \\_ { 0 } }$ and sends it to $\\\\mathcal { P }$ .\\\n\\\n\
              2. $\\\\mathcal { P }$ and $\\\\nu$ run a sumcheck protocol on\\\n\\\
              \n\\\n$$\\\n1 = \\\\sum \\_ { \\\\mathbf { x } , \\\\mathbf { y } \\\
              \\in { 0 , 1 } ^ { s \\_ { 1 } } } ( a \\\\tilde { d } d \\_ { 1 } (\
              \ \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf { x } , \\\\mathbf { y }\
              \ ) ( \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { x } ) + \\\\tilde { V\
              \ } \\_ { 1 } ( \\\\mathbf { y } ) ) + m \\\\tilde { u } l t \\_ { 1\
              \ } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf { x } , \\\\mathbf {\
              \ y } ) \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { x } ) \\\\tilde { V\
              \ } \\_ { 1 } ( \\\\mathbf { y } ) )\\\n$$\\\n\\\nAt the end of the\
              \ protocol, $\\\\nu$ receives $\\\\tilde { V } \\_ { 1 } ( \\\\mathbf\
              \ { u } ^ { ( 1 ) } )$ and $\\\\tilde { V } \\_ { 1 } ( \\\\mathbf {\
              \ v } ^ { ( 1 ) } )$ . $\\\\nu$ computes $\\\\begin{array} { r l r }\
              \ { m \\\\tilde { u } l t \\_ { 1 } ( { \\\\bf g } ^ { ( 0 ) } , { \\\
              \\bf u } ^ { ( 1 ) } , { \\\\bf v } ^ { ( 1 ) } ) , } & { { } a \\\\\
              tilde { d } d \\_ { 1 } ( { \\\\bf g } ^ { ( 0 ) } , { \\\\bf u } ^\
              \ { ( 1 ) } , { \\\\bf v } ^ { ( 1 ) } ) } & { \\\\tilde { \\\\mathrm\
              \ { a r } } } \\\\end{array}$ d checks that $\\\\tilde { a d d \\_ {\
              \ 1 } } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf { u } ^ { ( 1 )\
              \ } , \\\\mathbf { \\\\bar { v } } ^ { ( 1 ) } )$ $( \\\\tilde { V }\
              \ \\_ { 1 } ( \\\\mathbf { u } ^ { ( 1 ) } ) + \\\\tilde { V } \\_ {\
              \ 1 } ( \\\\mathbf { v } ^ { ( 1 ) } ) ) + m \\\\tilde { u } l t \\\
              _ { 1 } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf { u } ^ { ( 1 )\
              \ } , \\\\mathbf { v } ^ { ( 1 ) } ) \\ \\\\tilde { V } \\_ { 1 } (\
              \ \\\\mathbf { u } ^ { ( 1 ) } ) \\\\tilde { V } \\_ { 1 } ( \\\\mathbf\
              \ { v } ^ { ( 1 ) } )$ equals to the last message of the sumcheck.\\\
              \n\\\n3. For $i = 1 , . . . , d - 1$ :\\\n\\\n• $\\\\nu$ randomly selects\
              \ $\\\\alpha \\_ { i , 1 } , \\\\alpha \\_ { i , 2 } \\\\in \\\\mathbb\
              \ { F }$ and sends them to $\\\\mathcal { P }$ . • $\\\\mathcal { P\
              \ }$ and $\\\\nu$ run the sumcheck on the equation\\\n\\\n$$\\\n\\\\\
              begin{array} { l } { { \\\\displaystyle \\\\alpha \\_ { i , 1 } { \\\
              \\tilde { V } } \\_ { i } ( { \\\\bf u } ^ { ( i ) } ) + \\\\alpha \\\
              _ { i , 2 } { \\\\tilde { V } } \\_ { i } ( { \\\\bf v } ^ { ( i ) }\
              \ ) = } \\ ~ } \\ { { \\\\displaystyle \\\\sum \\_ { { \\\\bf x } ,\
              \ { \\\\bf y } \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } ( ( \\\\alpha\
              \ \\_ { i , 1 } a \\\\tilde { d } d \\_ { i + 1 } { \\\\bf u } ^ { (\
              \ i ) } , { \\\\bf x } , { \\\\bf y } ) + \\\\alpha \\_ { i , 2 } a\
              \ \\\\tilde { d } d \\_ { i + 1 } ( { \\\\bf v } ^ { ( i ) } , { \\\\\
              bf x } , { \\\\bf y } ) ) ( { \\\\tilde { V } } \\_ { i + 1 } ( { \\\
              \\bf x } ) + { \\\\tilde { V } } \\_ { i + 1 } ( { \\\\bf y } ) ) }\
              \ \\ ~ } \\ { { \\\\displaystyle ~ + ( \\\\alpha \\_ { i , 1 } m \\\\\
              tilde { u } l t \\_ { i + 1 } ( { \\\\bf u } ^ { ( i ) } , { \\\\bf\
              \ x } , { \\\\bf y } ) + \\\\alpha \\_ { i , 2 } m \\\\tilde { u } l\
              \ t \\_ { i + 1 } ( { \\\\bf v } ^ { ( i ) } , { \\\\bf x } , { \\\\\
              bf y } ) ) { \\\\tilde { V } } \\_ { i + 1 } ( { \\\\bf x } ) { \\\\\
              tilde { V } } \\_ { i + 1 } ( { \\\\bf y } ) ) } } \\\\end{array}\\\n\
              $$\\\n\\\n• At the end of the sumcheck protocol, $\\\\mathcal { P }$\
              \ sends $\\\\mathcal { V } \\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf\
              \ { u } ^ { ( i + 1 ) } )$ and $\\\\tilde { V } \\_ { i + 1 } ( \\\\\
              mathbf { v } ^ { ( i + 1 ) } )$\\\n\\\n• $\\\\nu$ computes the right-hand\
              \ side of the above equation by replacing $\\\\mathbf { x }$ and y by\
              \ $\\\\mathbf { u } ^ { ( i + 1 ) }$ and $\\\\mathbf { v } ^ { ( \\\
              \ i + 1 ) }$ respectively. checks if it equals to the last message of\
              \ the sumcheck. If all checks in the sumcheck pass, $V$ uses $\\\\tilde\
              \ { V } \\_ { i + 1 } ( \\\\mathbf { u } ^ { ( i + 1 ) } )$ and $\\\\\
              breve { V } \\_ { i + 1 } ( \\\\mathbf { v } ^ { ( i + 1 ) } )$ to proceed\
              \ to the $( i + 1 )$ -th layer. Otherwise, $\\\\nu$ outputs 0 and aborts.\\\
              \n\\\n4. At the input layer $d , \\\\nu$ has two claims $\\\\tilde {\
              \ V } \\_ { d } ( \\\\mathbf { u } ^ { ( d ) } )$ and $\\\\tilde { V\
              \ } \\_ { d } ( \\\\mathbf { v } ^ { ( d ) } )$ . $\\\\nu$ evaluates\
              \ $\\\\tilde { V \\_ { d } }$ at $\\\\mathbf { u } ^ { ( d ) }$ and\
              \ $\\\\mathbf { v } ^ { ( d ) }$ using the input and checks that they\
              \ are the same as the two claims. If yes, output 1; otherwise, output\
              \ 0.\\\n\\\nwhere $f$ is some polynomial from $\\\\mathbb { F } ^ {\
              \ \\\\ell }$ to $\\\\mathbb { F }$ and $\\\\mathbf { g }$ is a random\
              \ vector in $\\\\mathbb { F } ^ { \\\\ell }$ . For the multivariate\
              \ polynomial of $f$ defined in Equation 5.4, the prover time in Protocol\
              \ 8 is $O ( 2 ^ { \\\\ell } )$ . The proof size is $O ( \\\\ell )$ and\
              \ the verifier time is $O ( \\\\ell )$ .\\\n\\\nIn the setting of data-parallel\
              \ circuits, we distribute the sumcheck polynomial $f$ among parallel\
              \ machines. Suppose the data-parallel circuit C consists of $N$ identical\
              \ sub-circuits of $\\\\mathsf C \\_ { 0 } , \\\\cdots , \\\\mathsf C\
              \ \\_ { N - 1 }$ and $N = 2 ^ { n }$ for some integer $n$ without loss\
              \ of generality. The polynomial $f : \\\\mathbb { F } ^ { \\\\ell }\
              \ \\\\to \\\\mathbb { F }$ is defined on $C$ by Equation 5.4.\\\n\\\n\
              The idea of our distributed sumcheck protocol is to treat each sub-copy\
              \ as a new circuit as there is no wiring connections across different\
              \ sub-circuits. We define polynomials of ${ \\\\bf \\\\bar { \\\\boldsymbol\
              \ { f } } } ^ { ( 0 ) } , \\\\cdot \\\\cdot \\\\cdot , f ^ { ( N - 1\
              \ ) }$ on $\\\\mathsf { C } \\_ { 0 } , \\\\cdot \\\\cdot \\\\cdot ,\
              \ \\\\mathsf { C } \\_ { N - 1 } : \\\\mathbb { F } ^ { \\\\ell - n\
              \ } \\\\to \\\\mathbb { F }$ respectively by Equation 5.4 in the GKR\
              \ protocol, which have the same form as $f$ defined on $C$ . The naïve\
              \ approach is running the sumcheck protocol on these polynomials separately.\
              \ As there are $N$ proofs in total and each size is $O ( \\\\ell - n\
              \ )$ , the total proof size will be $O ( N ( \\\\ell - n ) )$ . To reduce\
              \ the proof size back to $\\\\ell$ , the prover needs to aggregate $N$\
              \ proofs to generate a single proof on $f$ . We observe that the sumcheck\
              \ protocol on data-parallel circuits satisfies $f ^ { ( i ) } ( { \\\
              \\bf x } ) = f ( { \\\\bf x } , \\\\mathbf { i } )$ . As shown in Protocol\
              \ 8, the protocol proceeds for $\\\\ell$ variables round by round. We\
              \ first run the sumcheck protocol on variables that are irrelevant to\
              \ the index of sub-copies in the circuit. In the first $( \\\\ell -\
              \ n )$ rounds, each prover $\\\\mathcal { P } \\_ { i }$ generates the\
              \ univariate polynomial of $f \\_ { j } ^ { ( i ) } ( x \\_ { j } )$\
              \ for $f ^ { ( i ) } ( { \\\\bf x } )$ and sends it to $\\\\mathcal\
              \ { P } \\_ { 0 }$ . $\\\\mathcal { P } \\_ { 0 }$ constructs the univariate\
              \ polynomial for $f \\_ { j } ( x \\_ { j } )$ by summing $f \\_ { j\
              \ } ^ { ( i ) } ( x \\_ { j } )$ altogether since $f \\_ { j } ( x \\\
              _ { j } ) = \\\\sum \\_ { i = 0 } ^ { N } f \\_ { j } ^ { ( i ) } (\
              \ x \\_ { j } )$ , and sends $f \\_ { j } ( x \\_ { j } )$ to $\\\\\
              nu$ in the $j$ -th round. The aggregation among parallel machines reduces\
              \ the proof size to constant in each round. Hence the final proof size\
              \ is only $O ( \\\\ell )$ . A similar approach has appeared in \\[WHGSW16\\\
              ]. The main focus of \\[WHGSW16\\] was improving the prover time of\
              \ the sumcheck protocol in the GKR protocol to $O ( 2 ^ { \\\\ell }\
              \ ( \\\\ell - n ) )$ for data-parallel circuits, which was later subsumed\
              \ by \\[XZZPS19b\\] with a prover running in $O ( 2 ^ { \\\\ell } )$\
              \ time. Instead, our scheme is focused on improving the prover time\
              \ by $N$ times with distributed computing on $N$ machines without any\
              \ overhead on the proof size.\\\n\\\nWith this idea in mind, we rewrite\
              \ the sumcheck equation on $f$ as follows.\\\n\\\n$$\\\nH = \\\\sum\
              \ \\_ { \\\\mathbf { b } \\\\in { 0 , 1 } ^ { \\\\ell } } f ( \\\\mathbf\
              \ { b } ) = \\\\sum \\_ { i = 0 } ^ { N - 1 } \\\\sum \\_ { \\\\mathbf\
              \ { b } \\\\in { 0 , 1 } ^ { \\\\ell - n } } f ^ { ( i ) } ( \\\\mathbf\
              \ { b } ) .\\\n$$\\\n\\\nThen we divide the original sumcheck protocol\
              \ on $f$ into 3 phases naturally in the setting of distributed computing.\
              \ We present the formal protocol of distributed sumcheck in Protocol\
              \ 10.\\\n\\\n1. From round 1 to round $( \\\\ell - n )$ (step 1 in Protocol\
              \ 10), $\\\\mathcal { P } \\_ { i }$ runs the sumcheck protocol on $\\\
              \\boldsymbol { f } ^ { ( i ) }$ and sends the univariate polynomial\
              \ to $\\\\mathcal { P } \\_ { 0 }$ . After receiving all univariate\
              \ polynomials from other machines, $\\\\mathcal { P } \\_ { 0 }$ aggregates\
              \ these univariate polynomials by summing them together and sends the\
              \ aggregated univariate polynomial to the verifier. When $\\\\mathcal\
              \ { P } \\_ { 0 }$ receives a random query from the verifier, $\\\\\
              mathcal { P } \\_ { 0 }$ relays the random challenge to all nodes as\
              \ the random query of the current round.\\\n2. In round $( \\\\ell -\
              \ n )$ (step 2 in Protocol 10), the polynomials of $\\\\boldsymbol {\
              \ f } ^ { ( 0 ) } , \\\\cdots , \\\\boldsymbol { f } ^ { ( N - 1 ) }$\
              \ have been condensed to one evaluation on a random vector $\\\\mathbf\
              \ { r } \\\\in \\\\mathbb { F } ^ { \\\\ell - n }$ . $\\\\mathcal {\
              \ P } \\_ { 0 }$ uses these $N$ points as an array to construct the\
              \ multi-linear polynomial $f ^ { \\\\prime } : \\\\mathbb { F } ^ {\
              \ n } \\\\to \\\\mathbb { F }$ such that $f ^ { \\\\prime } ( \\\\mathbf\
              \ { x } ) = f ( \\\\mathbf { r } , \\\\mathbf { x } \\[ 1 : n \\] )$\
              \ .³\\\n3. After round $( \\\\ell - n )$ (step 3 in Protocol 10), $\\\
              \\mathcal { P } \\_ { 0 }$ continues to run the sumcheck protocol on\
              \ $f ^ { \\\\prime }$ with $\\\\nu$ in last $n$ rounds.\\\n\\\nIn this\
              \ way, the computation of $\\\\mathcal { P } \\_ { i }$ is equivalent\
              \ to running the sumcheck protocol in Virgo on ${ \\\\mathsf { C } }\
              \ \\_ { i }$ . It accelerates the sumcheck protocol in Virgo by $N$\
              \ times without any overhead on the proof size using $N$ distributed\\\
              \n\\\nProtocol 10 (Distributed sumcheck). Suppose the prover has $N$\
              \ machines $\\\\mathcal { P } \\_ { 0 } , \\\\cdots , \\\\mathcal {\
              \ P } \\_ { N - 1 }$ and suppose $\\\\mathcal { P } \\_ { 0 }$ is the\
              \ master node. Each $P \\_ { i }$ holds a polynomial $f ^ { ( i ) }\
              \ : \\\\mathbb { F } ^ { \\\\ell - n } \\\\mathbb { F }$ such that $f\
              \ ^ { ( i ) } ( \\\\mathbf { x } ) =$ $f ( \\\\mathbf { x } \\[ 1 :\
              \ \\\\ell - n \\] , \\\\mathbf { i } )$ . Suppose $\\\\nu$ is the verifier.\
              \ The protocol proceeds in 3 phases consisting of $\\\\ell$ rounds.\\\
              \n\\\n1. In the $j$ -th round, where $1 \\\\leq j \\\\leq \\\\ell -\
              \ n$ , each $\\\\mathcal { P } \\_ { i }$ sends $P \\_ { 0 }$ a univariate\
              \ polynomial\\\n\\\n$$\\\nf \\_ { j } ^ { ( i ) } ( x \\_ { j } ) \\\
              \\stackrel { d e f } { = } \\\\sum \\_ { \\\\mathbf { b } \\\\in { 0\
              \ , 1 } ^ { \\\\ell - n - j } } f ^ { ( i ) } ( \\\\mathbf { r } \\\
              [ 1 : j - 1 \\] , x \\_ { j } , \\\\mathbf { b } ) ,\\\n$$\\\n\\\nAfter\
              \ receiving all univariate polynomials from $P \\_ { 1 } , \\\\cdots\
              \ , P \\_ { N - 1 } ,$ $P \\_ { 0 }$ computes\\\n\\\n$$\\\nf \\_ { j\
              \ } ( x \\_ { j } ) = \\\\sum \\_ { i = 0 } ^ { N - 1 } f \\_ { j }\
              \ ^ { ( i ) } ( x \\_ { j } )\\\n$$\\\n\\\nthen sends $f \\_ { j } (\
              \ x \\_ { j } )$ to $\\\\nu . \\ \\\\nu$ checks $f \\_ { j - 1 } ( r\
              \ \\_ { j - 1 } ) = f \\_ { j } ( 0 ) + f \\_ { j } ( 1 )$ , and sends\
              \ a random challenge $r \\_ { j } \\\\in \\\\mathbb { F }$ to $\\\\\
              mathcal { P } \\_ { 0 }$ . $\\\\mathcal { P } \\_ { 0 }$ relays $r \\\
              _ { j }$ to $P \\_ { 1 } , \\\\cdots , P \\_ { N - 1 }$ .\\\n\\\n2.\
              \ In the $j$ -th round, where $j ~ = ~ \\\\ell - n$ , after receiving\
              \ $\\\\boldsymbol { r } \\_ { j }$ from $\\\\mathcal { P } \\_ { 0 }$\
              \ , each $\\\\mathcal { P } \\_ { i }$ computes $f ^ { ( i ) } ( \\\\\
              mathbf { r } \\[ 1 : j \\] )$ and sends $f ^ { ( i ) } ( \\\\mathbf\
              \ { r } \\[ 1 : j \\] )$ to $\\\\mathcal { P } \\_ { 0 }$ . Then $\\\
              \\mathcal { P } \\_ { 0 }$ constructs a multi-linear polynomial $f ^\
              \ { \\\\prime } : \\\\mathbb { F } ^ { n } \\\\to \\\\mathbb { F }$\
              \ such that $f ^ { \\\\prime } ( \\\\mathbf { i } ) = f ^ { ( i ) }\
              \ ( \\\\mathbf { r } \\[ 1 : j \\] )$ for $0 \\\\leq i < N$ .\\\n\\\n\
              3. In the $j$ -th round, where $\\\\ell - n < j \\\\leq \\\\ell , \\\
              \\mathcal { P } \\_ { 0 }$ and $\\\\nu$ run Protocol 8 on the statement:\\\
              \n\\\n\\\n$$\\\nH ^ { \\\\prime } = \\\\sum \\_ { \\\\mathbf { b } \\\
              \\in { 0 , 1 } ^ { n } } f ^ { \\\\prime } ( \\\\mathbf { b } ) ,\\\n\
              $$\\\n\\\nwhere $\\\\begin{array} { r } { H ^ { \\\\prime } = \\\\sum\
              \ \\_ { i = 0 } ^ { N - 1 } f ^ { ( i ) } ( { \\\\bf r } \\[ 1 : \\\\\
              ell - n \\] ) . } \\\\end{array}$ .\\\n\\\nmachines, which is optimal\
              \ for distributed algorithms both in asymptotic complexity and in practice.\
              \ We give the complexity of Protocol 10 in the following.\\\n\\\nComplexity\
              \ of the distributed sumcheck protocol. For the multivariate polynomial\
              \ of $f$ defined in Equation 5.4, The total prover work is $O ( 2 ^\
              \ { \\\\ell } )$ while the prover work for each machine is $O ( \\\\\
              textstyle { \\\\frac { 2 ^ { \\\\ell } } { N } } )$ . The communication\
              \ between $N$ machines is $O ( N \\\\ell )$ . The proof size and the\
              \ verifier time are both $O ( \\\\ell )$ .\\\n\\\n# 5.4.3 Distributed\
              \ polynomial commitment\\\n\\\nIn the last step of the sumcheck phase,\
              \ the prover needs to prove to the verifier $y = f ( r \\_ { 1 } , \\\
              \\cdot \\\\cdot \\\\cdot , r \\_ { \\\\ell } )$ for some value $y$ .\
              \ In Virgo, The prover convinces $\\\\nu$ of the evaluation by invoking\
              \ the PC scheme. We present the PC scheme in Virgo and the complexity\
              \ of the scheme in the following.\\\n\\\nBackground: the polynomial\
              \ commitment in Virgo. Let $\\\\mathcal { F }$ be a family of $\\\\\
              ell$ -variate multi-linear polynomial over $\\\\mathbb { F }$ . Let\
              \ $\\\\mathbb { H } , \\\\mathbb { L }$ be two disjoint multiplicative\
              \ subgroups of $\\\\mathbb { F }$ such that $\\| \\\\mathbb { H } \\\
              | = 2 ^ { \\\\ell }$ and $\\| \\\\mathbb { L } \\| = \\\\rho \\| \\\\\
              mathbb { H } \\|$ , where $\\\\rho$ is a power of 2. The polynomial\
              \ commitment (PC) in Virgo for $f \\\\in { \\\\mathcal { F } }$ and\
              \ $\\\\mathbf { r } \\\\in \\\\mathbb { F } ^ { \\\\ell }$ consists\
              \ of the following algorithms:\\\n\\\n• $\\\\mathsf { p p P C . K e\
              \ y G e n ( 1 ^ { \\\\lambda } ) }$ : Given the security parameter $\\\
              \\lambda$ , the algorithm samples a collision resistant hash function\
              \ from a hash family as pp.\\\n\\\n• $\\\\mathsf { c o m } \\_ { f }\
              \ \\\\gets \\\\mathsf { P C . C o m m i t } ( f , \\\\mathsf { p p }\
              \ )$ : Given a multi-linear polynomial $f$ , the prover treats $2 ^\
              \ { \\\\ell }$ coefficients of $f$ as evaluations of a univariate polynomial\
              \ $f \\_ { U }$ on $\\\\mathbb { H }$ . The prover uses the inverse\
              \ fast Fourier transform (IFFT) to compute $f \\_ { U }$ . Then the\
              \ prover computes $\\\\mathbf { f } \\_ { \\\\mathbb { L } }$ as evaluations\
              \ of $f \\_ { U }$ on $\\\\mathbb { L }$ via the fast Fourier transform\
              \ (FFT). Let $\\\\mathsf { c o m } \\_ { f } = \\\\mathsf { M T . C\
              \ o m m i t } ( \\\\mathbf { f } \\_ { \\\\mathbb { L } } )$ .\\\n\\\
              \n• $( y , \\\\pi \\_ { f } ) \\\\gets \\\\mathsf { P C . O p e n }\
              \ ( f , \\\\mathbf { r } , \\\\mathsf { p p } )$ : The prover computes\
              \ $y ~ = ~ f ( \\\\mathbf { r } )$ . Given $c = O ( \\\\lambda )$ random\
              \ indexes $( k \\_ { 1 } , \\\\cdots , k \\_ { c } )$ , the prover computes\
              \ $( \\\\mathbf { f } \\_ { \\\\mathbb { L } } \\[ k \\_ { 1 } \\] ,\
              \ \\\\pi \\_ { k \\_ { 1 } } ) \\ = \\ \\\\mathsf { M T } . \\\\mathsf\
              \ { O p e n } ( \\\\mathbf { f } \\_ { \\\\mathbb { L } } , k \\_ {\
              \ 1 } )$ , · · · , $( \\\\mathbf { f } \\_ { \\\\mathbb { L } } \\[\
              \ k \\_ { c } \\] , \\\\pi \\_ { k \\_ { c } } ) =$ MT.Open $( \\\\\
              mathbf { f } \\_ { \\\\mathbb { L } } , k \\_ { c } )$ . Let $\\\\pi\
              \ \\_ { f } = ( \\\\mathbf { f } \\_ { \\\\mathbb { L } } \\[ k \\_\
              \ { 1 } \\] , \\\\pi \\_ { k \\_ { 1 } } , \\\\cdot \\\\cdot \\\\cdot\
              \ , \\\\mathbf { f } \\_ { \\\\mathbb { L } } \\[ k \\_ { c } \\] ,\
              \ \\\\hat { \\\\pi } \\_ { k \\_ { c } } )$ .⁴\\\n\\\n• ${ 1 , 0 } \\\
              \\gets \\\\mathsf { P C . V e r i f y } ( \\\\mathsf { c o m } \\_ {\
              \ f } , \\\\mathbf { r } , y , \\\\pi \\_ { f } , \\\\mathsf { p p }\
              \ ) .$ The verifier parses $\\\\pi \\_ { f } = ( \\\\mathbf { q } \\\
              _ { \\\\mathbb { L } } \\[ k \\_ { 1 } \\] , \\\\pi \\_ { k \\_ { 1\
              \ } } , \\\\cdot \\\\cdot \\\\cdot , \\\\mathbf { q } \\_ { \\\\mathbb\
              \ { L } } \\[ k \\_ { c } \\] , \\\\pi \\_ { k \\_ { c } } )$ , then\
              \ checks that $\\\\mathbf { q } \\_ { \\\\mathbb { L } } \\[ k \\_ {\
              \ 1 } \\] , \\\\cdot \\\\cdot \\\\cdot , \\\\mathbf { q } \\_ { \\\\\
              mathbb { L } } \\[ k \\_ { c } \\]$ are consistent with $y$ by a certain\
              \ equation $p ( f \\_ { \\\\mathbb { L } } \\[ k \\_ { 1 } \\] , \\\\\
              cdot \\\\cdot \\\\cdot , f \\_ { \\\\mathbb { L } } \\[ k \\_ { c }\
              \ \\] , y ) = 0$ , ⁵ and checks that $\\\\mathbf { f } \\_ { \\\\mathbb\
              \ { L } } \\[ k \\_ { 1 } \\] , \\\\cdot \\\\cdot \\\\cdot , \\\\mathbf\
              \ { f } \\_ { \\\\mathbb { L } } \\[ k \\_ { c } \\]$ are consistent\
              \ with ${ \\\\mathsf { c o m } } \\_ { f }$ by MT.Verify $( \\\\pi \\\
              _ { k \\_ { 1 } } , \\\\mathbf { f } \\_ { \\\\mathbb { L } } \\[ k\
              \ \\_ { 1 } \\] , \\\\mathsf { c o m } \\_ { f } )$ , · · · , MT.Verify\
              \ $( \\\\pi \\_ { k \\_ { c } } , \\\\mathbf { f } \\_ { \\\\mathbb\
              \ { L } } \\[ k \\_ { c } \\] , \\\\mathsf { c o m } \\_ { f } )$ .\
              \ If all checks pass, the verifier outputs 1, otherwise the verifier\
              \ outputs 0.\\\n\\\nComplexity of PC in Virgo. The prover time is $O\
              \ ( \\\\ell \\\\cdot 2 ^ { \\\\ell } )$ . The proof size is $O ( \\\\\
              lambda \\\\ell ^ { 2 } )$ and the verifier time is $O ( \\\\lambda \\\
              \\ell ^ { 2 } )$ .\\\n\\\nIn the setting of distributed PC, $\\\\mathcal\
              \ { P } \\_ { i }$ knows $\\\\boldsymbol { f } ^ { ( i ) }$ . With the\
              \ help of $\\\\beta$ function, we have\\\n\\\n$$\\\nf ( { \\\\mathbf\
              \ { r } } ) = \\\\sum \\_ { i = 0 } ^ { N - 1 } \\\\beta ( { \\\\mathbf\
              \ { r } } \\[ \\\\ell - n + 1 : \\\\ell \\] , { \\\\mathbf { i } } )\
              \ f ^ { ( i ) } ( { \\\\mathbf { r } } \\[ 1 : \\\\ell - n \\] ) .\\\
              \n$$\\\n\\\nA straightforward way for distributed PC is that $\\\\mathcal\
              \ { P } \\_ { i }$ runs the PC scheme on $\\\\boldsymbol { f } ^ { (\
              \ i ) }$ separately. In particular, $\\\\mathcal { P } \\_ { i }$ invokes\
              \ PC.Commit to commit $f ^ { ( i ) }$ in the beginning of the sumcheck\
              \ protocol. In the last round, $\\\\mathcal { P } \\_ { i }$ runs PC.Open\
              \ to compute $f ^ { ( i ) } ( { \\\\bf r } \\[ 1 : \\\\ell - n \\] )$\
              \ and sends the proof to $\\\\nu$ . After receiving all $f ^ { ( i )\
              \ } ( { \\\\bf r } \\[ 1 : \\\\ell - n \\] )$ from $\\\\mathcal { P\
              \ } \\_ { i }$ , $\\\\nu$ invokes PC.Verify to validate $N$ polynomial\
              \ commitments separately. Then $\\\\nu$ computes $\\\\beta ( { \\\\\
              bf r } \\[ \\\\ell - n + 1 : \\\\ell \\] , { \\\\bf i } )$ for each\
              \ $i$ . Finally, $\\\\nu$ checks $\\\\begin{array} { r } { f ( \\\\\
              mathbf { r } ) = \\\\sum \\_ { i = 0 } ^ { N - 1 } \\\\beta ( \\\\mathbf\
              \ { r } \\[ \\\\boldsymbol { \\\\ell } - n + 1 : \\\\boldsymbol { \\\
              \\ell } \\] , \\\\mathbf { i } ) f ^ { ( i ) } ( \\\\mathbf { r } \\\
              [ 1 : \\\\boldsymbol { \\\\ell } - n \\] ) } \\\\end{array}$ .\\\n\\\
              \nAlthough the aforementioned naïve distributed protocol achieves $O\
              \ ( 2 ^ { \\\\ell } ( \\\\ell - n ) )$ in computation time for each\
              \ machine, the total proof size is $O ( \\\\lambda N ( \\\\ell - n )\
              \ ^ { 2 } )$ as the individual proof size for each $\\\\mathcal { P\
              \ } \\_ { i }$ is $O ( \\\\lambda ( \\\\ell - n ) ^ { 2 } )$ . To reduce\
              \ the proof size, we optimize the algorithm by aggregating $N$ commitments\
              \ and $N$ proofs altogether. For simplicity, we assume $\\\\rho = 1$\
              \ without loss of generality in the multi-linear polynomial commitment⁶.\
              \ We present the formal protocol of distributed PC in Protocol 11.\\\
              \n\\\nProtocol 11 (Distributed PC). Suppose the prover has $N$ machines\
              \ of $\\\\mathcal { P } \\_ { 0 } , \\\\cdots , \\\\mathcal { P } \\\
              _ { N - 1 }$ and suppose $\\\\mathcal { P } \\_ { 0 }$ is the master\
              \ node. Each $P \\_ { i }$ holds a polynomial $f ^ { ( i ) } : \\\\\
              mathbb { F } ^ { \\\\ell - n } \\\\mathbb { F }$ such that $f ( \\\\\
              mathbf { x } ) = \\\\beta ( \\\\mathbf { x } \\[ \\\\ell - n + 1 :$\
              \ $\\\\ell \\] , \\\\mathbf { i } ) f ^ { ( i ) } ( x \\[ 1 : \\\\ell\
              \ - n \\] )$ . Suppose $\\\\nu$ is the verifier. Let $\\\\mathbb { H\
              \ }$ and $\\\\mathbb { L }$ be two disjoint multiplicative subgroups\
              \ of $\\\\mathbb { F }$ such that $\\\\textstyle \\\\left\\| \\\\mathbb\
              \ { H } \\\\right\\| \\ = \\ { \\\\frac { 2 ^ { \\\\ell } } { N } }\
              \ $ and $\\| \\\\mathbb { L } \\| = \\\\rho \\| \\\\mathbb { H } \\\
              |$ . For simplicity, We assume $\\\\rho = 1$ . Let $\\\\mathsf { p p\
              \ } = \\\\mathsf { P C . K e y G e n } ( 1 ^ { \\\\lambda } )$ . The\
              \ protocol proceeds in following steps.\\\n\\\n1. Each $\\\\mathcal\
              \ { P } \\_ { i }$ invokes PC.Commit $( f ^ { ( i ) } , { \\\\mathsf\
              \ { p p } } )$ to compute $\\\\mathbf { f } \\_ { \\\\mathbb { L } }\
              \ ^ { ( i ) }$ by IFFT and FFT.\\\n\\\n2. Each $\\\\mathcal { P } \\\
              _ { i }$ sends $\\\\mathbf { f } \\_ { \\\\mathbb { L } } ^ { ( i )\
              \ } \\[ 1 \\] , \\\\cdot \\\\cdot \\\\cdot , \\\\mathbf { f } \\_ {\
              \ \\\\mathbb { L } } ^ { ( i ) } \\[ N \\]$ to $\\\\mathcal { P } \\\
              _ { 0 } , \\\\cdots , \\\\mathcal { P } \\_ { N - 1 }$ separately.\\\
              \n\\\n3. Each $\\\\mathcal { P } \\_ { i }$ receives ${ \\\\bf f } \\\
              _ { \\\\mathbb { L } } ^ { ( 0 ) } \\[ i + 1 \\] , \\\\cdot \\\\cdot\
              \ \\\\cdot , { \\\\bf f } \\_ { \\\\mathbb { L } } ^ { ( N - 1 ) } \\\
              [ i + 1 \\]$ from other machines. Assuming ${ \\\\bf h } \\_ { \\\\\
              mathbb { L } } ^ { ( i ) } = ( { \\\\bf f } \\_ { \\\\mathbb { L } }\
              \ ^ { ( 0 ) } \\[ i +$\\\n\\\n   1\\], · · · , $\\\\mathbf { f } \\\
              _ { \\\\mathbb { L } } ^ { ( N - 1 ) } \\[ i + 1 \\] ,$ , $\\\\mathcal\
              \ { P } \\_ { i }$ computes $\\\\mathsf { c o m } \\_ { h ^ { ( i )\
              \ } } = \\\\mathsf { M T . C o m m i t } ( \\\\mathbf { h } \\_ { \\\
              \\mathbb { L } } ^ { ( i ) } )$ and sends $\\\\mathsf { c o m } \\_\
              \ { h ^ { ( i ) } }$ to $\\\\mathcal { P } \\_ { 0 }$ .\\\n\\\n4. Suppose\
              \ ${ \\\\bf h } = ( { \\\\mathsf { c o m } } \\_ { h ^ { ( 0 ) } } ,\
              \ \\\\cdot \\\\cdot \\\\cdot , { \\\\mathsf { c o m } } \\_ { h ^ {\
              \ ( N - 1 ) } } )$ , $\\\\mathcal { P } \\_ { 0 }$ computes com $=$\
              \ MT.Commit $\\\\mathbf { \\\\eta } ( \\\\mathbf { h } )$ and sends\
              \ com to $\\\\nu$ .\\\n\\\n5. After receiving the random vector $\\\\\
              mathbf { r }$ from $\\\\nu$ , $\\\\mathcal { P } \\_ { 0 }$ relays $\\\
              \\mathbf { r }$ to each $\\\\mathcal { P } \\_ { i }$ . Each $\\\\mathcal\
              \ { P } \\_ { i }$ computes $f ^ { ( i ) } ( { \\\\bf r } \\[ 1 : \\\
              \\ell - \\\\bar { n } \\] )$ and sends it to $\\\\nu$ via $\\\\mathcal\
              \ { P } \\_ { 0 }$ .\\\n\\\n6. To prove the correctness of $f ^ { (\
              \ i ) } ( { \\\\bf r } \\[ 1 : \\\\ell - n \\] )$ , given random index\
              \ of $k \\_ { 1 } , \\\\cdots , k \\_ { c }$ from $\\\\nu$ , $\\\\mathcal\
              \ { P } \\_ { k \\_ { 1 } - 1 }$ , · · · , $\\\\mathcal { P } \\_ {\
              \ k \\_ { c } - 1 }$ send $\\\\mathbf { h } \\_ { \\\\mathbb { L } }\
              \ ^ { ( k \\_ { 1 } - 1 ) } , \\\\cdot \\\\cdot \\\\cdot , \\\\mathbf\
              \ { h } \\_ { \\\\mathbb { L } } ^ { ( k \\_ { c } - 1 ) }$ to $\\\\\
              nu$ via $\\\\mathcal { P } \\_ { 0 } . \\\\mathcal { P } \\_ { 0 }$\
              \ also generates $( { \\\\bf h } \\[ k \\_ { 1 } \\] , \\\\pi \\_ {\
              \ k \\_ { 1 } } ) =$ MT.Open $( \\\\mathbf { h } , k \\_ { 1 } )$ ,\
              \ · · · , $( { \\\\bf h } \\[ k \\_ { c } \\] , \\\\pi \\_ { k \\_ {\
              \ c } } ) = { \\\\sf M } { \\\\sf T } . { \\\\sf O p e n } ( { \\\\\
              bf h } , k \\_ { c } )$ and send them to $\\\\nu$ .\\\n\\\n\\\n$7 .\
              \ \\ \\\\nu$ checks $\\\\begin{array} { r l r } { f ( { \\\\bf r } )\
              \ } & { { } = } & { \\\\sum \\_ { i = 0 } ^ { N - 1 } \\\\beta ( { \\\
              \\bf r } \\[ \\\\ell { \\\\bf \\\\Xi } - n { \\\\bf \\\\Xi } + 1 { \\\
              \\bf \\\\Xi } : { \\\\bf \\\\Lambda } \\\\cdot { \\\\bf \\\\Lambda }\
              \ \\\\ell \\] , { \\\\bf i } ) f ^ { ( i ) } ( { \\\\bf r } \\[ 1 {\
              \ \\\\bf \\\\Xi } : \\\\ell { \\\\bf \\\\Xi } - n \\] ) } \\\\end{array}$\
              \ . $\\\\nu$ checks $\\\\mathbf { h } \\[ k \\_ { 1 } \\] = \\\\mathsf\
              \ { M } \\\\mathsf { T } . \\\\mathsf { C o m m i t } ( \\\\mathbf {\
              \ h } \\_ { \\\\mathbb { L } } ^ { ( k \\_ { 1 } - 1 ) } ) , \\ \\\\\
              cdot \\\\cdot \\\\cdot , \\ \\\\mathbf { h } \\[ k \\_ { c } \\] = \\\
              \\mathsf { M } \\\\mathsf { T } . \\\\mathsf { C o m m i t } ( \\\\\
              mathbf { h } \\_ { \\\\mathbb { L } } ^ { ( k \\_ { c } - 1 ) } ) .$\
              \ Then $\\\\nu$ checks $\\\\pi \\_ { k \\_ { 1 } } , \\\\cdots , \\\\\
              pi \\_ { k \\_ { c } }$ by MT.Verify $( \\\\pi \\_ { k \\_ { 1 } } ,\
              \ \\\\mathbf { h } \\[ k \\_ { 1 } \\]$ , com), · · · , MT.Verify $(\
              \ \\\\pi \\_ { k \\_ { c } } , \\\\mathbf { h } \\[ k \\_ { c } \\]\
              \ , , \\\\mathsf { c o m } )$ . $\\\\nu$ also checks $q ( \\\\mathbf\
              \ { f } \\_ { \\\\mathbb { L } } ^ { ( i ) } \\[ k \\_ { 1 } \\] , \\\
              \\cdot \\\\cdot \\\\cdot , \\\\mathbf { f } \\_ { \\\\mathbb { L } }\
              \ ^ { ( i ) } \\[ k \\_ { c } \\] , \\\\mathbf { f } ^ { ( i ) } ( \\\
              \\mathbf { r } \\[ 1 ~ : ~ \\\\ell - n \\] ) ) = 0$ for each $i$ as\
              \ shown in PC.Verify. If all checks pass, $\\\\nu$ outputs 1, otherwise\
              \ $\\\\nu$ outputs 0.\\\n\\\nThe idea of our scheme is that each $\\\
              \\mathcal { P } \\_ { i }$ exchanges data with other machines immediately\
              \ after computing $\\\\mathbf { f } \\_ { \\\\mathbb { L } } ^ { ( i\
              \ ) }$ instead of invoking MT.Commit on $\\\\mathbf { f } \\_ { \\\\\
              mathbb { L } } ^ { ( i ) }$ directly. The advantage of such arrangement\
              \ is that the prover aggregates evaluation on the same index into one\
              \ branch and can open them together by a single Merkle tree proof for\
              \ this branch. As described in the polynomial commitment of Virgo, the\
              \ prover needs to open $f \\_ { \\\\mathbb { L } }$ on some random indexes\
              \ depending on $\\\\mathbf { r }$ in PC.Open. As $\\\\mathbf { r }$\
              \ is identical to each $\\\\boldsymbol { f } ^ { ( i ) }$ , the prover\
              \ would open each $f \\_ { \\\\mathbb { L } } ^ { ( i ) }$ at same indexes.\
              \ If the prover aggregates $f \\_ { \\\\mathbb { L } } ^ { ( i ) }$\
              \ by the indexes, she can open $N$ values in one shot by providing only\
              \ one Merkle tree path instead of naïvely providing $N$ Merkle tree\
              \ paths, which helps her to save the total proof size by a logarithmic\
              \ factor in the size of the polynomial.\\\n\\\nSpecifically, $\\\\mathcal\
              \ { P } \\_ { i }$ collects evaluations of ${ \\\\bf f } \\_ { \\\\\
              mathbb { L } } ^ { ( 0 ) } \\[ i + 1 \\] , \\\\cdot \\\\cdot \\\\cdot\
              \ , { \\\\bf f } \\_ { \\\\mathbb { L } } ^ { ( N - \\\\bar { 1 } )\
              \ } \\[ i + 1 \\]$ with identical index of $( i + 1 )$ in $\\\\mathbb\
              \ { L }$ from other machines (step 1 and step 2). Then $\\\\mathcal\
              \ { P } \\_ { i }$ invokes MT.Commit to get a commitment, $c o m \\\
              _ { h } ( i )$ , for these values, and submits $c o m \\_ { h } ( i\
              \ )$ to $\\\\mathcal { P } \\_ { 0 }$ (step 3). $\\\\mathcal { P } \\\
              _ { 0 }$ invokes MT.Commit on $^ { c o m } { } \\_ { h ^ { ( 0 ) } }\
              \ , \\\\cdot \\\\cdot \\\\cdot , c o m \\_ { \\_ { h } ( ^ { N - 1 }\
              \ ) }$ to compute the aggregated commitment, com, and $\\\\mathcal {\
              \ P } \\_ { 0 }$ sends com to $\\\\nu$ (step 4). In the PC.Open phase,\
              \ given a random index $k \\_ { j }$ from $\\\\nu$ , $\\\\mathcal {\
              \ P } \\_ { 0 }$ retrieves $\\\\mathbf { f } \\_ { \\\\mathbb { L }\
              \ } ^ { ( N - 1 ) } \\[ k \\_ { j } \\] , \\\\cdot \\\\cdot \\\\cdot\
              \ , \\\\mathbf { f } \\_ { \\\\mathbb { L } } ^ { ( N - 1 ) } \\[ k\
              \ \\_ { j } \\]$ from $\\\\mathcal { P } \\_ { k \\_ { j } - 1 }$ ,\
              \ computes $( \\\\mathsf { c o m } \\_ { h ^ { ( k \\_ { j } - 1 ) }\
              \ } , \\\\pi \\_ { k \\_ { j } } )$ $= \\\\mathsf { M T } . \\\\mathsf\
              \ { O }$ pen $( \\\\mathsf { c o m } , k \\_ { j } )$ , and sends these\
              \ messages to $\\\\nu$ (step 5 and step 6). $\\\\nu$ can validate $N$\
              \ evaluations by invoking MT.Verify only once (step 7). With this approach,\
              \ we reduce the proof size to $O ( \\\\lambda ( N + \\\\ell ^ { 2 }\
              \ ) )$ . And the complexity of Protocol 11 is shown in the following.\\\
              \n\\\nComplexity of distributed PC. Given that $f$ is a multi-linear\
              \ polynomial with $\\\\ell$ variables, the total communication among\
              \ $N$ machines is $O ( 2 ^ { \\\\ell } )$ . The total prover work is\
              \ ${ \\\\dot { O } } ( 2 ^ { \\\\ell } \\\\cdot \\\\ell )$ while the\
              \ prover work for each device is $\\\\Big ( \\\\frac { 2 ^ { \\\\ell\
              \ } } { N } \\\\cdot \\\\ell \\\\Big )$ . The proof size is $O ( \\\\\
              lambda ( N + \\\\ell ^ { 2 } ) )$ . The verification cost is $O ( \\\
              \\lambda ( N + \\\\ell ^ { 2 } ) )$ .\\\n\\\n# 5.4.4 Combining everything\
              \ together\\\n\\\nIn this section, we combine the distributed sumcheck\
              \ and the distributed PC altogether to build deVirgo.\\\n\\\nBackground:\
              \ The Virgo protocol. By combining the GKR protocol and the polynomial\
              \ commitment in Section 5.4.3 We present the formal protocol of Virgo\
              \ in Protocol 12 and the the complexity of Protocol 12 in the following⁷.\\\
              \n\\\nProtocol 12 (Virgo). Let $\\\\mathbb { F }$ be a finite field.\
              \ Let $C \\\\colon { \\\\mathbb { F } } ^ { m } \\\\to { \\\\mathbb\
              \ { F } } ^ { k }$ be a $d$ -depth layered arithmetic circuit. $\\\\\
              mathcal { P }$ wants to convince that $\\\\mathbf { 1 } = C ( \\\\mathbf\
              \ { x } , \\\\mathbf { w } )$ where $\\\\mathbf { x }$ and w are input\
              \ and 1 is the output. Without loss of generality, assume $m$ and $k$\
              \ are both powers of 2 and we can pad them if not.\\\n\\\n1. Set $\\\
              \\mathsf { p p P C . K e y G e n ( 1 ^ { \\\\lambda } ) }$ . $\\\\mathcal\
              \ { P }$ invokes PC.Commit $( \\\\tilde { V } \\_ { d } , \\\\mathsf\
              \ { p p } )$ to generate $\\\\mathsf { c o m } \\_ { \\\\tilde { V }\
              \ \\_ { d } }$ and sends $\\\\mathsf { c o m } \\_ { \\\\tilde { V }\
              \ \\_ { d } }$ to $\\\\nu$ .\\\n2. $\\\\mathcal { P }$ and $\\\\nu$\
              \ run step 1-3 in Protocol 9.\\\n3. At the input layer $d , \\\\nu$\
              \ has two claims $\\\\tilde { V } \\_ { d } ( \\\\mathbf { u } ^ { (\
              \ d ) } )$ and $\\\\tilde { V } \\_ { d } ( \\\\mathbf { v } ^ { ( d\
              \ ) } )$ . $\\\\mathcal { P }$ and $\\\\nu$ invoke PC.Open and PC.Verify\
              \ on $\\\\tilde { V } \\_ { d } ( \\\\mathbf { u } ^ { ( d ) } )$ and\
              \ $\\\\tilde { V } \\_ { d } ( \\\\mathbf { v } ^ { ( d ) } )$ with\
              \ $\\\\mathsf { c o m } \\_ { \\\\tilde { V } \\_ { d } }$ and pp. If\
              \ they are equal to $\\\\tilde { V } \\_ { d } ( \\\\mathbf { u } ^\
              \ { ( d ) } )$ and $\\\\tilde { V } \\_ { d } ( \\\\mathbf { v } ^ {\
              \ ( d ) } )$ sent by $\\\\mathcal { P } , \\\\mathcal { V }$ outputs\
              \ 1, otherwise $\\\\nu$ outputs 0.\\\n\\\nComplexity of Virgo \\[ZXZS20\\\
              ]. Given a layered arithmetic circuit $C$ with $d$ layers and $m$ inputs,\
              \ Protocol 12 is a zero-knowledge proof protocol as defined in Definition\
              \ 5.2.2 for the function computed by $C$ . The prover time is $O ( \\\
              | C \\| + m \\\\log m )$ . The proof size is $O ( d \\\\log \\| C \\\
              | + \\\\lambda \\\\log ^ { 2 } m )$ and The verification time is also\
              \ $O ( d \\\\log \\| C \\| + \\\\lambda \\\\log ^ { 2 } m )$ .\\\n\\\
              \ndeVirgo. For a data-parallel layered arithmetic circuit $C$ with $N$\
              \ copies and $d$ layers, following the workflow of Virgo in Protocol\
              \ 12, our distributed prover replaces $d$ sumcheck schemes in Virgo\
              \ by $d$ distributed sumcheck schemes, and replaces the PC scheme in\
              \ Virgo by our distributed PC scheme to generate the proof. We present\
              \ the formal protocol of deVirgo in Protocol 13. And we have the theorem\
              \ as follows.\\\n\\\nTheorem 5.4.1. Protocol 13 is an argument of knowledge\
              \ satisfying the completeness and knowledge soundness in Definition\
              \ 5.2.2 for the relation $C ( \\\\mathbf { x } , \\\\mathbf { w } )\
              \ = \\\\mathbf { 1 }$ , where $C$ consists of $N$ identical copies of\
              \ $C \\_ { 0 } , \\\\cdots , C \\_ { N - 1 }$ .\\\n\\\n⁷Protocol 12\
              \ is a knowledge argument system rather than a zero-knowledge proof\
              \ protocol as we actually use the knowledge argument system in our construction.\\\
              \n\\\nProtocol 13 (Distributed Virgo). Let $\\\\mathbb { F }$ be a finite\
              \ field. Let $C$ : $\\\\mathbb { F } ^ { m N } \\\\to \\\\mathbb { F\
              \ } ^ { k }$ be a $d$ -depth layered arithmetic circuit. Suppose $C$\
              \ is also a data-parallel circuit with $N$ identical copies. $\\\\mathcal\
              \ { P }$ is a prover with $N$ distributed machines and wants to convince\
              \ $\\\\nu$ that $\\\\mathbf { 1 } = C ( \\\\mathbf { x } , \\\\mathbf\
              \ { w } )$ where $\\\\mathbf { x }$ and w are input, and 1 is the output.\
              \ Without loss of generality, assume $m$ , $N$ , and $k$ are powers\
              \ of 2 and we can pad them if not.\\\n\\\n1. Set $\\\\mathsf { p p }\
              \ \\\\gets \\\\mathsf { P C . K e y G e n } ( 1 ^ { \\\\lambda } )$\
              \ . Define the multi-linear extension of array $( \\\\mathbf { x } ,\
              \ \\\\mathbf { w } )$ as $\\\\tilde { V } \\_ { d } , ~ \\\\mathcal\
              \ { P }$ invokes step 1-4 in Protocol 11 on $\\\\tilde { V \\_ { d }\
              \ }$ to get ${ \\\\mathsf { c o m } } \\_ { \\\\tilde { V } \\_ { d\
              \ } }$ and sends $\\\\mathsf { c o m } \\_ { \\\\tilde { V } \\_ { d\
              \ } }$ to $\\\\nu$ .\\\n\\\n2. Define the multi-linear extension of\
              \ array 1 as $\\\\tilde { V } \\_ { 0 }$ . $\\\\nu$ chooses a random\
              \ $\\\\boldsymbol { g } ~ \\\\in \\\\mathbb { F } ^ { s \\_ { 0 } }$\
              \ and sends it to $\\\\mathcal { P }$ .\\\n\\\n3. $\\\\mathcal { P }$\
              \ and $\\\\nu$ run Protocol 10, the distributed sumcheck protocol, on\\\
              \n\\\n\\\n$$\\\n1 = \\\\sum \\_ { \\\\mathbf { x } , \\\\mathbf { y\
              \ } \\\\in { 0 , 1 } ^ { s \\_ { 1 } } } ( a \\\\tilde { d } d \\_ {\
              \ 1 } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf { x } , \\\\mathbf\
              \ { y } ) ( \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { x } ) + \\\\tilde\
              \ { V } \\_ { 1 } ( \\\\mathbf { y } ) ) + m \\\\tilde { u } l t \\\
              _ { 1 } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf { x } , \\\\mathbf\
              \ { y } ) \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { x } ) \\\\tilde {\
              \ V } \\_ { 1 } ( \\\\mathbf { y } ) )\\\n$$\\\n\\\nAt the end of the\
              \ protocol, $\\\\nu$ receives $\\\\tilde { V } \\_ { 1 } ( \\\\mathbf\
              \ { u } ^ { ( 1 ) } )$ and $\\\\tilde { V } \\_ { 1 } ( \\\\mathbf {\
              \ v } ^ { ( 1 ) } )$ . $\\\\nu$ computes $\\\\begin{array} { r } { \\\
              \\tilde { m u l t } \\_ { 1 } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\\
              mathbf { u } ^ { ( 1 ) } , \\\\mathbf { v } ^ { ( 1 ) } ) , \\\\tilde\
              \ { a d d } \\_ { 1 } ( \\\\mathbf { g } ^ { ( 0 ) } , \\\\mathbf {\
              \ u } ^ { ( 1 ) } , \\\\mathbf { v } ^ { ( 1 ) } ) } \\\\end{array}$\
              \ and checks that $\\\\tilde { a d d \\_ { 1 } } ( \\\\mathbf { g }\
              \ ^ { ( 0 ) } , \\\\mathbf { u } ^ { ( 1 ) } , \\\\mathbf { \\\\bar\
              \ { v } } ^ { ( 1 ) } )$ $( \\\\tilde { V } \\_ { 1 } ( \\\\mathbf {\
              \ u } ^ { ( 1 ) } ) + \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { v } ^\
              \ { ( 1 ) } ) ) + m \\\\tilde { u } l t \\_ { 1 } ( \\\\mathbf { g }\
              \ ^ { ( 0 ) } , \\\\mathbf { u } ^ { ( 1 ) } , \\\\mathbf { v } ^ {\
              \ ( 1 ) } ) \\ \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { u } ^ { ( 1\
              \ ) } ) \\\\tilde { V } \\_ { 1 } ( \\\\mathbf { v } ^ { ( 1 ) } )$\
              \ equals to the last message of the sumcheck.\\\n\\\n4. For $i = 1 ,\
              \ . . . , d - 1$ :\\\n\\\n• $\\\\nu$ randomly selects $\\\\alpha \\\
              _ { i , 1 } , \\\\alpha \\_ { i , 2 } \\\\in \\\\mathbb { F }$ and sends\
              \ them to $\\\\mathcal { P }$ . • $\\\\mathcal { P }$ and $\\\\nu$ run\
              \ Protocol 10, the distributed sumcheck protocol, on\\\n\\\n$$\\\n\\\
              \\begin{array} { l } { { \\\\displaystyle \\\\alpha \\_ { i , 1 } {\
              \ \\\\tilde { V } } \\_ { i } ( { \\\\bf u } ^ { ( i ) } ) + \\\\alpha\
              \ \\_ { i , 2 } { \\\\tilde { V } } \\_ { i } ( { \\\\bf v } ^ { ( i\
              \ ) } ) = } \\ ~ } \\ { { \\\\displaystyle \\\\sum \\_ { { \\\\bf x\
              \ } , { \\\\bf y } \\\\in { 0 , 1 } ^ { s \\_ { i + 1 } } } ( ( \\\\\
              alpha \\_ { i , 1 } a { \\\\tilde { d } } d \\_ { i + 1 } { \\\\bf u\
              \ } ^ { ( i ) } , { \\\\bf x } , { \\\\bf y } ) + \\\\alpha \\_ { i\
              \ , 2 } a { \\\\tilde { d } } d \\_ { i + 1 } ( { \\\\bf v } ^ { ( i\
              \ ) } , { \\\\bf x } , { \\\\bf y } ) ) ( { \\\\tilde { V } } \\_ {\
              \ i + 1 } ( { \\\\bf x } ) + { \\\\tilde { V } } \\_ { i + 1 } ( { \\\
              \\bf y } ) ) } \\ ~ } \\ { { \\\\displaystyle ~ + ( \\\\alpha \\_ {\
              \ i , 1 } m { \\\\tilde { u } } l t \\_ { i + 1 } ( { \\\\bf u } ^ {\
              \ ( i ) } , { \\\\bf x } , { \\\\bf y } ) + \\\\alpha \\_ { i , 2 }\
              \ m { \\\\tilde { u } } l t \\_ { i + 1 } ( { \\\\bf v } ^ { ( i ) }\
              \ , { \\\\bf x } , { \\\\bf y } ) ) { \\\\tilde { V } } \\_ { i + 1\
              \ } ( { \\\\bf x } ) { \\\\tilde { V } } \\_ { i + 1 } ( { \\\\bf y\
              \ } ) ) } \\ ~ } \\\\end{array}\\\n$$\\\n\\\n• At the end of the sumcheck\
              \ protocol, $\\\\mathcal { P }$ sends $\\\\mathcal { V } \\\\tilde {\
              \ V } \\_ { i + 1 } ( \\\\mathbf { u } ^ { ( i + 1 ) } )$ and $\\\\\
              tilde { V } \\_ { i + 1 } ( \\\\mathbf { v } ^ { ( i + 1 ) } )$\\\n\\\
              \n• $\\\\nu$ computes the right-hand side of the above equation by replacing\
              \ $\\\\mathbf { x }$ and y by $\\\\mathbf { u } ^ { ( i + 1 ) }$ and\
              \ $\\\\mathbf { v } ^ { ( \\ i + 1 ) }$ respectively. checks if it equals\
              \ to the last message of the sumcheck. If all checks in the sumcheck\
              \ pass, $V$ uses $\\\\tilde { V } \\_ { i + 1 } ( \\\\mathbf { u } ^\
              \ { ( i + 1 ) } )$ and $\\\\breve { V } \\_ { i + 1 } ( \\\\mathbf {\
              \ v } ^ { ( i + 1 ) } )$ to proceed to the $( i + 1 )$ -th layer. Otherwise,\
              \ $\\\\nu$ outputs 0 and aborts.\\\n\\\n5. At the input layer $d , \\\
              \\nu$ has two claims $\\\\tilde { V } \\_ { d } ( \\\\mathbf { u } ^\
              \ { ( d ) } )$ and $\\\\tilde { V } \\_ { d } ( \\\\mathbf { v } ^ {\
              \ ( d ) } )$ . $\\\\mathcal { P }$ invokes step 5-6 in Protocol 11 to\
              \ open $\\\\tilde { V } \\_ { d } ( \\\\mathbf { u } ^ { ( d ) } )$\
              \ and $\\\\tilde { V } \\_ { d } ( \\\\mathbf { v } ^ { ( d ) } )$ while\
              \ $\\\\nu$ invokes step 7 in Protocol 11 to validate $\\\\tilde { V\
              \ } \\_ { d } ( \\\\mathbf { u } ^ { ( d ) } )$ and $\\\\tilde { V }\
              \ \\_ { d } ( \\\\mathbf { v } ^ { ( d ) } )$ . If they are equal to\
              \ $\\\\tilde { V } \\_ { d } ( \\\\mathbf { u } ^ { ( d ) } )$ and $\\\
              \\tilde { V } \\_ { d } \\\\big ( \\\\mathbf { v } ^ { ( d ) } \\\\\
              big )$ sent by $\\\\mathcal { P } , \\\\mathcal { V }$ outputs 1, otherwise\
              \ $\\\\nu$ outputs 0.\\\n\\\nProof (sketch). Completeness. The completeness\
              \ is straightforward.\\\n\\\nKnowledge soundness. deVirgo generates\
              \ the same proof as Virgo for $d$ sumcheck protocols. So we only need\
              \ to consider the knowledge soundness of distributed PC scheme. If the\
              \ commitment of $f$ is inconsistent with the opening of $f ( \\\\mathbf\
              \ { r } )$ in the distributed PC scheme, there must exist at least one\
              \ $f ^ { ( i ) } ( { \\\\bf r } \\[ 1 : \\\\ell - n \\] )$ being inconsistent\
              \ with the commitment $f$ by Equation 5.5. Otherwise, when all $f ^\
              \ { ( i ) } ( { \\\\bf r } \\[ 1 : \\\\ell - n \\] )$ are consistent\
              \ with the commitment of $f$ , $f ( \\\\mathbf { r } )$ must be consistent\
              \ with the commitment of $f$ . As shown in Protocol 11, $c o m \\_ {\
              \ f }$ is equivalent to $c o m \\_ { f } ( i )$ with additional dummy\
              \ messages in each element of the vector in the Merkle tree commitment.\
              \ It does not affect the soundness of the PC in Virgo in the random\
              \ oracle model \\[ZXZS20; ZXHSZ22\\]. The verifier outputs 0 in the\
              \ PC.Verify phase with the probability of $( 1 - \\\\mathsf { n e g\
              \ l } ( \\\\lambda ) )$ . Therefore, deVirgo still satisfies knowledge\
              \ soundness.\\\n\\\nThe zero-knowledge property is not necessary as\
              \ there is no private witness in the setting of zkbridge. However, we\
              \ can achieve zero-knowledge for deVirgo by adding some hiding polynomials.\
              \ Virgo uses the same method to achieve zero-knowledge.\\\n\\\nAdditionally,\
              \ Fiore and Nitulescu \\[FN16\\] introduced the notion of O-SNARK for\
              \ SNARK over authenticated data such as cryptographic signatures. Protocol\
              \ 13 is an O-SNARK for any oracle family, albeit in the random oracle\
              \ model. To see this, Virgo relies on the construction of computationally\
              \ sound proofs of Micali \\[Mic00\\] to achieve non-interactive proof\
              \ and knowledge soundness in the random oracle model, which has been\
              \ proven to be O-SNARK in \\[FN16\\]. Hence Virgo is an O-SNARK, and\
              \ so is deVirgo because deVirgo also relies on the same model.\\\n\\\
              \nProtocol 13 achieves optimal linear scalability on data-parallel circuits\
              \ without significant overhead on the proof size. In particular, our\
              \ protocol accelerates Virgo by $N$ times given $N$ distributed machines.\
              \ Additionally, the proof size in our scheme is reduced by a factor\
              \ of $N$ compared to the naïve solution of running each sub-copy of\
              \ data-parallel circuits separately and generating $N$ proofs. The complexity\
              \ of Protocol 13 is shown in the following.\\\n\\\nComplexity of distributed\
              \ Virgo. Given a data-parallel layered arithmetic circuit $C$ with $N$\
              \ sub-copies, each having $d$ layers and $m$ inputs, the total prover\
              \ work of Protocol 13 is $O ( \\| C \\| + N m \\\\log m )$ . The prover\
              \ work for a single machine is $O ( \\| C \\| / N { + } m \\\\log m\
              \ )$ , and the total communication among machines is $O ( N m +$ $N\
              \ d \\\\log \\\\left\\| C \\\\right\\| )$ . The proof size is $O ( \\\
              \\lg \\\\log \\| C \\| + \\\\lambda ( N + \\\\log ^ { 2 } m ) )$ ).\
              \ The verification cost is $O ( d \\\\log \\| C \\| + \\\\lambda ( N\
              \ +$ $\\\\log ^ { 2 } m )$ ).\\\n\\\n# 5.5 Reducing proof size and verifier\
              \ time\\\n\\\nAlthough deVirgo improves the prover time by orders of\
              \ magnitude, we want to further reduce the cost of the verification\
              \ time and the proof size. As mentioned in the above section, the circuit\
              \ which validates over 100 signatures is giant due to non-compatible\
              \ instructions on different curves across different blockchains. Additionally,\
              \ Virgo’s proof size, which is around 210KB for a circuit with 10 million\
              \ gates, is large in practice. Thus we cannot post deVirgo’s proof on-chain\
              \ and validate the proof directly. Aiming at smaller proof size and\
              \ simpler verification on-chain, we propose to further compress the\
              \ proof by recursive proofs with two layers. Intuitively, for a large-scale\
              \ statement $( \\\\mathbf { x } , \\\\mathbf { w } ) \\\\in \\\\mathcal\
              \ { R }$ in Definition 5.2.2, the prover generates the proof $\\\\pi\
              \ \\_ { 1 }$ by a protocol with fast prover time in the first layer.\
              \ If the length of $\\\\pi \\_ { 1 }$ is not as short as desired, then\
              \ the prover can produce a shorter proof $\\\\pi \\_ { 2 }$ by invoking\
              \ another protocol for $( \\\\mathbf { x } , \\\\pi \\_ { 1 } ) \\\\\
              in \\\\mathcal { R } ^ { \\\\prime }$ in the second layer, where $\\\
              \\mathcal { R } ^ { \\\\prime }$ represents that $\\\\pi \\_ { 1 }$\
              \ is a valid proof for $( \\\\mathbf { x } , \\\\mathbf { w } ) \\\\\
              in \\\\mathcal { R }$ . To shrink the proof size and simplify the verification\
              \ as much as possible, we choose Groth16 as the second layer ZKP protocol\
              \ since Groth16 has constant proof size and fast verification time.\
              \ Moreover, the curve in Groth16 is natively supported by Ethereum,\
              \ which is beneficial for saving on-chain cost on Ethereum. In our approach,\
              \ the prover invokes deVirgo to generate $\\\\pi \\_ { 1 }$ on the initial\
              \ circuit in the first layer. In the second layer, the prover invokes\
              \ Groth16 to generate $\\\\pi \\_ { 2 }$ on the circuit implementing\
              \ the verification algorithm of deVirgo where $\\| \\\\pi \\_ { 2 }\
              \ \\| \\\\ll \\| \\\\pi \\_ { 1 } \\|$ . The prover only needs to submit\
              \ $\\\\pi \\_ { 2 }$ on-chain for verification. The recursion helps\
              \ cross-chain bridges to reduce gas cost on blockchains because of simple\
              \ verification on the compatible curve. The security of recursive proofs\
              \ relies on random oracle assumption, which can be instantiated by a\
              \ cryptographic hash function in practice \\[COS20\\].\\\n\\\nTable\
              \ 5.1: The verification circuit size of deVirgo\\\n\\\n|     |     |\
              \     |     |\\\n| --- | --- | --- | --- |\\\n| \\# of sigs | Total\
              \ circuit size. | Circuit size for GKR part | Circuit size for PC part\
              \ |\\\n| 1 | 1.2 10 gates | 8.4 10 gates | 3.3 10 gates |\\\n| 4 | 1.2\
              \ 10 gates | 8.4 10 gates | 4.0 10 gates |\\\n| 32 | 1.3 10' gates |\
              \ 8.4 10 gates | 4.7 10 gates |\\\n| 128 | 1.4 10 gates | 8.4 10 gates\
              \ | 5.4 10 gates |\\\n\\\nPerformance gains. We use the signature validation\
              \ circuit for Cosmos \\[Cos\\] as an example to show concrete numbers\
              \ of the verification circuit of deVirgo in Table 5.1. We record the\
              \ size of the whole verification circuit in the $2 ^ { n d }$ column,\
              \ the size for the GKR part in the $3 ^ { r d }$ column, and the size\
              \ for the PC part in the $4 ^ { t h }$ column, as the number of signatures\
              \ in data-parallel circuits increases from 1 to 128 in the $1 ^ { s\
              \ t }$ column. The number of gates in the $2 ^ { n d }$ column equals\
              \ the sum of numbers of gates in the $3 ^ { r d }$ column and the $4\
              \ ^ { t h }$ column. As shown in Table 5.1, although the data-parallel\
              \ circuit size expands, the size for the sumcheck part in deVirgo’s\
              \ verification circuit does not change. That is because the verification\
              \ for the GKR part is only based on the structure of the sub-circuit,\
              \ which is identical among different copies. However, the size for the\
              \ PC part in deVirgo’s verification circuit up-scales sub-linearly in\
              \ the number of copies due to the growth of the polynomial size. Even\
              \ given 128 copies of the signature validation circuit, the bottleneck\
              \ of deVirgo’s verification circuit is the sumcheck part. Therefore,\
              \ the recursive proof size and the recursive verification cost are independent\
              \ of the number of signatures to validate in our instance. In addition,\
              \ the prover time of Groth16 on the verification circuit of deVirgo\
              \ is only $2 5 %$ of the prover time of deVirgo in practice. Therefore,\
              \ our recursive proof scheme reduces the on-chain proof verification\
              \ cost from $\\\\sim 8 \\\\times 1 0 ^ { 7 }$ gas (an estimation) to\
              \ less than $2 . 3 \\\\times 1 0 ^ { 5 }$ gas.\\\n\\\n# 5.6 Implementation\
              \ and Evaluation\\\n\\\nTo demonstrate the practicality of zkBridge,\
              \ we implement a prototype from Cosmos \\[Cos\\] (a PoS blockchain built\
              \ on top of the Tendermint \\[Kwo14\\] protocol) to Ethereum, and from\
              \ Ethereum to other EVM-compatible chains such as BSC. Supports for\
              \ other blockchains can be similarly implemented with additional engineering\
              \ effort, as long as they support light client protocols defined in\
              \ Definition 5.2.1. In this section, we discuss implementation detail,\
              \ its performance, as well as operational cost.\\\n\\\nThe bridge from\
              \ Cosmos to Ethereum is realized with the full blown zkBridge protocol\
              \ presented so far to achieve practical performance. In comparison,\
              \ the direction from Ethereum to other EVM-compatible chains incurs\
              \ much less overhead for proof generation and does not require deVirgo.\
              \ Therefore, in what follows, we mainly focus on the direction from\
              \ Cosmos to Ethereum.\\\n\\\n# 5.6.1 Implementation details\\\n\\\n\
              The bridge from Cosmos to Ethereum consists of four components: a relayer\
              \ that fetches Cosmos block headers and sends them to Ethereum (implemented\
              \ in $3 0 0 +$ lines of Python), deVirgo (implemented in $1 0 0 0 0\
              \ +$ lines of $\\\\mathrm { C } { + + }$ ) for distributed proof generation,\
              \ a handcrafted recursive verification circuit, and an updater contract\
              \ on Ethereum (implemented in $^ { 6 0 0 + }$ lines of Solidity). Our\
              \ signature verification circuit is based on the optimized signature\
              \ verification circuit \\[Edd\\]. However, we use Gnark instead of Circom\
              \ as in \\[Edd\\] for better efficiency for proof generation.\\\n\\\n\
              Generating correctness proofs. Relay nodes submit Cosmos block headers\
              \ to the updater contract on Ethereum along with correctness proofs,\
              \ which proves that the block is properly signed by the Cosmos validator\
              \ committee appointed by the previous block. (In Cosmos a hash of the\
              \ validator committee members is included in the previous block.)\\\n\
              \\\nIn Cosmos, each block header contains about 128 EdDSA signatures\
              \ (on Curve25519), Merkle roots for transactions and states, along with\
              \ other metadata, where 32 top signatures are required to achieve supermajority\
              \ stakes. However, the most efficient curve supported by the Ethereum\
              \ Virtual Machine (EVM) is BN254. To verify Cosmos digital signatures\
              \ in EVM, one must simulate Curve25519 on curve BN254, which will lead\
              \ to large circuits. Concretely, to verify a Cosmos block header (mainly,\
              \ to verify about 32 signatures), we need about 64 million gates. We\
              \ implement deVirgo (Section 5.4) and recursive verification (Section\
              \ 5.5) to accelerate proof generation and verification.\\\n\\\nMoreover,\
              \ in practical deployment, multiple relayers can form a pipeline to\
              \ increase the throughput. Looking ahead, based on the evaluation results,\
              \ our implementation can handle 1 second block time in Cosmos with $1\
              \ 2 0 +$ capable relayers in the network.\\\n\\\nFor proof verification,\
              \ we build an outer circuit that verifies Virgo proofs and use Gnark\
              \ \\[Gna\\] to generate the final Groth16 proof that can be efficiently\
              \ verified by the updater contract on Ethereum.\\\n\\\nThe updater contract.\
              \ We implement the updater contract on Ethereum in Solidity that verifies\
              \ Groth16 proofs and keeps a list of the Cosmos block headers in its\
              \ persistent storage. The cost of verifying a Groth16 proof on-chain\
              \ is less than $2 3 0 K$ gas.\\\n\\\nThe updater contract exposes a\
              \ simple API which takes block height as its input, and returns the\
              \ corresponding block header. The receiver contracts can then use the\
              \ block header to complete application-specific verification.\\\n\\\n\
              Batching. Instead of calling the updater contract on every new block\
              \ header, we implemented batching where the updater contract stores\
              \ Merkle roots of batches of $B$ consecutive block headers. The prover\
              \ will first collect $B$ consecutive blocks, and then makes a unified\
              \ proof for all $B$ blocks. The updater contract will only need to verify\
              \ one proof for the batch of $B$ blocks. After the verification, the\
              \ updater contract checks the difficulty, stores the block headers,\
              \ and updates the light-client state. Storing one Merkle root every\
              \ $B$ blocks also reduces storage cost. Thus $B$ can be set to balance\
              \ user experience and cost: With a larger $B$ , users need to wait longer,\
              \ but the cost of running the system is lower.\\\n\\\nWe implement the\
              \ aforementioned batched proof verification and show the experimental\
              \ results in Section 5.6.2. With batching, the cost for storing block\
              \ headers and maintaining light-client states is amortized across $B$\
              \ blocks. The bulk of the cost incurred by the updater contract is SNARK\
              \ proof verification, which is the focus of our evaluation below.\\\n\
              \\\nIn addition, we propose a more complex batching optimization presented\
              \ in the following for further optimization.\\\n\\\nOn-chain Gas Cost\
              \ Optimization To further optimize the on-chain gas cost of block header\
              \ verification and storage for a universal zkBridge, we propose the\
              \ following approach, in which the prover will not bother to pay for\
              \ on-chain proof verification or block header storage, and users are\
              \ encouraged to submit the proof they need by our incentive design.\\\
              \n\\\nIn our optimization, the same as the aforementioned batched proof,\
              \ the prover generates one single proof for every $2 ^ { d }$ blocks\
              \ where $d$ is a system configuration, and each proof checks and shows\
              \ the validity of all signatures in the corresponding $2 ^ { d }$ blocks.\
              \ However, instead of submitting the Merkle root of the batch along\
              \ with the proof on-chain immediately, provers simply post the proof\
              \ to the users (e.g., through a website), and it’s up to the users to\
              \ retrieve and post the proof on-chain. Thus there’s no more on-chain\
              \ gas cost for provers through the approach.\\\n\\\nFor users who want\
              \ to verify a transaction $t x$ in a block $b l k$ , the workflow is\
              \ as follows.\\\n\\\n1. If blk has already been submitted on-chain,\
              \ go to the next step. Otherwise, retrieve the proofs for the sequence\
              \ of blocks from the first unsubmitted one to $b l k$ , and then invoke\
              \ the updater contract to verify all the proofs on-chain and store the\
              \ information of the corresponding sequence of blocks. The process can\
              \ be expensive. However, once the proofs are verified and the blocks\
              \ are confirmed by the updater contract, the user becomes the owner\
              \ of all these proofs on-chain, and can benefit from the proofs by charging\
              \ later users who rely on these proofs to verify their transactions\
              \ on-chain.\\\n2. Thanks to the previously submitted proofs, the validity\
              \ of the corresponding block is already proved at this step. And the\
              \ work can never be accomplished without the efforts of proving all\
              \ the blocks prior to $b l k$ (including $b l k$ ). Suppose $b l k$\
              \ is the $\\\\hat { i } ^ { t h }$ block, then for each block with index\
              \ in the range $\\[ i - t + 1 , i \\]$ , the user should pay a certain\
              \ amount of fee to the block proof owner in compensation, where $t$\
              \ is a system configuration and the definition of block proof owner\
              \ is defined in the previous step.\\\n\\\nIn this case, provers don’t\
              \ bother to pay for on-chain verification any more, and the proofs are\
              \ only submitted and verified on demand, which is more cost-efficient\
              \ and can reduce possible waste. Moreover, through carefully-designed\
              \ incentive, we can actually encourage users to submit the proofs as\
              \ a possible investment, and it can also help with the popularity of\
              \ our bridge.\\\n\\\nThrough the optimization, the cost performance\
              \ of our bridge can be summarized as follows. If there is high demand,\
              \ then each proof will be submitted immediately upon generation, and\
              \ in this case each user needs to pay for at most one time of on-chain\
              \ proof verification. It then degenerates into our original batched\
              \ proof, but users are responsible of paying for the on-chain verification\
              \ instead. If the sender chain is so unpopular that there is little\
              \ bridging demand from the chain, then we successfully avoid unnecessarily\
              \ submitting the proofs on-chain for meaningless but costly verification.\
              \ And even if a user suddenly exists and requires bridging in this case,\
              \ the request can also be fulfilled by retrieving the proofs from provers\
              \ and sending them for on-chain verification one by one.\\\n\\\nAnd\
              \ thus we can see that, the new design can actually benefit both the\
              \ provers and the users.\\\n\\\n# 5.6.2 Evaluation\\\n\\\nWe evaluate\
              \ the performance of zkBridge (from Cosmos to Ethereum) from four aspects:\
              \ proof generation time, proof generation communication cost, proof\
              \ size, and on-chain verification cost.\\\n\\\nExperiment setup. We\
              \ envision that a relayer node in zkBridge will be deployed as a service\
              \ in a managed network, therefore we evaluate zkBridge in a data-center-like\
              \ environment. Specifically, we run all the experiments on 128 AWS EC2\
              \ c5.24xlarge instances with the Intel(R) Xeon(R) Platinum 8275CL CPU\
              \ $@$ 3.00GHz and 192GB of RAM. Our implementation for the proof generation\
              \ is parallelized with at most 128 machines. We report the average running\
              \ time of 10 executions. Whenever applicable, we report costs both in\
              \ terms of running time and monetary expenses.\\\n\\\nTable 5.2: Evaluation\
              \ results. RV is the shorthand for recursive verification.\\\n\\\n|\
              \     |     |     |     |     |     |     |     |     |     |\\\n| ---\
              \ | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\n|  | Proof\
              \ Gen. Time (seconds) | Proof Gen. Comm. (GB) | Proof Size (Bytes) |\
              \ On-chain Ver. Cost (gas) |\\\n| \\# of sigs | deVirgo | RV | total\
              \ | total | per-machine | w/o RV | w/RV | w/o RV | w/ RV |\\\n| 8 |\
              \ 12.52 | 4.90 | 17.42 | 7.34 | 0.92 | 1946476 | 131 | 78M | 227K |\\\
              \n| 32 | 12.80 | 5.41 | 18.21 | 32.24 | 1.01 | 1952492 | 131 | 78M |\
              \ 227K |\\\n| 128 | 13.28 | 5.49 | 18.77 | 131.89 | 1.03 | 1958508 |\
              \ 131 | 79M | 227K |\\\n\\\nProof generation time of deVirgo. We first\
              \ evaluate the main cryptographic building block—deVirgo— and compare\
              \ its performance with the original Virgo \\[ZXZS20\\]. The source code\
              \ of the original Virgo is obtained at [https://github.com/sunblaze-ucb/Virgo](https://github.com/sunblaze-ucb/Virgo).\
              \ We run both protocols on the same circuit for correctness proofs,\
              \ which mainly consists of $N$ invocation of EdDSA signature verification.\\\
              \n\\\nFigure 5.2 shows the prover time (in seconds) against different\
              \ $N$ . For deVirgo, we repeat the experiment with 8, 32, 128 distributed\
              \ machines. According to Fig. 5.2, the prover time of the original Virgo\
              \ increases linearly in the number of signatures $N$ , while the prover\
              \ time of deVirgo is almost independent of $N$ until $N$ is greater\
              \ than the number of servers when computation becomes an bottleneck.\
              \ The linear scalability suggests that the workload of each machine\
              \ only depends on its own sub-circuit and the communication overhead\
              \ is small. Table 5.2 reports the communication cost among parallel\
              \ machines. The total communication cost is linear in the number of\
              \ machines, consistent with the analysis in Section 5.4.4, with each\
              \ machine sending and receiving around 1 GB of data. Since we envision\
              \ a relayer node in zkBridge to be deployed in a data-center-like environment,\
              \ the amount of traffic is reasonable.\\\n\\\nIn practice, the Cosmos\
              \ block headers typically have $N = 1 2 8$ signatures while 32 top signatures\
              \ are sufficient to achieve super-majority. Therefore, generating a\
              \ correctness proof for a Cosmos block header would take more than 400\
              \ seconds with the original Virgo, but it decreases to 13.28 seconds\
              \ with deVirgo, implying a $3 0 \\\\mathrm { x }$ speedup. In general,\
              \ as is consistent with the analysis in Section 5.4, deVirgo accelerates\
              \ the proof generation on data-parallel circuits with $N$ copies by\
              \ a factor of almost $N$ , which is optimal for distributed algorithms.\\\
              \n\\\n# Proof size and verification time.\\\n\\\nTo reduce on-chain\
              \ verification cost, we use the recursive verification technique presented\
              \ in Section 5.5. Now we report on its efficacy.\\\n\\\nRecursive proof\
              \ generation time. We implement recursive verification by invoking Groth16\
              \ (constructed using gnark \\[Gna\\]) on the verification circuit. We\
              \ report the proof time in deVirgo, the generation time of recursive\
              \ proofs (the column marked RV), and the sum, in Table 5.2, for various\
              \ numbers of signatures. The RV time almost remains constant in the\
              \ number of signatures verified by the deVirgo proofs. That is because\
              \ of the data-parallel structure of the state transition proof circuit:\
              \ the size of Groth16 verification circuit is only a function of the\
              \ size of a sub-circuit.\\\n\\\n![](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/images/7514ca49ef2ff52a510a1c49eb75d058b6b5d26a63340956877b8dff4545655c.jpg)\\\
              \n\\\nFigure 5.2: Prover time of deVirgo and the original Virgo for\
              \ Cosmos block header verification.\\\n\\\nThe main benefit of recursive\
              \ verification is a reduction in both proof size and verification cost.\\\
              \n\\\nReduced proof size. Table 5.2 shows the proof size both with and\
              \ without recursive verification. For the practical scenario where $N\
              \ = 3 2$ , the proof size is reduced from $1 . 9 \\\\mathrm { M B }$\
              \ to 131 Bytes. Overall, for $N = 3 2$ , with an increase of about $2\
              \ 5 %$ in prover time, we get a reduction of around $1 4 0 0 0 \\\\\
              mathrm { x }$ in proof size.\\\n\\\nReduced on-chain verification cost.\
              \ The final proof is 131 Bytes while the final verification only costs\
              \ 3 pairings. As shown in Table 5.2, the on-chain verification cost\
              \ is constant (227K). In comparison, without recursive verification,\
              \ directly verifying Virgo proofs on-chain would be infeasible. (Our\
              \ estimation of the gas cost is 78M, which far exceeds the single block\
              \ gas limit 30M).\\\n\\\nComparison with optimistic bridges. With batching,\
              \ the confirmation latency of zkBridge is under 2 minutes, including\
              \ $3 \\\\times 3 2$ seconds for waiting for all blocks in the batch\
              \ and another 20 seconds for proof generation. While this is not blazing\
              \ fast, in comparison, optimistic bridges have much longer confirmation\
              \ time. E.g., NEAR’s Rainbow bridge has a challenge window of 4 hours\
              \ \\[Nea\\] before which the transfer cannot be confirmed.\\\n\\\n#\
              \ 5.6.3 Cost analysis\\\n\\\nIn this section, we analyze the operational\
              \ cost of zkBridge, which consists of off-chain cost (generating proofs)\
              \ and on-chain cost (storing headers and verifying proofs).\\\n\\\n\
              Off-chain cost. Off-chain cost can vary significantly based on the deployment.\
              \ While we use AWS in our performance benchmark, it may not be the best\
              \ option for practical deployment. AWS service is expensive due to its\
              \ high margin, elastic scaling capability, and high reliability, which\
              \ isn’t necessary for our proof generation process. To show a representative\
              \ range, we consider two deployment options: cloud-based and self-hosted.\
              \ For cloud-based deployment, we search for reputable and economical\
              \ dedicated server rental services and choose Hetzner\\[Het\\] as an\
              \ example. For self-hosted options, we calculate the cost to purchase\
              \ the hardware and the on-going cost (mainly the electricity).\\\n\\\
              \nOn AWS c5.24xlarge, it takes 18 seconds to generate a proof with 32\
              \ machines. Renting a server with a similar spec as AWS c5.24xlarge\
              \ from Hetzner costs $$ 253.12$ per month, thus the cost of cloud-based\
              \ deployment with Hetzner will be around $$ 8100$ per month for all\
              \ 32 machines. It translates to $$ 0.02$ per block.\\\n\\\nTo estimate\
              \ the cost for self-hosted deployment, we use online tools to configure\
              \ a machine with a comparable spec to that in AWS. Table 5.3 reports\
              \ the configuration and each machine costs around $$ 4.5\\\\mathrm {\
              \ k }$ . The total setup cost is thus around $$ 4.5k \\\\times 32=9144\
              \ k$ . For self-hosted servers, the main on-going cost is electricity.\
              \ With each machine consuming 657W power, a 32-machine cluster consumes\
              \ $0 . 1 0 5 \\\\mathrm { k W h }$ per block. Assuming US average electricity\
              \ rate $0.12/KWh \\[Use\\], the electricity cost is $$ 02$ per block,\
              \ or $$ 5184$ per month.\\\n\\\nTable 5.3: Prover hardware configuration.\\\
              \n\\\n|     |     |     |     |     |\\\n| --- | --- | --- | --- | ---\
              \ |\\\n| Hardware type | Hardware name | Power | Price | Quantity |\\\
              \n| CPU | AMD Ryzen Threadripper 3970X | 435w | $2325.99 | 1 |\\\n|\
              \ Memory | CMK256GX4M8D3600C18 | 96W | $1129.99 | 1 |\\\n| Motherboard\
              \ | MSI TRX40 PRO WIFI | 80W | $565.57 | 1 |\\\n| Power Supply | EVGA\
              \ 220-T2-1000-X1 | 94% efficiency | $332.88 | 1 |\\\n| SSD | MZ-V8P1T0B/AM\
              \ | 6.2W | $129.99 | 1 |\\\n| Total |  | 657W | $4484.42 |  |\\\n\\\n\
              On-chain cost. On-chain cost refers to the total gas used for on-chain\
              \ operation, and we report the equivalent USD cost based on the gas\
              \ price (about 20 gwei) and ETH price (about 1600 USD) at the time of\
              \ writing (August 2022). If we use efficient batched proofs, for a batch\
              \ of $N$ headers, the bulk of the verification cost is that of verifying\
              \ one Groth16 proof, which costs less than $2 3 0 K$ gas, roughly $$\
              \ 7.36$ . If we choose $N = 3 2$ for example, the on-chain cost will\
              \ be $$ 0.23$ per block. Moreover, if we adopt the optimization mentioned\
              \ in Section 5.6.1, we can further reduce the on-chain cost and offload\
              \ the cost to users if the number of users is large.\\\n\\\n# 5.6.4\
              \ Ethereum to other EVM-compatible chains\\\n\\\nSo far we have focused\
              \ on the bridge from Cosmos to Ethereum because generating and verifying\
              \ correctness proofs for that direction is challenging. We also implement\
              \ a prototype of a bridge from Ethereum to other EVM-compatible blockchains.\\\
              \n\\\nThe high level idea is simple: upon receiving a block header,\
              \ the updater contract on the receiver chain verifies the PoW and appends\
              \ it to the list of headers if the verification is passed. However,\
              \ a wrinkle to the implementation is that Ethereum uses a memory hard\
              \ hash function, EthHash $\\[ \\\\mathrm { W o o } { + } 1 4 \\]$ ,\
              \ which is prohibitively inefficient to run on-chain. Basically, EthHash\
              \ involves randomly accessing elements in a 1 gigabyte dataset (called\
              \ a DAG) derived from a public seed and the block height. Generating\
              \ the DAGs on-chain is prohibitively expensive.\\\n\\\nOur idea is to\
              \ pre-compute many DAGs off-chain and store their hashes on-chain. Specifically,\
              \ as part of zkBridge setup, we pre-compute 2,048 DAGs , build a Merkle\
              \ tree for each DAG using MiMC \\[AGRRT16\\], and store the Merkle roots\
              \ on-chain. Per EthHash specification, a new DAG is generated every\
              \ 30,000 blocks, so 2,048 of them can last for 10 years; the off-chain\
              \ pre-computation process takes no more than 4 days. Then, the correctness\
              \ proofs will show that a given EthHash PoW is correct with respect\
              \ to the Merkle root of the DAG corresponding to the block in question.\
              \ We emphasize that the setup process is verifiable and anyone can verify\
              \ the published Merkle roots on their own before using the service.\
              \ The circuit for verifying EthHash PoW has around 2 million gates.\\\
              \n\\\nThe rest of the protocol is the same as a regular light client,\
              \ which involves storing the headers, following the longest chain by\
              \ computing accumulated difficulty, resolving forks, etc.\\\n\\\nCost\
              \ analysis. Since EthHash PoW verification circuit has only around 2\
              \ million constraints, a single machine with the configuration in Table\
              \ 5.3 can generate a proof within 10 seconds. As long as the receiver\
              \ chain is EVM-compatible, the on-chain cost will be close to that presented\
              \ in Section 5.6.3, since the updater contract only verifies Groth16\
              \ proofs in all cases.\\\n\\\n# 5.7 Related work\\\n\\\nIn this section,\
              \ we compare zkBridge to existing cross-chain bridge systems and the\
              \ line of work on zk-rollups which also uses ZKPs for scalability and\
              \ security.\\\n\\\nCross-chain bridges in the wild and security issues.\
              \ Cross-chain systems are widely deployed and used. Below we briefly\
              \ survey the representative ones. The list is not meant to be exhaustive.\
              \ PolyNetwork \\[Polb\\] is an interoperability protocol using a side-chain\
              \ as the relay with a two-phase commitment protocol. Wormhole \\[Worb\\\
              ] is a generic message-passing protocol secured by a network of guardian\
              \ nodes, and its security relies on $\\\\frac { 2 } { 3 }$ of the committee\
              \ being honest. Ronin operates in a similar model. While relying on\
              \ decentralized committees for security, practical deployment usually\
              \ opts for relatively small ones for efficiency (e.g., 9 in case of\
              \ Ronin). Committee breaches are far from being rare in practice. In\
              \ a recent exploit against Ronin \\[Ron\\], the attacker obtained five\
              \ of the nine validator keys, stealing 624 million USD. PolyNetwork\
              \ and Wormhole were also recently attacked, losing $$ 6110$ \\[Pola\\\
              ] and $$ 3260$ \\[Wora\\] respectively. Key compromise was suspected\
              \ in the PolyNetwork attack.\\\n\\\nAn alternative design is to leverage\
              \ economic incentives. Nomad \\[Nomb\\] (which recently lost more than\
              \ $$ 1900$ to hackers due to an implementation bug \\[Noma\\]) and Near’s\
              \ Rainbow Bridge \\[Rai\\] are such examples. These systems require\
              \ participants to deposit a collateral, and rely on a watchdog service\
              \ to continuously monitor the blockchain and confiscate offenders’ collateral\
              \ upon detecting invalid updates. Optimistic protocols fundamentally\
              \ require a long confirmation latency in order to ensure invalid updates\
              \ can be detected with high probability (e.g., Near \\[Rai\\] requires\
              \ 4 hours). Moreover, participants must deposit significantly collateral\
              \ (e.g., 20 ETH in Near \\[Rai\\]). Both issues can be avoided by zkBridge.\\\
              \n\\\nIn summary, compared to existing protocols, zkBridge achieve both\
              \ efficiency and cryptographic assurance. zkBridge is “trustless” in\
              \ that it does not require extra assumptions other than those of blockchains\
              \ and underlying cryptographic protocols. It also avoids the long confirmation\
              \ of optimistic protocols.\\\n\\\nzk-rollups. Rollups are protocols\
              \ that batch transaction execution using ZKPs to scale up the layer-1\
              \ blockchains. Starkware \\[Sta\\], ZkSync \\[Zks\\], and Polygon Zero\
              \ \\[Pole\\] are a few examples.\\\n\\\nThese zk-rollup solutions have\
              \ not been applied to the bridge setting, where our work is the first\
              \ to use ZKP to enable a decentralized trustless bridge. In addition,\
              \ the current zk-rollup work in general has not dealt with such large\
              \ circuits as in zkBridge, whereas in our work, we need to design and\
              \ develop a number of techniques including deVirgo and proof recursion\
              \ to make building a ZKP-based bridge practical for the first time.\
              \ In particular, we leverage the data parallelism of the circuits to\
              \ obtain a ZKP protocol that is more than $1 0 0 \\\\mathrm { x }$ faster\
              \ than existing protocols for the workload in zkBridge and combine it\
              \ with proof recursion for efficient on-chain verification. The idea\
              \ behind deVirgo protocol may be applicable to zk-rollups too.\\\n\\\
              \n# Bibliography\\\n\\\n\\[ABFG14\\] G. Ateniese, I. Bonacina, A. Faonio,\
              \ and N. Galesi. “Proofs of space: When space is of the essence”. In:\
              \ International Conference on Security and Cryptography for Networks.\
              \ Springer. 2014, pp. 538–557.\\\n\\\n\\[ABST22\\] M. Ambrona, M. Beunardeau,\
              \ A.-L. Schmitt, and R. R. Toledo. aPlonK : Aggregated PlonK from Multi-Polynomial\
              \ Commitment Schemes. Cryptology ePrint Archive, Paper 2022/1352. [https://eprint.iacr.org/2022/1352](https://eprint.iacr.org/2022/1352).\
              \ 2022\\. URL: [https://eprint](https://eprint/). iacr.org/2022/1352.\\\
              \n\\\n\\[AGRRT16\\] M. Albrecht, L. Grassi, C. Rechberger, A. Roy, and\
              \ T. Tiessen. “MiMC: Efficient encryption and cryptographic hashing\
              \ with minimal multiplicative complexity”. In: International Conference\
              \ on the Theory and Application of Cryptology and Information Security.\
              \ Springer. 2016, pp. 191–219.\\\n\\\n\\[AHIV17\\] S. Ames, C. Hazay,\
              \ Y. Ishai, and M. Venkitasubramaniam. “Ligero: Lightweight sublinear\
              \ arguments without a trusted setup”. In: CCS. 2017.\\\n\\\n\\[Amu\\\
              ] A multichain approach is the future of the blockchain industry. 2022.\
              \ URL: https : / / cointelegraph.com/news/a-multichain-approach-is-the-future-of-theblockchain-industry\
              \ (visited on 04/24/2022).\\\n\\\n\\[arm\\] armfazh. flo-shani-aesni.\
              \ [https://github.com/armfazh/flo-shani-aesni](https://github.com/armfazh/flo-shani-aesni).\\\
              \n\\\n\\[Ate\\] Ate-pairing. [https://github.com/herumi/ate-pairing](https://github.com/herumi/ate-pairing).\\\
              \n\\\n\\[Aur\\] libIOP. [https://github.com/scipr-lab/libiop](https://github.com/scipr-lab/libiop).\\\
              \n\\\n\\[Axe\\] Axelar. [https://axelar.network/](https://axelar.network/).\
              \ 2022.\\\n\\\n\\[Azt\\] Aztec. [https://aztec.network/](https://aztec.network/).\
              \ 2022.\\\n\\\n\\[BBBPWM18\\] B. Bünz, J. Bootle, D. Boneh, A. Poelstra,\
              \ P. Wuille, and G. Maxwell. “Bulletproofs: Short Proofs for Confidential\
              \ Transactions and More”. In: IEEE S&P. Vol. 00. 2018, pp. 319– 338.\\\
              \n\\\n\\[BBCDPGL18\\] C. Baum, J. Bootle, A. Cerulli, R. Del Pino, J.\
              \ Groth, and V. Lyubashevsky. “Sub-linear Lattice-Based Zero-Knowledge\
              \ Arguments for Arithmetic Circuits”. In: CRYPTO. Springer. 2018, pp.\
              \ 669–699.\\\n\\\n\\[BCCGP16\\] J. Bootle, A. Cerulli, P. Chaidos, J.\
              \ Groth, and C. Petit. “Efficient zero-knowledge arguments for arithmetic\
              \ circuits in the discrete log setting”. In: International Conference\
              \ on the Theory and Applications of Cryptographic Techniques. 2016.\\\
              \n\\\n\\[BCCT13\\] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer.\
              \ “Recursive Composition and Bootstrapping for SNARKS and Proof-Carrying\
              \ Data”. In: Proceedings of the Forty-Fifth Annual ACM Symposium on\
              \ Theory of Computing. STOC ’13. Palo Alto, California, USA: Association\
              \ for Computing Machinery, 2013, pp. 111–120. ISBN: 9781450320290. DOI:\
              \ 10.1145/2488608.2488623. URL: [https://doi.org/10.1145/2488608.2488623](https://doi.org/10.1145/2488608.2488623).\\\
              \n\\\n\\[BCG20\\] J. Bootle, A. Chiesa, and J. Groth. “Linear-Time Arguments\
              \ with Sublinear Verification from Tensor Codes”. In: TCC (2020).\\\n\
              \\\n\\[BCGGHJ17\\] J. Bootle, A. Cerulli, E. Ghadafi, J. Groth, M. Hajiabadi,\
              \ and S. K. Jakobsen. “Linear-time zero-knowledge proofs for arithmetic\
              \ circuit satisfiability”. In: ASIACRYPT. Springer. 2017, pp. 336–365.\\\
              \n\\\n\\[BCL22\\] J. Bootle, A. Chiesa, and S. Liu. Zero-Knowledge IOPs\
              \ with Linear-Time Prover and Polylogarithmic-Time Verifier. EUROCRYPT.\
              \ 2022.\\\n\\\n\\[BCLMS20\\] B. Bünz, A. Chiesa, W. Lin, P. Mishra,\
              \ and N. Spooner. Proof-Carrying Data without Succinct Arguments. Cryptology\
              \ ePrint Archive, Paper 2020/1618. [https://eprint](https://eprint/).\
              \ iacr.org/2020/1618. 2020. URL: [https://eprint.iacr.org/2020/1618](https://eprint.iacr.org/2020/1618).\\\
              \n\\\n\\[BCMS20\\] B. Bünz, A. Chiesa, P. Mishra, and N. Spooner. Proof-Carrying\
              \ Data from Accumulation Schemes. Cryptology ePrint Archive, Paper 2020/499.\
              \ [https://eprint.iacr.org/](https://eprint.iacr.org/) 2020/499. 2020.\
              \ URL: [https://eprint.iacr.org/2020/499](https://eprint.iacr.org/2020/499).\\\
              \n\\\n\\[BDFG20\\] D. Boneh, J. Drake, B. Fisch, and A. Gabizon. Halo\
              \ Infinite: Recursive zk-SNARKs from any Additive Polynomial Commitment\
              \ Scheme. Cryptology ePrint Archive, 2020/1536. 2020.\\\n\\\n\\[BDLSY12\\\
              ] D. J. Bernstein, N. Duif, T. Lange, P. Schwabe, and B.-Y. Yang. “High-speed\
              \ high-security signatures”. In: Journal of cryptographic engineering\
              \ 2.2 (2012), pp. 77–89.\\\n\\\n\\[Bee\\] Beeple sold an NFT for $$\
              \ 69$ million - The Verge. 2022-04-24. URL: https : / / www . theverge.com/2021/3/11/22325054/beeple-\
              \ christies- nft- sale- costeverydays-69-million.\\\n\\\n\\[BEGKN94\\\
              ] M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor. “Checking the\
              \ correctness of memories”. In: Algorithmica 12.2-3 (1994), pp. 225–244.\\\
              \n\\\n\\[Ben+14\\] E. Ben-Sasson et al. “Zerocash: Decentralized Anonymous\
              \ Payments from Bitcoin”. In: IEEE S&P. 2014.\\\n\\\n\\[BFHVXZ20\\]\
              \ R. Bhadauria, Z. Fang, C. Hazay, M. Venkitasubramaniam, T. Xie, and\
              \ Y. Zhang. “Ligero $^ { + + }$ A New Optimized Sublinear IOP”. In:\
              \ CCS. 2020.\\\n\\\n\\[BFRSBW13\\] B. Braun, A. J. Feldman, Z. Ren,\
              \ S. T. V. Setty, A. J. Blumberg, and M. Walfish. “Verifying computations\
              \ with state”. In: SOSP. 2013.\\\n\\\n\\[BFS20\\] B. Bünz, B. Fisch,\
              \ and A. Szepieniec. “Transparent SNARKs from DARK compilers”. In: Eurocrypt.\
              \ [https://eprint.iacr.org/2019/1229](https://eprint.iacr.org/2019/1229).\
              \ 2020.\\\n\\\n\\[BG12\\] S. Bayer and J. Groth. “Efficient zero-knowledge\
              \ argument for correctness of a shuffle”. In: Annual International Conference\
              \ on the Theory and Applications of Cryptographic Techniques. Springer.\
              \ 2012, pp. 263–280.\\\n\\\n\\[BLMR14\\] I. Bentov, C. Lee, A. Mizrahi,\
              \ and M. Rosenfeld. “Proof of activity: Extending bitcoin’s proof of\
              \ work via proof of stake \\[extended abstract\\] y”. In: ACM SIGMETRICS\
              \ Performance Evaluation Review 42.3 (2014), pp. 34–37.\\\n\\\n\\[BLNS20\\\
              ] J. Bootle, V. Lyubashevsky, N. K. Nguyen, and G. Seiler. “A non-PCP\
              \ approach to succinct quantum-safe zero-knowledge”. In: CRYPTO. 2020.\\\
              \n\\\n\\[BMRS21\\] C. Baum, A. J. Malozemoff, M. Rosen, and P. Scholl.\
              \ “Mac’n’Cheese: Zero-Knowledge Proofs for Arithmetic Circuits with\
              \ Nested Disjunctions”. In: CRYPTO. 2021.\\\n\\\n\\[BMV19\\] B. Bünz,\
              \ M. Maller, and N. Vesely. “Efficient Proofs for Pairing-Based Languages”.\
              \ In: 2019.\\\n\\\n\\[BPS16\\] I. Bentov, R. Pass, and E. Shi. “Snow\
              \ White: Provably Secure Proofs of Stake.” In: IACR Cryptol. ePrint\
              \ Arch. 2016.919 (2016).\\\n\\\n\\[BSBHR18\\] E. Ben-Sasson, I. Bentov,\
              \ Y. Horesh, and M. Riabzev. “Fast reed-solomon interactive oracle proofs\
              \ of proximity”. In: 45th international colloquium on automata, languages,\
              \ and programming (icalp 2018). Schloss Dagstuhl-Leibniz-Zentrum fuer\
              \ Informatik. 2018.\\\n\\\n\\[BSBHR19\\] E. Ben-Sasson, I. Bentov, Y.\
              \ Horesh, and M. Riabzev. “Scalable zero knowledge with no trusted setup”.\
              \ In: CRYPTO. Springer. 2019, pp. 701–732.\\\n\\\n\\[BSCGTV13\\] E.\
              \ Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza. “SNARKs\
              \ for C: Verifying program executions succinctly and in zero knowledge”.\
              \ In: CRYPTO. 2013.\\\n\\\n\\[BSCRSVW19\\] E. Ben-Sasson, A. Chiesa,\
              \ M. Riabzev, N. Spooner, M. Virza, and N. P. Ward. “Aurora: Transparent\
              \ succinct arguments for R1CS”. In: Eurocrypt. Springer. 2019, pp. 103–128.\\\
              \n\\\n\\[BSCS16\\] E. Ben-Sasson, A. Chiesa, and N. Spooner. “Interactive\
              \ oracle proofs”. In: Theory of Cryptography Conference. Springer. 2016,\
              \ pp. 31–60.\\\n\\\n\\[BSCTV14a\\] E. Ben-Sasson, A. Chiesa, E. Tromer,\
              \ and M. Virza. “Scalable Zero Knowledge via Cycles of Elliptic Curves”.\
              \ In: CRYPTO. 2014, pp. 276–294.\\\n\\\n\\[BSCTV14b\\] E. Ben-Sasson,\
              \ A. Chiesa, E. Tromer, and M. Virza. Scalable Zero Knowledge via Cycles\
              \ of Elliptic Curves. Cryptology ePrint Archive, Paper 2014/595. [https://eprint.iacr](https://eprint.iacr/)\
              \ .org/2014/595. 2014. URL: [https://eprint.iacr.org/2014/595](https://eprint.iacr.org/2014/595).\\\
              \n\\\n\\[BSCTV14c\\] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza.\
              \ “Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture”.\
              \ In: Proceedings of the USENIX Security Symposium. 2014.\\\n\\\n\\\
              [But\\] Vbuterin comments on \\[AMA\\] We are the EF’s Research Team\
              \ (Pt. 7: 07 January, 2022). 2022. URL: https : / / old . reddit . com\
              \ / r / ethereum / comments / rwojtk / ama \\_ we \\_ are \\_ the \\\
              _ efs \\_ research \\_ team \\_ pt \\_ 7 \\_ 07 \\_ january / hrngyk8/\
              \ (visited on 04/24/2022).\\\n\\\n\\[CBC21\\] P. Chatzigiannis, F. Baldimtsi,\
              \ and K. Chalkias. “SoK: Blockchain Light Clients”. In: Cryptology ePrint\
              \ Archive (2021).\\\n\\\n\\[CCHLRR18\\] R. Canetti, Y. Chen, J. Holmgren,\
              \ A. Lombardi, G. N. Rothblum, and R. D. Rothblum. Fiat-Shamir From\
              \ Simpler Assumptions. Cryptology ePrint Archive, Report 2018/1004.\
              \ 2018.\\\n\\\n\\[CD98\\] R. Cramer and I. Damgård. “Zero-knowledge\
              \ proofs for finite field arithmetic, or: Can zero-knowledge be for\
              \ free?” In: Annual International Cryptology Conference (CRYPTO). 1998.\\\
              \n\\\n\\[CFS17\\] A. Chiesa, M. A. Forbes, and N. Spooner. “A Zero Knowledge\
              \ Sumcheck and its Applications”. In: CoRR abs/1704.02086 (2017). arXiv:\
              \ 1704.02086. URL: [http://arxiv](http://arxiv/). org/abs/1704.02086.\\\
              \n\\\n$\\\\left\\[ \\\\mathrm { C h a } { + } 1 7 \\\\right\\]$ M. Chase\
              \ et al. “Post-quantum zero-knowledge and signatures from symmetric-key\
              \ primitives”. In: CCS. ACM. 2017, pp. 1825–1842.\\\n\\\n\\[CHMMVW20\\\
              ] A. Chiesa, Y. Hu, M. Maller, P. Mishra, N. Vesely, and N. Ward. “Marlin:\
              \ Preprocessing zksnarks with universal and updatable srs”. In: Eurocrypt.\
              \ 2020, pp. 738–768.\\\n\\\n\\[Cira\\] Circom. [https://github.com/iden3/circom](https://github.com/iden3/circom).\
              \ 2022.\\\n\\\n\\[Cirb\\] ed25519-circom. [https://github.com/Electron-Labs/ed25519-circom](https://github.com/Electron-Labs/ed25519-circom).\
              \ 2022.\\\n\\\n\\[CMT12\\] G. Cormode, M. Mitzenmacher, and J. Thaler.\
              \ “Practical Verified Computation with Streaming Interactive Proofs”.\
              \ In: Proceedings of the 3rd Innovations in Theoretical Computer Science\
              \ Conference. ITCS ’12. 2012.\\\n\\\n\\[Coi\\] Cryptocurrency prices,\
              \ charts and market capitalizations. 2022. URL: [https://coinma](https://coinma/)\
              \ rketcap.com/.\\\n\\\n\\[Cos\\] Cosmos. [https://cosmos.network/](https://cosmos.network/).\
              \ 2022.\\\n\\\n$\\\\left\\[ \\\\mathrm { C o s } { + } 1 5 \\\\right\\\
              ]$ C. Costello et al. “Geppetto: Versatile verifiable computation”.\
              \ In: IEEE S&P. 2015.\\\n\\\n\\[COS20\\] A. Chiesa, D. Ojha, and N.\
              \ Spooner. “Fractal: Post-quantum and transparent recursive proofs from\
              \ holography”. In: Eurocrypt. [https://eprint.iacr.org/2019/1076](https://eprint.iacr.org/2019/1076).\
              \ 2020, pp. 769–793.\\\n\\\n\\[CRVW02\\] M. Capalbo, O. Reingold, S.\
              \ Vadhan, and A. Wigderson. “Randomness Conductors and Constant-Degree\
              \ Lossless Expanders”. In: STOC. 2002.\\\n\\\n\\[CS07\\] A. Czumaj and\
              \ C. Sohler. “Testing Expansion in Bounded-Degree Graphs”. In: IEEE\
              \ FOCS. 2007.\\\n\\\n\\[CT10\\] A. Chiesa and E. Tromer. “Proof-Carrying\
              \ Data and Hearsay Arguments from Signature Cards”. In: Innovations\
              \ in Computer Science - ICS 2010, Tsinghua University, Beijing, China,\
              \ January 5-7, 2010. Proceedings. Ed. by A. C. Yao. Tsinghua University\
              \ Press, 2010, pp. 310–331. URL: [http://conference.iiis.tsinghua.edu.cn/ICS2010/](http://conference.iiis.tsinghua.edu.cn/ICS2010/)\
              \ content/papers/25.html.\\\n\\\n\\[DFKP15\\] S. Dziembowski, S. Faust,\
              \ V. Kolmogorov, and K. Pietrzak. “Proofs of space”. In: Annual Cryptology\
              \ Conference. Springer. 2015, pp. 585–605.\\\n\\\n\\[DGKR17\\] B. David,\
              \ P. Ga, A. Kiayias, and A. Russell. “Ouroboros praos: An adaptively-secure,\
              \ semi-synchronous proof-of-stake protocol”. In: Cryptology ePrint Archive\
              \ (2017).\\\n\\\n\\[DI14\\] E. Druk and Y. Ishai. “Linear-Time Encodable\
              \ Codes Meeting the Gilbert-Varshamov Bound and Their Cryptographic\
              \ Applications”. In: ITCS. 2014.\\\n\\\n\\[Din70\\] E. A. Dinic. “Algorithm\
              \ for solution of a problem of maximum flow in networks with power estimation”.\
              \ In: Soviet Math. Doklady. 1970.\\\n\\\n\\[DIO21\\] S. Dittmer, Y.\
              \ Ishai, and R. Ostrovsky. “Line-point zero knowledge and its applications”.\
              \ In: ITC. 2021.\\\n\\\n\\[Edd\\] ed25519-circom. [https://github.com/Electron-Labs/ed25519-circom](https://github.com/Electron-Labs/ed25519-circom).\
              \ 2022.\\\n\\\n\\[EFG22\\] L. Eagen, D. Fiore, and A. Gabizon. cq: Cached\
              \ quotients for fast lookups. Cryptology ePrint Archive, Paper 2022/1763.\
              \ [https://eprint.iacr.org/2022/1763](https://eprint.iacr.org/2022/1763).\
              \ 2022\\. URL: [https://eprint.iacr.org/2022/1763](https://eprint.iacr.org/2022/1763).\\\
              \n\\\n\\[ESLL19\\] M. F. Esgin, R. Steinfeld, J. K. Liu, and D. Liu.\
              \ “Lattice-based zero-knowledge proofs: new techniques for shorter and\
              \ faster constructions and applications”. In: CRYPTO. 2019.\\\n\\\n\\\
              [FDNZ21\\] Z. Fang, D. Darais, J. Near, and Y. Zhang. “Zero Knowledge\
              \ Static Program Analysis”. In: CCS. 2021.\\\n\\\n\\[FFGKOP16\\] D.\
              \ Fiore, C. Fournet, E. Ghosh, M. Kohlweiss, O. Ohrimenko, and B. Parno.\
              \ “Hash first, argue later: Adaptive verifiable computations on outsourced\
              \ data”. In: CCS. 2016.\\\n\\\n\\[Fil\\] Filecoin: A Decentralized Storage\
              \ Network. 2014. URL: [https://filecoin.io/filec](https://filecoin.io/filec)\
              \ oin.pdf.\\\n\\\n\\[FN16\\] D. Fiore and A. Nitulescu. “On the (in)\
              \ security of SNARKs in the presence of oracles”. In: Theory of Cryptography\
              \ Conference. Springer. 2016, pp. 108–138.\\\n\\\n\\[FQZDC21\\] B. Feng,\
              \ L. Qin, Z. Zhang, Y. Ding, and S. Chu. ZEN: Efficient Zero-Knowledge\
              \ Proofs for Neural Networks. Cryptology ePrint Archive, Report 2021/087.\
              \ 2021.\\\n\\\n\\[FS86\\] A. Fiat and A. Shamir. “How to Prove Yourself:\
              \ Practical Solutions to Identification and Signature Problems”. In:\
              \ CRYPTO. 1986.\\\n\\\n\\[GAZBW22\\] P. Grubbs, A. Arun, Y. Zhang, J.\
              \ Bonneau, and M. Walfish. “Zero-Knowledge Middleboxes”. In: USENIX\
              \ Security. 2022.\\\n\\\n\\[GGPR13\\] R. Gennaro, C. Gentry, B. Parno,\
              \ and M. Raykova. “Quadratic Span Programs and Succinct NIZKs without\
              \ PCPs”. In: Annual International Conference on the Theory and Applications\
              \ of Cryptographic Techniques (Eurocrypt). 2013, pp. 626–645.\\\n\\\n\
              \\[GHMVZ17\\] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich.\
              \ “Algorand: Scaling byzantine agreements for cryptocurrencies”. In:\
              \ Proceedings of the 26th symposium on operating systems principles.\
              \ 2017, pp. 51–68.\\\n\\\n\\[Gil52\\] E. N. Gilbert. “A comparison of\
              \ signalling alphabets”. In: The Bell system technical journal 31.3\
              \ (1952), pp. 504–522.\\\n\\\n\\[GKMMM18\\] J. Groth, M. Kohlweiss,\
              \ M. Maller, S. Meiklejohn, and I. Miers. “Updatable and universal common\
              \ reference strings with applications to zk-SNARKS”. In: CRYPTO. Springer.\
              \ 2018, pp. 698–728.\\\n\\\n\\[GKR08\\] S. Goldwasser, Y. T. Kalai,\
              \ and G. Rothblum. “Delegating computation: interactive proofs for muggles”.\
              \ In: STOC. 2008, pp. 113–122.\\\n\\\n\\[GKR15\\] S. Goldwasser, Y.\
              \ T. Kalai, and G. N. Rothblum. “Delegating Computation: Interactive\
              \ Proofs for Muggles”. In: J. ACM 62.4 (Sept. 2015), 27:1–27:64. ISSN:\
              \ 0004-5411.\\\n\\\n\\[Ham22\\] J. Hamlin. Big investors are finally\
              \ serious about crypto. but experienced talent is still scarce. 2022.\
              \ URL: https : / / www . institutionalinvestor . com / article / b1x\
              \ 0gr2y3dzzp3 / Big - Investors - Are - Finally - Serious - About -\
              \ Crypto - But - Experienced-Talent-Is-Still-Scarce.\\\n\\\n\\[Her\\\
              ] Hermez. [https://polygon.technology/solutions/polygon-hermez/](https://polygon.technology/solutions/polygon-hermez/).\
              \ 2022.\\\n\\\n\\[Het\\] Hetzner. [https://www.hetzner.com/](https://www.hetzner.com/).\
              \ 2022.\\\n\\\n\\[HLW06\\] S. Hoory, N. Linial, and A. Wigderson. “Expander\
              \ graphs and their applications”. In: BULL. AMER. MATH. SOC. 43.4 (2006),\
              \ pp. 439–561.\\\n\\\n\\[HR22\\] J. Holmgren and R. Rothblum. “Faster\
              \ Sounder Succinct Arguments and IOPs”. In: 2022.\\\n\\\n\\[Hyr\\] Hyrax\
              \ reference implementation. [https://github.com/hyraxZK/hyraxZK](https://github.com/hyraxZK/hyraxZK).\\\
              \n\\\n\\[IKO\\] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. “Efficient\
              \ Arguments without Short PCPs”. In: 22nd Annual IEEE Conference on\
              \ Computational Complexity (CCC 2007).\\\n\\\n\\[IKOS07\\] Y. Ishai,\
              \ E. Kushilevitz, R. Ostrovsky, and A. Sahai. “Zero-knowledge from secure\
              \ multiparty computation”. In: Proceedings of the annual ACM symposium\
              \ on Theory of computing. ACM. 2007, pp. 21–30.\\\n\\\n\\[Int\\] Hyperledger\
              \ Sawtooth. 2017. URL: [https://sawtooth.hyperledger.org/](https://sawtooth.hyperledger.org/)\
              \ (visited on 2017).\\\n\\\n\\[ISW21\\] Y. Ishai, H. Su, and D. J. Wu.\
              \ “Shorter and faster post-quantum designated-verifier zksnarks from\
              \ lattices”. In: CCS. 2021.\\\n\\\n\\[Jsn\\] “jSNARK”. In: 2015.\\\n\
              \\\n\\[Kil92\\] J. Kilian. “A Note on Efficient Zero-Knowledge Proofs\
              \ and Arguments (Extended Abstract)”. In: STOC. 1992.\\\n\\\n\\[KKW18\\\
              ] J. Katz, V. Kolesnikov, and X. Wang. “Improved non-interactive zero\
              \ knowledge with applications to post-quantum signatures”. In: CCS.\
              \ 2018.\\\n\\\n\\[KMSWP\\] A. Kosba, A. Miller, E. Shi, Z. Wen, and\
              \ C. Papamanthou. “Hawk: The blockchain model of cryptography and privacy-preserving\
              \ smart contracts”. In: Proceedings of Symposium on security and privacy\
              \ (SP), 2016.\\\n\\\n\\[KPPS20\\] A. E. Kosba, D. Papadopoulos, C. Papamanthou,\
              \ and D. Song. “MIRAGE: Succinct Arguments for Randomized Algorithms\
              \ with Applications to Universal zk-SNARKs”. In: USENIX Security. 2020.\\\
              \n\\\n\\[KRDO17\\] A. Kiayias, A. Russell, B. David, and R. Oliynykov.\
              \ “Ouroboros: A provably secure proofof-stake blockchain protocol”.\
              \ In: Annual international cryptology conference. Springer. 2017, pp.\
              \ 357–388.\\\n\\\n\\[KS16\\] S. Khot and R. Saket. “Hardness of Bipartite\
              \ Expansion”. In: ESA. 2016.\\\n\\\n\\[KS22\\] A. Kothapalli and S.\
              \ Setty. SuperNova: Proving universal machine executions without universal\
              \ circuits. Cryptology ePrint Archive, Paper 2022/1758. https : / /\
              \ eprint . iacr.org/2022/1758. 2022. URL: [https://eprint.iacr.org/2022/1758](https://eprint.iacr.org/2022/1758).\\\
              \n\\\n|     |     |\\\n| --- | --- |\\\n|  |\\\n| \\[GLSTW\\] | A. Golovnev,\
              \ J. Lee, S. Setty, J. Thaler, and R. S. Wahby. Brakedown: Linear-time\
              \ and post-quantum SNARKs for R1CS. Cryptology ePrint Archive. https\
              \ : //ia. cr/2021/ 1043. |\\\n| \\[GMO16\\] | 1\\. Giacomelli, J. Madsen,\
              \ and C. Orlandi. \\*ZKBoo: Faster Zero-Knowledge for Boolean Circuits.\"\
              \ In: USENIX Security. 2016, pp. 1069-1083. S Goldwasser, S Micali,\
              \ and C Rackoff. The Knowledge Complexity of Interactive Proof- |\\\n\
              | \\[GMR\\] | systems\". In: ST0C 1985, pp. 291-304. S. Goldwasser,\
              \ S. Micali, and C. Rackoff. The knowledge complexity of interactive\
              \ proof |\\\n| \\[GMR89\\] | systems\". In: SIAM Journal on computing\
              \ 18.1 (1989), pp. 186-208. |\\\n| \\[Gna\\] | gnark. https://docs.gnark.\
              \ consensys.net/en/latest/. 2022. |\\\n| \\[Gnu\\] | The GNU multiple\
              \ precision arithmetic library. https : //gmp1ib. org/. A. V. Goldberg.\
              \ Finding a maximum density subgraph. University of California Berkeley,\
              \ |\\\n| \\[Gol84\\] \\[GR11\\] | 1984\\. O. Goldreich and D. Ron. \"\
              On Testing Expansion in Bounded-Degree Graphs\". In: Stud- |\\\n|  |\
              \ ies in Complexity and Cryptography. Miscellanea on the Interplay between\
              \ Randomness and Computation: In Collaboration with Lidor Avigad, Mihir\
              \ Bellare, Zvika Brakerski, Shafi Goldwasser, Shai Halevi, Tali Kaufman,\
              \ Leonid Levin, Noam Nisan, Dana Ron, Madhu Sudan, Luca Trevisan, Salil\
              \ Vadhan, Avi Wigderson, David Zuckerman. Ed. by O. Goldreich. Berlin,\
              \ Heidelberg: Springer Berlin Heidelberg, 2011, pp. 68-75. isbn: 978-3-\
              \ 642-22670-0. D0I: 10. 1007/978-3-642-22670-0\\_9. URL: https : //doi.\
              \ 0rg/10. 1007/978-3-642-22670-0\\_9. |\\\n| \\[Gro10\\] | national\
              \ Cryptology Conference (CRYPTO). Springer, 2009, pp. 192-208. J. Groth.\
              \ \"Short pairing-based non-interactive zero-knowledge arguments\".\
              \ In: Interna- |\\\n|  | tional Conference on the Theory and Application\
              \ of Cryptology and Information Security. Springer. 2010, pp. 321-340.\
              \ |\\\n| \\[Gro16\\] \\[GWC19a\\] | J. Groth. \"On the Size of Pairing-Based\
              \ Non-interactive Arguments\". In: EUROCRYPT 2016. 2016, pp. 305-326.\
              \ A. Gabizon, Z. J. Williamson, and O. Ciobotaru. PLONK: Permutations\
              \ over Lagrange- |\\\n|  | bases for Oecumenical Noninteractive arguments\
              \ of Knowledge. Cryptology ePrint Archive, Report 2019/953. 2019. |\\\
              \n| \\[GWC19b\\] | A. Gabizon, Z. J. Williamson, and O. Ciobotaru. \"\
              Plonk: Permutations over lagrange- bases for oecumenical noninteractive\
              \ arguments of knowledge\". In: Cryptology ePrint Archive (2019). |\\\
              \n| \\[Hab22\\] | U. Habock. Multivariate lookups based on logarithmic\
              \ derivatives. Cryptology ePrint Archive, Paper 2022/1530. https : /\
              \ / eprint . iacr . org / 2022 / 1530. 2022. URL: https://eprint.iacr.org/2022/1530.\
              \ |\\\n| \\[Hal\\] | The halo2 book. URl: https://zcash.github.io/halo2/.\
              \ |\\\n\\\n|     |     |\\\n| --- | --- |\\\n| \\[KST22\\] | A. Kothapalli,\
              \ S. Setty, and I. Tzialla. Nova: Recursive Zero-Knowledge Arguments\
              \ from |\\\n|  | Folding Schemes\". In: Advances in Cryptology - CRYPTO\
              \ 2022. Ed. by Y. Dodis and T. Shrimpton. Cham: Springer Nature Switzerland,\
              \ 2022, pp. 359-388. isBn: 978-3-031- 15985-5. |\\\n| \\[Kwo14\\] |\
              \ J. Kwon. \"Tendermint: Consensus without mining\". In: Draft v. 0.6,\
              \ fall 1.11 (2014). |\\\n| \\[KZG\\] | A. Kate, G. M. Zaverucha, and\
              \ I. Goldberg. \"Constant-Size Commitments to Polynomials and Their\
              \ Applications\". In: ASIACRYPT 2010, pp. 177-194. |\\\n| \\[Lay\\]\
              \ | LayerZero. https://layerzero.network/. 2022. |\\\n| \\[LFKN92\\\
              ] | C. Lund, L. Fortnow, H. Karloff, and N. Nisan. \"Algebraic Methods\
              \ for Interactive Proof Systems\". In: J. ACM 39.4 (Oct. 1992), pp.\
              \ 859-868. 1ssn: 0004-5411. |\\\n| \\[Liba\\] | \"libsnark\". In: 2014.\
              \ |\\\n| \\[Libb\\] | Reference implementation of Libra. https: //github.\
              \ com/sunblaze-ucb/Libra. |\\\n| \\[Lin01\\] | Y. Lindell. Parallel\
              \ Coin-Tossing and Constant-Round Secure Two-Party Computation. Cryptology\
              \ ePrint Archive, Paper 2001/107. https : //eprint . 1acr . org/2001/107\
              \ 2001. URL: https://eprint.iacr.org/2001/107. |\\\n| \\[Lip12\\] |\
              \ H. Lipmaa. \"Progression-free sets and sublinear pairing-based non-interactive\
              \ zero-knowledge arguments\". In: Theory of Cryptography Conference.\
              \ 2012. |\\\n| \\[LKKO20\\] | S. Lee, H. Ko, J. Kim, and H. Oh. vCNN:\
              \ Verifiable Convolutional Neural Network based on zk-SNARKs. Cryptology\
              \ ePrint Archive, Report 2020/584. 2020. |\\\n| \\[LXZ21\\] | T. Liu,\
              \ X. Xie, and Y. Zhang. \"zkCNN: Zero Knowledge Proofs for Convolutional\
              \ Neural Network Predictions and Accuracy\". In: CCS. 2021. |\\\n| \\\
              [MBKM19\\] | M. Maller, S. Bowe, M. Kohlweiss, and S. Meiklejohn. \"\
              Sonic: Zero-knowledge SNARKs from linear-size universal and updatable\
              \ structured reference strings'. In: CCS. https : //eprint.iacr.org/2019/099.\
              \ 2019. |\\\n| \\[Mer87\\] | R. C. Merkle. \"A digital signature based\
              \ on a conventional encryption function\". In: Con- ference on the theory\
              \ and application of cryptographic techniques. 1987. |\\\n| \\[Mic00\\\
              ] | S. Micali. \"Computationally Sound Proofs\". In: SIAM J. Comput.\
              \ (2000). |\\\n| \\[Mie09\\] | T. Mie. \"Short PCPPs verifiable in polylogarithmic\
              \ time with O (1) queries\". In: Annals of Mathematics and Artificial\
              \ Intelligence (2009). |\\\n| \\[Mul\\] | Multi-chain future likely\
              \ as Ethereum's DeFi dominance declines \\| Bloomberg Profes. sional\
              \ Services. 2022. uRL: https : //www . bloomberg. com/professional/blog/\
              \ multi- chain-future-likely-as-ethereums-defi-dominance-declines/ |\\\
              \n| \\[Nak08\\] | (visited on 04/24/2022). S. Nakamoto. \"Bitcoin: A\
              \ peer-to-peer electronic cash system'. In: Decentralized Busi- |\\\n\
              | \\[Nea\\] | ness Review (2008), p. 21260. ETH-NEAR Rainbow Bridge\
              \ - NEAR Protocol. 2022. URL: https: //near . org/b1og/ eth-near-rainbow-bridge/\
              \ (visited on 05/02/2022). |\\\n\\\n\\[NS07\\] \\[PHGR13\\] \\[Pip76\\\
              ] \\[Pold\\]\\\n\\\nNomad crypto bridge loses $$ 200$ million in “chaotic”\
              \ hack. [https://www.theverge](https://www.theverge/). com/2022/8/2/23288785/nomad-bridge-200-million-chaotic-hack-smartcontract-cryptocurrency.\
              \ 2022.\\\n\\\nNomad Protocol. https:// docs.nomad. xyz/the- nomad -\
              \ protocol/overview. 2021.\\\n\\\nA. Nachmias and A. Shapira. “Testing\
              \ the Expansion of a Graph.” In: Electronic Colloquium on Computational\
              \ Complexity (ECCC) 14 (Jan. 2007). DOI: 10 . 1016 / j . ic . 2009.09.002.\\\
              \n\\\nB. Parno, J. Howell, C. Gentry, and M. Raykova. “Pinocchio: Nearly\
              \ practical verifiable computation”. In: IEEE S&P. 2013, pp. 238–252.\\\
              \n\\\nN. Pippenger. “On the evaluation of powers and related problems”.\
              \ In: SFCS 1976. IEEE Computer Society. 1976.\\\n\\\nAt least $611 million\
              \ stolen in massive cross-chain hack. 2021. URL: https : / / www . theblockcrypto\
              \ . com / post / 114045 / at - least - 611 - million - stolen - in -\
              \ massive-cross-chain-hack.\\\n\\\nPoly Network. [https://poly.network/](https://poly.network/).\
              \ 2020.\\\n\\\nPolygon Hermez. [https://polygon.technology/solutions/polygon-hermez/](https://polygon.technology/solutions/polygon-hermez/).\
              \ 2022.\\\n\\\nPolygon Miden. https : / / polygon . technology / solutions\
              \ / polygon - miden/. 2022.\\\n\\\nPolygon Zero. [https://polygon.technology/solutions/polygon-zero/](https://polygon.technology/solutions/polygon-zero/).\
              \ 2022\\. C. Papamanthou, E. Shi, and R. Tamassia. “Signatures of Correct\
              \ Computation”. In: TCC 2013. 2013, pp. 222–242.\\\n\\\nK. Qin, L. Zhou,\
              \ B. Livshits, and A. Gervais. “Attacking the defi ecosystem with flash\
              \ loans for fun and profit”. In: International Conference on Financial\
              \ Cryptography and Data Security. Springer. 2021, pp. 3–32.\\\n\\\n\
              Rainbow Bridge. [https://near.org/bridge/](https://near.org/bridge/).\
              \ 2020.\\\n\\\nL. Ren and S. Devadas. “Proof of space from stacked expanders”.\
              \ In: Theory of Cryptography Conference. Springer. 2016, pp. 262–285.\\\
              \n\\\nRisc Zero. [https://www.risczero.com/](https://www.risczero.com/).\
              \ 2022.\\\n\\\nRonin Attack Shows Cross-Chain Crypto Is a ‘Bridge’ Too\
              \ Far. 2022. URL: https:// [www.coindesk.com/layer2/2022/04/05/ronin-attack-shows-cross-chaincrypto-is-a-bridge-too-far/](http://www.coindesk.com/layer2/2022/04/05/ronin-attack-shows-cross-chaincrypto-is-a-bridge-too-far/)\
              \ (visited on 04/24/2022).\\\n\\\nN. Ron-Zewi and R. D. Rothblum. “Local\
              \ proofs approaching the witness length”. In: FOCS. 2020.\\\n\\\nN.\
              \ Ron-Zewi and R. D. Rothblum. “Proving as fast as computing: Succinct\
              \ arguments with constant prover overhead”. In: STOC. 2022.\\\n\\\n\
              J. T. Schwartz. “Fast probabilistic algorithms for verification of polynomial\
              \ identities”. In: Journal of the ACM (JACM) 27.4 (1980), pp. 701–717.\\\
              \n\\\n\\[Pole\\] \\[PST13\\] \\[QZLG21\\] \\[Ris\\] \\[Ron\\] \\[RR20\\\
              ] \\[RR22\\] \\[Sch80\\]\\\n\\\n\\[SCPTZ21\\] S. Srinivasan, A. Chepurnoy,\
              \ C. Papamanthou, A. Tomescu, and Y. Zhang. “Hyperproofs: Aggregating\
              \ and Maintaining Proofs in Vector Commitments”. In: IACR Cryptol. ePrint\
              \ Arch. (2021), p. 599.\\\n\\\n\\[Scr\\] Scroll. [https://scroll.io/](https://scroll.io/).\
              \ 2022.\\\n\\\n\\[Set20\\] S. Setty. “Spartan: Efficient and general-purpose\
              \ zkSNARKs without trusted setup”. In: CRYPTO. Springer International\
              \ Publishing, 2020, pp. 704–737.\\\n\\\n\\[SL20\\] S. Setty and J. Lee.\
              \ Quarks: Quadruple-efficient transparent zkSNARKs. Cryptology ePrint\
              \ Archive, Report 2020/1275. 2020.\\\n\\\n\\[Spi96\\] D. A. Spielman.\
              \ “Linear-time encodable and decodable error-correcting codes”. In:\
              \ IEEE Transactions on Information Theory 42.6 (1996), pp. 1723–1731.\\\
              \n\\\n\\[Sta\\] Starkware. [https://starkware.co/](https://starkware.co/).\
              \ 2022.\\\n\\\n\\[SZT02\\] D. Song, D. Zuckerman, and J. Tygar. “Expander\
              \ graphs for digital stream authentication and robust overlay networks”.\
              \ In: S&P. IEEE. 2002.\\\n\\\n\\[Tha13a\\] J. Thaler. “Time-Optimal\
              \ Interactive Proofs for Circuit Evaluation”. In: Advances in Cryptology\
              \ – CRYPTO 2013. Ed. by R. Canetti and J. A. Garay. 2013. ISBN: 978-3-642-40084-\
              \ 1.\\\n\\\n\\[Tha13b\\] J. Thaler. “Time-Optimal Interactive Proofs\
              \ for Circuit Evaluation”. In: Annual International Cryptology Conference\
              \ (CRYPTO). Ed. by R. Canetti and J. A. Garay. 2013. ISBN: 978-3-642-40084-1.\\\
              \n\\\n\\[Tha15\\] J. Thaler. A Note on the GKR Protocol. Available at\
              \ [http://people.cs.georgetown](http://people.cs.georgetown/). edu/jthaler/GKRNote.pdf.\
              \ 2015.\\\n\\\n\\[Tur90\\] K. Turkowski. “Filters for common resampling\
              \ tasks”. In: Graphics gems. Academic Press Professional, Inc. 1990,\
              \ pp. 147–165.\\\n\\\n\\[Use\\] Average Price of Electricity. [https://www.eia.gov/electricity/monthly/epm](https://www.eia.gov/electricity/monthly/epm)\\\
              _ table\\_grapher.php?t $=$ epmt\\_5\\_6\\_a. 2022.\\\n\\\n\\[Var57\\\
              ] R. R. Varshamov. “Estimate of the number of signals in error correcting\
              \ codes”. In: Docklady Akad. Nauk, SSSR 117 (1957), pp. 739–741.\\\n\
              \\\n\\[Vira\\] Reference implementation of Virgo. [https://github.com/sunblaze-](https://github.com/sunblaze-)\
              \ ucb/Virgo. 2020.\\\n\\\n\\[Virb\\] Virgo implementation. [https://github.com/TAMUCrypto/virgo-plus](https://github.com/TAMUCrypto/virgo-plus).\
              \ 2021.\\\n\\\n\\[Vit\\] An Incomplete Guide to Rollups. https : / /\
              \ vitalik . ca / general / 2021 / 01 / 05 / rollup.html. 2022.\\\n\\\
              \n\\[VSBW13\\] V. Vu, S. Setty, A. J. Blumberg, and M. Walfish. “A Hybrid\
              \ Architecture for Interactive Verifiable Computation”. In: Proceedings\
              \ of the 2013 IEEE Symposium on Security and Privacy. SP ’13. 2013.\\\
              \n\\\n\\[Wa\\] R. S. Wahby and lcpc authors. lcpc. [https://github.com/conroi/lcpc](https://github.com/conroi/lcpc).\\\
              \n\\\n\\[Wah+17\\] R. S. Wahby et al. “Full accounting for verifiable\
              \ outsourcing”. In: Proceedings of the 2017 ACM SIGSAC Conference on\
              \ Computer and Communications Security. ACM. 2017.\\\n\\\n# \\[WHGSW16\\\
              ]\\\n\\\n\\[Win21\\]\\\n\\\n# \\[Woo+14\\]\\\n\\\n\\[Wora\\] \\[Worb\\\
              ] \\[WSRBW15\\] \\[WTSTW18\\] \\[WYKW20\\] \\[WYXKW21\\]\\\n\\\nR. S.\
              \ Wahby, M. Howald, S. Garg, A. Shelat, and M. Walfish. “Verifiable\
              \ asics”. In: IEEE Symposium on Security and Privacy (SP). IEEE. 2016,\
              \ pp. 759–778.\\\n\\\nL. Wintermeyer. Institutional money is pouring\
              \ into the crypto market and its only going to grow. 2021. URL: [https://www.forbes.com/sites/lawrencewintermeyer/](https://www.forbes.com/sites/lawrencewintermeyer/)\
              \ 2021/08/12/institutional-money-is-pouring-into-the-crypto-marketand-its-only-going-to-grow/?sh\
              \ $\\\\underset { . } { = }$ 2660a69d1459.\\\n\\\nG. Wood et al. “Ethereum:\
              \ A secure decentralised generalised transaction ledger”. In: Ethereum\
              \ project yellow paper 151.2014 (2014), pp. 1–32.\\\n\\\nBlockchain\
              \ Bridge Wormhole Suffers Possible Exploit Worth Over $326M. 2022. URL:\
              \ [https://www.coindesk.com/tech/2022/02/02/blockchain-bridge-wormhole](https://www.coindesk.com/tech/2022/02/02/blockchain-bridge-wormhole)\
              \ -suffers-possible-exploit-worth-over-250m/ (visited on 2022).\\\n\\\
              \nWormhole Solana. [https://solana.com/wormhole](https://solana.com/wormhole).\
              \ 2020.\\\n\\\nR. S. Wahby, S. T. Setty, Z. Ren, A. J. Blumberg, and\
              \ M. Walfish. “Efficient RAM and control flow in verifiable outsourced\
              \ computation”. In: NDSS. 2015.\\\n\\\nR. S. Wahby, I. Tzialla, A. Shelat,\
              \ J. Thaler, and M. Walfish. “Doubly-efficient zkSNARKs without trusted\
              \ setup”. In: S&P. IEEE. 2018, pp. 926–943.\\\n\\\nC. Weng, K. Yang,\
              \ J. Katz, and X. Wang. “Wolverine: Fast, Scalable, and CommunicationEfficient\
              \ Zero-Knowledge Proofs for Boolean and Arithmetic Circuits”. In: S&P.\
              \ 2020. C. Weng, K. Yang, X. Xie, J. Katz, and X. Wang. Mystique: Efficient\
              \ Conversions for ZeroKnowledge Proofs with Applications to Machine\
              \ Learning. USENIX Security. 2021. H. Wu, W. Zheng, A. Chiesa, R. A.\
              \ Popa, and I. Stoica. “DIZK: A Distributed ZeroKnowledge Proof System”.\
              \ In: (2018).\\\n\\\nT. Xie et al. “zkBridge: Trustless Cross-chain\
              \ Bridges Made Practical”. In: arXiv preprint arXiv:2210.00264 (2022).\\\
              \n\\\nT. Xie, Y. Zhang, and D. Song. “Orion: Zero Knowledge Proof with\
              \ Linear Prover Time”. In: Springer-Verlag, 2022.\\\n\\\nT. Xie, J.\
              \ Zhang, Y. Zhang, C. Papamanthou, and D. Song. “Libra: Succinct zero-knowledge\
              \ proofs with optimal prover computation”. In: CRYPTO. 2019.\\\n\\\n\
              T. Xie, J. Zhang, Y. Zhang, C. Papamanthou, and D. Song. “Libra: Succinct\
              \ zero-knowledge proofs with optimal prover computation”. In: CRYPTO.\
              \ 2019.\\\n\\\nT. Xie, J. Zhang, Y. Zhang, C. Papamanthou, and D. Song.\
              \ “Libra: Succinct zero-knowledge proofs with optimal prover computation”.\
              \ In: CRYPTO. 2019.\\\n\\\nYouTube includes NFTs in new creator tools.\
              \ 2022. URL: https : / / www . nbcnews . com / pop - culture / viral\
              \ / youtube - includes - nfts - new - creator - tools - rcna15813.\\\
              \n\\\nK. Yang, P. Sarkar, C. Weng, and X. Wang. “QuickSilver: Efficient\
              \ and Affordable ZeroKnowledge Proofs for Circuits and Polynomials over\
              \ Any Field”. In: CCS. 2021.\\\n\\\nA. Zapico, V. Buterin, D. Khovratovich,\
              \ M. Maller, A. Nitulescu, and M. Simkin. “Caulk: Lookup Arguments in\
              \ Sublinear Time”. In: Cryptology ePrint Archive (2022).\\\n\\\n\\[WZCPS18\\\
              ] \\[Xie+22\\] \\[XZS22\\] \\[XZZPS19a\\] \\[XZZPS19b\\] \\[XZZPS19c\\\
              ]\\\n\\\n\\[You\\]\\\n\\\n\\[YSWW21\\] \\[ZBKMNS22\\]\\\n\\\n\\[Zca\\\
              ] Zcash. [https://z.cash/](https://z.cash/).\\\n\\\n\\[ZFZS20\\] J.\
              \ Zhang, Z. Fang, Y. Zhang, and D. Song. “Zero Knowledge Proofs for\
              \ Decision Tree Predictions and Accuracy”. In: CCS. 2020.\\\n\\\n\\\
              [ZGKPP17a\\] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou.\
              \ A Zero-Knowledge Version of vSQL. Cryptology ePrint. 2017.\\\n\\\n\
              \\[ZGKPP17b\\] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C.\
              \ Papamanthou. A Zero-Knowledge Version of vSQL. Cryptology ePrint Archive:\
              \ Report 2017/1146. 2017.\\\n\\\n\\[ZGKPP17c\\] Y. Zhang, D. Genkin,\
              \ J. Katz, D. Papadopoulos, and C. Papamanthou. “vSQL: Verifying arbitrary\
              \ SQL queries over dynamic outsourced databases”. In: Security and Privacy\
              \ (SP), 2017 IEEE Symposium on. IEEE. 2017, pp. 863–880.\\\n\\\n\\[ZGKPP17d\\\
              ] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou.\
              \ “vSQL: Verifying arbitrary SQL queries over dynamic outsourced databases”.\
              \ In: S&P. 2017.\\\n\\\n\\[ZGKPP18\\] Y. Zhang, D. Genkin, J. Katz,\
              \ D. Papadopoulos, and C. Papamanthou. “vRAM: Faster verifiable RAM\
              \ with program-independent preprocessing”. In: S&P. 2018.\\\n\\\n\\\
              [Zha+21a\\] J. Zhang et al. “Doubly Efficient Interactive Proofs for\
              \ General Arithmetic Circuits with Linear Prover Time”. In: CCS. 2021.\\\
              \n\\\n\\[Zha+21b\\] J. Zhang et al. “Doubly efficient interactive proofs\
              \ for general arithmetic circuits with linear prover time”. In: Proceedings\
              \ of the 2021 ACM SIGSAC Conference on Computer and Communications Security.\
              \ 2021, pp. 159–177.\\\n\\\n\\[Zip79\\] R. Zippel. “Probabilistic algorithms\
              \ for sparse polynomials”. In: International Symposium on Symbolic and\
              \ Algebraic Manipulation. Springer. 1979, pp. 216–226.\\\n\\\n\\[Zkr\\\
              ] An Incomplete Guide to Rollups. https : / / vitalik . ca / general\
              \ / 2021 / 01 / 05 / rollup.html.\\\n\\\n\\[Zks\\] zkSync. [https://zksync.io/](https://zksync.io/).\
              \ 2022.\\\n\\\n\\[ZXHSZ22\\] J. Zhang, T. Xie, T. Hoang, E. Shi, and\
              \ Y. Zhang. “Polynomial Commitment with a {Oneto-Many} Prover and Applications”.\
              \ In: 31st USENIX Security Symposium (USENIX Security 22). 2022, pp.\
              \ 2965–2982.\\\n\\\n\\[ZXZS20\\] J. Zhang, T. Xie, Y. Zhang, and D.\
              \ Song. “Transparent polynomial delegation and its applications to zero\
              \ knowledge proof”. In: S&P. IEEE. 2020, pp. 859–876."
            metadata:
              scrapeId: fd1d01bd-b042-4856-af09-2878a1d47666
              sourceURL: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-35.pdf
              url: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-35.pdf
              statusCode: 200
              numPages: 158
              proxyUsed: basic
              cacheState: miss
          - title: 'Zero-Knowledge Proof Frameworks: A Survey - arXiv'
            description: In this work, we survey and evaluate 25 general-purpose,
              prominent ZKP frameworks. Recognizing that ZKPs have various constructions
              and underlying arithmetic ...
            url: https://arxiv.org/html/2502.07063v1
            markdown: 'HTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html)
              due to content that did not convert correctly from the source. This
              paper uses the following packages that are not yet supported by the
              HTML conversion tool. Feedback on these issues are not necessary; they
              are known and are being worked on.


              - failed: environ


              Authors: achieve the best HTML results from your LaTeX submissions by
              following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).


              [License: CC BY 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)


              arXiv:2502.07063v1 \[cs.CR\] 10 Feb 2025


              # Zero-Knowledge Proof Frameworks: A Survey


              Report issue for preceding element


              Nojan Sheybani1, Anees Ahmed2, Michel Kinsy2, Farinaz Koushanfar1


              1UC San Diego, 2Arizona State University


              1{nsheyban, farinaz}@ucsd.edu, 2{aahmed90, mkinsy}@asu.edu


              Report issue for preceding element


              ###### Abstract


              Report issue for preceding element


              Zero-Knowledge Proofs (ZKPs) are a cryptographic primitive that allows
              a prover to demonstrate knowledge of a secret value to a verifier without
              revealing anything about the secret itself. ZKPs have shown to be an
              extremely powerful tool, as evidenced in both industry and academic
              settings. In recent years, the utilization of user data in practical
              applications has necessitated the rapid development of privacy-preserving
              techniques, including ZKPs. This has led to the creation of several
              robust open-source ZKP frameworks. However, there remains a significant
              gap in understanding the capabilities and real-world applications of
              these frameworks. Furthermore, identifying the most suitable frameworks
              for the developers’ specific applications and settings is a challenge,
              given the variety of options available. The primary goal of our work
              is to lower the barrier to entry for understanding and building applications
              with open-source ZKP frameworks.


              Report issue for preceding element


              In this work, we survey and evaluate 25 general-purpose, prominent ZKP
              frameworks. Recognizing that ZKPs have various constructions and underlying
              arithmetic schemes, our survey aims to provide a comprehensive overview
              of the ZKP landscape. These systems are assessed based on their usability
              and performance in SHA-256 and matrix multiplication experiments. Acknowledging
              that setting up a functional development environment can be challenging
              for these frameworks, we offer a fully open-source collection of Docker
              containers. These containers include a working development environment
              and are accompanied by documented code from our experiments. We conclude
              our work with a thorough analysis of the practical applications of ZKPs,
              recommendations for ZKP settings in different application scenarios,
              and a discussion on the future development of ZKP frameworks.


              Report issue for preceding element


              ## I Introduction


              Report issue for preceding element


              Privacy-preserving cryptographic methods have become increasingly vital
              as privacy and data security evolve into a higher priority in new applications.
              Zero-Knowledge Proofs (ZKPs) enable a prover 𝒫𝒫\\mathcal{P}caligraphic\_P
              to prove to a verifier 𝒱𝒱\\mathcal{V}caligraphic\_V that a statement
              is true, without revealing any information beyond the validity of the
              statement itself. While ZKPs are most prominently known to the general
              public in blockchain applications \[ [48](https://arxiv.org/html/2502.07063v1#bib.bib48
              ""), [57](https://arxiv.org/html/2502.07063v1#bib.bib57 ""), [45](https://arxiv.org/html/2502.07063v1#bib.bib45
              ""), [55](https://arxiv.org/html/2502.07063v1#bib.bib55 "")\], they
              have also been effectively applied in many other real-world domains,
              such as healthcare \[ [129](https://arxiv.org/html/2502.07063v1#bib.bib129
              ""), [118](https://arxiv.org/html/2502.07063v1#bib.bib118 ""), [67](https://arxiv.org/html/2502.07063v1#bib.bib67
              "")\], traditional finance \[ [111](https://arxiv.org/html/2502.07063v1#bib.bib111
              ""), [126](https://arxiv.org/html/2502.07063v1#bib.bib126 ""), [95](https://arxiv.org/html/2502.07063v1#bib.bib95
              "")\], and government \[ [30](https://arxiv.org/html/2502.07063v1#bib.bib30
              ""), [93](https://arxiv.org/html/2502.07063v1#bib.bib93 "")\]. ZKPs
              are an excellent solution for verifying data and computation in a secure
              fashion, however there are still many challenges before they can become
              a practical privacy-preserving solution.


              Report issue for preceding element


              Although introduced in the 1980s \[ [75](https://arxiv.org/html/2502.07063v1#bib.bib75
              "")\], recent algorithmic and computing advances have garnered the evolution
              of ZKPs from a theoretical construct to a relatively practical cryptographic
              primitive. ZKPs have garnered the interest of researchers and developers
              as concerns over data privacy grow, which has caused significant improvements
              in both theory and implementation. The first significant milestone in
              the practical application of ZKPs was the development of zero-knowledge
              succinct non-interactive arguments of knowledge (zk-SNARKs) introduced
              by Ben-Sasson et. al \[ [40](https://arxiv.org/html/2502.07063v1#bib.bib40
              "")\] in 2013.


              Report issue for preceding element


              In the decade since the introduction of zk-SNARKs, the zero-knowledge
              landscape has evolved to include a diverse set of ZKP constructions,
              such as zk-STARKs \[ [38](https://arxiv.org/html/2502.07063v1#bib.bib38
              "")\], which build off of zk-SNARKs and are discussed at length in this
              work. For many of the ZKP constructions that are available, there are
              several prominent frameworks, stemming from industry and academia, that
              allow developers to create their own ZKP applications. Despite the availability
              of these open-source frameworks and the demand of privacy-preservation
              in real-world systems, the implementation of ZKPs in practical applications
              has been limited. This can be attributed to three ongoing challenges:
              1) performance; 2) usability; 3) accessibility. These are the attributes
              that we evaluate the chosen open-source frameworks on in this work.

              The journey towards making ZKPs a de facto solution for privacy-preserving
              applications is hamstrung by the performance, due to the complexity
              of current accessible ZKP protocols.

              In this work, we hope to find the schemes with the best performance
              for each type of ZKP construction, evaluated over several metrics on
              CPU and we will discuss the next steps that can be taken towards practical
              ZKP adoption.


              Report issue for preceding element


              Usability and accessibility are common problems that face privacy-preserving
              technologies, especially those stemming from academia, and the ZK landscape
              is no different. Due to the surge of research that has been done in
              the ZK space, there has been a sudden increase in the number of available
              frameworks for developers. For a nascent developer of ZKP applications,
              especially one with little exposure to cryptography and ZK concepts,
              this can seem like a near-impossible field to navigate. Even for experienced
              developers, these frameworks are often hard to use, due to their (mostly)
              poor documentation or reproducible examples. While this is understandable
              in academic settings, due to time and resource constraints, a significant
              step towards enabling practical ZKP usage is demystifying the currently
              existing frameworks and lowering the barrier of entry for experienced
              and unexperienced developers. Alongside this, it is also currently difficult
              for developers to decipher whether a framework is usable for their custom
              application, due to the different ZKP constructions available, each
              with different underlying arithmetic, security guarantees, and interaction/communication
              requirements.


              Report issue for preceding element


              While there is no arguing that the development of the open-source ZKP
              frameworks has significantly reduced the amount of necessary effort
              for building new applications, the field is still difficult to navigate.
              The available open source frameworks have been used to enable secure
              verification of computation, data, and identity in the domains of machine
              learning \[ [143](https://arxiv.org/html/2502.07063v1#bib.bib143 "")\],
              networking \[ [80](https://arxiv.org/html/2502.07063v1#bib.bib80 "")\],
              IP protection \[ [119](https://arxiv.org/html/2502.07063v1#bib.bib119
              "")\], and many more. Although there has been this evident uptick in
              ZKP frameworks and applications, there is no overview of the ZK landscape
              that is both cryptographer and non-cryptographer friendly. Alongside
              this, it is hard to find a clear path for where ZKPs can be improved
              so they can be more broadly integrated into practical real-world applications.


              Report issue for preceding element


              This paper aims to provide users with a guide to ZKPs and the available
              ZKP frameworks, allowing readers to gain a high-level overview of the
              ZK landscape, while also providing new quantitative benchmarks and details
              for developers to choose the best ZKP framework for their application.
              To achieve this goal, we conduct an extensive survey of the ZK landscape,
              gathering several state-of-the-art frameworks representing the seminal
              ZKP constructions. We first evaluate these existing tools based on the
              usability and accessibility of their repositories for a non-experienced
              cryptographic application developer, highlighting their features and
              shortcomings from a design standpoint.

              We then evaluate a subset of the most accessible and usable frameworks,
              primarily those that expose a high-level API, based on their performance
              through an in-depth analysis of their runtime and communication complexity.
              Performance is measured over two custom benchmarks that represent commonly
              used functions in privacy-preserving computation: matrix multiplication
              and SHA-256 compression.


              Report issue for preceding element


              We provide a discussion of the different constructions at a high-level
              to guide developers in their choice of framework. Our experimental evaluation,
              insights, and recommendations should provide a general guide to developers
              on how to whittle down the available frameworks to ones that fit their
              application setting, bandwidth, and computational requirements.

              We conclude our work with a discussion on some of the cutting-edge applications
              that ZKPs have been utilized in, the challenges that ZKP applications
              currently face, and the future of ZKPs.


              Report issue for preceding element


              Unfortunately, many of the prominent works that provide open-source
              frameworks do not include a proper documentation or reproducible examples,
              thus hindering developers in integrating these frameworks into their
              applications. Alongside this, many of the frameworks require complex
              local environment build dependencies. To combat this hurdle, we provide
              a new open-source Github repository111https://github.com/ACESLabUCSD/ZeroKnowledgeFrameworksSurvey
              containing all the tools necessary to build a custom ZKP application
              with any framework discussed in this survey. Not only do we provide
              open-source Docker environments for each frameworks with reproducible
              documented examples, but we also include Docker containers for other
              helpful tools, such as circuit building and inspection tools. This repository
              is also well-documented and actively maintained to encourage users to
              immediately start building custom applications, rather than focusing
              on setup troubles.


              Report issue for preceding element


              The goal of this survey is to lower the barrier of entry to building
              ZKP applications by providing an in-depth overview of ZKPs, the existing
              constructions, the available open-source frameworks and their capabilities,
              and the usability, accessibility, and performance of each available
              framework. This paper is written so that a reader with no prior knowledge
              of ZKPs can garner a high-level understanding of the landscape, while
              experienced readers can sharpen their knowledge of the details of ZKPs
              and gain insights on the available tools for ZK-based application development.
              In short, our scientific contributions are:


              Report issue for preceding element


              - •



              We present the first survey of open-source ZKP frameworks, spanning
              all ZKP constructions, with accompanying open-source environments for
              each framework, including benchmarks and documentation.


              Report issue for preceding element


              - •



              We perform extensive analysis of select open-source ZKP frameworks on
              scalability, runtime, and proof size on two benchmarks representing
              prominent domains of ZKPs in current practice.


              Report issue for preceding element


              - •



              We provide a thorough analysis of the capabilities, usability, and accessibility
              of each open-source ZKP framework. Based on the insights of our work,
              we customize suggestions of frameworks for different use cases based
              on available compute power, developer experience, and application type.
              Finally, we provide novel insights on the current state of ZKP and the
              necessary path to further boost practicality.


              Report issue for preceding element



              ### I-ARelated Work


              Report issue for preceding element


              To the best of our knowledge, this work is the first to systematically
              survey and benchmark open-source ZKP frameworks spanning all constructions
              for practical settings and realization. \[ [56](https://arxiv.org/html/2502.07063v1#bib.bib56
              ""), [127](https://arxiv.org/html/2502.07063v1#bib.bib127 "")\] have
              considered a very limited amount of frameworks, but their industry-led
              work is largely comparing different constructions to each other (zk-SNARK
              vs. zk-STARK), rather than comparing frameworks of the same construction
              to each other (zk-SNARK vs. zk-SNARK). While there are very interesting
              insights made, we believe that our work is much more objective, systematic
              and extensive, while also adding the element of usability and accessibility
              analysis.

              Another survey on ZKP frameworks has been conducted \[ [124](https://arxiv.org/html/2502.07063v1#bib.bib124
              "")\], however this work only focuses on zk-SNARKs and does not look
              into the usability, accessibility, or performance of the chosen frameworks.
              Also, the work is largely focused on the application of zk-SNARKs in
              the blockchain. While we believe that surveying zk-SNARKs is very important,
              we note that many zk-SNARK schemes are not post-quantum secure. As post-quantum
              security becomes a rapidly growing concern, our work purposefully inspects
              every available ZKP construction to provide insights into post-quantum
              secure frameworks, alongside more established zk-SNARK frameworks. We
              believe that limiting our work to zk-SNARKs would not be fully representative
              of the ZK landscape.


              Report issue for preceding element


              We model our paper after the seminal surveys in privacy-preserving technology
              centered around MPC \[ [82](https://arxiv.org/html/2502.07063v1#bib.bib82
              "")\] and FHE \[ [131](https://arxiv.org/html/2502.07063v1#bib.bib131
              "")\].

              Like these works, we aim to provide as detailed of a description as
              we can surrounding the usability, accessibility, and performance of
              our chosen frameworks, while providing a digestible guide for developers
              choosing a tool for their ZK-based applications.


              Report issue for preceding element


              ## II Zero-Knowledge Proofs


              Report issue for preceding element


              Zero-Knowledge Proofs (ZKPs) are a cryptographic primitive that allow
              a prover 𝒫𝒫\\mathcal{P}caligraphic\_P to prove to a verifier 𝒱𝒱\\mathcal{V}caligraphic\_V
              that they know a secret value w𝑤witalic\_w, called the witness, without
              revealing anything about w𝑤witalic\_w. 𝒫𝒫\\mathcal{P}caligraphic\_P
              does this by showing that they know a secret value w𝑤witalic\_w such
              that ℱℱ\\mathcal{F}caligraphic\_F evaluated at w𝑤witalic\_w equals some
              public output y𝑦yitalic\_y. Formally, 𝒫𝒫\\mathcal{P}caligraphic\_P sends
              a proof attesting that ℱ⁢(x;w)=yℱ𝑥𝑤𝑦\\mathcal{F}(x;w)=ycaligraphic\_F
              ( italic\_x ; italic\_w ) = italic\_y, where x𝑥xitalic\_x and y𝑦yitalic\_y
              are public inputs and outputs, respectively. ZKPs have three core attributes
              \[ [73](https://arxiv.org/html/2502.07063v1#bib.bib73 "")\]:


              Report issue for preceding element


              1. 1.



              Soundness: 𝒱𝒱\\mathcal{V}caligraphic\_V will find out, with a very high
              probability, if a 𝒫𝒫\\mathcal{P}caligraphic\_P is dishonest if the statement
              is false.


              Report issue for preceding element


              2. 2.



              Completeness: An honest 𝒫𝒫\\mathcal{P}caligraphic\_P can convince 𝒱𝒱\\mathcal{V}caligraphic\_V
              if the statement is true.


              Report issue for preceding element


              3. 3.



              Zero-Knowledge: If the statement is true, 𝒱𝒱\\mathcal{V}caligraphic\_V
              will learn nothing about the 𝒫𝒫\\mathcal{P}caligraphic\_P’s private
              inputs - only that the statement is true.


              Report issue for preceding element



              In the following sections, we discuss the evolution of ZKPs, the nuances
              of specific classes and schemes, and provide a detailed overview of
              the current ZK landscape.


              Report issue for preceding element


              ### II-ATaxonomy of ZKPs


              Report issue for preceding element


              In this work, we analyze 25 ZK protocols. Amongst these protocols are
              a mix of interactive and non-interactive schemes. An in-depth explanation
              of the difference between interactive and non-interactive schemes can
              be found in Appendix [A](https://arxiv.org/html/2502.07063v1#A1 "Appendix
              A Interactive vs. Non-Interactive ‣ Zero-Knowledge Proof Frameworks:
              A Survey"). From now on, we describe computation as circuits 𝒞𝒞\\mathcal{C}caligraphic\_C,
              as that is what they are referred to as in ZK literature. This is due
              to the process of arithmetization, which represents functions, such
              as Python/C++ code, as arithmetic circuits, then converts these circuits
              into a mathematical representation (e.g. polynomials) that can be used
              within ZKPs. Oftentimes, an intermediate step between the input and
              output is a set of constraints that describes the code/circuit. These
              constraints act as the basis for the mathematical representation. For
              brevity’s sake, we do not discuss the details of arithmetization and
              refer to the brilliant explanations of \[ [12](https://arxiv.org/html/2502.07063v1#bib.bib12
              ""), [52](https://arxiv.org/html/2502.07063v1#bib.bib52 "")\]. In this
              text, we only treat arithmetization as a black-box and do not require
              the knowledge of specific details, only the inputs (e.g. code) and outputs
              (e.g. mathematical representation). Table [I](https://arxiv.org/html/2502.07063v1#S2.T1
              "TABLE I ‣ II-A Taxonomy of ZKPs ‣ II Zero-Knowledge Proofs ‣ Zero-Knowledge
              Proof Frameworks: A Survey") compares the seminal ZK protocols at a
              high-level. Below, we describe the taxonomy of the general schemes that
              underlie our chosen ZK protocols in detail.


              Report issue for preceding element


              | Construction | Key Advantages | Key Disadvantages |

              | --- | --- | --- |

              | zk-SNARKs | Succinct, Publicly Verifiable | Trusted Setup Required,
              Computationally Expensive to Prove, Not Post-Quantum |

              | zk-STARKs | No Trusted Setup, Post-Quantum Secure, Scalable Prover,
              Publicly Verifiable | Larger Proof Sizes, Slow Verification |

              | MPCitH | No Trusted Setup, Post-Quantum Secure, Publicly Verifiable
              | Slow Verification, Computationally Expensive Proving |

              | VOLE-ZK | Highest Scalability, No Trusted Setup, Post-Quantum Secure
              | Slow Verification, Designated Verifier |


              TABLE I: Core Attributes of Popular ZKP ConstructionsReport issue for
              preceding element


              |  | zk-SNARKs | zk-STARKs | MPCitH | VOLE-ZK |

              | Prover complexity | O⁢(n⁢log⁡(n))𝑂𝑛𝑛O(n\\log{}(n))italic\_O ( italic\_n
              roman\_log ( italic\_n ) ) | O⁢(n⁢poly-log⁢(n))𝑂𝑛poly-log𝑛O(n\\text{poly-log}(n))italic\_O
              ( italic\_n poly-log ( italic\_n ) ) | O⁢(n)𝑂𝑛O(n)italic\_O ( italic\_n
              ) | O⁢(n)𝑂𝑛O(n)italic\_O ( italic\_n ) |

              | Verifier complexity | O⁢(1)𝑂1O(1)italic\_O ( 1 ) | O⁢(poly-log⁢(n))𝑂poly-log𝑛O(\\text{poly-log}(n))italic\_O
              ( poly-log ( italic\_n ) ) | O⁢(n)𝑂𝑛O(n)italic\_O ( italic\_n ) | O⁢(n)𝑂𝑛O(n)italic\_O
              ( italic\_n ) |

              | Proof size | O⁢(1)𝑂1O(1)italic\_O ( 1 ) | O⁢(poly-log⁢(n))𝑂poly-log𝑛O(\\text{poly-log}(n))italic\_O
              ( poly-log ( italic\_n ) ) | O⁢(n)𝑂𝑛O(n)italic\_O ( italic\_n ) | O⁢(n)𝑂𝑛O(n)italic\_O
              ( italic\_n ) |

              | Trusted setup | ✓ | ✗ | ✗ | ✗ |

              | Non-interactive | ✓ | ✓ | ✓ | ✗ |

              | Post-quantum secure | ✗ | ✓ | ✓ | ✓ |

              | Practical proof size | 120-500 bytes | 10 KB - 1 MB | 10-1000 KB |
              5-200 KB |


              TABLE II: Asymptotic attributes of presented ZKP constructions. We do
              note that, due to the variance of schemes within each construction,
              the algorithmic complexities are generalized and may not hold true for
              all schemes within a given construction.Report issue for preceding element


              Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARKs)
              are, as the name suggests, a class of non-interactive protocols that
              boast small proof size \[ [40](https://arxiv.org/html/2502.07063v1#bib.bib40
              "")\]. Although ZKPs were originally conceived in the late 1980’s \[
              [75](https://arxiv.org/html/2502.07063v1#bib.bib75 "")\], zk-SNARKs
              were formally introduced about a decade after. Efficient instantiations
              of zk-SNARKs were introduced in the last decade, resulting in recent
              advancements in making zk-SNARKs practical and efficient for widespread
              use.

              This means there are much more mature open-source and real-world implementations
              available. The most common forms of zk-SNARKs are referred to as pre-processing
              zk-SNARKs. One of the main drawbacks of these zk-SNARKs are that they
              require a trusted setup for every new circuit 𝒞𝒞\\mathcal{C}caligraphic\_C,
              which is computationally intensive and requires communication of large
              proving and verifying keys to the respective parties.

              Alongside this, 𝒫𝒫\\mathcal{P}caligraphic\_P must normally be computationally
              powerful in order to ensure small proof size. This is due to the fact
              that most zk-SNARKs are reliant on elliptic curve cryptography (ECC)
              as their underlying cryptographic arithmetic.

              Recent works have introduced zk-SNARKs that can utilize universal trusted
              setups \[ [68](https://arxiv.org/html/2502.07063v1#bib.bib68 ""), [58](https://arxiv.org/html/2502.07063v1#bib.bib58
              "")\] for established maximum circuit sizes, and zk-SNARKs that do not
              require a trusted setup at all \[ [117](https://arxiv.org/html/2502.07063v1#bib.bib117
              ""), [134](https://arxiv.org/html/2502.07063v1#bib.bib134 "")\].

              Due to the non-interactivity, zk-SNARKs are publicly verifiable, meaning
              any verifier can verify them without recomputing the proof. One of the
              most common underlying schemes, especially in our highlighted frameworks,
              for zk-SNARKs is Groth16 \[ [77](https://arxiv.org/html/2502.07063v1#bib.bib77
              "")\], which improves upon the original Pinocchio \[ [108](https://arxiv.org/html/2502.07063v1#bib.bib108
              "")\] protocol. zk-SNARK arithmetization typically results in a set
              of constraints, called Rank 1 Constraint Systems (R1CS) \[ [36](https://arxiv.org/html/2502.07063v1#bib.bib36
              "")\], which are then converted to a set of polynomials, called a Quadratic
              Arithmetic Program (QAP) \[ [71](https://arxiv.org/html/2502.07063v1#bib.bib71
              "")\]. We do note that there are different formats that are zk-SNARKs
              are compatible with, such as Algebraic Intermediate Representations
              (AIR) \[ [38](https://arxiv.org/html/2502.07063v1#bib.bib38 "")\] and
              Plonkish tables - we simply highlight R1CS as a prevalent constraint
              system. The Groth16 zk-SNARK generation and verification process can
              be represented at a high-level with the following algorithms:


              Report issue for preceding element


              - •



              (𝒱⁢𝒦,𝒫⁢𝒦)←absent←𝒱𝒦𝒫𝒦absent(\\mathcal{VK,PK})\\xleftarrow\[\]{}( caligraphic\_V
              caligraphic\_K , caligraphic\_P caligraphic\_K ) start\_ARROW start\_OVERACCENT
              end\_OVERACCENT ← end\_ARROW Setup(𝒞𝒞\\mathcal{C}caligraphic\_C): A
              trusted third party or 𝒱𝒱\\mathcal{V}caligraphic\_V run a setup procedure
              to generate a prover key 𝒫⁢𝒦𝒫𝒦\\mathcal{PK}caligraphic\_P caligraphic\_K
              and verifier key 𝒱⁢𝒦𝒱𝒦\\mathcal{VK}caligraphic\_V caligraphic\_K. These
              keys are used for proof generation and verification, respectively. This
              setup must be repeated each time 𝒞𝒞\\mathcal{C}caligraphic\_C changes.


              Report issue for preceding element


              - •



              π←absent←𝜋absent\\pi\\xleftarrow\[\]{}italic\_π start\_ARROW start\_OVERACCENT
              end\_OVERACCENT ← end\_ARROW Prove(𝒫⁢𝒦𝒫𝒦\\mathcal{PK}caligraphic\_P
              caligraphic\_K, 𝒞𝒞\\mathcal{C}caligraphic\_C, x𝑥xitalic\_x, y𝑦yitalic\_y,
              w𝑤witalic\_w): 𝒫𝒫\\mathcal{P}caligraphic\_P generates proof π𝜋\\piitalic\_π
              to convince 𝒱𝒱\\mathcal{V}caligraphic\_V that w𝑤witalic\_w is a valid
              witness.


              Report issue for preceding element


              - •



              1/0←absent←10absent1/0\\xleftarrow\[\]{}1 / 0 start\_ARROW start\_OVERACCENT
              end\_OVERACCENT ← end\_ARROW Verify(𝒱⁢𝒦𝒱𝒦\\mathcal{VK}caligraphic\_V
              caligraphic\_K, 𝒞𝒞\\mathcal{C}caligraphic\_C, x𝑥xitalic\_x, y𝑦yitalic\_y,
              π𝜋\\piitalic\_π): 𝒱𝒱\\mathcal{V}caligraphic\_V accepts or rejects proof
              π𝜋\\piitalic\_π. Due to soundness property of zk-SNARKs, 𝒱𝒱\\mathcal{V}caligraphic\_V
              cannot be convinced that w𝑤witalic\_w is a valid witness by a cheating
              𝒫𝒫\\mathcal{P}caligraphic\_P.


              Report issue for preceding element



              In Appendix [B](https://arxiv.org/html/2502.07063v1#A2 "Appendix B Recursive
              zk-SNARKs ‣ Zero-Knowledge Proof Frameworks: A Survey"), we describe
              how zk-SNARKs can be extended to allow recursive construction and verification
              of proofs.


              Report issue for preceding element


              As we stated, one of the drawbacks of traditional pre-processing zk-SNARKs
              is their reliance on a trusted setup per circuit 𝒞𝒞\\mathcal{C}caligraphic\_C.

              PLONKS, a subset of zk-SNARKs, are a class non-interactive ZK protocols
              that improve upon pre-processing zk-SNARKs by getting rid of the trusted
              setup per circuit 𝒞𝒞\\mathcal{C}caligraphic\_C, while adding a bit more
              arithmetic flexibility \[ [68](https://arxiv.org/html/2502.07063v1#bib.bib68
              "")\]. PLONKs utilize the idea of a universal and updatable trusted
              setup, introduced in theory by \[ [78](https://arxiv.org/html/2502.07063v1#bib.bib78
              "")\] and in practice by \[ [101](https://arxiv.org/html/2502.07063v1#bib.bib101
              "")\], in which a trusted setup procedure is done for circuits up to
              a certain size.

              Every circuit 𝒞𝒞\\mathcal{C}caligraphic\_C that fits within these size
              constraints can utilize the parameters generated by the universal trusted
              setup process. While PLONKs introduce a universal trusted setup, it
              comes at the cost of proof size and 𝒱𝒱\\mathcal{V}caligraphic\_V runtime.
              PLONK proofs are normally 2−5×2-5\\times2 - 5 × the size of zk-SNARKs,
              and 𝒱𝒱\\mathcal{V}caligraphic\_V runtime is marginally higher. It is
              important to note that, although PLONK proofs are larger than those
              of zk-SNARKs, proof size still remains in the KB range. The advantage
              that PLONKs have is that they are flexible in the commitment scheme
              they can use. By using the standard Kate commitments \[ [87](https://arxiv.org/html/2502.07063v1#bib.bib87
              "")\], PLONKs become more zk-SNARK-like, as these commitments are based
              on ECC. FRI commitments \[ [37](https://arxiv.org/html/2502.07063v1#bib.bib37
              "")\], which rely on Reed-Solomon codes and low-degree polynomials/testing
              for verifiers, can also be used to make PLONKs more zk-STARK-like. The
              type of commitment schemes allows developers to balance the tradeoff
              between performance and security assumptions. PLONK arithmetization
              is similar to that of zk-SNARKs, meaning that the resulting representation
              is a set of polynomials. To get there, PLONKs sets constraints for each
              gate (e.g. multiplication, addition) from the arithmetic circuit representation
              of the computation in the form of Lagrange polynomials. Once the constraints
              are set, a special permutation function is used to check consistency
              between commitments. Finally, a final set of polynomials is constructed
              to fully represent the given computation. Overall, PLONKs provide a
              method to flexibly construct ZKPs with a less stringent trusted setup
              requirement, at the slight cost of performance.


              Report issue for preceding element


              Zero-Knowledge Scalable Transparent Arguments of Knowledge (zk-STARKs),
              which can be thought of as interactive oracle proof (IOP)-based zk-SNARKS,
              completely remove the dependence on trusted setup. Rather than using
              randomness from a trusted party, these protocols use publicly verifiable
              randomness for generating the necessary parameters for proof generation
              and verification. zk-STARKs achieve post-quantum security guarantees
              by utilizing collision-resistant hash functions as their underlying
              cryptography, rather than ECC. This increased security comes at a cost,
              as zk-STARK proofs are typically an order of magnitude larger than zk-SNARKs
              and PLONKs, and require more computational resources to generate and
              verify \[ [38](https://arxiv.org/html/2502.07063v1#bib.bib38 "")\].
              The main contributor towards these drawbacks are the underlying data
              structure that are used in proof generation: Merkle trees. In zk-STARKs,
              Merkle trees are used to create a compact representation of the computation’s
              execution trace. During proof generation, the computation’s execution
              trace is arithmetized into polynomials, which are verified by performing
              low-degree testing, a process which ensures that the polynomials are
              of expected degree. Low-degree testing is enabled by the use of FRI
              commitments \[ [81](https://arxiv.org/html/2502.07063v1#bib.bib81 "")\].
              The polynomials are evaluated at certain points to verify their correct
              represenation of the execution trace, and these evaluations are used
              as the leaf nodes of the Merkle tree. The root of the Merkle tree then
              acts as a sort of commitment to these evaluated polynomials, hence allowing
              the verifier to simply verify the root, rather than verifying the whole
              computation trace. \[ [27](https://arxiv.org/html/2502.07063v1#bib.bib27
              "")\] The use of Merkle trees are what enable the scalability of zk-STARKs.
              While the Merkle trees support efficient verification, the proof size
              is drastically increased due to the inclusion of the material needed
              for verification, such as the Merkle root, polynomial evaluations, FRI
              commitments, and necessary Merkle branches. We note that there are IOP-based
              zk-SNARKs that stray away from this general protocol, but these steps
              are the most consistently utilized in current literature. Overall, zk-STARKs
              primarily benefit from being scalable and post-quantum secure with no
              trusted setup, at a significant cost to proof size and 𝒫𝒫\\mathcal{P}caligraphic\_P/𝒱𝒱\\mathcal{V}caligraphic\_V
              computation.


              Report issue for preceding element


              MPC-in-the-Head (MPCitH) ZKPs are a class of ZK protocols that take
              a completely novel approach towards proof generation and verification.
              The primary cryptographic basis is secure multiparty computation (MPC).
              MPC is a cryptographic primitive that allows for n𝑛nitalic\_n parties
              to jointly compute a function f⁢(x1,…,xn)𝑓subscript𝑥1…subscript𝑥𝑛f(x\_{1},...,x\_{n})italic\_f
              ( italic\_x start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , … , italic\_x
              start\_POSTSUBSCRIPT italic\_n end\_POSTSUBSCRIPT ), on private inputs
              from each party, without leaking any information about the private inputs.
              One of the prominent approaches to enable MPC is secret sharing, in
              which parties distributes secret shares of their private inputs amongst
              each other to compute a function. MPCitH, proposed by \[ [85](https://arxiv.org/html/2502.07063v1#bib.bib85
              "")\], allows for 𝒫𝒫\\mathcal{P}caligraphic\_P to simulate the n𝑛nitalic\_n
              MPC parties and following computation locally, or ”in the head”. Theoretically,
              any MPC protocol that can compute arbitrary functions can be transformed
              into a MPCitH ZKP. For n𝑛nitalic\_n parties {P1,…,Pn}subscript𝑃1…subscript𝑃𝑛\\{P\_{1},...,P\_{n}\\}{
              italic\_P start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , … , italic\_P
              start\_POSTSUBSCRIPT italic\_n end\_POSTSUBSCRIPT }, secret shares are
              generated by each party and distributed to every other party. For the
              underlying arithmetic, the circuit 𝒞𝒞\\mathcal{C}caligraphic\_C is defined
              in an MPC manner to operate on secret shared data. 𝒫𝒫\\mathcal{P}caligraphic\_P
              can then simulate each parties’ computation of the circuits with the
              secret shares they obtained from all other parties. After this is complete,
              𝒫𝒫\\mathcal{P}caligraphic\_P has n𝑛nitalic\_n sets of messages and data
              that were generated and received by each party, called views. 𝒫𝒫\\mathcal{P}caligraphic\_P
              uses a standard commitment scheme to generate n𝑛nitalic\_n view commitments.
              Finally, 𝒫𝒫\\mathcal{P}caligraphic\_P and 𝒱𝒱\\mathcal{V}caligraphic\_V
              interactively verify a subset of these views for consistency and correctness
              \[ [121](https://arxiv.org/html/2502.07063v1#bib.bib121 "")\]. While
              MPCitH protocols are innately interactive, they can be made non-interactive
              using the Fiat-Shamir transform. Theoretically, a huge advantage of
              the MPCitH approach is that MPC-friendly optimizations, which have been
              much further studied, can be utilized during proof generation to drastically
              improve 𝒫𝒫\\mathcal{P}caligraphic\_P efficiency and proof length. However,
              the most effective optimizations for MPC may translate to effective
              solutions for MPCitH. One of the core parameters MPCitH schemes aim
              to minimize is the communication complexity, as this directly reduces
              the amount of data that is present in each party’s committed view. Just
              like zk-STARKs, MPCitH-based ZKPs do not require a trusted setup and
              are post-quantum secure, as MPC is thought to be generally quantum secure
              \[ [121](https://arxiv.org/html/2502.07063v1#bib.bib121 "")\]. Overall,
              MPCitH proposes a unique approach towards ZKP construction that are
              transparent post-quantum secure that allows flexibility in the underlying
              arithmetic to optimize the cost of proof generation and verification
              and proof size.


              Report issue for preceding element


              Vector Oblivious Linear Evaluation (VOLE)-based ZK

              protocols are a set of interactive techniques that achieve high efficiency
              and scalability through the use of information-theoretic message authentication
              code (IT-MAC)-based commitment schemes, which can be efficiently implemented
              using VOLE correlations. In VOLE-based ZKP protocols, the prover acts
              as the VOLE sender, while the verifier takes on the role of the VOLE
              receiver.

              VOLE correlations are a pair of random variables, (u, x), known by 𝒫𝒫\\mathcal{P}caligraphic\_P
              and (v, ΔΔ\\Deltaroman\_Δ), only known by 𝒱𝒱\\mathcal{V}caligraphic\_V,
              in which u, x, and v are vectors, and ΔΔ\\Deltaroman\_Δ is a scalar
              key . These variables satisfy the relation:


              Report issue for preceding element


              |     |     |     |

              | --- | --- | --- |

              |  | ui=vi+xi⋅Δsubscript𝑢𝑖subscript𝑣𝑖⋅subscript𝑥𝑖Δu\_{i}=v\_{i}+x\_{i}\\cdot\\Deltaitalic\_u
              start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT = italic\_v start\_POSTSUBSCRIPT
              italic\_i end\_POSTSUBSCRIPT + italic\_x start\_POSTSUBSCRIPT italic\_i
              end\_POSTSUBSCRIPT ⋅ roman\_Δ |  |


              This functionality typically operates over a finite field.

              Generally, in VOLE-based ZK, IT-MACs are used as commitments to authenticated
              wire values in arithmetic or boolean circuits representing a computation
              𝒞𝒞\\mathcal{C}caligraphic\_C. 𝒫𝒫\\mathcal{P}caligraphic\_P demonstrates
              knowledge of a private vector w, which represents the witness, where
              𝒞⁢(w)=1𝒞w1\\mathcal{C}(\\textbf{w})=1caligraphic\_C ( w ) = 1, while
              proving the consistency throughout the protocol, without revealing any
              information about w.


              VOLE-based proofs provide unparalleled scalability and communication
              optimizations, however, they are inherently designated-verifier protocols,
              meaning that 𝒫𝒫\\mathcal{P}caligraphic\_P must communicate with every
              𝒱𝒱\\mathcal{V}caligraphic\_V that aims to verify the proof, as 𝒱𝒱\\mathcal{V}caligraphic\_V
              must maintain the secret ΔΔ\\Deltaroman\_Δ to ensure soundness. To address
              this, \[ [31](https://arxiv.org/html/2502.07063v1#bib.bib31 "")\] proposes
              a new VOLE-based paradigm, entitled VOLE-in-the-head (VOLEitH), which
              enables non-interactive VOLE-based ZK.


              Report issue for preceding element


              ## III ZKP Libraries


              Report issue for preceding element


              |     |     |     |     |     |     |     |     |

              | --- | --- | --- | --- | --- | --- | --- | --- |

              |  | Usability | Accessibility |  |

              | Framework | Language(s) | Custom 𝒞𝒞\\mathcal{C}caligraphic\_C | License
              | Examples | Documentation | GitHub Issues | Last Major Update |

              |  | zk-SNARKs |

              | Arkworks \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26 "")\]
              | Rust | Report issue for preceding element | MIT, Apache-2 | Report
              issue for preceding element | ✓ | Report issue for preceding element
              | Dec. 2023 |

              | Gnark \[ [49](https://arxiv.org/html/2502.07063v1#bib.bib49 "")\]
              | Go | Report issue for preceding element | Apache-2 | Report issue
              for preceding element | ✓ | Report issue for preceding element | Dec.
              2024 |

              | Hyrax \[ [2](https://arxiv.org/html/2502.07063v1#bib.bib2 "")\] |
              Python | Report issue for preceding element | Apache-2 | Report issue
              for preceding element | ✗ | Report issue for preceding element | Feb.
              2018 |

              | LEGOSnark \[ [3](https://arxiv.org/html/2502.07063v1#bib.bib3 "")\]
              | C++ | Report issue for preceding element | MIT, Apache-2 | Report
              issue for preceding element | ✗ | Report issue for preceding element
              | Oct. 2020 |

              | LibSNARK \[ [4](https://arxiv.org/html/2502.07063v1#bib.bib4 "")\]
              | C++, Java (xJsnark \[ [90](https://arxiv.org/html/2502.07063v1#bib.bib90
              "")\]) | Report issue for preceding element | MIT | Report issue for
              preceding element | ✗ | Report issue for preceding element | Jul. 2020
              |

              | Zokrates \[ [64](https://arxiv.org/html/2502.07063v1#bib.bib64 "")\]
              | Zokrates DSL | Report issue for preceding element | LGPL-3.0 | Report
              issue for preceding element | ✓ | Report issue for preceding element
              | Nov.2023 |

              | Mirage \[ [5](https://arxiv.org/html/2502.07063v1#bib.bib5 "")\] |
              Java | Report issue for preceding element | MIT | Report issue for preceding
              element | ✗ | Report issue for preceding element | Jan. 2021 |

              | PySNARK \[ [7](https://arxiv.org/html/2502.07063v1#bib.bib7 "")\]
              | Python | Report issue for preceding element | Custom (MIT-like) |
              Report issue for preceding element | ✓ | Report issue for preceding
              element | May 2023 |

              | SnarkJS \[ [34](https://arxiv.org/html/2502.07063v1#bib.bib34 "")\]
              | Circom \[ [104](https://arxiv.org/html/2502.07063v1#bib.bib104 "")\]
              | Report issue for preceding element | GPL-3 | Report issue for preceding
              element | ✗ | Report issue for preceding element | Oct. 2024 |

              | Rapidsnark \[ [8](https://arxiv.org/html/2502.07063v1#bib.bib8 "")\]
              | Circom \[ [104](https://arxiv.org/html/2502.07063v1#bib.bib104 "")\]
              | Report issue for preceding element | GPL-3 | Report issue for preceding
              element | ✗ | Report issue for preceding element | Dec. 2023 |

              | Spartan\[ [10](https://arxiv.org/html/2502.07063v1#bib.bib10 "")\]
              | Rust | Report issue for preceding element | MIT | Report issue for
              preceding element | ✗ | Report issue for preceding element | Jan. 2023
              |

              | Aurora (libiop) \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] | C++ | Report issue for preceding element | MIT | Report issue
              for preceding element | ✗ | Report issue for preceding element | May
              2021 |

              | Fractal (libiop) \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] | C++ | Report issue for preceding element | MIT | Report issue
              for preceding element | ✗ | Report issue for preceding element | May
              2021 |

              | Virgo \[ [125](https://arxiv.org/html/2502.07063v1#bib.bib125 "")\]
              | Python | Report issue for preceding element | Apache-2 | Report issue
              for preceding element | ✗ | Report issue for preceding element | Jul.
              2021 |

              | Noir \[ [17](https://arxiv.org/html/2502.07063v1#bib.bib17 "")\] |
              Rust DSL | Report issue for preceding element | MIT, Apache-2 | Report
              issue for preceding element | ✓ | Report issue for preceding element
              | Nov. 2024 |

              | Dusk-PLONK \[ [13](https://arxiv.org/html/2502.07063v1#bib.bib13 "")\]
              | Rust | Report issue for preceding element | MPL-2 | Report issue for
              preceding element | ✓ | Report issue for preceding element | Aug. 2024
              |

              | Halo2 \[ [14](https://arxiv.org/html/2502.07063v1#bib.bib14 "")\]
              | Rust | Report issue for preceding element | MIT, Apache-2 | Report
              issue for preceding element | ✓ | Report issue for preceding element
              | Nov. 2023 |

              |  | MPC-in-the-Head |

              | Limbo \[ [92](https://arxiv.org/html/2502.07063v1#bib.bib92 "")\]
              | Bristol \[ [128](https://arxiv.org/html/2502.07063v1#bib.bib128 "")\]
              | Report issue for preceding element | MIT | Report issue for preceding
              element | ✗ | Report issue for preceding element | May 2021 |

              | Ligero (libiop) \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] | C++ | Report issue for preceding element | MIT | Report issue
              for preceding element | ✗ | Report issue for preceding element | May
              2021 |

              |  | VOLE-Based ZK |

              | Mozzarella \[ [32](https://arxiv.org/html/2502.07063v1#bib.bib32 "")\]
              | Rust | Report issue for preceding element | MIT | Report issue for
              preceding element | ✗ | Report issue for preceding element | Mar. 2022
              |

              | Diet Mac’n’Cheese \[ [1](https://arxiv.org/html/2502.07063v1#bib.bib1
              "")\] | PicoZK \[ [6](https://arxiv.org/html/2502.07063v1#bib.bib6 "")\]
              | Report issue for preceding element | MIT | Report issue for preceding
              element | ✗ | Report issue for preceding element | Sep. 2024 |

              | Emp-ZK \[ [136](https://arxiv.org/html/2502.07063v1#bib.bib136 "")\]
              | C++ | Report issue for preceding element | MIT | Report issue for
              preceding element | ✗ | Report issue for preceding element | Sep. 2023
              |

              |  | zk-STARKs |

              | MidenVM \[ [20](https://arxiv.org/html/2502.07063v1#bib.bib20 "")\]
              | Miden Assembly | Report issue for preceding element | MIT | Report
              issue for preceding element | ✓ | Report issue for preceding element
              | Nov. 2023 |

              | Zilch \[ [130](https://arxiv.org/html/2502.07063v1#bib.bib130 "")\]
              | Java DSL | Report issue for preceding element | MIT | Report issue
              for preceding element | ✗ | Report issue for preceding element | Apr.
              2022 |

              | RISC Zero \[ [112](https://arxiv.org/html/2502.07063v1#bib.bib112
              "")\] | Rust, C++ | Report issue for preceding element | Apache-2 |
              Report issue for preceding element | ✓ | Report issue for preceding
              element | Dec. 2024 |


              TABLE III: ZK Framework AttributesReport issue for preceding element


              In this section, we discuss the details of the 25 frameworks that we
              target in this work. We aim to highlight frameworks bred from both industry
              and academia. We primarily focus on works that present novel implementations
              of proving schemes that can be integrated with their own exposed high-level
              API for custom circuit design, or a general-purpose ZKP circuit development
              frontend, such as Circom \[ [104](https://arxiv.org/html/2502.07063v1#bib.bib104
              "")\] or Zokrates \[ [64](https://arxiv.org/html/2502.07063v1#bib.bib64
              "")\].


              Report issue for preceding element


              Alongside the in-depth descriptions of each framework, we provide an
              evaluation of these frameworks at a high-level on usability and accessibility
              metrics, presented in Table [III](https://arxiv.org/html/2502.07063v1#S3.T3
              "TABLE III ‣ III ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A
              Survey"). Our measurement of some metrics require further explanation:


              Report issue for preceding element


              - •



              Custom 𝒞𝒞\\mathcal{C}caligraphic\_C: Report issue for preceding element===
              Non-cryptography software engineer can build custom circuits, Report
              issue for preceding element=== Building custom circuits requires deep
              knowledge of syntax; A developer could not read the code and understand
              it, Report issue for preceding element=== Custom circuits require deep
              knowledge of protocol and syntax; normally requires manual translation
              of constraints to gates


              Report issue for preceding element


              - •



              Examples: Report issue for preceding element=== Plenty of examples are
              shared that fully show the capabilities of the system, Report issue
              for preceding element=== Examples are included, but are not representative
              of the system’s full capabilities


              Report issue for preceding element


              - •



              Github Issues: Report issue for preceding element=== Users and developers
              are both active in issues forum, Report issue for preceding element===
              Users are relatively active and developers are sporadically active,
              Report issue for preceding element=== No activity


              Report issue for preceding element



              Table [V](https://arxiv.org/html/2502.07063v1#A3.T5 "TABLE V ‣ Appendix
              C Features of ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey")
              in Appendix [C](https://arxiv.org/html/2502.07063v1#A3 "Appendix C Features
              of ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey") outlines
              the discussed frameworks at a high level.


              Report issue for preceding element


              ### III-Azk-SNARKs


              Report issue for preceding element


              libsnark. The libsnark C++ development library \[ [4](https://arxiv.org/html/2502.07063v1#bib.bib4
              "")\] is widely regarded as the original and most well-developed library
              for zk-SNARKs. This is highlighted by the fact that Zcash, the first
              real-world implementation of zk-SNARKs, was built upon libsnark. libsnark
              supports the Pinocchio \[ [108](https://arxiv.org/html/2502.07063v1#bib.bib108
              "")\] and Groth16 \[ [77](https://arxiv.org/html/2502.07063v1#bib.bib77
              "")\] proving schemes, alongside many different underlying elliptic
              curves. Much of the novelty of libsnark comes from the different forms
              of circuits that it supports. It supports R1CS and QAPs, as most frameworks
              do, but also supports higher level forms such as Unitary-Square Constraint
              Systems (USCS) and Two-input Boolean Circuit Satisfiability (TBCS) \[
              [62](https://arxiv.org/html/2502.07063v1#bib.bib62 "")\]. The scheme
              used in libsnark is described as a preprocessing zk-SNARK, which simply
              highlights that trusted setup is performed before proof generation and
              verification. libsnark provides low-level ”gadgets”, which can be combined
              and built upon to represent the desired computation in R1CS format,
              however it is not the easiest way to develop zk-SNARKs in this library.
              \[ [90](https://arxiv.org/html/2502.07063v1#bib.bib90 "")\] presents
              xJsnark, a high-level Java framework that allows a user to essentially
              code their computation in standard Java. Behind the scenes, this framework
              optimizes computation and outputs the computation in R1CS format. This
              output can be used directly with libsnark’s zk-SNARK generation script.
              Combined with xJsnark, libsnark is a highly-accessible option for inexperienced
              ZKP developers.


              Report issue for preceding element


              gnark. The gnark library \[ [49](https://arxiv.org/html/2502.07063v1#bib.bib49
              "")\] enables developers to build zk-SNARK-based applications using
              the high-level API it offers in Go language. The primary focus of gnark
              is runtime speed \[ [60](https://arxiv.org/html/2502.07063v1#bib.bib60
              "")\]. It offers both Groth16 \[ [77](https://arxiv.org/html/2502.07063v1#bib.bib77
              "")\] and PLONK \[ [68](https://arxiv.org/html/2502.07063v1#bib.bib68
              "")\] (with KZG and FRI polynomial commitment) SNARK protocols. It offers
              a lot of curves, and can build R1CS circuits. In terms of hashing, it
              offers MiMC \[ [23](https://arxiv.org/html/2502.07063v1#bib.bib23 "")\],
              SHA2, and SHA3 gadgets out-of-the-box. It also offers a collection of
              high-level gadgets for ease of building custom circuits. This framework
              exposes a high-level API that allows users to build their own gadgets,
              while utilizing the Go standard language and the provided gadgets. Recently,
              gnark has introduced GPU support with the support of the Icicle library
              \[ [84](https://arxiv.org/html/2502.07063v1#bib.bib84 "")\]. This work
              is in active development and seems to have an active community around
              it, making it an accessible option for inexperienced ZKP developers.
              We recommend this for beginners and experts alike for almost any custom
              applications. This framework utilizes a readable and robust API that
              any user can take advantage of and build custom applications with.


              Report issue for preceding element


              arkworks. The arkworks Rust ecosystem \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26
              "")\] is an extensive and modular collection of libraries that can be
              used for efficient zk-SNARK programming. This ecosystem provides highly
              efficient implementations of arithmetic over various curves and fields,
              even allowing curve specific optimizations. The main offering of arkworks
              is a generic application development framework that supports both experienced
              and non-experienced zk-SNARK developers. This framework enables high-level
              zk-SNARK development, as it allows users to implement their circuit
              as constraints (R1CS), while abstracting out details of SNARKs and curves,
              using an arkworks library. To venture into lower-level optimizations,
              arkworks provides libraries for the user to describe their circuit in
              native code. This allows the users to make several design decisions,
              such as specifying which proving system, such as Groth16, they would
              like to use. Alongside this, arkworks also provides libraries implementing
              low-level finite field, elliptic curve, and polynomial interfaces. In
              addition to SHA256, ZKP-friendly hashes such as Pedersen \[ [35](https://arxiv.org/html/2502.07063v1#bib.bib35
              "")\] and Poseidon \[ [76](https://arxiv.org/html/2502.07063v1#bib.bib76
              "")\] hashing are also offered. The arkworks development ecosystem is
              actively maintained and has an active community. We recommend this framework
              for users that have a deep knowledge of ZKPs, as one of the main advantages
              of arkworks, other than it’s fantastic and usable codebase, is the ability
              to tweak certain parameters to optimize operations for your custom application.


              Report issue for preceding element


              hyraxZK.Hyrax is a ”doubly-efficient” zk-SNARK scheme, providing a concretely
              efficient prover and verifier, with low communication cost and no trusted
              setup \[ [134](https://arxiv.org/html/2502.07063v1#bib.bib134 "")\].
              Instead of following a standard underlying zk-SNARK structure, Hyrax
              is built on top of the Giraffe interactive proof scheme \[ [133](https://arxiv.org/html/2502.07063v1#bib.bib133
              "")\]. The authors apply a technique to reduce communication cost and
              add cryptopgraphic operations to turn the interactive proof into a ZKP.
              With the addition of optimized cryptographic commitments, the concrete
              cost of this scheme is significantly reduced and results in an interactive
              ZKP scheme. Using the Fiat-Shamir transform \[ [88](https://arxiv.org/html/2502.07063v1#bib.bib88
              "")\], this scheme is made non-interactive. hyraxZK\[ [2](https://arxiv.org/html/2502.07063v1#bib.bib2
              "")\] provides a cleanly-developed Python and C++ development environment
              using Hyrax as the underlying zk-SNARK scheme. The provided framework
              is well-developed, however there is a lack of documentation that makes
              it challenging to build custom circuits.


              Report issue for preceding element


              libspartan.libspartan\[ [10](https://arxiv.org/html/2502.07063v1#bib.bib10
              "")\] is a Rust library that implements the Spartan zk-SNARK proof system
              \[ [117](https://arxiv.org/html/2502.07063v1#bib.bib117 "")\]. Spartan
              is a transparent zk-SNARK proof system, meaning that it requires no
              trusted setup. libspartan utilizes a Rust implemention of group operations
              on prime-order group Ristretto \[ [11](https://arxiv.org/html/2502.07063v1#bib.bib11
              "")\] and elliptic curve Curve25519 \[ [43](https://arxiv.org/html/2502.07063v1#bib.bib43
              "")\], which ensures security and speed.

              By adding a new commitment scheme, alongside a novel cryptographic compiler
              and a compact encoding of R1CS instances, Spartan is able to achieve
              the first transparent proof system with sub-linear verification costs
              and a time-optimal prover, at the cost of memory-heavy computation on
              the prover side. libspartan is a well-developed and maintained framework,
              however implementing custom functions is not very straightforward based
              on the provided documentation. Developing a custom ZKP circuit in libspartan
              requires the user to have the parameters of the R1CS instance, alongside
              knowledge of how to encode the constraints into R1CS matrices. Depending
              on the size of the ZKP circuit, this process can be very rigorous and
              involved, while also requiring a full knowledge of R1CS representations.

              Zokrates\[ [64](https://arxiv.org/html/2502.07063v1#bib.bib64 "")\]
              provides a high-level API to build an R1CS for custom ZKP circuits,
              however a developer then has to manually convert these into a format
              that is readable by libspartan, which can be time-intensive depending
              on the number of constraints in the circuit. We only recommend this
              framework to users that have an in-depth knowledge of ZK constraint
              systems, however, we do note that this framework’s backend is state-of-the-art
              and, upon integration with a standard frontend, would be a perfect solution
              for most ZK applications.


              Report issue for preceding element


              Mirage.Mirage\[ [89](https://arxiv.org/html/2502.07063v1#bib.bib89 "")\]
              is a universal zk-SNARK scheme and aptly named Java framework \[ [5](https://arxiv.org/html/2502.07063v1#bib.bib5
              "")\] implementing such scheme. Mirage’s main contribution is a universal
              trusted setup, such that trusted setup does not have to be performed
              everytime the circuit changes, as is done in zk-SNARKs. This saves a
              great amount of time and computation at the cost of higher proof computation
              overhead. This work introduces the idea of separated zk-SNARKs, which
              enables efficient randomized checks in zk-SNARK circuits. This results
              in simplified verification complexity. Combining this with their novel
              universal circuit generator that produces circuits linear in the number
              of additions and multiplications, the Mirage zk-SNARK scheme is introduced.
              The underlying scheme and circuit generator are implemented in the mirage
              codebase, which has a Java frontend for circuit generation and a C++
              backend implementing Mirage on top of libsnark. The core of development
              is done in mirage’s universal circuit generator, as that is where the
              ZKP circuits are specified by the user. This codebase provides very
              readable and diverse examples that highlight the use cases of their
              high-level Java API.

              Not only is there a bit of a learning curve to get acquainted with mirage’s
              syntax, but we also found that the codebase is relatively outdated,
              meaning that the code no longer compiles.


              Report issue for preceding element


              LegoSNARK.LegoSNARK\[ [54](https://arxiv.org/html/2502.07063v1#bib.bib54
              "")\] is a zk-SNARK scheme and library that focuses on linking SNARK
              ”gadgets” together to build zk-SNARKs with a modular approach. This
              library implements the modular zk-SNARKs in the form of commit-and-prove
              zk-SNARKs (CP-SNARKs) \[ [96](https://arxiv.org/html/2502.07063v1#bib.bib96
              "")\], which are a class of zk-SNARKs that prove statements about committed
              values. As previous CP-SNARK schemes are limited due to their reliance
              on a single commitment scheme, one of the most important contributions
              of this work is a generic construction that can convert a broad class
              of zk-SNARKS, such as QAP-based, to CP-SNARKs. The LegoSNARK library
              \[ [3](https://arxiv.org/html/2502.07063v1#bib.bib3 "")\] provides end-to-end
              proving and verification using the proposed scheme in a C++ package.
              This work builds upon libsnark, albeit with integration to high-level
              libsnark frameworks, such as xJsnark. Nevertheless, this library provides
              readable examples for developing gadgets, making it relatively easy
              for experienced C++ developers to build custom gadgets for their ZK
              applications without an in-depth knowledge of ZKPs. We recommend this
              framework to users that are building modular applications that benefit
              from CP-SNARKs, such as matrix arithmetic.


              Report issue for preceding element


              PySNARK.PySNARK\[ [7](https://arxiv.org/html/2502.07063v1#bib.bib7 "")\]
              is a Python library that allows developers to use pure Python syntax
              to develop zk-SNARKs with various backends. PySNARK gives users access
              to libsnark, qaptools, zkinterface, and snarkjs backends. Compiling
              computation with the libsnark and qaptools performs proof generation
              and verification using the Groth16 and Pinnochio proving systems, respectively.
              Using the zkinterface backend simply generates .zkif files that can
              be used with the zkinterface package for proof generation and verification,
              where the underlying scheme can be chosen. Similarly, using the snarkjs
              backend generates the witness and R1CS files that can be used within
              our provided snarkjs environment. Overall, PySNARK is a brilliantly
              documented and developed library for beginners with zk-SNARKs, however
              it is not actively maintained. Developers that are comfortable with
              Python should have no trouble developing ZK applications once they become
              familiar with the library’s syntax. Due to the Python compilation process,
              PySNARK experiences non-ideal operation times, so users should primarily
              use this for testing applications on the Groth16 proving system, but
              not for practical application development.


              Report issue for preceding element


              SnarkJS + RapidSNARK.SnarkJS\[ [34](https://arxiv.org/html/2502.07063v1#bib.bib34
              "")\] is built on Javascript (JS) and Pure Web Assembly (WASM) and supports
              the Groth16, PLONK, and FFLONK underlying proving schemes. This framework
              accepts circuits designed in circom\[ [104](https://arxiv.org/html/2502.07063v1#bib.bib104
              "")\], which provides a very accessible frontend with a well-documented
              API for building ZK circuits. The protocols that are supported all require
              trusted setup, whether it be a circuit-specific setup for Groth16, or
              a universal setup for PLONK/FFLONK. Also, switching between ZK schemes
              is simply done by specifying the desired scheme as a command line argument.
              SnarkJS provides a multi-step universal setup protocol that all programs
              perform, alongside a Groth16-specific setup. Alongside this, the circuit
              to proof compilation process is done in a modular way that allows for
              closer debugging. In the proof generation process, the circuit characteristic’s
              are listed for the developer (e.g. constraints, public inputs) which
              enables quick sanity checks. Finally, SnarkJS provides simple routes
              to turning the verifier into a smart contract, or performing the end-to-end
              ZKP process in browser, due to the JS and WASM backend. RapidSNARK\[
              [8](https://arxiv.org/html/2502.07063v1#bib.bib8 "")\] is built upon
              C++ and Intel assembly by the same developers, and significantly improves
              upon SnarkJS. Using a very similar API, and even accepting SnarkJS-generated
              files as inputs (e.g. proving/verifier keys, witness), RapidSNARK allows
              for faster proof generation with a simple change in command line arguments
              from the SnarkJS commands. The main advantage of this framework is the
              utilization of parallelization within proof generation, yielding much
              faster results than SnarkJS, however the downside is that only Groth16
              proofs are supported. While SnarkJS is more actively maintained than
              RapidSNARK, both frameworks are highly accessible for those with little
              experience in developing ZK applications, due to the ability to utilize
              a circom frontend.


              Report issue for preceding element


              Virgo.Virgo\[ [145](https://arxiv.org/html/2502.07063v1#bib.bib145 "")\]
              is an implementation of a novel interactive doubly-efficient ZK argument
              system. The main advantage of this protocol is the lack of trusted setup,
              which is oftentimes the most cumbersome task in zk-SNARKs. Virgo sees
              the most benefits for layered arithmetic circuits, rather than all general
              arithmetic circuits, as it is based off the GKR protocol \[ [74](https://arxiv.org/html/2502.07063v1#bib.bib74
              "")\], which also is only catered towards structured circuits. General
              arithmetic circuits are addressed in a follow up work, Virgo++\[ [144](https://arxiv.org/html/2502.07063v1#bib.bib144
              "")\]. The open-source implementation of this work does not have ZK
              commitments implemented yet, which is why we do not consider it in our
              survey. The main enabling factor of Virgo is a novel ZK verifiable polynomial
              delegation (zkVPD) scheme, which can essentially be seen as a commitment
              scheme in this scenario.

              Due to the reliance on zkVPD and the allowed interactivity in this scheme,
              the implementation only relies on lightweight cryptography, making it
              a feasible development solution. While an impressive solution with great
              results, the repository is not actively maintained and lacks clear documentation,
              meaning it is not the most suitable candidate for ZK application developers.


              Report issue for preceding element


              libiop

              The libiop framework \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] is a collection of three protocol implementations: Aurora \[ [39](https://arxiv.org/html/2502.07063v1#bib.bib39
              "")\], Fractal \[ [59](https://arxiv.org/html/2502.07063v1#bib.bib59
              "")\], and Ligero \[ [24](https://arxiv.org/html/2502.07063v1#bib.bib24
              "")\]. Ligero falls under the MPCitH category, so it is discussed later
              in the paper. Aurora and Fractal are both post-quantum, transparent
              zk-SNARKs, which classifies them more as succinct zk-STARKs. However,
              the authors classify their work as zk-SNARKs, which is why they are
              discussed here. Both works outperform prior zk-SNARKs by proposing new
              interactive oracle proofs (IOPs). Fractal proposes a holographic IOP
              \[ [29](https://arxiv.org/html/2502.07063v1#bib.bib29 "")\], while Aurora
              proposes an IOP based around Reed-Solomon codes.

              As for the libiop implementations, it does not seem to be actively maintained.
              While there are a few example applications for each protocol, the most
              useful tool in was the benchmarking scripts that were provided. This
              allows users to input parameters, such as number of constraints and
              variables, to specify a random circuit and outputs the performance metrics
              of the protocol. This shows how the protocols scale based on the size
              of the circuit. These parameters can be extracted from R1CS files (made
              by frameworks such as Zokrates), using our provided R1CSReader scripts.
              While the benchmarking is convenient, developing custom applications
              with this framework requires a deeper knowledge of the protocol that
              may not be easily accessible to all developers. We only recommend this
              to users that have a deep knowledge of the literature that these frameworks
              stem from.


              Report issue for preceding element


              Noir.Noir\[ [17](https://arxiv.org/html/2502.07063v1#bib.bib17 "")\]
              is a general Rust-like framework for developing applications based on
              ZKPs. Fundamentally, Noir is a domain-specific language that resembles
              Rust. It enables one to build circuits that implement complex logic
              without having to learn the low-level details of ZKP systems. Since
              it acts like a generalized front end, it is capable of building circuits
              for a variety of back ends. Currently, Barretenberg \[ [28](https://arxiv.org/html/2502.07063v1#bib.bib28
              "")\] serves as the default back end, and generates PLONK proofs and
              Solidity contracts. The Barretenberg back end can also use WASM to create
              proofs and verify them directly in the browser. Arkworks is also available
              as an out-of-the-box back end, which can generate Groth16 and Marlin
              proofs. This generalization is possible because Noir framework compiles
              the circuit to an intermediate language referred to as ACIR (Abstract
              Circuit Intermediate Representation), which can then be further compiled
              to specific R1CS or arithmetic circuit compatible with a specific back
              end. The framework also provides a Typescript library for direct integration
              into web applications. There is active development going on, but Noir
              currently supports a full control flow with the ability to create custom
              circuits using readable code. This is a great option for developers
              who would like to avoid the details of ZKPs and build applications using
              a Rust-like DSL. We recommend this for those who want to build simplistic
              applications who have little experience with ZKPs.


              Report issue for preceding element


              Dusk-PLONK.Dusk-PLONK\[ [13](https://arxiv.org/html/2502.07063v1#bib.bib13
              "")\] is a pure Rust implementation of the PLONK proving system. This
              implementation supports operation over the BLS12-381 and JubJub elliptic
              curves. The developers of this framework use Kate commitments \[ [87](https://arxiv.org/html/2502.07063v1#bib.bib87
              "")\] as their primary polynomial commitment scheme to utilize its homomorphism
              and maintain constant size commitments. The provided codebase is extremely
              detailed and well-commented and provides helpful documentation. Similar
              to other PLONK frameworks, Dusk-PLONK only provides a very low-level
              API for custom circuit development. To build a custom circuit, developers
              must translate their computation into an arithmetic or boolean circuit
              gate format (e.g. add, multiply). This is perfectly digestible for small
              circuits, as shown in the examples, however becomes an intensely laborious
              task as the circuit and number of inputs or input dimensions scales
              up. While the code is well-written and yields excellent results, this
              framework requires a more sophisticated high-level API that utilizes
              common software engineering structures to build custom circuits before
              new developers can start building practical ZKP applications with it.
              We do note that this is a fantastic implementation of the PLONK proving
              system for and recommend it for developers that have experience with
              logic design and ZKPs.


              Report issue for preceding element


              Halo2.

              Built by the same creators of Zcash and the original Halo \[ [50](https://arxiv.org/html/2502.07063v1#bib.bib50
              "")\] framework, the Halo2 framework \[ [14](https://arxiv.org/html/2502.07063v1#bib.bib14
              "")\] optimizes upon some of the inefficiencies of its predecessors
              by utilizing a PLONK-ish scheme as the underlying proving system. The
              underlying polynomial commitment scheme in this framework is Kate commitments.
              In its original repository and documentation, building a custom circuit
              with Halo2 requires a developer to design their computation in the form
              of a circuit, by implementing gates and utilizing them to build a chip.
              This can be relatively confusing for new developers.

              However, Halo2 is a powerful proof system that is utilized widely across
              the industry, including a prominent verifiable machine learning framework,
              ezkl\[ [146](https://arxiv.org/html/2502.07063v1#bib.bib146 "")\]. This
              prominence has garnered a strong community backing the framework and
              has resulted in many works that either provide more examples of how
              the framework can be used \[ [15](https://arxiv.org/html/2502.07063v1#bib.bib15
              "")\], or expose higher-level APIs for building custom circuits. Overall,
              while the Halo2 framework only exposes a lower-level API for custom
              circuit building, the community around it makes it a relatively accessible
              solution for practical application of PLONKs. We believe this is a good
              framework for those experienced with applied cryptography and interest
              in building machine-learning focused applications.


              Report issue for preceding element


              ### III-BMPC-in-the-head


              Report issue for preceding element


              Ligero (libiop).

              The Ligero \[ [24](https://arxiv.org/html/2502.07063v1#bib.bib24 "")\]
              protocol is implemented in libiop\[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] framework. This interactive protocol applies the general IKOS
              \[ [85](https://arxiv.org/html/2502.07063v1#bib.bib85 "")\] transformation
              that transforms MPC-based interactive proofs into ZKPs, which is typical
              for MPC-in-the-Head (MPCitH) systems. This means that the key aspect
              of designing the Ligero is the underlying MPC protocol. While this protocol
              is interactive, it can be transformed into a zk-SNARK using the Fiat-Shamir
              transform, just like any other interactive protocol. Additionally, the
              Ligero protocol only relies on collision resistant hash functions for
              the underlying cryptography and does not require a trusted setup. As
              this is implemented using the same backend as the Aurora and Fractal
              zk-SNARK protocols, all implementation details remain the same as described
              in section [III-A](https://arxiv.org/html/2502.07063v1#S3.SS1 "III-A
              zk-SNARKs ‣ III ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey").


              Report issue for preceding element


              Limbo.

              Similar to Ligero, Limbo’s implementation \[ [92](https://arxiv.org/html/2502.07063v1#bib.bib92
              "")\] and underlying protocol \[ [63](https://arxiv.org/html/2502.07063v1#bib.bib63
              "")\] is reliant on the IKOS transformation that MPCitH protocols often
              rely on. Limbo improves upon Ligero by highlighting the tradeoff between
              MPCitH parties involved, proof size, and runtime.

              The main work Limbo compares to is Ligero, as they are both transparent
              MPCitH schemes that only rely on collision resistant hash functions.
              Limbo claims to work better on small and medium circuits. While the
              Limbo framework is not as extensively developed, maintained, and documented
              as some of the other frameworks highlighted in this work, it greatly
              benefits from its ability to take Bristol Circuit (BC), a common way
              to describe MPC circuits \[ [128](https://arxiv.org/html/2502.07063v1#bib.bib128
              "")\], descriptions as inputs. This allows developers to build custom
              applications by describing their general computations in BC format.
              We provide a simple pipeline for developing BCs, alongside examples
              using readable syntax. We recommend this for users who have experience
              building optimized BCs and have a relatively deep understanding of MPC.


              Report issue for preceding element


              ### III-CVOLE-Based ZK


              Report issue for preceding element


              Diet Mac’n’CheeseDiet Mac’n’Cheese\[ [1](https://arxiv.org/html/2502.07063v1#bib.bib1
              "")\] is a novel framework that implements the Mac’n’Cheese protocol
              \[ [33](https://arxiv.org/html/2502.07063v1#bib.bib33 "")\], a Vector
              Oblivious Linear Evaluation (VOLE)-based zero-knowledge protocol over
              the ℤ2ksubscriptℤsuperscript2𝑘\\mathbb{Z}\_{2^{k}}blackboard\_Z start\_POSTSUBSCRIPT
              2 start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT end\_POSTSUBSCRIPT
              ring. Similar to Mozℤ2ksubscriptℤsuperscript2𝑘\\mathbb{Z}\_{2^{k}}blackboard\_Z
              start\_POSTSUBSCRIPT 2 start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT
              end\_POSTSUBSCRIPTarella, this is a crucial step in making ZKPs more
              practical, as most real-world compute hardware operates on integer rings,
              and not finite fields. Diet Mac’n’Cheese makes many improvements to
              the state-of-the-art in VOLE-based ZK protocols by optimizing the underlying
              sVOLE subprotocol. This optimization yields significant performance
              improvements over prior VOLE protocols that operate over integer rings.
              The provided implementation comes in the form of a C++ package that
              directly implements the proposed scheme and uses the Swanky ecosystem
              \[ [69](https://arxiv.org/html/2502.07063v1#bib.bib69 "")\] for easy
              integration. This framework is still in its early stages of development
              and currently lacks extensive documentation and concrete examples, making
              it harder for new ZKP developers to use it. Alongside this, Diet Mac’n’Cheese
              currently only supports fixed-point integer operations. It exposes a
              low-level API that requires a developer to explicitly define all computations
              as arithmetic and boolean gates that are operated on using the framework’s
              provided functions. However, a recent work has introduced a Python frontend
              with great documentation that can translate Python code into an intermediate
              representation that is recognized by the Diet Mac’n’Cheese framework.
              This frontend, entitled PicoZK \[ [6](https://arxiv.org/html/2502.07063v1#bib.bib6
              "")\], contains many examples and is even able to integrate with the
              popular numpy and pandas packages. PicoZK is a perfect pairing with
              Diet Mac’n’Cheese and allows for the development of simple applications.
              We recommend this framework to any developer that aims to build a scalable
              application that is conducive to a designated-verifier environment,
              such as federated or split learning. We do note that any floating point
              operations that are done with this framework must be converted to fixed-point.


              Report issue for preceding element


              emp-zk.

              The emp-zk development framework \[ [136](https://arxiv.org/html/2502.07063v1#bib.bib136
              "")\] is a part of the emp-toolkit\[ [135](https://arxiv.org/html/2502.07063v1#bib.bib135
              "")\], a collection of cryptographic front-ends and back-ends that allow
              for easy development of multi-party computation applications. Alongside
              ZKPs, emp-toolkit also provides libraries for garbled circuits and oblivious
              transfer. emp-zk has implementations of three novel interactive ZK systems:


              Report issue for preceding element


              - •



              Wolverine \[ [138](https://arxiv.org/html/2502.07063v1#bib.bib138 "")\],
              the first of these systems, presents a constant-round, scalable, and
              prover-efficient interactive ZK scheme.


              Report issue for preceding element


              - •



              Mystique \[ [139](https://arxiv.org/html/2502.07063v1#bib.bib139 "")\],
              built on top of Wolverine, focuses on machine learning applications.
              This work presents efficient conversions for arithmetic and boolean
              values, fixed-point and floating-point values, and committed and authenticated
              values.


              Report issue for preceding element


              - •



              Quicksilver \[ [141](https://arxiv.org/html/2502.07063v1#bib.bib141
              "")\], also built on top of Wolverine, further improves communication
              costs and scalability.


              Report issue for preceding element



              The main primitive these schemes take advantage of is subfield Vector
              Oblivious Linear Evaluation (sVOLE), which the authors extend and optimize
              for their ZK scheme.

              For sake of brevity, we spare the technical detail in this paper and
              refer to \[ [137](https://arxiv.org/html/2502.07063v1#bib.bib137 "")\]
              for an excellent explanation. emp-zk provides a very user-friendly interface
              to all 3 ZK systems, with clear-cut examples. Although documentation
              is not explicitly provided, emp-zk largely relies on C++ syntax and
              does not require much knowledge about the underlying work in ZKPs, making
              it one of the more accessible options. One potential downside of these
              systems are that they are interactive, meaning all proofs are designated-verifier.
              We highly recommend this framework for users who are building custom
              machine learning-based custom applications that rely on floating-point
              operations, or applications that rely on scalability (e.g. database
              operations).


              Report issue for preceding element


              Mozℤ2ksubscriptℤsuperscript2𝑘\\mathbb{Z}\_{2^{k}}blackboard\_Z start\_POSTSUBSCRIPT
              2 start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT end\_POSTSUBSCRIPTarella.

              This work \[ [32](https://arxiv.org/html/2502.07063v1#bib.bib32 "")\]
              presents a new protocol that utilizes an novel vector oblivious linear
              evaluation (VOLE), a tool from secure two-party computation, extension
              to perform zero knowledge proof operations efficiently over the integer
              ring ℤ2ksubscriptℤsuperscript2𝑘\\mathbb{Z}\_{2^{k}}blackboard\_Z start\_POSTSUBSCRIPT
              2 start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT end\_POSTSUBSCRIPT.
              This is very important as most ZK systems are made to operate over finite
              fields, which is not representative of modern CPUs. The proof system
              is coined with the term Quarksilver. This protocol outperforms the previous
              state-of-the-art VOLE-based works that operate over finite fields. The
              accompanying implementation enables development of ZK applications with
              the Quarksilver protocol as the underlying scheme. The Mozℤ2ksubscriptℤsuperscript2𝑘\\mathbb{Z}\_{2^{k}}blackboard\_Z
              start\_POSTSUBSCRIPT 2 start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT
              end\_POSTSUBSCRIPTarella repository is not actively maintained, however
              has 3 sub-libraries for oblivious transfer, garbled and arithmetic circuits,
              and private set-intersection. Within these sub-libraries there are several
              examples that explain how to use the Mozℤ2ksubscriptℤsuperscript2𝑘\\mathbb{Z}\_{2^{k}}blackboard\_Z
              start\_POSTSUBSCRIPT 2 start\_POSTSUPERSCRIPT italic\_k end\_POSTSUPERSCRIPT
              end\_POSTSUBSCRIPTarella syntax, including examples for Quarksilver.
              While the examples are somewhat clear, using this library to build custom
              applications requires a deep knowledge of the underlying proof system,
              as users must be aware of the parameters that are being set on a per
              application basis. We only recommend this to users who’s applications
              fully rely on using the specific underlying protocol in this framework.


              Report issue for preceding element


              ### III-Dzk-STARKs


              Report issue for preceding element


              Miden VM.Miden VM\[ [20](https://arxiv.org/html/2502.07063v1#bib.bib20
              "")\] is a zero-knowledge virtual machine (zkVM) implemented in Rust,
              in which all programs that are run generate a zk-STARK that can be verified
              by anyone.

              Miden VM is designed as a stack machine, consisting of a stack, memory,
              chiplets, and a host. The stack, the main user-facing component, is
              a push-down stack of field elements, which is where inputs and outputs
              of operations are stored. Increasing the amount of inputs that are initialized
              on the stack before program execution increases the verifier cost. Whatever
              is left on the stack after program computation is declared as a public
              input to the verifier, which also increases cost to the verifier. A
              prover’s private inputs must be pushed to the stack during program computation
              to be kept private.

              The aim of Miden VM is, in their own words, to ”make Miden VM an easy
              compilation for high-level languages such as Rust” \[ [18](https://arxiv.org/html/2502.07063v1#bib.bib18
              "")\]. As these compilers do not yet exist, the only way to build custom
              circuits is using Miden’s assembly language, a very low-level API that
              interfaces with the Miden stack, and Miden chiplets, which are optimized
              assembly-based modules that perform common operations, like field arithmetic.
              Although Miden VM is Turing complete and offers standard control flow,
              it is often challenging for a developer to translate their desired computation
              to assembly commands and managing the stack at the same time, especially
              as the size of computation scales up. While Miden VM is a very valuable
              tool, we believe that its highest potential will be achieved upon completion
              of an accompanying compiler from a high-level language to Miden assembly.
              We recommend that users use this to benchmark certain atomic operations,
              but to avoid building custom applications with this framework due to
              the lack of a frontend.


              Report issue for preceding element


              Zilch.

              The Zilch framework \[ [103](https://arxiv.org/html/2502.07063v1#bib.bib103
              "")\] consists of a Java-like frontend (ZeroJava) that interfaces with
              a novel zero-knowledge MIPS processor model (zMIPS) \[ [130](https://arxiv.org/html/2502.07063v1#bib.bib130
              "")\] to enable efficient interactive zk-STARK proof generation for
              custom computations. The ZeroJava frontend is highly sophisticated and
              is one of the only frameworks to enable an object-oriented programming
              approach. All ZeroJava programs are compiled into optimized and verifiable
              zMIPS instructions. As all of the instructions are verifiable, any program
              that can be expressed in ZeroJava can be verified using ZKPs. The underlying
              zMIPS processor can implement and verify any arbitrary computation in
              zero-knowledge. The zMIPS instructions are implemented using the zk-STARK
              library \[ [38](https://arxiv.org/html/2502.07063v1#bib.bib38 "")\].
              After computation description in ZeroJava and compilation to zMIPS,
              the constraints for the program are represent in algebraic intermediate
              representation (AIR) format. The prover and verifier interactively undergo
              the zk-STARK process until the verifier is convinced that the prover’s
              work is sound.

              Zilch provides an elegant and accessible approach to building custom
              circuits that utilize zk-STARKs. Although the works lacks dedicated
              documentation, the examples that are provided show that development
              of custom applications is almost as simple as implementing the program
              in Java, with a few ZeroJava design considerations. We recommend this
              for users with general knowledge of the MIPS instruction set architecture,
              which should allow them to build optimized programs.


              Report issue for preceding element


              RISC Zero.RISC Zero is a zkVM \[ [112](https://arxiv.org/html/2502.07063v1#bib.bib112
              "")\] implemented in Rust with an underlying RISC-V processor and instruction
              set architecture. The goal of this work is to produce publicly verifiable
              proofs of all the computations that are done within the framework. As
              the underlying instructions are derived from RISC-V, virtually any arbitrary
              computation can be expressed and verified in zero-knowledge.

              In this framework, custom circuits can be built using standard Rust
              syntax, with a few minor modifications to incorporates the framework’s
              API. This program is compiled to a set of RISC-V instructions, which
              is then executed within a RISC Zero session, which is recorded. A receipt
              of this session is recorded and used as part of the zk-STARK proof,
              which can be verified by any verifier to check validity of the computation.

              RISC Zero provides a relatively readable high-level Rust API, alongside
              several examples and very detailed documentation. Due to the maturity
              of the Rust development and RISC Zero as a whole, developers are able
              to import a majority of the most used standard Rust crates without trouble,
              enabling much more streamlined and efficient application development.
              For instance, developers can use the JPG crate \[ [16](https://arxiv.org/html/2502.07063v1#bib.bib16
              "")\] to build zero-knowledge applications around images. Alongside
              this, RISC Zero enables GPU acceleration, so that relevant applications
              can take advantage of computational speedup. We do note that although
              GPU acceleration is implemented in the RISC Zero codebase, we were not
              able to get it actually working due to some inconsistencies within the
              codebase. However, RISC Zero has an active community around it, including
              active development by the creators, and a very well-documented and accessible
              code, making it a great candidate for new developers of custom ZKP applications.
              The primary drawback for this framework is that, due the nature of zkVMs
              and the simulation of a RISC-V processor and ISA, this framework has
              relatively significant initialization and operation costs.


              Report issue for preceding element


              ## IV Experimental Evaluation


              Report issue for preceding element


              |     |     |     |     |     |     |     |     |     |

              | --- | --- | --- | --- | --- | --- | --- | --- | --- |

              |  | Matrix Multiplication | SHA-256 |

              | Framework | Setup (ms) | Prover (ms) | Comm./Proof Size | Verifier
              (ms) | Setup (ms) | Prover (ms) | Comm./Proof Size | Verifier (ms) |

              |  | zk-SNARKs |

              | Arkworks (Groth16) \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26
              "")\] | 31.939 | 45.665 | 128 B | 2.553 | 334.562 | 566.634 | 128 B
              | 1.310 |

              | Arkworks (Marlin) \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26
              "")\] | 31.939 | 45.665 | 128 B | 2.553 | Unsupported operands |

              | Gnark (Groth16) \[ [49](https://arxiv.org/html/2502.07063v1#bib.bib49
              "")\] | 182.896 | 37.449 | 164 B | 1.848 | 1154.924 | 149.497 | 164
              B | 1.447 |

              | Gnark (PLONK-FRI) \[ [49](https://arxiv.org/html/2502.07063v1#bib.bib49
              "")\] | 1291.463 | 1444.085 | -222We could not measure proof size for
              this framework | 2.594 | 135458.192 | 145301.453 | -3 | 5.252 |

              | Gnark (PLONK-KZG) \[ [49](https://arxiv.org/html/2502.07063v1#bib.bib49
              "")\] | 47.396 | 21.638 | 552 B | 2.554 | 2806.739 | 635.682 | 552 B
              | 2.018 |

              | Zokrates (Groth16) \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26
              "")\] | 609 | 622 | 128 B | 310 | 1265 | 1296 | 128 B | 190 |

              | Zokrates (GM17) \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26
              "")\] | 782 | 807 | 96 B | 240 | 1411 | 1465 | 96 B | 180 |

              | Hyrax \[ [2](https://arxiv.org/html/2502.07063v1#bib.bib2 "")\] |
              - | 4687.244 | 315 B | 317.408 | - | 5497.327 | 59.904 KB | 484.598
              |

              | LibSNARK \[ [4](https://arxiv.org/html/2502.07063v1#bib.bib4 "")\]
              | 160.3 | 179.547 | 127.375 B | 0.895 | 1579.5 | 588.2 | 127.375 B |
              0.9 |

              | PySNARK \[ [7](https://arxiv.org/html/2502.07063v1#bib.bib7 "")\]
              | 1781.331 | 266.899 | 127.375 B | 4.561 | 31809.606 | 8006.642 | 127.375
              B | 4.667 |

              | SnarkJS (Groth16) \[ [34](https://arxiv.org/html/2502.07063v1#bib.bib34
              "")\] | 3113 | 1410 | 802 B | 804 | 29100 | 1919 | 805 B | 637 |

              | SnarkJS (PLONK) \[ [34](https://arxiv.org/html/2502.07063v1#bib.bib34
              "")\] | 190632 | 282897 | 2.247 KB | 686 | 205550 | 378833 | 2.245 KB
              | 670 |

              | Noir \[ [17](https://arxiv.org/html/2502.07063v1#bib.bib17 "")\] |
              6972.139333 | 2.368 KB | 6037.378 | 10508.3432 | 2.368 KB | 1154.979
              |

              |  | VOLE-based ZK |

              | Emp-ZK \[ [136](https://arxiv.org/html/2502.07063v1#bib.bib136 "")\]
              | 596.118 | 1.917 | 595.004 KB | 16.483 | 522.763 | 90.302 | 212.709
              KB | 38.112 |

              | Diet Mac’n’Cheese \[ [1](https://arxiv.org/html/2502.07063v1#bib.bib1
              "")\] | 3817.626 | 4411.310 | 7.005 MB | 2397.265 | 3754.559 | 4861.536
              | 3.558 MB | 4863.095 |

              |  | MPC-in-the-Head |

              | Limbo \[ [92](https://arxiv.org/html/2502.07063v1#bib.bib92 "")\]
              | - | 96690.593 | 7.617802 MB | 72999.073 | - | 1129.368 | 113.57 KB
              | 879.399 |

              |  | zk-STARKs |

              | MidenVM \[ [20](https://arxiv.org/html/2502.07063v1#bib.bib20 "")\]
              | Memory overflow for this benchmark | - | 514 | 71KB | 11 |

              | RISC Zero \[ [112](https://arxiv.org/html/2502.07063v1#bib.bib112
              "")\] | - | 57268.609 | 279.640 KB | 59.058 | - | 4196.679 | 215.348
              KB | 44.918 |


              TABLE IV: ZK Framework Performance. 2 Noir only allows us to measure
              setup and prover time together. 3 PLONK-FRI did not allow for accurate
              proof measurementReport issue for preceding element


              ### IV-AConfiguration


              Report issue for preceding element


              For all experiments, we build custom Docker environments that setup
              all dependencies and import all necessary programs to enable reproducible
              results. All reported results are the mean of 10 test runs. Benchmarking
              is done on a 128GB RAM, AMD Ryzen 3990X CPU desktop.


              Report issue for preceding element


              ### IV-BExperimental Setup


              Report issue for preceding element


              This paper is focused on the usability and accessibility of ZKP frameworks
              and, more importantly, aims to serve as a guide to developers of novel
              ZKP-based applications. Our goal with this work is to allow new developers
              to have a full overview of the ZK development landscape after reading
              it. More importantly, we aim to provide a developer with the necessary
              insights to allow them to choose the framework that best suits their
              desired ZK-based application. Due to this developer-focused approach,
              we weed out some of the frameworks that we discuss in section [III](https://arxiv.org/html/2502.07063v1#S3
              "III ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey"), due
              to the overhead that would be required for a new developer to build
              a custom circuit. This is not meant in a malicious manner to say the
              framework is not usable - these frameworks are state-of-the-art and
              provide excellent results. We simply are focused on frameworks that
              expose higher-level APIs, or can be easily integrated behind accessible
              frontends, for streamlined custom application development. Simply put,
              all the works discussed in section [III](https://arxiv.org/html/2502.07063v1#S3
              "III ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey") are
              fantastic, and we highlight them as the best in the field. While some
              are missing a high-level API or frontend, they provide great value to
              the landscape. We still include their development environments with
              examples in our open-source repository to allow more experienced ZKP
              developers to easily access them and build applications with them.


              Report issue for preceding element


              While we recognize that there is no completely fair way to benchmark
              these, we aim to do so by measuring the trusted setup (when applicable)
              and proof generation and verification runtimes, alongside communication
              for interactive protocols and proof size for non-interactive protocols.
              These are standard efficiency measures for ZKPs \[ [39](https://arxiv.org/html/2502.07063v1#bib.bib39
              "")\]. While these quantitative results may not paint the whole picture,
              such as memory consumption and bandwidth considerations, we believe
              that they provide measurable proof of algorithmic complexity when independently
              benchmarked in the same isolated environment. We encourage readers to
              recreate our benchmarks, which are provided in our open-source repository,
              to gauge performance on their available hardware. To provide a rough
              estimate of the size of our benchmarks, we perform arithmetization to
              compile the benchmarks to R1CS format, and report the number of constraints
              of each circuit. Constraints are used often in ZK literature to describe
              the size of a ZK circuit. We evaluate the frameworks on the following
              benchmarks:


              Report issue for preceding element


              32×\\times×32 Matrix Multiplication: The prover aims to convince the
              verifier that they know two private matrices 𝑨32×32superscript𝑨3232\\bm{\\mathit{A^{32\\times
              32}}}bold\_italic\_A start\_POSTSUPERSCRIPT bold\_italic\_32 bold\_×
              bold\_italic\_32 end\_POSTSUPERSCRIPT and 𝑩32×32superscript𝑩3232\\bm{\\mathit{B^{32\\times
              32}}}bold\_italic\_B start\_POSTSUPERSCRIPT bold\_italic\_32 bold\_×
              bold\_italic\_32 end\_POSTSUPERSCRIPT that multiply to a public matrix
              𝑪32×32superscript𝑪3232\\bm{\\mathit{C^{32\\times 32}}}bold\_italic\_C
              start\_POSTSUPERSCRIPT bold\_italic\_32 bold\_× bold\_italic\_32 end\_POSTSUPERSCRIPT,
              without revealing anything about 𝑨𝑨\\bm{\\mathit{A}}bold\_italic\_A
              or 𝑩𝑩\\bm{\\mathit{B}}bold\_italic\_B. This is a commonly used benchmark
              in this domain. This circuit is not too large and should be handled
              relatively easily by most frameworks, although some frameworks struggle
              with it due to memory issues. In R1CS format, this benchmark consists
              of 32,768 constraints.


              Report issue for preceding element


              SHA-256:

              The prover aims to convince the verifier that they know x𝑥xitalic\_x,
              a private 512-bit preimage, to the 2-to-1 hash function SHA-256(x)=y𝑥𝑦(x)=y(
              italic\_x ) = italic\_y, where y𝑦yitalic\_y is a public 256-bit hashed
              value. This is quite a large circuit, compared to the matrix multiplication
              circuit. Some frameworks target this operation as one to optimize. We
              choose to evaluate on this benchmark as we believe it provides a good
              representation of a framework’s performance, and it is a commonly used
              benchmark in this domain. In R1CS format, this benchmark consists of
              59, 281 constraints.


              Report issue for preceding element


              ### IV-CResults & Takeaways


              Report issue for preceding element


              While we provide streamlined workflows for building custom applications
              for almost all frameworks that are discussed in section [III](https://arxiv.org/html/2502.07063v1#S3
              "III ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey"), we
              narrow down our evaluation to frameworks that provide a novel, usable,
              and accessible approach for developing custom applications. Some frameworks,
              such as Gnark and SnarkJS, provide PLONK and zk-SNARK backends, so we
              evaluate our benchmarks on both backends. Overall, we analyze 18 systems
              for performance on our selected benchmarks. In this section, we discuss
              the implications of these results and the takeaways for developers.
              Alongside this, we provide recommendations for which frameworks or protocols
              are best to use in certain settings. The results can be seen in Table
              [IV](https://arxiv.org/html/2502.07063v1#S4.T4 "TABLE IV ‣ IV Experimental
              Evaluation ‣ Zero-Knowledge Proof Frameworks: A Survey").


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2502.07063v1/x1.png)(a) Scaling
              of trusted setup runtime.Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2502.07063v1/x2.png)(b) Scaling
              of proof generation runtime.Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2502.07063v1/x3.png)(c) Scaling
              of proof size (or communication in Emp-ZK’s case).Report issue for preceding
              element


              ![Refer to caption](https://arxiv.org/html/2502.07063v1/x4.png)(d) Scaling
              of proof verification runtime.Report issue for preceding element


              Figure 1: Analysis of scalability of select frameworks over matrix multiplication
              benchmarks spanning 8×8888\\times 88 × 8 matrix size, resulting in 64
              constraints, up to 128×128128128128\\times 128128 × 128 matrix size,
              resulting in 2,097,152 constraints.Report issue for preceding element


              In figure [1](https://arxiv.org/html/2502.07063v1#S4.F1 "Figure 1 ‣
              IV-C Results & Takeaways ‣ IV Experimental Evaluation ‣ Zero-Knowledge
              Proof Frameworks: A Survey"), we perform an extensive scalability test
              on a subset of our evaluated frameworks to show how the trusted setup,
              proof generation and verification, and proof size/communication all
              scale as computation grows. We only do this for the matrix multiplication
              benchmark to avoid redundancies, and we believe it is sufficiently indicative
              of the framework’s scalability. The subset of frameworks is chosen due
              to their promising performance, outlined in section [IV-C](https://arxiv.org/html/2502.07063v1#S4.SS3
              "IV-C Results & Takeaways ‣ IV Experimental Evaluation ‣ Zero-Knowledge
              Proof Frameworks: A Survey"), and their ability to handle large circuits.
              Also, some frameworks that were evaluated in section [IV-C](https://arxiv.org/html/2502.07063v1#S4.SS3
              "IV-C Results & Takeaways ‣ IV Experimental Evaluation ‣ Zero-Knowledge
              Proof Frameworks: A Survey") ran into memory overflow issues on our
              machine as circuits scaled.


              Report issue for preceding element


              We found that proof size/communication and proof verification stay relatively
              constant for zk-SNARKs and Gnark’s PLONK implementation. Proof size
              and verification time follow very similar curves in the case of both
              Emp-ZK and RISC Zero. Most trusted setup times and proof generation
              times follow similar trajectories as circuits scale, except for Emp-ZK,
              which stays relatively constant. Diet Mac’n’Cheese provided us with
              interesting results that seem to separate it quite a bit from Emp-ZK,
              although they are both VOLE-based ZK solutions. Upon further inspection,
              we found that the only frontend that is available, PicoZK, serves as
              the main bottleneck. PicoZK compiles everything to the DARPA SIEVE Intermediate
              Representation (IR), which can be read by Diet Mac’n’Cheese. However,
              Diet Mac’n’Cheese is not optimized for operations presented in SIEVE
              IR format, which is why the presented scalability results make it seem
              like a less performant candidate. Upon our own code review and discussion
              with the PicoZK authors, we believe that further work into building
              a direct bridge between PicoZK and Diet Mac’n’Cheese can result in results
              that are much closer to Emp-ZK, while still being able to take advantage
              of PicoZK’s extremely user-friendly development process. RISC Zero’s
              proof generation time is several orders of magnitude larger than the
              other evaluated frameworks, however we believe this is due to it’s nature
              as a zkVM, which requires extra underlying RISC-V-based operations to
              perform these tasks. Finally, we observe that zk-SNARKs exhibit essentially
              the same pattern of growth as circuits scale. PySNARK proof generation
              time grows drastically with circuit size, but we believe this is due
              to Python’s compilation process, which results in slower runtimes. We
              highlight Emp-ZK, Arkworks, and Gnark’s zk-SNARK and PLONK implementation
              as excellent scalable frameworks for custom applications.


              Report issue for preceding element


              Takeaways. One of the main observations we make is the prevalance of
              usable zk-SNARK frameworks compared to all other constructions, and
              the lack of available tools for building systems with MPCitH ZKPs. This
              is primarily attributed to the fact that MPCitH ZKPs are primarily an
              academia-driven concept, meaning that the developers of the frameworks
              are not as concerned with commercialization, which naturally puts developer
              usability and accessibility to the wayside.

              We also find that there is a lack of accessible dedicated PLONK-based
              Zk-SNARK frameworks. This is most likely due to the arithmetic and cryptographic
              flexibility that are attributed with PLONKs. Rather than building a
              dedicated PLONK framework, many developers, such as the developers of
              SnarkJS and Gnark, simply modify their frameworks to also support PLONK
              proving systems. As for zk-STARKs, we show that there are only a few
              accessible frameworks that can be utilized by developers. We do want
              to note that these frameworks are excellent, with a majority providing
              extensive documentation and very accessible frontends and APIs for those
              experienced with applied cryptography.


              Report issue for preceding element


              In our evaluation, we aim to keep settings (e.g. ECC curve, bitwidths,
              etc.) consistent between experiments as much as the frameworks allow
              us.

              Nevertheless, it is not possible or fair to compare all of these frameworks
              to each other and choose a single best one, as each different type of
              ZKP (zk-SNARKs, MPCitH, etc.) is built with different cryptographic,
              interactivity, and trusted setup assumptions. Rather, we analyze the
              results and discuss what application settings would benefit from each
              type of ZKP, and what frameworks can be used to realize those applications:


              Report issue for preceding element


              zk-SNARKs:  Building an application powered by zk-SNARKs requires a
              computationally strong prover and trusted third party (for trusted setup),
              due to the underlying elliptic curve cryptographic assumption. As trusted
              setup parameters must be recomputed for every new circuit, zk-SNARKs
              are ideal when the computation remains relatively static. The perk of
              zk-SNARKs is that the proof size is succinct and somewhat constant and
              proofs are publicly-verifiable. zk-SNARKS are ideal for settings that
              are bandwidth-constrained and/or have resource-constrained verifiers.
              For building custom zk-SNARK-based applications, we recommend Arkworks
              or Gnark. These works provide excellent documentation, active development
              communities and forums, and many examples that can guide developers,
              while still maintaining competitive runtime and succinct proofs.


              Report issue for preceding element


              PLONKs have also proven to be a valuable tool for cryptographers, serving
              as the basis for some interesting applications \[ [21](https://arxiv.org/html/2502.07063v1#bib.bib21
              "")\]. Due to the cryptographic flexibility, PLONKs are ideal for applications
              where available bandwidth and computation may require switching underlying
              cryptography. Alongside this, applications that can benefit from a single,
              versatile trusted setup are ideal candidates for PLONK-based design.
              For building custom PLONK-based applications, we recommend GNARK-KZG.
              The implementations provided in Gnark’s FRI and SnarkJS are valuable,
              however, as can be seen by the benchmarked results, they are not the
              most efficient. Noir offers detailed documentation and many examples,
              coupled with an active development community that are constantly presenting
              new applications built with Noir \[ [106](https://arxiv.org/html/2502.07063v1#bib.bib106
              "")\], however is outperformed by GNARK-KZG. We do note that Noir is
              also a fantastic option for developers. However, GNARK-KZG achieves
              excellent performance with an easily accessible API.


              Report issue for preceding element


              VOLE-based ZK:  Options for building VOLE-based ZK systems are admittedly
              limited, and the evaluations do not paint the full picture, as the presented
              runtimes are the amount of time that the prover and verifier must stay
              online, rather than time spent actively computing. VOLE-based ZK is
              an excellent candidates for custom applications when the setting naturally
              requires communication, such as distributed learning or the IoT, especially
              because they do not require trusted setup. These protocols also distribute
              the computational load between the prover and the verifier, rather than
              putting all of the work on the prover. For building custom VOLE-based
              ZK applications, we recommend Emp-ZK. This work provides great examples
              and readable C++ code, but most importantly, it supports arithmetic,
              Boolean, and mixed computation. Most importantly, due to the inclusion
              of Boolean circuit evaluation, this framework also supports floating
              point operations, which is not done by any other frameworks that we
              discuss. Although Diet Mac’n’Cheese, paired with PicoZK, is also a great
              solution, it still requires a bit more development before it is ready
              for application development without too many limitations (e.g. floating
              point support). However, we do note that this pairing can be used with
              quite an efficient development process, as it solely relies on readable
              Python code. Although it does present rather slow prover and verification
              times, we would like to emphasize that this is due to PicoZK’s compilation
              process being reliant on the SIEVE intermediate representation (IR)
              \[ [9](https://arxiv.org/html/2502.07063v1#bib.bib9 "")\]. Diet Mac’n’Cheese
              can operate over SIEVE IR files, but it has not been completely optimized
              for this process yet. While this is not a direct reflection of Diet
              Mac’n’Cheese performance, we believe it is currently the only solution
              to properly build ZKPs using the underlying Diet Mac’n’Cheese proof
              system. Nevertheless, the pairing of Diet Mac’n’Cheese with PicoZK provides
              the easiest route towards developing relatively complex applications
              that we have encountered through writing this paper.


              Report issue for preceding element


              MPCitH.

              Once again, the options for building MPCitH ZKPs are quite limited.
              MPCitH ZKPs have most prominently been used in digital signatures \[
              [110](https://arxiv.org/html/2502.07063v1#bib.bib110 ""), [25](https://arxiv.org/html/2502.07063v1#bib.bib25
              ""), [116](https://arxiv.org/html/2502.07063v1#bib.bib116 "")\],, however,
              there are not many general-purpose frameworks available. For the purpose
              of this work, Limbo is the most accessible general-purpose framework
              for developing MPCitH ZK-based applications. This requires a baseline
              knowledge of Bristol fashion circuits \[ [128](https://arxiv.org/html/2502.07063v1#bib.bib128
              "")\], as this is how any computation 𝒞𝒞\\mathcal{C}caligraphic\_C is
              described in Limbo. However, once this hurdle is overcome, Limbo is
              a straightforward framework for building efficient MPCitH ZKPs. The
              main shortcoming of Limbo is its lack of support for anything but Boolean
              computation, which is why it performed poorly on the matrix multiplication
              benchmark.


              Report issue for preceding element


              zk-STARKs:  zk-STARKs have the potential to be an excellent solution
              for applications aiming to integrate ZKPs, however not many academic
              works have started integrating them into their applications, due to
              their relative nascency. Due to their lack of trusted setup and post-quantum,
              lightweight cryptography, they serve as great candidates for applications
              with strong provers and enough bandwidth to support proof transmission.

              For building custom zk-STARK-based applications, we recommend RISC Zero.

              Zilch is another fantastic framework, however caused memory overflow
              for both of our benchmarks, which is why we do not consider it here.

              RISC Zero is the main offering from a startup, meaning the documentation
              is extensive and the framework is very well-developed. The main advantage
              of this framework is its ability to integrate with standard Rust crate
              easily, while still maintaining acceptable performance metrics. While
              the performance is a bit worse than Miden VM, it also do not require
              as much memory as Miden VM does, which caused memory overflow on a powerful
              server.


              Report issue for preceding element


              To accompany our suggestions, and to also take resource availability
              into account, figure [2](https://arxiv.org/html/2502.07063v1#S4.F2 "Figure
              2 ‣ IV-C Results & Takeaways ‣ IV Experimental Evaluation ‣ Zero-Knowledge
              Proof Frameworks: A Survey") provides a flow chart that developers can
              use to find the perfect framework for their applications, based on available
              resources and preferences. We note that most frameworks that we discuss
              in this survey can be used as solutions for building ZKP applications,
              however we believe that the highlighted frameworks in figure [2](https://arxiv.org/html/2502.07063v1#S4.F2
              "Figure 2 ‣ IV-C Results & Takeaways ‣ IV Experimental Evaluation ‣
              Zero-Knowledge Proof Frameworks: A Survey") are the most promising and
              reliable.


              Report issue for preceding element


              ![Refer to caption](https://arxiv.org/html/2502.07063v1/x5.png)Figure
              2: Flow chart to guide users to the framework that best fits the requirements
              of their application and available resources.Report issue for preceding
              element


              ## V Discussion


              Report issue for preceding element


              ZKPs in their current state have been used in cutting-edge applications,
              but there still remains a long path towards practicality. We highlight
              the novel ZKP applications in-depth in Appendix [D](https://arxiv.org/html/2502.07063v1#A4
              "Appendix D ZKP Applications ‣ Zero-Knowledge Proof Frameworks: A Survey").
              The current challenges that hinder practical ZKP-based applications
              are three-fold:


              Report issue for preceding element


              Usability. As we’ve shown in this work, there are many, many great frameworks
              that enable the development of state-of-the-art ZKP, however the usability
              of many of them are hindered by their lack of a higher-level API or
              compatibility with a circuit description frontend, like Zokrates, Circom,
              or xJsnark. This makes the process of developing complex ZK-based applications
              much more difficult, as a user must learn the intricacies of a new protocol
              and the necessary syntax to take advantage of the promised performance.


              Report issue for preceding element


              Accessibility. Accessibility poses an issue, especially when evaluating
              academic frameworks. Academic frameworks often present state-of-the-art
              results, but normally lack documentation, examples, and other information
              that would allow for a user to replicate their results. This is not
              beneficial to the developers of the frameworks, as it presents a huge
              hurdle towards realizing the practicality of their proposed protocols
              in real-world applications. Frameworks that stem from industry are often,
              but not always, better in this respect, as the work is developed with
              a consumer in mind. The usability and accessibility issue can be solved
              by simply providing extensive documentation and attempting solutions
              that promote interoperability between similar frameworks. Another achievable
              solution is promoting communities where developers can discuss applications
              and solutions (e.g. Gitter). We acknowledge that there have been attempts
              to achieve interoperability for ZKP frameworks, such as CirC \[ [107](https://arxiv.org/html/2502.07063v1#bib.bib107
              "")\] and zkinterface \[ [42](https://arxiv.org/html/2502.07063v1#bib.bib42
              "")\], however there still remains a lot of work to be done.


              Report issue for preceding element


              Performance. Perhaps the most difficult problem with ZKPs to address
              is the computational overhead. The results we present in this work represent
              only tidbits of computation that would make up a full end-to-end ZK-based
              application. As can be seen, these state-of-the-art implementations
              still introduce a relatively large amount of overhead, even for simple
              tasks. This overhead only gets more overwhelming as applications get
              more complex. One realistic solution towards improving ZKP performance
              and reduce the computational overhead is hardware acceleration of state-of-the-art
              algorithms. This is a similar approach that is taken by the Intel HERACLES
              \[ [53](https://arxiv.org/html/2502.07063v1#bib.bib53 "")\], which is
              an attempt to build an end-to-end accelerator for FHE, with the goal
              of bringing FHE computation times down to the same order of magnitude
              as plaintext computation. One of the goals of this work is to provide
              a high-level overview of the state-of-the-art ZKP implementations, which
              is the first step toward identifying potential candidate protocols for
              acceleration. In addition to hardware acceleration, the continued exploration
              of algorithmic refinements and optimizations, such as the emerging research
              topic of GPU-based cryptographic optimizations \[ [98](https://arxiv.org/html/2502.07063v1#bib.bib98
              ""), [100](https://arxiv.org/html/2502.07063v1#bib.bib100 "")\], could
              lead to more efficient performance. There have also been solutions to
              propose custom hardware for end-to-end ZKP applications \[ [22](https://arxiv.org/html/2502.07063v1#bib.bib22
              ""), [120](https://arxiv.org/html/2502.07063v1#bib.bib120 "")\] and
              proof generation \[ [114](https://arxiv.org/html/2502.07063v1#bib.bib114
              ""), [61](https://arxiv.org/html/2502.07063v1#bib.bib61 "")\], however,
              they have not yet reached a stage of practicality.


              Report issue for preceding element


              The works highlighted in this paper represent the progression of algorithmic
              optimizations that have been instilled to bridge the gap between theory
              and practicality in the real-world application of ZKPs. While there
              are still significant hurdles that need to be overcome, many of them
              have actionable tasks, such as open-source framework developers providing
              clear examples and documentation, alongside an accessible API or general-purpose
              frontend compatibility. The future of ZKP lies in a collaborative effort
              across academia, industry, and the open-source community to address
              these challenges, leading to a landscape where ZKPs are not only theoretically
              profound but also a practically viable solution towards securing data
              and computations.


              Report issue for preceding element


              Our contributions toward this effort are this survey, alongside our
              provided open-source collection of development environments and accompanying
              examples for each framework, which will be actively maintained after
              publication of this paper. Our hope for this repository is to allow
              developers of new and existing frameworks to contribute Docker containers
              and examples programs upon release of their work. This provides a centralized
              hub for developers to test their custom applications on several different
              frameworks before making a final choice. The objective of this survey
              and accompanying repository is to demystify the ZK landscape for developers
              and new cryptographers and to significantly lower the barrier of entry
              to the field of ZKPs, while providing valuable insights as to which
              frameworks and constructions best suit their custom applications.


              Report issue for preceding element


              ## VI Acknowledgments


              Report issue for preceding element


              This work was supported by DARPA Proofs under grant number HR0011-23-1-0006.


              Report issue for preceding element


              ## References


              Report issue for preceding element


              - \[1\]↑

              Diet Mac’n’Cheese.

              https://github.com/GaloisInc/swanky/tree/dev/diet-mac-and-cheese.


              - \[2\]↑

              hyraxZK.

              https://github.com/hyraxZK/hyraxZK.


              - \[3\]↑

              LegoSNARK.

              https://github.com/imdea-software/legosnark/.


              - \[4\]↑

              libsnark.

              https://github.com/scipr-lab/libsnark.


              - \[5\]↑

              Mirage.

              https://github.com/akosba/mirage/tree/master.


              - \[6\]↑

              PicoZK.

              https://github.com/uvm-plaid/picozk.


              - \[7\]↑

              PySNARK.

              https://github.com/meilof/pysnark.


              - \[8\]↑

              RapidSNARK.

              https://github.com/iden3/rapidsnark.


              - \[9\]↑

              SIEVE Intermediate Representation.

              https://github.com/sieve-zk/ir.


              - \[10\]↑

              Spartan.

              https://github.com/microsoft/Spartan.


              - \[11\]↑

              The Ristretto Group.

              https://ristretto.group.


              - \[12\]↑

              Arithmetization schemes for zk-snarks, Jan. 2023.


              - \[13\]↑

              dusk-plonk - rust, 2023.


              - \[14\]↑

              The halo2 book, 2023.


              - \[15\]↑

              halo2.club, 2023.


              - \[16\]↑

              image, 2023.


              - \[17\]↑

              Introducing noir.

              https://noir-lang.org, 2023.


              - \[18\]↑

              Polygon miden vm overview, 2023.


              - \[19\]↑

              Zero-knowledge proof: Applications and use cases.

              https://chain.link/education-hub/zero-knowledge-proof-use-cases, 2023.


              - \[20\]↑

              0xPolygonMiden.

              miden-vm, 2023.


              - \[21\]↑

              0xPolygonZero.

              plonky2, 2023.


              - \[22\]↑

              A. Ahmed, N. Sheybani, D. Moreno, N. B. Njungle, T. Gong, M. Kinsy,
              and F. Koushanfar.

              Amaze: Accelerated mimc hardware architecture for zero-knowledge applications
              on the edge.

              arXiv preprint arXiv:2411.06350, 2024.


              - \[23\]↑

              M. Albrecht, L. Grassi, C. Rechberger, A. Roy, and T. Tiessen.

              Mimc: Efficient encryption and cryptographic hashing with minimal multiplicative
              complexity.

              Cryptology ePrint Archive, Paper 2016/492, 2016.

              https://eprint.iacr.org/2016/492.


              - \[24\]↑

              S. Ames, C. Hazay, Y. Ishai, and M. Venkitasubramaniam.

              Ligero: Lightweight sublinear arguments without a trusted setup.

              In Proceedings of the 2017 acm sigsac conference on computer and communications
              security, pages 2087–2104, 2017.


              - \[25\]↑

              N. Aragon, M. Bardet, L. Bidoux, J.-J. Chi-Domínguez, V. Dyseryn, T. Feneuil,
              P. Gaborit, A. Joux, M. Rivain, J.-P. Tillich, et al.

              Ryde specifications.

              2023.


              - \[26\]↑

              arkworks contributors.

              arkworks zksnark ecosystem, 2022.


              - \[27\]↑

              T. Ashur and S. Dhooghe.

              Marvellous: a stark-friendly family of cryptographic primitives.

              Cryptology ePrint Archive, 2018.


              - \[28\]↑

              AztecProtocol.

              barretenberg, 2023.


              - \[29\]↑

              L. Babai.

              Transparent (holographic) proofs.

              In Annual Symposium on Theoretical Aspects of Computer Science, pages
              525–534. Springer, 1993.


              - \[30\]↑

              K. A. Bamberger, R. Canetti, S. Goldwasser, R. Wexler, and E. J. Zimmerman.

              Verification dilemmas in law and the promise of zero-knowledge proofs.

              Berkeley Tech. LJ, 37:1, 2022.


              - \[31\]↑

              C. Baum, L. Braun, C. D. de Saint Guilhem, M. Klooß, E. Orsini, L. Roy,
              and P. Scholl.

              Publicly verifiable zero-knowledge and post-quantum signatures from
              vole-in-the-head.

              In Annual International Cryptology Conference, pages 581–615. Springer,
              2023.


              - \[32\]↑

              C. Baum, L. Braun, A. Munch-Hansen, and P. Scholl.

              Moz z 2 k arella: efficient vector-ole and zero-knowledge proofs over
              z 2 k.

              In Annual International Cryptology Conference, pages 329–358. Springer,
              2022.


              - \[33\]↑

              C. Baum, A. J. Malozemoff, M. B. Rosen, and P. Scholl.

              Mac’n’cheese: Zero-knowledge proofs for boolean and arithmetic circuits
              with nested disjunctions.

              In Advances in Cryptology–CRYPTO 2021: 41st Annual International Cryptology
              Conference, CRYPTO 2021, Virtual Event, August 16–20, 2021, Proceedings,
              Part IV 41, pages 92–122. Springer, 2021.


              - \[34\]↑

              J. Baylina.

              iden3/snarkjs, 2020.


              - \[35\]↑

              J. Baylina1 and M. Belle‘s.

              4-bit window pedersen hash on the baby jubjub elliptic curve.


              - \[36\]↑

              M. Bellés-Muñoz, M. Isabel, J. L. Muñoz-Tapia, A. Rubio, and J. Baylina.

              Circom: A circuit description language for building zero-knowledge applications.

              IEEE Transactions on Dependable and Secure Computing, 2022.


              - \[37\]↑

              E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev.

              Fast reed-solomon interactive oracle proofs of proximity.

              In 45th international colloquium on automata, languages, and programming
              (icalp 2018). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018.


              - \[38\]↑

              E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev.

              Scalable, transparent, and post-quantum secure computational integrity.

              Cryptology ePrint Archive, 2018.


              - \[39\]↑

              E. Ben-Sasson, A. Chiesa, M. Riabzev, N. Spooner, M. Virza, and N. P.
              Ward.

              Aurora: Transparent succinct arguments for r1cs.

              Cryptology ePrint Archive, Paper 2018/828, 2018.

              https://eprint.iacr.org/2018/828.


              - \[40\]↑

              E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza.

              Succinct {{\\{{Non-Interactive}}\\}} zero knowledge for a von neumann
              architecture.

              In 23rd USENIX Security Symposium (USENIX Security 14), pages 781–796,
              2014.


              - \[41\]↑

              R. Benadjila, T. Feneuil, and M. Rivain.

              Mq on my mind: Post-quantum signatures from the non-structured multivariate
              quadratic problem.

              In 2024 IEEE 9th European Symposium on Security and Privacy (EuroS&P),
              pages 468–485. IEEE, 2024.


              - \[42\]↑

              D. Benarroch, K. Gurkan, R. Kahat, A. Nicolas, and E. Tromer.

              zkinterface, a standard tool for zero-knowledge interoperability.

              In 2nd ZKProof Workshop. https://docs. zkproof. org/pages/standards/acceptedworkshop2/proposal–zk-interop-zkinterface.
              pdf, 2019.


              - \[43\]↑

              D. J. Bernstein.

              Curve25519: new diffie-hellman speed records.

              In Public Key Cryptography-PKC 2006: 9th International Conference on
              Theory and Practice in Public-Key Cryptography, New York, NY, USA, April
              24-26, 2006. Proceedings 9, pages 207–228. Springer, 2006.


              - \[44\]↑

              S. Bettaieb, L. Bidoux, V. Dyseryn, A. Esser, P. Gaborit, M. Kulkarni,
              and M. Palumbi.

              Perk: compact signature scheme based on a new variant of the permuted
              kernel problem.

              Designs, Codes and Cryptography, pages 1–27, 2024.


              - \[45\]↑

              Binance.

              What Is Zero-knowledge Proof and How Does It Impact Blockchain? — Binance
              Academy — academy.binance.com.

              https://academy.binance.com/en/articles/what-is-zero-knowledge-proof-and-how-does-it-impact-blockchain.


              - \[46\]↑

              N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer.

              Recursive composition and bootstrapping for snarks and proof-carrying
              data.

              In Proceedings of the forty-fifth annual ACM symposium on Theory of
              computing, pages 111–120, 2013.


              - \[47\]↑

              K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
              D. Ramage, A. Segal, and K. Seth.

              Practical secure aggregation for privacy-preserving machine learning.

              In proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
              Security, pages 1175–1191, 2017.


              - \[48\]↑

              E. Boo, J. Kim, and J. Ko.

              Litezkp: Lightening zero-knowledge proof-based blockchains for iot and
              edge platforms.

              IEEE Systems Journal, 16(1):112–123, 2021.


              - \[49\]↑

              G. Botrel, T. Piellard, Y. E. Housni, I. Kubjas, and A. Tabaie.

              Consensys/gnark: v0.9.0, Feb. 2023.


              - \[50\]↑

              S. Bowe, J. Grigg, and D. Hopwood.

              Recursive proof composition without a trusted setup.

              Cryptology ePrint Archive, 2019.


              - \[51\]↑

              L. Breidenbach, C. Cachin, B. Chan, A. Coventry, S. Ellis, A. Juels,
              F. Koushanfar, A. Miller, B. Magauran, D. Moroz, et al.

              Chainlink 2.0: Next steps in the evolution of decentralized oracle networks.

              2021.


              - \[52\]↑

              V. Buterin.

              Quadratic arithmetic programs: From zero to hero, 2023.


              - \[53\]↑

              R. Cammarota.

              Intel heracles: Homomorphic encryption revolutionary accelerator with
              correctness for learning-oriented end-to-end solutions.

              In Proceedings of the 2022 on Cloud Computing Security Workshop, pages
              3–3, 2022.


              - \[54\]↑

              M. Campanelli, D. Fiore, and A. Querol.

              Legosnark: Modular design and composition of succinct zero-knowledge
              proofs.

              In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications
              Security, pages 2075–2092, 2019.


              - \[55\]↑

              D. Čapko, S. Vukmirović, and N. Nedić.

              State of the art of zero-knowledge proofs in blockchain.

              In 2022 30th Telecommunications Forum (TELFOR), pages 1–4. IEEE, 2022.


              - \[56\]↑

              Celer Network.

              The pantheon of zero knowledge proof development frameworks (updated!),
              2023.


              - \[57\]↑

              Chainlink.

              Overview Of Zero-Knowledge Blockchain Projects — Chainlink — chain.link.

              https://chain.link/education-hub/zero-knowledge-proof-projects.


              - \[58\]↑

              A. Chiesa, Y. Hu, M. Maller, P. Mishra, N. Vesely, and N. Ward.

              Marlin: Preprocessing zksnarks with universal and updatable srs.

              In Advances in Cryptology–EUROCRYPT 2020: 39th Annual International
              Conference on the Theory and Applications of Cryptographic Techniques,
              Zagreb, Croatia, May 10–14, 2020, Proceedings, Part I 39, pages 738–768.
              Springer, 2020.


              - \[59\]↑

              A. Chiesa, D. Ojha, and N. Spooner.

              Fractal: Post-quantum and transparent recursive proofs from holography.

              Cryptology ePrint Archive, Paper 2019/1076, 2019.

              https://eprint.iacr.org/2019/1076.


              - \[60\]↑

              ConsenSys, Inc.

              gnark.

              https://docs.gnark.consensys.net/overview#gnark-is-fast, 2023.


              - \[61\]↑

              A. Daftardar, B. Reagen, and S. Garg.

              Szkp: A scalable accelerator architecture for zero-knowledge proofs.

              In Proceedings of the 2024 International Conference on Parallel Architectures
              and Compilation Techniques, pages 271–283, 2024.


              - \[62\]↑

              G. Danezis, C. Fournet, J. Groth, and M. Kohlweiss.

              Square span programs with applications to succinct nizk arguments.

              Cryptology ePrint Archive, Paper 2014/718, 2014.

              https://eprint.iacr.org/2014/718.


              - \[63\]↑

              C. D. de Saint Guilhem, E. Orsini, and T. Tanguy.

              Limbo: Efficient zero-knowledge mpcith-based arguments.

              Cryptology ePrint Archive, Paper 2021/215, 2021.

              https://eprint.iacr.org/2021/215.


              - \[64\]↑

              J. Eberhardt and S. Tai.

              Zokrates-scalable privacy-preserving off-chain computations.

              In 2018 IEEE International Conference on Internet of Things (iThings)
              and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber,
              Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData),
              pages 1084–1091. IEEE, 2018.


              - \[65\]↑

              M. Fang, X. Cao, J. Jia, and N. Gong.

              Local model poisoning attacks to {{\\{{Byzantine-Robust}}\\}} federated
              learning.

              In 29th USENIX security symposium (USENIX Security 20), pages 1605–1622,
              2020.


              - \[66\]↑

              B. Feng, L. Qin, Z. Zhang, Y. Ding, and S. Chu.

              Zen: An optimizing compiler for verifiable, zero-knowledge neural network
              inferences.

              Cryptology ePrint Archive, 2021.


              - \[67\]↑

              G. S. Gaba, M. Hedabou, P. Kumar, A. Braeken, M. Liyanage, and M. Alazab.

              Zero knowledge proofs based authenticated key agreement protocol for
              sustainable healthcare.

              Sustainable Cities and Society, 80:103766, 2022.


              - \[68\]↑

              A. Gabizon, Z. J. Williamson, and O. Ciobotaru.

              Plonk: Permutations over lagrange-bases for oecumenical noninteractive
              arguments of knowledge.

              Cryptology ePrint Archive, Paper 2019/953, 2019.

              https://eprint.iacr.org/2019/953.


              - \[69\]↑

              Galois, Inc.

              swanky: A suite of rust libraries for secure computation.

              https://github.com/GaloisInc/swanky, 2019.


              - \[70\]↑

              C. Ganesh, A. Nitulescu, and E. Soria-Vazquez.

              Rinocchio: Snarks for ring arithmetic.

              Journal of Cryptology, 36(4):41, 2023.


              - \[71\]↑

              R. Gennaro, C. Gentry, B. Parno, and M. Raykova.

              Quadratic span programs and succinct nizks without pcps.

              In Advances in Cryptology–EUROCRYPT 2013: 32nd Annual International
              Conference on the Theory and Applications of Cryptographic Techniques,
              Athens, Greece, May 26-30, 2013. Proceedings 32, pages 626–645. Springer,
              2013.


              - \[72\]↑

              Z. Ghodsi, M. Javaheripi, N. Sheybani, X. Zhang, K. Huang, and F. Koushanfar.

              zprobe: Zero peek robustness checks for federated learning.

              In Proceedings of the IEEE/CVF International Conference on Computer
              Vision, pages 4860–4870, 2023.


              - \[73\]↑

              O. Goldreich and Y. Oren.

              Definitions and properties of zero-knowledge proof systems.

              Journal of Cryptology, 7(1):1–32, 1994.


              - \[74\]↑

              S. Goldwasser, Y. T. Kalai, and G. N. Rothblum.

              Delegating computation: interactive proofs for muggles.

              Journal of the ACM (JACM), 62(4):1–64, 2015.


              - \[75\]↑

              S. Goldwasser, S. Micali, and C. Rackoff.

              The knowledge complexity of interactive proof-systems.

              In Providing sound foundations for cryptography: On the work of shafi
              goldwasser and silvio micali, pages 203–225. 2019.


              - \[76\]↑

              L. Grassi, D. Khovratovich, C. Rechberger, A. Roy, and M. Schofnegger.

              Poseidon: A new hash function for Zero-Knowledge proof systems.

              In 30th USENIX Security Symposium (USENIX Security 21), pages 519–535.
              USENIX Association, Aug. 2021.


              - \[77\]↑

              J. Groth.

              On the size of pairing-based non-interactive arguments.

              In M. Fischlin and J.-S. Coron, editors, Advances in Cryptology – EUROCRYPT
              2016, pages 305–326, Berlin, Heidelberg, 2016. Springer Berlin Heidelberg.


              - \[78\]↑

              J. Groth, M. Kohlweiss, M. Maller, S. Meiklejohn, and I. Miers.

              Updatable and universal common reference strings with applications to
              zk-snarks.

              Cryptology ePrint Archive, Paper 2018/280, 2018.

              https://eprint.iacr.org/2018/280.


              - \[79\]↑

              J. Groth and M. Maller.

              Snarky signatures: Minimal signatures of knowledge from simulation-extractable
              snarks.

              In Annual International Cryptology Conference, pages 581–612. Springer,
              2017.


              - \[80\]↑

              P. Grubbs, A. Arun, Y. Zhang, J. Bonneau, and M. Walfish.

              {{\\{{Zero-Knowledge}}\\}} middleboxes.

              In 31st USENIX Security Symposium (USENIX Security 22), pages 4255–4272,
              2022.


              - \[81\]↑

              U. Haböck.

              A summary on the fri low degree test.

              Cryptology ePrint Archive, 2022.


              - \[82\]↑

              M. Hastings, B. Hemenway, D. Noble, and S. Zdancewic.

              Sok: General purpose compilers for secure multi-party computation.

              In 2019 IEEE symposium on security and privacy (SP), pages 1220–1237.
              IEEE, 2019.


              - \[83\]↑

              D. Hopwood, S. Bowe, T. Hornby, N. Wilcox, et al.

              Zcash protocol specification.

              GitHub: San Francisco, CA, USA, 4(220):32, 2016.


              - \[84\]↑

              Ingonyama.

              Icicle: Gpu library for zk acceleration.


              - \[85\]↑

              Y. Ishai, E. Kushilevitz, R. Ostrovsky, and A. Sahai.

              Zero-knowledge from secure multiparty computation.

              In Proceedings of the thirty-ninth annual ACM symposium on Theory of
              computing, pages 21–30, 2007.


              - \[86\]↑

              A. Juels and F. Koushanfar.

              Props for machine-learning security.

              arXiv preprint arXiv:2410.20522, 2024.


              - \[87\]↑

              A. Kate, G. M. Zaverucha, and I. Goldberg.

              Constant-size commitments to polynomials and their applications.

              In Advances in Cryptology-ASIACRYPT 2010: 16th International Conference
              on the Theory and Application of Cryptology and Information Security,
              Singapore, December 5-9, 2010. Proceedings 16, pages 177–194. Springer,
              2010.


              - \[88\]↑

              J. Kilian.

              A note on efficient zero-knowledge proofs and arguments.

              In Proceedings of the twenty-fourth annual ACM symposium on Theory of
              computing, pages 723–732, 1992.


              - \[89\]↑

              A. Kosba, D. Papadopoulos, C. Papamanthou, and D. Song.

              {{\\{{MIRAGE}}\\}}: Succinct arguments for randomized algorithms with
              applications to universal {{\\{{zk-SNARKs}}\\}}.

              In 29th USENIX Security Symposium (USENIX Security 20), pages 2129–2146,
              2020.


              - \[90\]↑

              A. Kosba, C. Papamanthou, and E. Shi.

              xjsnark: A framework for efficient verifiable computation.

              In 2018 IEEE Symposium on Security and Privacy (SP), pages 944–961.
              IEEE, 2018.


              - \[91\]↑

              A. Kothapalli, S. Setty, and I. Tzialla.

              Nova: Recursive zero-knowledge arguments from folding schemes.

              In Annual International Cryptology Conference, pages 359–388. Springer,
              2022.


              - \[92\]↑

              KULeuven-COSIC.

              Limbo, 2023.


              - \[93\]↑

              S. Landau.

              Zero knowledge and the department of defense.

              Notices of the American Mathematical Society, 35(1):5–12, 1988.


              - \[94\]↑

              S. Lee, H. Ko, J. Kim, and H. Oh.

              vcnn: Verifiable convolutional neural network based on zk-snarks.

              Cryptology ePrint Archive, 2020.


              - \[95\]↑

              C. Lin, M. Luo, X. Huang, K.-K. R. Choo, and D. He.

              An efficient privacy-preserving credit score system based on noninteractive
              zero-knowledge proof.

              IEEE systems journal, 16(1):1592–1601, 2021.


              - \[96\]↑

              H. Lipmaa.

              Prover-efficient commit-and-prove zero-knowledge snarks.

              In Progress in Cryptology–AFRICACRYPT 2016: 8th International Conference
              on Cryptology in Africa, Fes, Morocco, April 13-15, 2016, Proceedings
              8, pages 185–206. Springer, 2016.


              - \[97\]↑

              T. Liu, X. Xie, and Y. Zhang.

              Zkcnn: Zero knowledge proofs for convolutional neural network predictions
              and accuracy.

              In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications
              Security, pages 2968–2985, 2021.


              - \[98\]↑

              T. Lu, C. Wei, R. Yu, C. Chen, W. Fang, L. Wang, Z. Wang, and W. Chen.

              Cuzk: Accelerating zero-knowledge proof with a faster parallel multi-scalar
              multiplication algorithm on gpus.

              Cryptology ePrint Archive, 2022.


              - \[99\]↑

              H. Lycklama, L. Burkhalter, A. Viand, N. Küchler, and A. Hithnawi.

              Rofl: Robustness of secure federated learning.

              In 2023 IEEE Symposium on Security and Privacy (SP), pages 453–476.
              IEEE, 2023.


              - \[100\]↑

              W. Ma, Q. Xiong, X. Shi, X. Ma, H. Jin, H. Kuang, M. Gao, Y. Zhang,
              H. Shen, and W. Hu.

              Gzkp: A gpu accelerated zero-knowledge proof system.

              In Proceedings of the 28th ACM International Conference on Architectural
              Support for Programming Languages and Operating Systems, Volume 2, pages
              340–353, 2023.


              - \[101\]↑

              M. Maller, S. Bowe, M. Kohlweiss, and S. Meiklejohn.

              Sonic: Zero-knowledge snarks from linear-size universal and updateable
              structured reference strings.

              Cryptology ePrint Archive, Paper 2019/099, 2019.

              https://eprint.iacr.org/2019/099.


              - \[102\]↑

              Monero.

              Home — monero - secure, private, untraceable.

              https://www.getmonero.org, 2023.


              - \[103\]↑

              D. Mouris and N. G. Tsoutsos.

              Zilch: A framework for deploying transparent zero-knowledge proofs.

              IEEE Transactions on Information Forensics and Security, 16:3269–3284,
              2021.


              - \[104\]↑

              J. L. Muñoz-Tapia, M. Belles, M. Isabel, A. Rubio, and J. Baylina.

              Circom: A robust and scalable language for building complex zero-knowledge
              circuits.

              2022.


              - \[105\]↑

              National Institute of Standards and Technology (NIST).

              Round 2 additional signatures.

              https://csrc.nist.gov/projects/pqc-dig-sig/round-2-additional-signatures,
              2020.


              - \[106\]↑

              Noir-Lang.

              Benchmarks in awesome-noir, 2023.


              - \[107\]↑

              A. Ozdemir, F. Brown, and R. S. Wahby.

              Circ: Compiler infrastructure for proof systems, software verification,
              and more.

              In 2022 IEEE Symposium on Security and Privacy (SP), pages 2248–2266.
              IEEE, 2022.


              - \[108\]↑

              B. Parno, J. Howell, C. Gentry, and M. Raykova.

              Pinocchio: Nearly practical verifiable computation.

              Communications of the ACM, 59(2):103–112, 2016.


              - \[109\]↑

              Polygon Labs UI (Cayman) Ltd.

              Polygon zkevm — scaling for the ethereum virtual machine.

              https://polygon.technology/polygon-zkevm, 2023.


              - \[110\]↑

              PQC-MIRATH Consortium.

              Pqc-mirath.

              https://pqc-mirath.org/, 2023.


              - \[111\]↑

              M. O. Rabin, Y. Mansour, S. Muthukrishnan, and M. Yung.

              Strictly-black-box zero-knowledge and efficient validation of financial
              transactions.

              In International Colloquium on Automata, Languages, and Programming,
              pages 738–749. Springer, 2012.


              - \[112\]↑

              RISC Zero, Inc.

              Introduction — risc zero developer docs, 2023.


              - \[113\]↑

              A. Roy Chowdhury, C. Guo, S. Jha, and L. van der Maaten.

              Eiffel: Ensuring integrity for federated learning.

              In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications
              Security, pages 2535–2549, 2022.


              - \[114\]↑

              N. Samardzic, S. Langowski, S. Devadas, and D. Sanchez.

              Accelerating zero-knowledge proofs through hardware-algorithm co-design.

              In 2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO),
              pages 366–379. IEEE, 2024.


              - \[115\]↑

              SciprLab.

              libiop, 2023.


              - \[116\]↑

              SDITH.

              Sdith.

              https://sdith.org/index.html, 2023.


              - \[117\]↑

              S. Setty.

              Spartan: Efficient and general-purpose zksnarks without trusted setup.

              In Annual International Cryptology Conference, pages 704–737. Springer,
              2020.


              - \[118\]↑

              B. Sharma, R. Halder, and J. Singh.

              Blockchain-based interoperable healthcare using zero-knowledge proofs
              and proxy re-encryption.

              In 2020 International Conference on COMmunication Systems & NETworkS
              (COMSNETS), pages 1–6. IEEE, 2020.


              - \[119\]↑

              N. Sheybani, Z. Ghodsi, R. Kapila, and F. Koushanfar.

              Zkrownn: Zero knowledge right of ownership for neural networks.

              In 2023 60th ACM/IEEE Design Automation Conference (DAC), pages 1–6.
              IEEE, 2023.


              - \[120\]↑

              N. Sheybani, T. Gong, A. Ahmed, N. B. Njungle, M. Kinsy, and F. Koushanfar.

              Gotta hash’em all! speeding up hash functions for zero-knowledge proof
              applications.

              arXiv preprint arXiv:2501.18780, 2025.


              - \[121\]↑

              N. Sidorenco, S. Oechsner, and B. Spitters.

              Formal security analysis of mpc-in-the-head zero-knowledge protocols.

              In 2021 IEEE 34th Computer Security Foundations Symposium (CSF), pages
              1–14. IEEE, 2021.


              - \[122\]↑

              S. Šimunić, D. Bernaca, and K. Lenac.

              Verifiable computing applications in blockchain.

              IEEE Access, 9:156729–156745, 2021.


              - \[123\]↑

              J. So, B. Güler, and A. S. Avestimehr.

              Byzantine-resilient secure federated learning.

              IEEE Journal on Selected Areas in Communications, 39(7):2168–2181, 2020.


              - \[124\]↑

              X. Sun, F. R. Yu, P. Zhang, Z. Sun, W. Xie, and X. Peng.

              A survey on zero-knowledge proof in blockchain.

              IEEE Network, 35(4):198–205, 2021.


              - \[125\]↑

              sunblaze ucb.

              Virgo, 2023.


              - \[126\]↑

              C. Thorpe and D. C. Parkes.

              Zero-knowledge proofs in large trades, July 9 2009.

              US Patent App. 12/261,249.


              - \[127\]↑

              B. Threadbare, D. Schmid, T. Carstens, B. Retford, D. Lubarov, A. Nagornyi,
              and V. Tan.

              Zk system benchmarking, 2023.


              - \[128\]↑

              S. Tillich and N. Smart.

              (bristol format) circuits of basic functions suitable for mpc and fhe,
              2023.


              - \[129\]↑

              A. E. B. Tomaz, J. C. Do Nascimento, A. S. Hafid, and J. N. De Souza.

              Preserving privacy in mobile health systems using non-interactive zero-knowledge
              proof and blockchain.

              IEEE access, 8:204441–204458, 2020.


              - \[130\]↑

              TrustworthyComputing.

              Zilch, 2023.


              - \[131\]↑

              A. Viand, P. Jattke, and A. Hithnawi.

              Sok: Fully homomorphic encryption compilers.

              In 2021 IEEE Symposium on Security and Privacy (SP), pages 1092–1108.
              IEEE, 2021.


              - \[132\]↑

              A. Viand, C. Knabenhans, and A. Hithnawi.

              Verifiable fully homomorphic encryption.

              arXiv preprint arXiv:2301.07041, 2023.


              - \[133\]↑

              R. S. Wahby, Y. Ji, A. J. Blumberg, A. Shelat, J. Thaler, M. Walfish,
              and T. Wies.

              Full accounting for verifiable outsourcing.

              In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
              Security, pages 2071–2086, 2017.


              - \[134\]↑

              R. S. Wahby, I. Tzialla, A. Shelat, J. Thaler, and M. Walfish.

              Doubly-efficient zksnarks without trusted setup.

              In 2018 IEEE Symposium on Security and Privacy (SP), pages 926–943.
              IEEE, 2018.


              - \[135\]↑

              X. Wang.

              Emp-toolkit.


              - \[136\]↑

              X. Wang.

              Emp-zk.


              - \[137\]↑

              C. Weng, A. Coventry, S. Hussain, D. Malkhi, A. Topliceanu, X. Wang,
              and F. Zhang.

              Vole-based interactive commitments, Jan. 2023.


              - \[138\]↑

              C. Weng, K. Yang, J. Katz, and X. Wang.

              Wolverine: fast, scalable, and communication-efficient zero-knowledge
              proofs for boolean and arithmetic circuits.

              In 2021 IEEE Symposium on Security and Privacy (SP), pages 1074–1091.
              IEEE, 2021.


              - \[139\]↑

              C. Weng, K. Yang, X. Xie, J. Katz, and X. Wang.

              Mystique: Efficient conversions for {{\\{{Zero-Knowledge}}\\}} proofs
              with applications to machine learning.

              In 30th USENIX Security Symposium (USENIX Security 21), pages 501–518,
              2021.


              - \[140\]↑

              H. Wu, F. Wang, et al.

              A survey of noninteractive zero knowledge proof system and its applications.

              The Scientific World Journal, 2014, 2014.


              - \[141\]↑

              K. Yang, P. Sarkar, C. Weng, and X. Wang.

              Quicksilver: Efficient and affordable zero-knowledge proofs for circuits
              and polynomials over any field.

              IACR Cryptol. ePrint Arch., 2021:76, 2021.


              - \[142\]↑

              F. Zhang, D. Maram, H. Malvai, S. Goldfeder, and A. Juels.

              Deco: Liberating web data using decentralized oracles for tls.

              In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications
              Security, pages 1919–1938, 2020.


              - \[143\]↑

              J. Zhang, Z. Fang, Y. Zhang, and D. Song.

              Zero knowledge proofs for decision tree predictions and accuracy.

              In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications
              Security, pages 2039–2053, 2020.


              - \[144\]↑

              J. Zhang, T. Liu, W. Wang, Y. Zhang, D. Song, X. Xie, and Y. Zhang.

              Doubly efficient interactive proofs for general arithmetic circuits
              with linear prover time.

              Cryptology ePrint Archive, Paper 2020/1247, 2020.

              https://eprint.iacr.org/2020/1247.


              - \[145\]↑

              J. Zhang, T. Xie, Y. Zhang, and D. Song.

              Transparent polynomial delegation and its applications to zero knowledge
              proof.

              In 2020 IEEE Symposium on Security and Privacy (SP), pages 859–876.
              IEEE, 2020.


              - \[146\]↑

              Zkonduit Inc.

              What is ezkl?, 2023.



              ## Appendix A Interactive vs. Non-Interactive


              Report issue for preceding element


              ZKPs can broadly be classed into two categories: interactive and non-interactive
              \[ [140](https://arxiv.org/html/2502.07063v1#bib.bib140 "")\]. Interactive
              protocols, as the name suggests, require several rounds interaction
              before 𝒱𝒱\\mathcal{V}caligraphic\_V is convinced that 𝒫𝒫\\mathcal{P}caligraphic\_P’s
              proof is valid. This is done by 𝒱𝒱\\mathcal{V}caligraphic\_V sending
              random challenges to 𝒫𝒫\\mathcal{P}caligraphic\_P until 𝒱𝒱\\mathcal{V}caligraphic\_V
              is convinced that 𝒫𝒫\\mathcal{P}caligraphic\_P’s proof is valid. Interactive
              ZKPs require that both 𝒫𝒫\\mathcal{P}caligraphic\_P and 𝒱𝒱\\mathcal{V}caligraphic\_V
              stay online until 𝒱𝒱\\mathcal{V}caligraphic\_V is convinced. This somewhat
              limits the utility of interactive ZKPs, as the proofs are designated-verifier,
              meaning that 𝒫𝒫\\mathcal{P}caligraphic\_P’s proof can only be used to
              be convinced a single verifier. A separate protocol must be performed
              for each new 𝒱𝒱\\mathcal{V}caligraphic\_V. Conversely, non-interactive
              ZKPs are normally publicly verifiable, meaning 𝒫𝒫\\mathcal{P}caligraphic\_P
              can generate a single proof in one-shot that any 𝒱𝒱\\mathcal{V}caligraphic\_V
              can verify. Non-interactive ZKPs often rely on a trusted setup process
              from a third-party, or in some cases 𝒱𝒱\\mathcal{V}caligraphic\_V, to
              generate randomness that allows for a proof to be generated that 𝒱𝒱\\mathcal{V}caligraphic\_V
              accepts as valid without further interaction. Many non-interactive schemes
              aim to minimize proof size, which results in higher 𝒫𝒫\\mathcal{P}caligraphic\_P
              computational power requirements. This limits the scalability of these
              schemes, especially in scenarios where 𝒫𝒫\\mathcal{P}caligraphic\_P
              is resource-constrained. The interactivity of interactive ZKPs allows
              for a more scalable approach in terms of 𝒫𝒫\\mathcal{P}caligraphic\_P
              computation, albeit limiting the amount of verifiers that can verify
              a proof. If needed, there is a method for turning public-coin interactive
              ZKPs into non-interactive ZKPs. The Fiat-Shamir transform \[ [88](https://arxiv.org/html/2502.07063v1#bib.bib88
              "")\] replaces 𝒱𝒱\\mathcal{V}caligraphic\_V’s randomness with a random
              oracle (i.e. a cryptographic hash function), thus removing the interaction
              and turning interactive ZKPs into non-interactive ZKPs.


              Report issue for preceding element


              ## Appendix B Recursive zk-SNARKs


              Report issue for preceding element


              Recent works \[ [50](https://arxiv.org/html/2502.07063v1#bib.bib50 ""),
              [91](https://arxiv.org/html/2502.07063v1#bib.bib91 ""), [46](https://arxiv.org/html/2502.07063v1#bib.bib46
              "")\] have shown the usability of recursive zk-SNARKs, which is the
              process of verifying multiple zk-SNARKs in a single zk-SNARK. As the
              verification algorithm of zk-SNARKs is simply an arbitrary computation,
              it can be represented as a circuit 𝒞𝒞\\mathcal{C}caligraphic\_C. This
              enables one 𝒫𝒫\\mathcal{P}caligraphic\_P to generate many proofs, then
              generate a proof that verifies these proofs and send it to 𝒱𝒱\\mathcal{V}caligraphic\_V.
              While this results in substantially more work on 𝒫𝒫\\mathcal{P}caligraphic\_P,
              𝒱𝒱\\mathcal{V}caligraphic\_V now only has to generate one proof to verify
              all of 𝒫𝒫\\mathcal{P}caligraphic\_P’s data, rather than many individual
              proofs.


              Report issue for preceding element


              ## Appendix C Features of ZKP Libraries


              Report issue for preceding element


              Table [V](https://arxiv.org/html/2502.07063v1#A3.T5 "TABLE V ‣ Appendix
              C Features of ZKP Libraries ‣ Zero-Knowledge Proof Frameworks: A Survey")
              provides a compact, high-level description of the 25 frameworks we discuss
              in this work.


              Report issue for preceding element


              |     |     |     |     |     |     |     |

              | --- | --- | --- | --- | --- | --- | --- |

              | Framework | Frontend/High-Level API | Dev. Language | Proof System(s)
              | Notable Gadgets | Extra Features | Target Audience |

              |  | zkSNARKs |

              | Arkworks \[ [26](https://arxiv.org/html/2502.07063v1#bib.bib26 "")\]
              | Self-contained | Rust | Groth16, Marlin \[ [58](https://arxiv.org/html/2502.07063v1#bib.bib58
              "")\], GM17 \[ [79](https://arxiv.org/html/2502.07063v1#bib.bib79 "")\],
              Plonk | Polynomial, Boolean, and UInt Arithmetic | - | Experienced ZK
              SW Developers |

              | Gnark \[ [49](https://arxiv.org/html/2502.07063v1#bib.bib49 "")\]
              | Self-contained | Go | Groth16, Plonk (KZG, FRI) | Hashes, Merkle proofs,
              EdDSA | GPU support | SW Developers |

              | Hyrax \[ [2](https://arxiv.org/html/2502.07063v1#bib.bib2 "")\] |
              None | Python | Hyrax | - | Excellent research paper | ZK Researchers
              |

              | Zokrates \[ [64](https://arxiv.org/html/2502.07063v1#bib.bib64 "")\]
              | Self-contained | Zokrates DSL | Groth16, GM17 \[ [79](https://arxiv.org/html/2502.07063v1#bib.bib79
              "")\], Marlin \[ [58](https://arxiv.org/html/2502.07063v1#bib.bib58
              "")\], Nova \[ [91](https://arxiv.org/html/2502.07063v1#bib.bib91 "")\]
              | Hashes, ECC | zkinterface support | SW Developers |

              | LEGOSnark \[ [3](https://arxiv.org/html/2502.07063v1#bib.bib3 "")\]
              | None | C++ | Brakedown-like \[\] | Sumcheck, Matrix & vector arithmetic
              | - | ZK Researchers |

              | LibSNARK \[ [4](https://arxiv.org/html/2502.07063v1#bib.bib4 "")\]
              | xjSnark \[ [90](https://arxiv.org/html/2502.07063v1#bib.bib90 "")\]
              | Java, C++ | Groth16, Pinocchio, GGPR \[\] | Hashes, Merkle trees,
              set commitment | Boolean 𝒞𝒞\\mathcal{C}caligraphic\_C support, TinyRAM
              | Experienced ZK SW Researchers |

              | Mirage \[ [5](https://arxiv.org/html/2502.07063v1#bib.bib5 "")\] |
              None | Java | Pinocchio-like | AES128, Merge Sort, SHA256 | - | ZK Researchers
              |

              | PySNARK \[ [7](https://arxiv.org/html/2502.07063v1#bib.bib7 "")\]
              | Self-contained | Python | Groth16 | Hashes, linear algebra operations
              | Boolean 𝒞𝒞\\mathcal{C}caligraphic\_C support | Beginner ZK SW developers
              |

              | SnarkJS \[ [34](https://arxiv.org/html/2502.07063v1#bib.bib34 "")\]
              | Circom \[ [104](https://arxiv.org/html/2502.07063v1#bib.bib104 "")\]
              | JavaScript, Circom DSL | Groth16, Plonk (via WASM) | Hashes, EdDSA,
              Comparators | Smart contract deployment support | SW Developers |

              | Rapidsnark \[ [8](https://arxiv.org/html/2502.07063v1#bib.bib8 "")\]
              | Circom \[ [104](https://arxiv.org/html/2502.07063v1#bib.bib104 "")\]
              | JavaScript, Circom DSL | Groth16 | Hashes, EdDSA, Comparators | Android/iOS
              𝒫𝒫\\mathcal{P}caligraphic\_P support | SW Developers |

              | Spartan \[ [10](https://arxiv.org/html/2502.07063v1#bib.bib10 "")\]
              | None | Rust | Spartan | - | Excellent research paper | Experienced
              ZK SW Developers |

              | Aurora (libiop) \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] | None | C++ | Aurora | - | Excellent research paper | ZK Researchers
              |

              | Fractal (libiop) \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] | None | C++ | Fractal | - | Excellent research paper | ZK Researchers
              |

              | Virgo \[ [125](https://arxiv.org/html/2502.07063v1#bib.bib125 "")\]
              | None | Python | Virgo | SHA256, Lanczos algorithm | Excellent research
              paper | ZK Researchers |

              | Noir \[ [17](https://arxiv.org/html/2502.07063v1#bib.bib17 "")\] |
              Self-Contained | Rust (Noir DSL) | Any ACIR-compatible system | Hashes,
              Big Integers, Merkle Trees | Recursive proof capabilities | SW Developers
              |

              | Dusk-PLONK \[ [13](https://arxiv.org/html/2502.07063v1#bib.bib13 "")\]
              | None | Rust | PLONK | - | - | ZK Researchers |

              | Halo2 \[ [14](https://arxiv.org/html/2502.07063v1#bib.bib14 "")\]
              | None (Rust API) | Rust | PLONK-like | Hashes, lookup range check,
              field decomposition | Backend for zkML framework ezkl\[ [146](https://arxiv.org/html/2502.07063v1#bib.bib146
              "")\] | Experienced ZK SW Developers |

              |  | MPC-in-the-Head |

              | Limbo \[ [92](https://arxiv.org/html/2502.07063v1#bib.bib92 "")\]
              | EMP-tool \[ [135](https://arxiv.org/html/2502.07063v1#bib.bib135 "")\]
              | C++ | MPCitH | SHA256 | High level of protocol customizability | Experienced
              privacy SW Developers |

              | Ligero (libiop) \[ [115](https://arxiv.org/html/2502.07063v1#bib.bib115
              "")\] | None | C++ | Ligero | - | Excellent research paper | ZK Researchers
              |

              |  | VOLE-Based ZK |

              | Mozzarella \[ [32](https://arxiv.org/html/2502.07063v1#bib.bib32 "")\]
              | None | Rust | Mozzarella | - | Excellent research paper | ZK Researchers
              |

              | Diet Mac’n’Cheese \[ [1](https://arxiv.org/html/2502.07063v1#bib.bib1
              "")\] | PicoZK | Python | Mac’n’Cheese \[ [33](https://arxiv.org/html/2502.07063v1#bib.bib33
              "")\] | Hashes, vector operations, histogram | Numpy, Pandas, PyTorch
              support | SW Developers |

              | Emp-ZK \[ [136](https://arxiv.org/html/2502.07063v1#bib.bib136 "")\]
              | Self-contained (C++ API) | C++ | Wolverine \[ [138](https://arxiv.org/html/2502.07063v1#bib.bib138
              "")\], Quicksilver \[ [141](https://arxiv.org/html/2502.07063v1#bib.bib141
              "")\] | Comparators, Arithmetic (e.g. log, cos) | Floating point support
              | SW Developers |

              |  | zkSTARKs |

              | MidenVM \[ [20](https://arxiv.org/html/2502.07063v1#bib.bib20 "")\]
              | None | Miden Assembly | FRI-STARK | Hashes, 64-bit arithmetic | -
              | ZK Researchers |

              | Zilch \[ [130](https://arxiv.org/html/2502.07063v1#bib.bib130 "")\]
              | ZeroJava \[\] | Java | FRI-STARK | Arithmetic, logical, and bitwise
              operators | - | ZK SW Developers |

              | RISC Zero \[ [112](https://arxiv.org/html/2502.07063v1#bib.bib112
              "")\] | Self-contained | Rust, C++ | FRI-STARK | Compiles any Rust code
              | Easy blockchain integration | SW Developers |


              TABLE V: ZK Framework AttributesReport issue for preceding element


              ## Appendix D ZKP Applications


              Report issue for preceding element


              In this section, we discuss some of the cutting-edge ZKP applications
              that have been introduced in academia and industry. For an extensive
              view on the more simplistic applications of ZKPs, we refer readers to
              the excellent work of \[ [19](https://arxiv.org/html/2502.07063v1#bib.bib19
              "")\].


              Report issue for preceding element


              Verifiable Machine Learning.

              Verifiable computation (VC) is a technique enabled by ZKPs that allows
              one party to prove to another that computation was performed correctly
              and soundly without revealing any information about the underlying data
              or computation details \[ [122](https://arxiv.org/html/2502.07063v1#bib.bib122
              "")\]. This is most common when there is a computationally weak verifier
              that would like to outsource their computation to a strong prover. This
              scenario lends itself quite nicely to verifiable machine learning (VML),
              in which a verifier can outsource their inference to a prover who owns
              a proprietary model. Many academic \[ [139](https://arxiv.org/html/2502.07063v1#bib.bib139
              ""), [97](https://arxiv.org/html/2502.07063v1#bib.bib97 ""), [94](https://arxiv.org/html/2502.07063v1#bib.bib94
              ""), [66](https://arxiv.org/html/2502.07063v1#bib.bib66 "")\] and industry
              \[ [146](https://arxiv.org/html/2502.07063v1#bib.bib146 "")\] works
              have enabled VML, in which a cloud server (the prover) provides a ZKP
              that attests to the verifier that inference was computed soundly, without
              revealing any information about the server’s proprietary model.


              Report issue for preceding element


              zk-Rollups.

              One of the biggest problems that faces the widespread implementation
              of ZKPs in modern systems is the difficulty of scalability. This is
              evident in blockchain applications, like Zcash \[ [83](https://arxiv.org/html/2502.07063v1#bib.bib83
              "")\] and Monero \[ [102](https://arxiv.org/html/2502.07063v1#bib.bib102
              "")\], which require heavy computational efforts to protect each transaction
              on the blockchain that they hope to keep private. zk-Rollups aim to
              address similar problems, although not specific to Zcash and Monero,
              by aggregating multiple transactions into a single batch and generating
              a single proof that validates all of them in one shot. This is mostly
              enabled by the use of recursive zk-SNARKs \[ [91](https://arxiv.org/html/2502.07063v1#bib.bib91
              "")\], in which a ZKP for each transaction is built, followed by a ZKP
              that validates all of the transactions at once. This significantly lightens
              the computational load on the verifier. zk-Rollups have become a more
              prominent solution towards applying ZKPs at scale on the blockchain
              in several industrial efforts \[ [21](https://arxiv.org/html/2502.07063v1#bib.bib21
              ""), [109](https://arxiv.org/html/2502.07063v1#bib.bib109 "")\].


              Report issue for preceding element


              Robust Federated Learning.

              Byzantine attacks on federated learning refer to a security threat in
              which malicious users aim to harm the central model \[ [65](https://arxiv.org/html/2502.07063v1#bib.bib65
              "")\]. The introduction of secure aggregation \[ [47](https://arxiv.org/html/2502.07063v1#bib.bib47
              "")\], which was devised to secure individual user updates, has made
              it much easier for malicious users to perform Byzantine attacks. In
              secure aggregation, malicious users can simply hide amongst benign users
              and inject poisoned updates that affect the central model’s accuracy.
              Even if a malicious attack is detected, the privacy-preserving nature
              of secure aggregation, the attacker cannot be identified. Several academic
              works \[ [72](https://arxiv.org/html/2502.07063v1#bib.bib72 ""), [123](https://arxiv.org/html/2502.07063v1#bib.bib123
              ""), [113](https://arxiv.org/html/2502.07063v1#bib.bib113 ""), [99](https://arxiv.org/html/2502.07063v1#bib.bib99
              "")\] have proposed scalable and secure secure aggregation schemes that
              utilize ZKPs to check individual user gradients, allowing for detection
              and exclusion of malicious users, while still maintaining end-to-end
              privacy.


              Report issue for preceding element


              Digital Signatures.

              In the search for more post-quantum secure digital signatures, the National
              Institute of Standards and Technology (NIST) began a search for additional
              schemes to standardize in 2023 \[ [105](https://arxiv.org/html/2502.07063v1#bib.bib105
              "")\], following up their previous digital signature standardization
              efforts. Their goal was to identify lightweight digital signature schemes
              that maintain high privacy and security in the presence of quantum adversaries.
              In particular, NIST called for general-purpose schemes that do not rely
              on lattices and maintain fast verification and short signature size.
              ZKPs have proven to be an excellent cryptographic primitive for the
              digital signature schemes that have found success in the NIST standardization
              process. Recently, in October 2024, NIST announced 14 second-round candidates
              for post-quantum digital signatures. Out of the 14 candidates, 6 of
              the candidates are built using ZKP schemes. The schemes Mirath \[ [110](https://arxiv.org/html/2502.07063v1#bib.bib110
              "")\], MQOM \[ [41](https://arxiv.org/html/2502.07063v1#bib.bib41 "")\],
              PERK \[ [44](https://arxiv.org/html/2502.07063v1#bib.bib44 "")\], RYDE
              \[ [25](https://arxiv.org/html/2502.07063v1#bib.bib25 "")\], and SDitH
              \[ [116](https://arxiv.org/html/2502.07063v1#bib.bib116 "")\] all utilize
              the MPCitH ZK scheme, while FAEST \[ [31](https://arxiv.org/html/2502.07063v1#bib.bib31
              "")\] uses VOLE-in-the-head, a non-interactive implementation of VOLE-based
              ZK. These works are currently undergoing a thorough cryptanalysis and
              evaluation process before they are advanced to standardization. These
              efforts highlight the effectiveness of ZKP schemes, especially non-interactive
              ones, in real-world and large-scale applications. ZKPs serve as the
              perfect underlying technology for post-quantum digital signature due
              to their public verifiability and succinct proof sizes, which enables
              fast verification at scale.


              Report issue for preceding element


              FHE Integrity.

              Similar to VML, FHE integrity consists of a verifier sending their data
              to a cloud server for computation. However, in FHE, the computation
              is done on encrypted data, making the ZKP generation process much more
              complex. As FHE operations are more computationally intensive and use
              underlying ring arithmetic, the circuit that expresses the computation
              for a ZKP grows to be very complex. \[ [70](https://arxiv.org/html/2502.07063v1#bib.bib70
              "")\] introduces a ring-based zk-SNARK enabling verifiable computation
              over encrypted data, however new works \[ [132](https://arxiv.org/html/2502.07063v1#bib.bib132
              "")\] have shown that, although this make FHE integrity proofs feasible,
              the overhead makes it an impractical solution.


              Report issue for preceding element


              Data Authenticity.

              ZKPs have been integrated into DECO \[ [142](https://arxiv.org/html/2502.07063v1#bib.bib142
              "")\], a protocol that is being used in practice by Chainlink Labs \[
              [51](https://arxiv.org/html/2502.07063v1#bib.bib51 "")\] which allows
              users to prove the authenticity of their data without revealing any
              information about the data itself, including the length of the datapoints.
              DECO allows users to prove that their data was sourced from a legitimate
              location, while also allowing them to prove certain attributes of the
              data (e.g. proving account balance is above a certain threshold). Proofs
              surrounding data authenticity, validity, and attributes lend themselves
              very nicely to ZKP settings. Several domains, such as healthcare and
              finance, which Chainlink has shown feasibility of, can benefit from
              integrating ZKPs to protect user data while still gathering meaningful
              information. Recent work \[ [86](https://arxiv.org/html/2502.07063v1#bib.bib86
              "")\] has shown the value of using ZKPs to build protected pipelines,
              or props for short, to provide verifiable, privacy-preserving access
              to deep web data for machine learning pipelines. This kind of secure
              access to deep web data is an integral part of advancing machine learning
              paradigms, as it enables developers to bypass the bottleneck of limited
              high-quality training data that is not currently accessible.


              Report issue for preceding element


              Report IssueReport Issue for Selection


              Generated by

              [L\\

              A\\

              T\\

              Exml![[LOGO]](<Base64-Image-Removed>)](https://math.nist.gov/~BMiller/LaTeXML/)'
            metadata:
              title: 'Zero-Knowledge Proof Frameworks: A Survey'
              favicon: https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png
              viewport: width=device-width, initial-scale=1, shrink-to-fit=no
              language: en
              scrapeId: 68258ced-6b5c-45a3-bf37-1edd5f97d78a
              sourceURL: https://arxiv.org/html/2502.07063v1
              url: https://arxiv.org/html/2502.07063v1
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
          - title: Zero-Knowledge Proof Breakthroughs - Meegle
            description: This cryptographic innovation allows one party to prove the
              validity of a statement to another party without revealing any underlying
              information.
            url: https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs
            markdown: '[![meegle](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/logo.07e350fa.ef82adf9.png)](https://www.meegle.com/)


              Why MeegleSolutions [Templates](https://www.meegle.com/templates) Resources
              [Pricing](https://www.meegle.com/pricing)


              Sign In


              Get it Free

              Contact Us


              [Home](https://www.meegle.com/en_us) [Topics](https://www.meegle.com/en_us/topics/)
              [Zero-Knowledge Proofs](https://www.meegle.com/en_us/topics/zero-knowledge-proofs)
              Zero-Knowledge Proof Breakthroughs


              [Zero-Knowledge Proofs](https://www.meegle.com/en_us/topics/zero-knowledge-proofs)


              [Zero-Knowledge Proofs](https://www.meegle.com/en_us/topics/zero-knowledge-proofs)


              # Zero-Knowledge Proof Breakthroughs


              Explore diverse perspectives on Zero-Knowledge Proofs with structured
              content covering applications, benefits, challenges, and future trends
              in various industries.


              ![](https://p16-hera-sg.larksuitecdn.com/tos-alisg-i-hn4qzgxq2n-sg/8055f6941c2640fb974b4475dff17541~tplv-hn4qzgxq2n-png:0:0.png)2025/8/23


              Try Meegle for Free


              In an era where data breaches and privacy concerns dominate headlines,
              the need for robust security mechanisms has never been more critical.
              Zero-Knowledge Proof (ZKP) technology has emerged as a groundbreaking
              solution, offering unparalleled security and privacy in digital transactions
              and communications. This cryptographic innovation allows one party to
              prove the validity of a statement to another party without revealing
              any underlying information. From blockchain applications to identity
              verification, ZKP is reshaping industries and setting new standards
              for secure interactions. This article delves into the intricacies of
              Zero-Knowledge Proof breakthroughs, exploring their foundational concepts,
              real-world applications, implementation strategies, and future potential.
              Whether you''re a business leader, developer, or security professional,
              this comprehensive guide will equip you with actionable insights to
              harness the power of ZKP effectively.


              * * *


              Table of Contents


              [Understanding the basics of zero-knowledge proof](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs#understanding-the-basics-of-zero-knowledge-proof)
              [The importance of zero-knowledge proof in modern applications](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs#the-importance-of-zero-knowledge-proof-in-modern-applications)
              [How to implement zero-knowledge proof effectively](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs#how-to-implement-zero-knowledge-proof-effectively)
              [Innovations and trends in zero-knowledge proof](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs#innovations-and-trends-in-zero-knowledge-proof)
              [Best practices for zero-knowledge proof adoption](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs#best-practices-for-zero-knowledge-proof-adoption)
              [Faqs about zero-knowledge proof](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs#faqs-about-zero-knowledge-proof)


              Implement \[Zero-Knowledge Proofs\] to enhance secure data sharing across
              remote teams.


              Try for Free


              ## Understanding the basics of zero-knowledge proof


              ### What is Zero-Knowledge Proof?


              Zero-Knowledge Proof (ZKP) is a cryptographic protocol that enables
              one party (the prover) to demonstrate the truth of a statement to another
              party (the verifier) without disclosing any additional information beyond
              the validity of the statement itself. This concept was first introduced
              in the 1980s by researchers Shafi Goldwasser, Silvio Micali, and Charles
              Rackoff. ZKP is built on the principles of mathematical proofs and cryptographic
              algorithms, ensuring that sensitive data remains private while still
              enabling verification.


              For example, imagine proving you are over 18 years old without revealing
              your exact age. ZKP allows this by verifying the truth of the statement
              ("I am over 18") without exposing the underlying data (your birthdate).
              This revolutionary approach has profound implications for privacy and
              security in digital systems.


              ### Key Features of Zero-Knowledge Proof


              Zero-Knowledge Proofs are characterized by several unique features that
              make them highly effective for secure and private interactions:


              1. **Completeness**: If the statement is true, the verifier will be
              convinced of its validity.

              2. **Soundness**: If the statement is false, the verifier will not be
              convinced, ensuring the integrity of the proof.

              3. **Zero-Knowledge**: The verifier gains no additional information
              beyond the fact that the statement is true.


              These features enable ZKP to be applied in scenarios where privacy and
              security are paramount, such as financial transactions, identity verification,
              and secure communications.


              * * *


              ## The importance of zero-knowledge proof in modern applications


              ### Benefits of Zero-Knowledge Proof for Businesses


              Businesses across industries are increasingly adopting Zero-Knowledge
              Proof technology to address critical challenges related to security,
              privacy, and compliance. Here are some key benefits:


              1. **Enhanced Privacy**: ZKP ensures that sensitive data remains confidential,
              reducing the risk of data breaches and unauthorized access.

              2. **Regulatory Compliance**: By enabling secure and private transactions,
              ZKP helps businesses comply with stringent data protection regulations
              such as GDPR and CCPA.

              3. **Cost Efficiency**: ZKP reduces the need for complex data-sharing
              mechanisms, streamlining operations and lowering costs.

              4. **Trust Building**: By demonstrating transparency without compromising
              privacy, ZKP fosters trust among customers and partners.


              ### Real-World Use Cases of Zero-Knowledge Proof


              Zero-Knowledge Proof technology is being leveraged in various industries
              to solve complex problems. Here are three detailed examples:


              #### Blockchain and Cryptocurrencies


              ZKP is revolutionizing blockchain technology by enabling private and
              secure transactions. For instance, Zcash, a cryptocurrency, uses ZKP
              to allow users to make transactions without revealing their identities
              or transaction details. This ensures privacy while maintaining the integrity
              of the blockchain.


              #### Identity Verification


              ZKP is transforming identity verification processes by enabling individuals
              to prove their identity without sharing sensitive information. For example,
              a user can prove they are a citizen of a country without disclosing
              their passport details, enhancing privacy in digital interactions.


              #### Secure Voting Systems


              In electronic voting systems, ZKP ensures that votes are cast and counted
              securely without revealing voter identities or preferences. This technology
              is being explored to enhance transparency and trust in democratic processes.


              * * *


              Related:


              [Neural Network Vs Hybrid Models](https://www.meegle.com/en_us/topics/neural-networks/neural-network-vs-hybrid-models?frompages=topics_zero-knowledge-proofs_zero-knowledge-proof-breakthroughs)


              Click here to utilize our free project management templates!


              ## How to implement zero-knowledge proof effectively


              ### Step-by-Step Guide to Zero-Knowledge Proof Implementation


              Implementing Zero-Knowledge Proof technology requires careful planning
              and execution. Here’s a step-by-step guide:


              1. **Understand the Requirements**: Identify the specific problem you
              want to solve and determine whether ZKP is the right solution.

              2. **Choose the Right ZKP Protocol**: Select a ZKP protocol that aligns
              with your use case, such as zk-SNARKs or zk-STARKs.

              3. **Develop the Cryptographic Model**: Design the mathematical proof
              and cryptographic algorithms required for your application.

              4. **Integrate with Existing Systems**: Ensure seamless integration
              with your current infrastructure, such as blockchain platforms or identity
              management systems.

              5. **Test and Validate**: Conduct rigorous testing to verify the accuracy
              and security of the ZKP implementation.

              6. **Deploy and Monitor**: Deploy the solution and continuously monitor
              its performance to address any issues.


              ### Common Challenges and How to Overcome Them


              While Zero-Knowledge Proof offers significant advantages, implementing
              it can be challenging. Here are some common obstacles and strategies
              to overcome them:


              1. **Complexity**: ZKP protocols can be mathematically and computationally
              complex. Collaborate with cryptographic experts to simplify implementation.

              2. **Performance Issues**: ZKP can be resource-intensive, impacting
              system performance. Optimize algorithms and leverage hardware acceleration
              to improve efficiency.

              3. **Scalability**: Scaling ZKP solutions for large-scale applications
              can be difficult. Use advanced protocols like zk-STARKs for better scalability.

              4. **Integration Challenges**: Integrating ZKP with legacy systems may
              require significant modifications. Plan integration carefully and test
              extensively.


              * * *


              ## Innovations and trends in zero-knowledge proof


              ### Emerging Technologies Related to Zero-Knowledge Proof


              The field of Zero-Knowledge Proof is evolving rapidly, with new technologies
              and innovations enhancing its capabilities. Some notable advancements
              include:


              1. **zk-SNARKs**: Short for Zero-Knowledge Succinct Non-Interactive
              Arguments of Knowledge, zk-SNARKs are widely used for efficient and
              scalable ZKP implementations.

              2. **zk-STARKs**: These are an improvement over zk-SNARKs, offering
              better scalability and eliminating the need for trusted setups.

              3. **Layer 2 Solutions**: ZKP is being integrated into Layer 2 blockchain
              solutions to enable faster and more private transactions.


              ### Future Predictions for Zero-Knowledge Proof


              The future of Zero-Knowledge Proof is promising, with several trends
              shaping its trajectory:


              1. **Wider Adoption in Blockchain**: ZKP will become a standard feature
              in blockchain platforms, enhancing privacy and scalability.

              2. **Integration with AI**: Combining ZKP with artificial intelligence
              will enable secure and private AI applications.

              3. **Expansion into IoT**: ZKP will be used to secure IoT devices and
              networks, addressing privacy concerns in connected environments.


              * * *


              Related:


              [Neural Network Vs Hybrid Models](https://www.meegle.com/en_us/topics/neural-networks/neural-network-vs-hybrid-models?frompages=topics_zero-knowledge-proofs_zero-knowledge-proof-breakthroughs)


              Click here to utilize our free project management templates!


              ## Best practices for zero-knowledge proof adoption


              ### Industry Standards and Compliance


              Adopting Zero-Knowledge Proof technology requires adherence to industry
              standards and compliance requirements. Here are some key considerations:


              1. **Follow Cryptographic Standards**: Ensure that your ZKP implementation
              aligns with established cryptographic standards.

              2. **Comply with Data Protection Regulations**: Use ZKP to meet the
              requirements of GDPR, CCPA, and other privacy laws.

              3. **Collaborate with Industry Experts**: Work with cryptographic professionals
              to ensure the accuracy and security of your implementation.


              ### Tips for Seamless Integration


              Integrating Zero-Knowledge Proof into your systems can be challenging.
              Here are some tips to ensure a smooth process:


              | **Do''s** | **Don''ts** |

              | --- | --- |

              | Conduct thorough research on ZKP protocols. | Avoid rushing the implementation
              process. |

              | Test extensively before deployment. | Don''t neglect performance optimization.
              |

              | Collaborate with cryptographic experts. | Avoid using outdated protocols.
              |

              | Ensure compliance with regulations. | Don''t overlook scalability
              requirements. |


              * * *


              ## Faqs about zero-knowledge proof


              ### What Are the Common Misconceptions About Zero-Knowledge Proof?


              One common misconception is that ZKP is only applicable to blockchain
              technology. In reality, ZKP has diverse applications, including identity
              verification, secure communications, and more.


              ### How Does Zero-Knowledge Proof Compare to Other Technologies?


              ZKP stands out for its ability to ensure privacy and security without
              revealing sensitive information, unlike traditional encryption methods
              that require data sharing.


              ### What Are the Costs Associated with Zero-Knowledge Proof?


              The costs of implementing ZKP can vary depending on the complexity of
              the application and the chosen protocol. However, the long-term benefits
              often outweigh the initial investment.


              ### How Can Zero-Knowledge Proof Improve Security and Privacy?


              ZKP enhances security by preventing unauthorized access to sensitive
              data and improves privacy by enabling verification without data exposure.


              ### Where Can I Learn More About Zero-Knowledge Proof?


              You can explore resources such as academic papers, online courses, and
              industry blogs to deepen your understanding of ZKP technology.


              * * *


              By understanding the fundamentals, exploring real-world applications,
              and adopting best practices, professionals can leverage Zero-Knowledge
              Proof breakthroughs to transform security and privacy in their organizations.
              This comprehensive guide serves as a blueprint for success in implementing
              and utilizing ZKP effectively.


              Implement \[Zero-Knowledge Proofs\] to enhance secure data sharing across
              remote teams.


              Try for Free


              Navigate Project Success with Meegle


              Pay less to get more today.


              [Contact sales](https://www.meegle.com/contact?from=topics_right_contact)


              ## Explore More in Zero-Knowledge Proofs


              [Go to the Topic](https://www.meegle.com/en_us/topics/zero-knowledge-proofs)


              [![an image for applications of Zero-Knowledge Proofs](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-10.d9c7ffdd.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              applications of Zero-Knowledge Proofs\\

              \\

              Learn about applications of Zero-Knowledge Proofs with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/applications-of-zero-knowledge-proofs)
              [![an image for Zero-Knowledge Proof academic papers](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-14.a202a215.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof academic papers\\

              \\

              Learn about Zero-Knowledge Proof academic papers with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-academic-papers)
              [![an image for Zero-Knowledge Proof acquisitions](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-3.acd286b6.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof acquisitions\\

              \\

              Learn about Zero-Knowledge Proof acquisitions with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-acquisitions)
              [![an image for Zero-Knowledge Proof adoption](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-9.a2120410.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof adoption\\

              \\

              Learn about Zero-Knowledge Proof adoption with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-adoption)
              [![an image for Zero-Knowledge Proof advanced techniques](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-21.289cbc02.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof advanced techniques\\

              \\

              Learn about Zero-Knowledge Proof advanced techniques with actionable
              insights, practical strategies, and expert guidance tailored to enhance
              understanding and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-advanced-techniques)
              [![an image for Zero-Knowledge Proof algorithms](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-19.374e9c43.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof algorithms\\

              \\

              Learn about Zero-Knowledge Proof algorithms with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-algorithms)
              [![an image for Zero-Knowledge Proof architectures](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-4.43dbf92e.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof architectures\\

              \\

              Learn about Zero-Knowledge Proof architectures with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-architectures)
              [![an image for Zero-Knowledge Proof beginner''s guide](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/cover-1.937cf537.png)\\

              \\

              Zero Knowledge Proofs\\

              \\

              Zero-Knowledge Proof beginner''s guide\\

              \\

              Learn about Zero-Knowledge Proof beginner''s guide with actionable insights,
              practical strategies, and expert guidance tailored to enhance understanding
              and implementation.](https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-beginner''s-guide)


              ### Limited time offers are available. Pay less to get more today.


              Try for Free [Book a Demo](https://www.meegle.com/contact?from=)


              ![](https://sf16-scmcdn.larksuitecdn.com/obj/lark-static-sg/meegle/pseo/static/image/logo.e5739d50.5db551e6.png)


              Features


              [Workflow](https://www.meegle.com/meegle_features/workflow) [Role &
              Team](https://www.meegle.com/meegle_features/teams-and-roles) [Views](https://www.meegle.com/meegle_features/views)
              [Automation](https://www.meegle.com/meegle_features/automation) [Toolkit](https://www.meegle.com/meegle_features/toolkit)
              [Charts](https://www.meegle.com/meegle_features/charts) [Scheduling](https://www.meegle.com/meegle_features/scheduling)
              [Integration](https://www.meegle.com/meegle_features/integration)


              Product Comparison


              [Meegle vs. Jira](https://www.meegle.com/productcomparison/jira) [Meegle
              vs. Monday.com](https://www.meegle.com/productcomparison/monday) [Meegle
              vs. ClickUp](https://www.meegle.com/productcomparison/clickup) [Meegle
              vs. Airtable](https://www.meegle.com/productcomparison/airtable) [Meegle
              vs. Asana](https://www.meegle.com/productcomparison/asana) [Meegle vs.
              Trello](https://www.meegle.com/productcomparison/trello)


              Solutions


              [Software Development](https://www.meegle.com/solution/software-development)
              [Game Development](https://www.meegle.com/solution/game-development)
              [Agile Development](https://www.meegle.com/solution/agile-development)
              [Sales Management](https://www.meegle.com/solution/sales-management)
              [Retail Management](https://www.meegle.com/solution/store-operation)
              [Food and Beverage](https://www.meegle.com/solution/food-beverage-innovation)
              [Media Operations](https://www.meegle.com/solution/media-operation)
              [Incident Management](https://www.meegle.com/solution/issue-to-resolution)
              [OKR Management](https://www.meegle.com/solution/okr-management) [PMO](https://www.meegle.com/solution/project-manager)
              [Product](https://www.meegle.com/solution/product-manager) [Development](https://www.meegle.com/solution/developer)
              [Operation](https://www.meegle.com/solution/operation-team) [Sales](https://www.meegle.com/solution/sales-team)


              Templates


              [Agile Development](https://www.meegle.com/templates/agile-development-template)
              [App Development](https://www.meegle.com/templates/app-development-template)
              [Feature Management](https://www.meegle.com/templates/feature-management-template)
              [Game Process Management](https://www.meegle.com/templates/game-process-management-template)
              [Game Project Management](https://www.meegle.com/templates/game-project-management-template)
              [Construction Engineering](https://www.meegle.com/templates/engineering-project-management-template)
              [Content Management](https://www.meegle.com/templates/content-management-template)
              [Lead to Cash](https://www.meegle.com/templates/lead-to-cash-template)
              [Manufacturing](https://www.meegle.com/templates/manufacturing-project-management-template)
              [Recruitment Management](https://www.meegle.com/templates/recruitment-management-template)
              [Advanced Templates](https://www.meegle.com/en_us/advanced-templates)


              Customer Stories


              [Nas Daily](https://www.meegle.com/customer/nas-daily-software) [POP
              MART](https://www.meegle.com/customer/pop-draw-experience) [LIZHI](https://www.meegle.com/customer/audio-platform-release-products-faster)
              [Mediastorm](https://www.meegle.com/customer/meegle-navigates-central-theme-in-video-production)
              [Skylink Studio](https://www.meegle.com/customer/playbook-for-delivering-games-on-time)
              [ZHUOYU](https://www.meegle.com/customer/zhuoyu-intelligent-driving)


              Resources


              [Blogs](https://www.meegle.com/blogs) [Help Center](https://www.meegle.com/b/helpcenter/home?_lang=en)
              [Podcast](https://www.meegle.com/podcast) [Customer Support](mailto:meeglesupport@larksuite.com)
              [Topics](https://www.meegle.com/en_us/topics)


              Company


              [Sign Up](https://project.larksuite.com/) [Contact Us](https://www.meegle.com/contact)
              [Pricing](https://www.meegle.com/pricing)


              Security


              [Trust](https://www.meegle.com/trust) [Customer Terms of Service](https://www.larksuite.com/en_us/customer-terms-of-service)
              [User Terms of Service](https://www.larksuite.com/en_us/user-terms-of-service)
              [Privacy Policy](https://www.larksuite.com/en_us/privacy-policy) [Acceptable
              Use Policy](https://www.larksuite.com/en_us/acceptable-use-policy) [Cookie
              Policy](https://www.larksuite.com/en_us/cookie-policy)


              © Lark Technologies Pte. Ltd.


              [![discord](https://p16-hera-sg.larksuitecdn.com/tos-alisg-i-hn4qzgxq2n-sg/aac496287272408a95abfc7957662936~tplv-hn4qzgxq2n-image-v1:0:0.image)](https://discord.gg/6U7EvhEtMj)


              [![linkedin](https://p16-hera-sg.larksuitecdn.com/tos-alisg-i-hn4qzgxq2n-sg/537f206962d246649fa5d8ffc2bbe21c~tplv-hn4qzgxq2n-image-v1:0:0.image)](https://www.linkedin.com/company/meeglehq/)


              [![youtube](https://p16-hera-sg.larksuitecdn.com/tos-alisg-i-hn4qzgxq2n-sg/40eb5ccd56254507bb2c06cf88337145~tplv-hn4qzgxq2n-png:0:0.png)](https://www.youtube.com/@meeglehq)


              [![twitter](https://p16-hera-sg.larksuitecdn.com/tos-alisg-i-hn4qzgxq2n-sg/bb921fd4e055493eae5f2767d25a7616~tplv-hn4qzgxq2n-png:0:0.png)](https://twitter.com/intent/follow?screen_name=MeegleHQ)


              We use cookies and similar technologies to provide and maintain our
              services and ensure performance, security, and stability of our website.
              We also use first and third party cookies for analytics and marketing
              purposes. Learn more about how we use cookies in our [Cookie Policy](https://www.larksuite.com/en_us/cookie-policy).
              You can manage your cookie preference at any time.


              Got ItManage Settings'
            metadata:
              layoutmode:
              - standard
              - standard
              format-detection:
              - telephone=no
              - telephone=no
              title: Zero-Knowledge Proof Breakthroughs
              favicon: https://p16-hera-sg.larksuitecdn.com/tos-alisg-i-hn4qzgxq2n-sg/8055f6941c2640fb974b4475dff17541~tplv-hn4qzgxq2n-png:0:0.png
              imagemode:
              - force
              - force
              viewport:
              - width=device-width,initial-scale=1,maximum-scale=5
              - width=device-width,initial-scale=1,shrink-to-fit=no,viewport-fit=cover,minimum-scale=1,maximum-scale=1,user-scalable=no
              renderer:
              - webkit
              - webkit
              wap-font-scale:
              - 'no'
              - 'no'
              language: en
              x-pseo-deploy-manifest: '{"version":"1.0.0.287","branch":"master","commitHash":"a056097acf818f94f681fdce5187bef036a2acee"}'
              description: Explore diverse perspectives on Zero-Knowledge Proofs with
                structured content covering applications, benefits, challenges, and
                future trends in various industries.
              scrapeId: 04a8f09d-e69e-48ec-a417-07080af734fd
              sourceURL: https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs
              url: https://www.meegle.com/en_us/topics/zero-knowledge-proofs/zero-knowledge-proof-breakthroughs
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
          - title: What is Zero-Knowledge Proof - a hot technology bringing ...
            description: In 2019, the World Economic Forum announced zero-knowledge
              proof as one of the five privacy-enhancing technologies that bring new
              value to the financial sector ...
            url: https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof
            markdown: '![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/kv.jpg?h=1280&iar=0&w=2732&rev=fa79a6352a734a3bb844ecdb47218200)


              - ShareNot displayedFacebookLinkedInX


              - [Home](https://www.nttdata.com/global/en)

              - [Insights](https://www.nttdata.com/global/en/insights)

              - [NTT DATA Focus](https://www.nttdata.com/global/en/insights/focus)


              # What is Zero-Knowledge Proof - a hot technology bringing trustworthiness
              to Web3 privacy?


              Recently, "zero-knowledge proof" is attracting attention. In 2019, the
              World Economic Forum announced zero-knowledge proof as one of the five
              privacy-enhancing technologies that bring new value to the financial
              sector (\*1). Why is this idea, invented in the 1980s, receiving attention
              now? This article gives an overview of the technology, examples of its
              application, and looks into its future.


              - (\*1) [World Economic Forum, "The Next Generation of Data-Sharing
              in Financial Services: Using Privacy Enhancing Techniques to Unlock
              New Value," September 2019.](https://www.weforum.org/whitepapers/the-next-generation-of-data-sharing-in-financial-services-using-privacy-enhancing-techniques-to-unlock-new-value/)


              Index



              - [What is Zero-Knowledge Proof?](https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof#section01)

              - [Intuitive understanding of Zero-Knowledge Proofs](https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof#section02)

              - [Social Application Examples](https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof#section03)

              - [Prospect](https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof#section04)


              ## What is Zero-Knowledge Proof?


              Zero-knowledge proof; ZKP is a technology in which a person who wants
              to prove something (Prover; hereafter referred to as P) proves the fact
              that he knows the knowledge without giving any other knowledge to the
              person who wants to verify it (Verifier; hereafter referred to as V).


              As a result, V can only verify the fact that P knows the knowledge without
              obtaining any other knowledge (Figure 1).


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img01.png?h=378&iar=0&w=800&rev=6d7d71ac7c564b25984a2df33508640b)


              Figure 1: Concept of Zero-Knowledge Proof



              In the real world, when you want to assert that you hold certain credentials,
              it is common to present evidence to convince the other person that you
              hold the credentials.


              However, when you do so, the other person may be presented with too
              much information about what you want to prove, such as your address
              or age in the evidence. If you cannot trust the other person, you may
              feel uncomfortable giving them too much information. However, if you
              don''t show them the evidence, they are unlikely to trust your claim.
              How can you convince someone that you hold the qualification without
              giving them extra information?


              The technology to achieve this is zero-knowledge proof. The idea of
              zero-knowledge proof originated in cryptography research in the 1980s
              (\*2).


              - (\*2) [Goldwasser, S., Micali, S., Rackoff, C.: "The knowledge complexity
              of interactive proof-systems," STOC 1985.](https://dl.acm.org/doi/10.1145/22145.22178)



              The claims that can be proven with zero-knowledge proof are knowledge
              about propositions. A proposition is a verbal expression of a judgment
              that is clearly true or false (\*3).


              - (\*3)

              For example, "2023 is equal to 7×17×17" is a proposition, and it is
              a true fact. "I know the prime factorization of 2023" is knowledge related
              to the stated proposition and is an example of a claim that can be used
              for zero-knowledge proof. On the other hand, "2023 is a large number"
              is subjective and not a proposition. Therefore, the claim that "I know
              2023 is a big number" is not a subject of zero-knowledge proof.



              In general, a zero-knowledge proof must satisfy three properties: completeness,
              soundness, and zero-knowledge (Table 1).


              | Nature | Overview |

              | --- | --- |

              | Completeness | If the prover is correct, it will be determined to
              be correct by the verifier |

              | Soundness | If the prover is incorrect, it must be determined to be
              incorrect by the verifier with a high probability |

              | Zero-Knowledge | The verifier cannot obtain any knowledge other than
              the fact that the prover wants to prove |


              Table 1: Requirements for a zero-knowledge proof


              ## Intuitive understanding of Zero-Knowledge Proofs


              Here are two examples to help you understand zero-knowledge proofs intuitively.


              ### 1\. The cave problem


              This explanation was introduced in the paper "How to explain zero-knowledge
              protocols to your children" (\*4).


              - (\*4) [Jean-Jacques Quisquater et al., "How to Explain Zero-Knowledge
              Protocols to Your Children," CRYPTO 1989. (PDF: 227KB)](https://pages.cs.wisc.edu/~mkowalcz/628.pdf)


              Inside the cave is a magic door that opens when you say the password.
              The prover P knows the password and gives it in exchange for money.
              The door is at the far end of the cave shown in Figure 2. There are
              two paths to the door, A and B. The person who knows the password can
              open the door and move from A to B or vice versa.


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img02.jpg?h=453&iar=0&w=800&rev=cf4c7228935441d3b38f0fd9442af117)


              Figure 2: The Cave Problem



              V, the verifier, wants to buy the password, but he doubts whether P
              really knows the password and cannot start a transaction. If P can convince
              V that P knows the secret password without telling V the secret password
              itself, V can start a transaction. So, here''s what they are trying
              to do.


              First, V waits outside the cave. Then P enters the cave, randomly chooses
              either path A or B, and goes to the door (Figure 3).


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img03.jpg?h=533&iar=0&w=800&rev=0918e3fa17984bbe8d735ff3c9df3166)


              Figure 3: Prover P''s Random Selection



              Next, V enters the cave, goes to the branching point of the paths, randomly
              chooses A or B in their head, and shouts to P to come out from the chosen
              path (Figure 4).


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img04.jpg?h=401&iar=0&w=800&rev=945bfc0651e54daea0b604e2edd6f2a4)


              Figure 4: Verifier V''s Random Selection



              If P knows the password:


              P can use the password to open the door and come out of the designated
              path, whichever way V tells him to go (Figure 5). This means completeness.


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img05.jpg?h=466&iar=0&w=800&rev=6088ed6bec1c4fd3a3ac05b15c69a53a)


              Figure 5: The Case that Prover P Knows the Password



              If P does not know the password:


              P can only come out of the path he entered, so the probability of coming
              out of the path chosen by V is 50%. If they repeat this process over
              and over again, it''s almost impossible for P to fool V every time (Figure
              6). For example, if they try 30 times, the probability that P can fool
              V is about 0.0000001%. This means soundness.


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img06.jpg?h=421&iar=0&w=800&rev=db7f0b94506a47679157cddc1b1a33bf)


              Figure 6: The Case that Prover P Does Not Know the Password



              So, if P succeeds on all his attempts, V must be convinced that P knows
              the password. If V tries even more, he can get his chance of being cheated
              as close to 0% as V wants. At this time, V will not gain any knowledge
              about the password. This means zero-knowledge.


              Literally, what P wants to prove has been proved to V with zero-knowledge.


              ### 2\. The Problem of Finding a Seabird


              Professor Amit Sahai of the University of California, Los Angeles (UCLA)
              explains the concept of zero-knowledge proof on YouTube to children,
              teenagers, college students, graduate students, and experts in five
              different difficulty levels (\*5). Here is a child-friendly explanations
              that will help you get a sense of the main points.


              - (\*5) [Computer Scientist Explains One Concept in 5 Levels of Difficulty,
              WIRED](https://www.youtube.com/watch?v=fOGdb1CTu5c)


              The professor shows the child a picture. The picture shows a crowd of
              hundreds of penguins. He says, "There is one puffin (a penguin-like
              seabird), and I know where it is, but I don''t want to tell you. Do
              you believe me? I''m going to prove it without revealing its location."


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img07.jpg?h=505&iar=0&w=800&rev=3f05fc0c1f934735a75fbbae8353800f)


              Figure 7: The Problem of Finding a Seabird



              The professor pulls out a piece of black paper several times larger
              than the photo. The paper has a small hole, and the photo is pasted
              on the back of the paper so that the hole matches the position of the
              puffin. The child looks into the hole and says, "I see a puffin". But
              the child can''t see the position of the photo on the back of the paper,
              so she can''t tell where the puffin is in the original photo. "This
              is an example of a zero-knowledge proof," the professor explains (Figure
              8).


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/img08.jpg?h=370&iar=0&w=800&rev=46de5598e3f64c609c0c7fd1a156c661)


              Figure 8: Zero-Knowledge Proof for the Problem of Finding a Seabird



              This exchange satisfies completeness because a professor who knows the
              location of the puffin can always prove it.


              Furthermore, it satisfies soundness because if the professor does not
              know the location of the puffin, the cheating will be exposed with a
              high probability if the child looks into the hole and confirms it.


              Furthermore, it satisfies zero-knowledge because the child cannot obtain
              any knowledge other than the fact that the professor knows the location
              of the puffin.


              ## Social Application Examples


              This paper introduces an application example of zero-knowledge proof
              to society and considers prospects.


              ### 1\. Blockchain Privacy Enhancement


              Blockchain is widely used in society, a representative example being
              virtual currencies. Its transparency is maintained by decentralized
              management of its ledger by all participants in the blockchain. However,
              due to its high transparency, securing user privacy may be a challenge.


              In recent years, zero-knowledge proofs have begun to be used to improve
              blockchain privacy. For example, in the case of cryptocurrencies, methods
              known collectively as zk-SNARK (\*6) and zk-STARK (\*7) have begun to
              be introduced as zero-knowledge proofs to show that the transaction
              operation was indeed performed, without disclosing the transaction contents
              such as the sender, recipient, and remittance amount.


              In addition, zero-knowledge proofs have attracted even more attention
              because they can contribute to speeding up blockchain processing.


              - (\*6)

              zk-SNARK: Zero-Knowledge Succinct Non-Interactive Argument of Knowledge


              - (\*7)

              zk-STARK: Zero-Knowledge Scalable Transparent Argument of Knowledge



              ### 2\. Proof of Income Range


              In November 2017, ING, a major Dutch bank, developed zero-knowledge
              range proofs (ZKRP) (\*8). ZKRP is an application of zero-knowledge
              proofs. ZKRP can prove that a numerical value, such as an amount of
              money, is within a certain range without showing the numerical value
              to the other party. For example, mortgage applicants can prove that
              their income is within a certain range required by loan screening without
              telling the income itself.


              - (\*8)[ING launches Zero-Knowledge Range Proof solution, a major addition
              to blockchain technology](https://www.ingwb.com/en/insights/distributed-ledger-technology/ing-launches-major-addition-to-blockchain-technology)


              ### 3\. Selective Disclosure of Attribute Information


              The W3C, which standardizes Web technologies, has standardized a data
              model for the concept of verifiable credentials (VC) (\*9). It introduces
              zero-knowledge proof, in which you select your attribute information
              and prove only that the attribute satisfies certain conditions.


              For example, it shows a use case in which you select and prove only
              the information that a university graduate received a degree without
              revealing his or her identity or other unnecessary personal information.


              - (\*9) [W3C Recommendation, Verifiable Credentials Data Model v1.1,
              2022.](https://www.w3.org/TR/vc-data-model/#zero-knowledge-proofs)



              VC is currently being discussed in the "Trusted Web" initiative led
              by the Cabinet Secretariat of Japan. It shows the expectation of zero-knowledge
              proof as a method to realize selective disclosure of data(\*10).


              - (\*10) [Secretariat of the Headquarters for Digital Market Competition,
              the Cabinet Secretariat of Japan, "Trusted Web White Paper Ver 2.0,
              Overview" August 2022 (PDF: 1.7MB)](https://www.kantei.go.jp/jp/singi/digitalmarket/pdf_e/Trusted_Web_White_Paper_ver2.0_Overview.pdf)


              ### 4\. User Authentication


              Currently, ID and password authentication is mainly used for websites
              of various services. However, since the string length of a password
              is limited to a range that can be remembered or managed by the human
              brain, it is vulnerable to brute-force and password-list-type attacks.


              Furthermore, if an attacker takes over the server, not only the password
              itself, but also information useful for guessing the password is leaked,
              which becomes a hint for the attacker, and the password may be leaked
              in the future. If user authentication is implemented with zero-knowledge
              proof, the server can be more secure because no information related
              to the password exists from the beginning.


              As a zero-knowledge proof that can be applied to user authentication,
              there is the Schnorr protocol (\*11). In this method, knowledge about
              the solution of a mathematically difficult problem called the discrete
              logarithm problem is assumed to be information that only the user can
              know and is authenticated with zero-knowledge proof. Compared with the
              ID and password method, this method has not been adopted in the world
              for many years due to its disadvantages such as high communication volume,
              slow processing speed, and "The size of the data to be kept secret is
              too large for humans to remember."


              - (\*11) [IETF, RFC 8235, Schnorr Non-interactive Zero-Knowledge Proof,
              September 2017](https://www.rfc-editor.org/info/rfc8235)


              In recent years, however, with the spread of technologies such as "faster
              communication networks," "faster processing speeds of servers and terminals,"
              and "memory areas that can be securely stored in smart cards and smartphones,"
              conventional disadvantages are going to be no longer disadvantages.


              ## Prospect


              In recent years, the term "Web3" has attracted attention, and although
              there are various interpretations, its constituent concepts are said
              to be centered on "blockchain," "decentralization" and "decentralized
              ID." Application cases (1) and (2) mentioned above are measures to improve
              the privacy of blockchain, and (3) and (4) are related to decentralization
              and decentralized ID. Therefore, zero-knowledge proof can be said to
              be "a technology that brings trustworthiness to the privacy of Web3."


              In the future, zero-knowledge proof will become an essential technology
              for safe and secure future societies that require a high level of privacy.


              NTT DATA will continue to keep up with the latest trends and accumulate
              and disclose know-hows.


              ![](https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/hiroaki-oguro.jpg?rev=470b7539b1bb46cf86cfef3e0f138a2d)


              Hiroaki Oguro


              NTT DATA Japan Corporation


              He engages in R&D, in-house applications, and business applications
              in cryptography, Web application security, and software engineering.
              CISSP. Senior member of the Information Processing Society of Japan
              (IPSJ). Expert committee member of the Special Interest Groups (SIG)
              of the Computer Security (CSEC) in IPSJ.'
            metadata:
              og:type: article
              og:url: https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof
              og:description: 'Recently, "zero-knowledge proof" is attracting attention.
                In 2019, the World Economic Forum announced zero-knowledge proof as
                one of the five privacy-enhancing technologies that bring new value
                to the financial sector. '
              og:image: https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/index-list.jpg?rev=ff34be8828a9426e9e8278ff1bd1f1a0
              twitter:card: summary
              og:site_name: NTT DATA
              ogTitle: What is Zero-Knowledge Proof - a hot technology bringing trustworthiness
                to Web3 privacy?
              ogSiteName: NTT DATA
              favicon: https://www.nttdata.com/global/en/-/media/assets/images/android-chrome-256256.png?rev=b1d7877f056340d181794ead6f1b3c16
              language: en
              ogDescription: 'Recently, "zero-knowledge proof" is attracting attention.
                In 2019, the World Economic Forum announced zero-knowledge proof as
                one of the five privacy-enhancing technologies that bring new value
                to the financial sector. '
              viewport: width=device-width, initial-scale=1
              og:title: What is Zero-Knowledge Proof - a hot technology bringing trustworthiness
                to Web3 privacy?
              ogImage: https://www.nttdata.com/global/en/-/media/nttdataglobal/1_images/insights/focus/what-is-zero-knowledge-proof/index-list.jpg?rev=ff34be8828a9426e9e8278ff1bd1f1a0
              format-detection: telephone=no, address=no, email=no
              title: What is Zero-Knowledge Proof - a hot technology bringing trustworthiness
                to Web3 privacy? | NTT DATA Group
              description: 'Recently, "zero-knowledge proof" is attracting attention.
                In 2019, the World Economic Forum announced zero-knowledge proof as
                one of the five privacy-enhancing technologies that bring new value
                to the financial sector. '
              ogUrl: https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof
              scrapeId: 76a24230-1753-450a-8bc4-c0e4fce54b77
              sourceURL: https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof
              url: https://www.nttdata.com/global/en/insights/focus/2024/what-is-zero-knowledge-proof
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
          - title: 'Don''t Trust When You Can Verify: A Primer on Zero-Knowledge Proofs'
            description: Combining ZKPs with blockchain technology introduces a new
              level of transparency and accountability in AI and machine learning.
              Blockchain ...
            url: https://5g.wilsoncenter.org/article/dont-trust-when-you-can-verify-primer-zero-knowledge-proofs
            markdown: "Close\n\n[Get Updates](https://engage.wilsoncenter.org/a/5g)\n\
              \n[Skip to main content](https://5g.wilsoncenter.org/article/dont-trust-when-you-can-verify-primer-zero-knowledge-proofs#maincontent)\n\
              \n## Introduction\n\nFrom finance to communications to commerce, the\
              \ most essential things in our lives are increasingly digital, and at\
              \ a pace that only continues to accelerate. This has fostered unprecedented\
              \ economic growth and technological innovations, however our most sensitive\
              \ and private information has necessarily come along for the ride. This\
              \ puts individuals, private organizations, and governments increasingly\
              \ at risk of becoming victims of data breaches and hacks.\n\nSolutions\
              \ to these problems often call for increased know your customer practices\
              \ (KYC) and reporting. KYC is a regulatory and security process where\
              \ businesses verify the identity of their clients to prevent identity\
              \ theft, financial fraud, money laundering, and terrorist financing.\
              \ While there are benefits to this approach, it comes with the risk\
              \ of sensitive data being distributed to even more parties, thus increasing\
              \ the potential surface area for attack, and further reducing individual\
              \ privacy. In a world where trust in institutions is historically low,\
              \ this can be a hard pill for individuals to swallow. But what if there\
              \ was a solution that allowed individuals, private organizations, and\
              \ governments alike to verify things like identity and financial data\
              \ with said data always remaining encrypted and obfuscated? What if\
              \ you didn’t have to trust because instead, you could verify?\n\nZero-knowledge\
              \ proofs (ZKPs) have emerged as a pivotal cryptographic innovation representing\
              \ a paradigm shift replacing the need to trust with the ability to _verify_.\
              \ This comprehensive exploration will shed light on how ZKPs are reshaping\
              \ privacy and security paradigms across various sectors. By the end\
              \ of this article, policymakers will have gained a nuanced understanding\
              \ of ZKPs' potential to improve security while maintaining privacy across\
              \ a wide range of use cases and why they are indispensable in today’s\
              \ digital ecosystem.\n\n## An Idea Ahead of Its Time\n\nFirst described\
              \ in a [1985 MIT paper](https://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Proof%20Systems/The_Knowledge_Complexity_Of_Interactive_Proof_Systems.pdf),\
              \ zero-knowledge proofs (ZKPs) have been an idea simmering on the back\
              \ burner of cryptographic research for decades. Although conceptually\
              \ sound, the technology required for large-scale and cost-effective\
              \ deployment was not yet available. However, with recent advancements\
              \ in computational power and the advent of blockchain technology, ZKPs\
              \ are now coming to the forefront.\n\nThe feasibility of ZKP applications\
              \ now being able to be deployed at scale can be attributed primarily\
              \ to two key developments:\n\n1. **Advancements in Computational Power:**\
              \ Historically, ZKPs were computationally intensive, requiring significant\
              \ processing power which limited their practicality. The exponential\
              \ growth in computational capabilities, in particular, more efficient\
              \ processors and the widespread availability of cloud computing, has\
              \ made it feasible to perform complex ZKP computations quickly and cost-effectively.\n\
              \n2. **Synergies with Blockchain Technology:** The cryptographic nature\
              \ of ZKPs aligns seamlessly with blockchain technologies. Blockchain's\
              \ inherent characteristics of decentralization, immutability, and transparency\
              \ provide a conducive environment for ZKP applications. Several blockchain\
              \ platforms have integrated ZKPs as a core component of their technology\
              \ stack, fostering ready-built platforms for the development and deployment\
              \ of ZKP-based applications.\n\n\nThese technological advancements have\
              \ transformed ZKPs from a theoretical concept into a practical tool,\
              \ unlocking their potential to enhance privacy and security in an increasingly\
              \ digital world.\n\n## How Do Zero-Knowledge Proofs Work?\n\nIn a zero-knowledge\
              \ proof, there are two parties: a prover and a verifier. In this transaction,\
              \ the prover can assure a verifier of the truthfulness of a particular\
              \ assertion regarding a data point without revealing any extra details\
              \ about the corresponding data.\n\nZKPs can be categorized into two\
              \ types:\n\n- **Interactive**, where the prover must engage in the verification\
              \ process anew for each distinct verifier.\n\n- **Non-interactiv** e,\
              \ where the prover creates a universally verifiable proof.\n\n\nThe\
              \ three key characteristics that encapsulate a ZKP are:\n\n- **Completeness**:\
              \ For any true statement, a credible prover can successfully persuade\
              \ an honest verifier of their knowledge about the accurate input.\n\n\
              - **Soundness:** In the case of a false statement, no deceitful prover\
              \ can independently convince an honest verifier of their knowledge about\
              \ the accurate input.\n\n- **Zero-Knowledge**: When the statement is\
              \ true, the verifier gains no additional information from the prover\
              \ beyond the fact that the statement is indeed true.\n\n\nThe math that\
              \ makes this possible is beyond the scope of this piece, however, a\
              \ simple example can help conceptualize how a ZKP works.\n\nImagine\
              \ you have a \"Where's Waldo?\" book, and you claim to know exactly\
              \ where Waldo is on a particular page. Your friend, however, is skeptical\
              \ and wants proof of your claim. But here's the challenge: you need\
              \ to prove you know where Waldo is without pointing him out directly,\
              \ thus keeping his location a secret.\n\n![A photo in sepia of a crowd\
              \ with a man wearing glasses and a red and white stripped sweater and\
              \ had in color. ](https://5g.wilsoncenter.org/sites/default/files/styles/fullbleed_image/public/media/uploads/images/8560929002_bd81ba6679_o.jpg)\n\
              \nImage Credit\n\nWhere's Waldo? byBarbara Friedman\n\n[https://www.flickr.com/photos/btf5/8560929002/in/photolist-e3uZWb-2njZwsF-2n8Dk9e-Cbkd28-2n8yfHm-4nFLBz-2n8Dk9u-2jDsCuZ-Masdhh-81uW91-FgJx5U-ZGrxHA-BTMey-2n1CRfi-2nj6p3n-2nj7FQu-8EUaoj-2niYPhG-2nj5bAN-2nj5avb-2nj7Gk2-2iFCpo8-2nj6oyr-hiqBnv-2niYNej-2nj5kie-2nj5b9L-2nj7F9e-2nj59gY-2nj59Sh-2nj5kVB-2niYN7a-2nj6noa-2nj7EwH-9Zj7wT-9Ckm8q-4DdCfU-deaSce-23ViBAN-PUW8UA-2niYNTR-2eJqgA5-dCixw7-mBSP44-4D9nJk-2nj6nA4-qqtWBz-4D9mWF-5ApDf5-jFMTTg](https://www.flickr.com/photos/btf5/8560929002/in/photolist-e3uZWb-2njZwsF-2n8Dk9e-Cbkd28-2n8yfHm-4nFLBz-2n8Dk9u-2jDsCuZ-Masdhh-81uW91-FgJx5U-ZGrxHA-BTMey-2n1CRfi-2nj6p3n-2nj7FQu-8EUaoj-2niYPhG-2nj5bAN-2nj5avb-2nj7Gk2-2iFCpo8-2nj6oyr-hiqBnv-2niYNej-2nj5kie-2nj5b9L-2nj7F9e-2nj59gY-2nj59Sh-2nj5kVB-2niYN7a-2nj6noa-2nj7EwH-9Zj7wT-9Ckm8q-4DdCfU-deaSce-23ViBAN-PUW8UA-2niYNTR-2eJqgA5-dCixw7-mBSP44-4D9nJk-2nj6nA4-qqtWBz-4D9mWF-5ApDf5-jFMTTg)\n\
              \nHere's how you can do it: \"Where's Waldo?\"\n\n1. **The Challenge:**\
              \ You open the \"Where's Waldo?\" book to the page in question and show\
              \ it to your friend.\n\n2. **The Proof Technique:** To prove your knowledge\
              \ without revealing Waldo's location, you take a large piece of cardboard\
              \ with a small hole cut in it.\n\n3. **The Verification:** You place\
              \ the cardboard over the page so that the hole reveals Waldo, but nothing\
              \ else on the page is visible. Your friend can now see Waldo through\
              \ the hole, confirming you know his location.\n\n4. **Maintaining Secrecy:**\
              \ Despite verifying your claim, your friend still doesn't know where\
              \ on the page Waldo is. The rest of the page is covered, keeping the\
              \ information hidden.\n\n\nIn this scenario:\n\n- **Completeness:**\
              \ If you truly know where Waldo is, you can easily align the hole in\
              \ the cardboard to reveal him, convincing your friend of your knowledge.\n\
              \n- **Soundness:** If you don’t actually know where Waldo is, you won’t\
              \ be able to align the hole correctly, and your friend won’t be convinced\
              \ of your claim.\n\n- **Zero-Knowledge:** Despite proving you know Waldo’s\
              \ location, you haven’t revealed any additional information about where\
              \ on the page Waldo is.\n\n\nThese proofs enable one party to prove\
              \ the validity of a statement to another without revealing any underlying\
              \ information. In an era where data breaches are rampant, ZKPs offer\
              \ hope for secure and private online interactions.\n\n## A Myriad of\
              \ Real-World and Digital-World Applications\n\nZKPs have a wide array\
              \ of applications, each demonstrating their versatility and importance\
              \ in enhancing privacy and security in various digital domains:\n\n\
              ### Decentralized Identity and Authentication:\n\nZKPs can serve as\
              \ a foundational technology for identity management systems by offering\
              \ a dual advantage: they enable robust identity verification while safeguarding\
              \ personal information. This is particularly relevant in systems built\
              \ on blockchains, which are inherently global and interoperable, facilitating\
              \ secure international information sharing.\n\n- **Offline Applications:**\
              \ ZKPs can be used in everyday situations like confirming age for alcohol\
              \ purchase or even verifying citizenship and non-sanctioned status at\
              \ international borders. In these cases, ZKPs provide proof of specific\
              \ personal attributes without revealing any additional personal information.\n\
              \n- **Online Applications:** The decentralized nature of blockchain\
              \ networks limits traditional KYC practices, but ZKPs offer a way for\
              \ central entities to securely verify user identities.\n\n\nSince it\
              \ is one of the most impactful applications of ZKPs, the following section\
              \ takes a deep dive into decentralized identity.\n\n### Voting Systems:\n\
              \nZKPs introduce a new paradigm in voting systems, particularly in conjunction\
              \ with distributed ledger technologies. Together, they enable a voting\
              \ process that is both anonymous and verifiable, enhancing the integrity\
              \ and transparency of elections.\n\n- **Identity Verification and Eligibility\
              \ Checks:** Leveraging the decentralized identity solutions discussed\
              \ earlier, ZKPs can be used to verify a voter's identity and their eligibility\
              \ to vote. This approach ensures that only qualified individuals participate\
              \ in the voting process and that no one can vote more than once. Such\
              \ identity verification acts as a gatekeeper to access existing voting\
              \ systems, upholding the principle that every vote counts and should\
              \ be counted correctly.\n\n- **Anonymous Verifiable Voting:** Beyond\
              \ verifying voter identity, ZKPs can preserve the anonymity of the voting\
              \ process. Voters can confidently validate their eligibility and cast\
              \ their ballots without having to reveal their identities or the specifics\
              \ of their vote. This application of ZKPs allows each vote to remain\
              \ confidential while ensuring the entire voting process is transparent\
              \ and auditable.\n\n- **Auditable Yet Private Voting System:** The integration\
              \ of ZKPs in voting systems is transformative, enhancing both the verification\
              \ mechanism and the voting process itself. By incorporating ZKPs, the\
              \ system not only links each vote to an eligible voter but also maintains\
              \ voter anonymity. This dual capability creates a voting environment\
              \ that is secure, transparent, and respectful of voter privacy. The\
              \ system can be implemented either as an identity check before accessing\
              \ existing voting platforms or as an integral part of a new blockchain-based\
              \ voting system, embedding both identity verification and vote casting\
              \ within a unified, secure framework.\n\n\n### AI and Machine Learning:\n\
              \n- Privacy Preservation in Data Usage:\n  - A key challenge in AI and\
              \ machine learning is accessing large datasets for training models without\
              \ compromising sensitive information contained within the data. ZKPs\
              \ enable the verification of data authenticity and integrity for these\
              \ models while keeping the underlying data elements private.\n\n  -\
              \ The capability to verify information while maintain privacy is particularly\
              \ crucial in industries like healthcare or finance, where data confidentiality\
              \ is paramount. ZKPs allow for the utilization of detailed datasets\
              \ for model training without exposing individual data points, thus upholding\
              \ privacy standards and regulatory compliance.\n- Blockchain Integration\
              \ for Model Accountability:\n  - Combining ZKPs with blockchain technology\
              \ introduces a new level of transparency and accountability in AI and\
              \ machine learning. Blockchain provides an immutable record of transactions\
              \ which enables the tracking of data changes, model updates, and decision-making\
              \ processes when applied to AI models.\n\n  - This integration allows\
              \ for a transparent audit trail of how AI models evolve over time and\
              \ how data influences these models. It addresses concerns around model\
              \ integrity and reliability, ensuring that changes or updates to AI\
              \ systems are transparent and accountable.\n- Enhancing Trust in AI\
              \ Systems:\n  - By utilizing ZKPs, AI and machine learning systems can\
              \ demonstrate that they function as intended without revealing their\
              \ internal workings or the proprietary data they process. This builds\
              \ trust among users and stakeholders, assuring them that the AI systems\
              \ are not only effective but also respect privacy and data security.\n\
              \n  - In scenarios where decisions made by AI systems need to be justified\
              \ or explained, such as in credit scoring or medical diagnostics, the\
              \ combination of ZKPs and blockchain can provide necessary assurances\
              \ about the data and processes used without compromising sensitive information.\n\
              - Facilitating Collaborative AI Development:\n  - ZKPs enable multiple\
              \ parties to contribute data to AI models securely and privately. This\
              \ collaborative approach, bolstered by the trust mechanisms of ZKPs\
              \ and blockchain, can accelerate AI innovation by allowing diverse data\
              \ sources to be used collectively, broadening the scope and applicability\
              \ of AI solutions.\n\n### Privacy on Public Blockchains:\n\n- The immutable\
              \ and public nature of data stored on a blockchain is a defining and\
              \ often beneficial feature, this feature can become an issue in transactions\
              \ that require privacy. For more on the challenges and opportunities\
              \ presented by the transparent nature of public blockchains, check out\
              \ our previous [Blockchain Brief on blockchain privacy.](https://www.wilsoncenter.org/article/blockchain-worlds-least-private-diary)\n\
              \  - **Private Transactions:** ZKPs are used in blockchains for privacy-preserving\
              \ transactions that keep details like monetary amounts and participant\
              \ identities private.  ZKPs can keep this information private while\
              \ verifying that users are not participating in illicit activity or\
              \ transacting with sanctioned entities.\n\n  - **Private Exchange and\
              \ Settlement of Digital Assets:** ZKPs ensure the privacy of transactions\
              \ and participants during the exchange of digital tokens, such as equity\
              \ tokens. This is crucial for both centralized and decentralized exchanges,\
              \ allowing for efficient and private asset settlement. As more real-world\
              \ assets (RWAs) like real estate and high-valuable collectibles are\
              \ tokenized and more transactions involving RWAs are conducted on-chain,\
              \ this efficiency and privacy is paramount.\n\n### Scalable Ethereum\
              \ Layer 2 Rollups:\n\nZKPs, through methods like zero-knowledge rollups\
              \ (ZK-rollups), are highly secure and scalable Layer 2 solutions on\
              \ Ethereum that facilitate faster, more efficient transactions. If you\
              \ need a refresher on the difference between a Layer 1 and Layer 2 blockchain\
              \ before we dive deeper into the current state of ZK rollups, be sure\
              \ to check out our previous [Blockchain Brief where we break it down.](https://www.wilsoncenter.org/article/understanding-ethereums-layer-1-and-layer-2-differences-adoption-and-drawbacks)\n\
              \n### Oracle-Enhanced Verifiable Computations:\n\n- In decentralized\
              \ oracle networks, ZKPs can be leveraged for verifiable computations\
              \ related to off-chain data points. [As explained in a previous Blockchain\
              \ Brief](https://www.wilsoncenter.org/article/delphi-defi-how-crypto-oracles-are-shaping-future-finance),\
              \ blockchain oracles provide smart contracts with access to external\
              \ data and computation results. Using ZKPs in this context ensures the\
              \ integrity and confidentiality of the data processed by the oracles.\
              \ Relevant off-chain data points include:Financial Data: Verifying stock\
              \ prices or foreign exchange rates for use in smart contracts without\
              \ revealing sensitive market data.\n\n- Supply Chain Information: Confirming\
              \ the authenticity of supply chain events like product manufacturing\
              \ or shipping status without disclosing proprietary details.\n\n- Real-World\
              \ Events: Maintaining data privacy while validating outcomes of real-world\
              \ events, like sports results and election outcomes, that impact contract\
              \ executions Weather Data: Securely integrating weather information\
              \ for agriculture-related smart contracts without full data exposure.\n\
              \n\n### Internet of Things (IoT):\n\n- Securing IoT device communications\
              \ and reducing data transmission through ZKPs enhances both privacy\
              \ and efficiency in interconnected devices.\n\n\n### Supply Chains:\n\
              \n- ZKPs can authenticate compliance and origin in supply chain management\
              \ without revealing sensitive data, which is crucial for businesses\
              \ that wish to keep supplier information confidential.\n\n\nThese diverse\
              \ applications across sectors underscores the significance of ZKPs in\
              \ addressing privacy and security challenges in the digital age by offering\
              \ robust solutions for secure, private, and efficient digital interactions.\n\
              \n## A Deeper Dive into Decentralized Digital Identity and Securing\
              \ Personal Identifiable Information\n\nZero-knowledge proofs present\
              \ a unique solution to address the urgent need for safe and secure methods\
              \ of digital identity verification and storage of personal identifiable\
              \ information (PII). ZPKs minimize the exposure of PII by enabling the\
              \ verification of essential information while keeping other personal\
              \ details hidden, thereby fortifying systems against data breaches and\
              \ preserving individual privacy. This is crucial in scenarios ranging\
              \ from social media interactions to financial transactions.\n\nConsider\
              \ the routine action of showing an ID to purchase alcohol – you inadvertently\
              \ expose more information than necessary.\n\nThe cashier only needs\
              \ to verify two things: that the id is a valid, government issued id\
              \ and that you are 21 or older. Yet you are revealing your full name,\
              \ home address, birthdate and age, sex, height, weight, eye color, and\
              \ driver’s license number. These pieces of information are individually\
              \ harmless, but when they are used together, there is potential for\
              \ abuse, not to mention a violation of an individual’s right to privacy.\n\
              \nThis scenario is amplified online, where the sharing of social security\
              \ numbers, financial details, and personal activities often leads to\
              \ privacy invasion and increases the risk of cyberattacks. Consider\
              \ the following three examples representing massive misuse and exposure\
              \ of sensitive user data, and how Zero-Knowledge Proofs (ZKPs) could\
              \ have potentially mitigated these incidents:\n\n1\\. Cambridge Analytica\
              \ Scandal:\n\n- **Real-World Incident:** A third-party app, This Is\
              \ Your Digital Life, allowed unauthorized collection of personal data\
              \ from millions of Facebook users. Cambridge Analytica used that data\
              \ for political advertising, including in the 2016 U.S. presidential\
              \ election campaign. This breach raised significant concerns about privacy\
              \ and the influence of social media on politics.\n\n- **ZKP Mitigation:**\
              \ ZKPs could have been used to verify the specific user attributes (e.g.,\
              \ age, location, political interests) necessary for academic research\
              \ or targeted advertising without revealing or transferring the underlying\
              \ data. That way, Facebook could confirm specific demographics of its\
              \ user base to third parties without exposing individual user data.\n\
              \n\n2\\.  T-Mobile Data Breaches:\n\n- **Real-World Incident:** Caused\
              \ by a misconfigured API, T-Mobile experienced a data breach that exposed\
              \ the personal data of 37 million customers. The stolen data was used\
              \ by cybercriminals for sophisticated phishing, vishing, and smishing\
              \ attacks.\n\n- **ZKP Mitigation:** ZKPs could have been employed in\
              \ T-Mobile’s data handling processes to validate user identity and credentials\
              \ without exposing user data. For instance, a customer service application\
              \ could verify that a person is a T-Mobile customer and check their\
              \ plan details without the API accessing the full range of personal\
              \ information stored in the database.\n\n\n3\\. Equifax Data Breach\
              \ of 2017:\n\n- **Real-World Incident:** This breach, one of the largest\
              \ in U.S. history, compromised the personal information of about 147.9\
              \ million Americans, as well as millions of British and Canadian citizens.\
              \ Hackers accessed names, Social Security numbers, birth dates, addresses,\
              \ and in some cases, driver's license numbers. The breach was deemed\
              \ \"entirely preventable\" by the House Committee on Oversight.\n\n\
              - **ZKP Mitigation:** If ZKPs had been used, Equifax could have allowed\
              \ third-party services to confirm individuals' creditworthiness or identity\
              \ without accessing detailed personal data like Social Security numbers\
              \ or birth dates. For example, a lender could verify if a person's credit\
              \ score falls within a specific range without Equifax needing to share\
              \ the actual credit report.\n\n\nIn each of these scenarios, ZKPs would\
              \ have offered a way to validate and prove necessary information without\
              \ exposing data, thus significantly reducing the risk of data breaches\
              \ and misuse of personal information. Implementing ZKPs requires rethinking\
              \ how systems interact with personal data and moving towards a model\
              \ where verification is possible without data exposure. The adoption\
              \ of ZKPs benefits individuals whose personal data remains protected\
              \ and private as well as businesses, which can avoid the substantial\
              \ financial and reputational damage often associated with such data\
              \ breaches. By enhancing data security and integrity, ZKPs provide two\
              \ key benefits: they help in building trust among consumers and simultaneously\
              \ safeguard businesses against the risks and liabilities of data mismanagement.\n\
              \n## The Current State of ZK-Rollups\n\nAs noted earlier, the two developments\
              \ that have allowed ZKPs to finally transition from academic concept\
              \ to real world use have been increased power and availability of compute\
              \ and blockchains. While smart contract platforms like Solana and Avalanche\
              \ have seen significant growth in daily active users, ecosystem development,\
              \ and capital inflows in 2023, Ethereum and its Layer 2 blockchains\
              \ remain the dominant smart contract ecosystem. As of 1/17/24, Ethereum\
              \ and its L2 chains have a combined market cap ($322B) 1.6X higher than\
              \ [every other smart contract platform combined](https://www.coingecko.com/en/categories/smart-contract-platform)\
              \ and 72% ($78B) of [total value locked](https://defillama.com/chains)\
              \ (TVL) in [decentralized finance (DeFi)](https://www.wilsoncenter.org/article/defi-101-good-bad-and-regulatory).\n\
              \nAs discussed in our previous article, breaking down the difference\
              \ between [L1 and L2 Ethereum](https://www.wilsoncenter.org/article/understanding-ethereums-layer-1-and-layer-2-differences-adoption-and-drawbacks),\
              \ L2 blockchains are pivotal in enabling Ethereum to scale. As a quick\
              \ refresher, there are two types of rollups: Optimistic rollups and\
              \ ZK rollups. While ZK rollups are broadly considered the superior technology,\
              \ the increased complexity of ZKP development, higher compute requirements,\
              \ and layer 1 technological limitations have given optimistic rollups\
              \ a strong first mover advantage. The top three optimistic rollups,\
              \ [Arbitrum](https://arbitrum.foundation/), [Optimism](https://www.optimism.io/),\
              \ and [Base](https://www.base.org/), currently hold 81% of the total\
              \ L2 market share.\n\nThe tide has begun to change, as several notable\
              \ ZK-rollups went live in 2023. As of 2024, the development and implementation\
              \ of ZK-rollups on Ethereum have advanced significantly, showing promising\
              \ growth and innovation in various projects.\n\nYou can find a list\
              \ of notable Optimistic and ZK-rollups in the previous Blockchain Brief,\
              \ [Understanding Ethereum's Layer 1 and Layer 2](https://www.wilsoncenter.org/article/understanding-ethereums-layer-1-and-layer-2-differences-adoption-and-drawbacks).\n\
              \nWhile optimistic rollups collectively represent the majority of L2\
              \ activity and TVL, ZK-rollups are quickly picking up steam and are\
              \ expected to overtake their optimistic cousins. Notably, over the last\
              \ 30 days, [zkSync Era](https://zksync.io/) has processed more transactions\
              \ than Arbitrum, Optimism, Base, and Ethereum Mainnet. Both Arbitrum\
              \ and Optimism have both stated they expect to transition their respective\
              \ chains to ZK-rollups eventually.\n\nThe key takeaway here is that\
              \ the myriad of real-world use cases enabled by ZKPs requires a compatible\
              \ blockchain. That compatibility now exists with the advent of ZK-rollups.\
              \ This, in conjunction with the upcoming [Dencun upgrade](https://www.coindesk.com/tech/2023/10/27/ethereums-dencun-upgrade-is-a-step-toward-a-scalable-settlement-layer-goldman-sachs/)\
              \ to Ethereum set to launch in the coming months (currently live on\
              \ testnet as of 1/17/24), which will dramatically decrease transaction\
              \ costs for L2s while bringing enhanced security, will not only allow\
              \ all of these use cases to deploy but also allow them to do so cost-effectively\
              \ at scale.\n\n## Why Policymakers Should Pay Attention\n\nWe live in\
              \ an increasingly digital world. As individuals, private organizations,\
              \ and governments move more of their interactions online, ever more\
              \ of our most sensitive data is put at risk of data breaches and hacks.\
              \ At a time when faith in public institutions is at an [all time low](https://www.pewresearch.org/politics/2023/09/19/public-trust-in-government-1958-2023/)\
              \ and global ransomware attacks are predicted to [exceed $265B by 2031](https://cybersecurityventures.com/global-ransomware-damage-costs-predicted-to-reach-250-billion-usd-by-2031/),\
              \ the need for technologies like ZKPs to restore faith in the integrity\
              \ of elections, bolster online security, and protect an individual's\
              \ right to privacy is abundantly clear.\n\nThere are many applications\
              \ of ZKPs that can help balance privacy, security, and regulatory compliance.\
              \ This is especially relevant in the context of global and interoperable\
              \ blockchain technology, where ZKPs can bolster blockchains ability\
              \ to enhance the resilience and accessibility of critical infrastructure\
              \ and international cooperation.\n\n### Challenges in the US Regulatory\
              \ Environment\n\nThe US’s ambiguous regulatory environment is currently\
              \ driving blockchain and ZKP-based technology development overseas.\
              \ A lack of clear guidelines is causing a brain drain in this sector,\
              \ with developers and companies opting for more predictable and supportive\
              \ environments in countries like Japan, Singapore, and parts of the\
              \ EU. This regulatory uncertainty is particularly impactful in the area\
              \ of decentralized finance (DeFi), where traditional frameworks struggle\
              \ to adapt to the novel nature of blockchain technologies.\n\n### ZKPs:\
              \ A Potential Solution to DeFi KYC\n\nWithin this challenging regulatory\
              \ landscape, the proposed digital assets tax reporting regulations in\
              \ the bipartisan infrastructure bill have defined decentralized entities\
              \ as brokers. This definition is incompatible with the decentralized\
              \ nature of these entities' protocols, as many lack a central entity\
              \ capable of conducting traditional Know Your Customer (KYC) practices.\
              \ The significant compliance and cost burden for startups could drive\
              \ talent offshore, potentially cutting off US users from innovative\
              \ products. Furthermore, the decentralized structure of these platforms\
              \ allows users bypass front-end data collection and access the backend\
              \ directly.\n\nZero-Knowledge Proofs (ZKPs) emerge as a feasible solution\
              \ in this context. They enable the verification of essential information\
              \ and reporting through smart contracts, all without the need to store\
              \ sensitive data. By using ZKPs, compliance with regulations can be\
              \ achieved while maintaining a balance between privacy, security, and\
              \ innovation. This technology not only minimizes the risk of spreading\
              \ sensitive data across multiple parties but also alleviates the compliance\
              \ burden for emerging companies. In turn, this fosters a healthier environment\
              \ for technological advancement in the US, particularly in the burgeoning\
              \ field of DeFi.\n\n## Conclusion: A Call to Action for Policymakers\n\
              \nAs we navigate the complexities of the digital age, Zero-Knowledge\
              \ Proofs emerge as a powerful tool in preserving privacy while ensuring\
              \ security. Policymakers face the challenge of fostering an environment\
              \ that supports the growth and application of ZKPs while protecting\
              \ consumer rights and privacy. Regulations should be forward-thinking,\
              \ adaptable, and balanced to encourage innovation in this space. The\
              \ harmonious blend of privacy and security that ZKPs provide is not\
              \ just a technological advancement but a step towards a more secure\
              \ and equitable digital world.\n\nIn conclusion, the potential of ZKPs\
              \ is vast and multifaceted. From securing online transactions to safeguarding\
              \ AI and machine learning models, they offer a solution that strikes\
              \ a balance between privacy and security. As machine learning continues\
              \ to evolve and our digital footprints expand, the role of ZKPs in protecting\
              \ our digital identities is critical. It is imperative for policymakers\
              \ to understand these dynamics and create a regulatory environment that\
              \ nurtures innovation, protects consumers, and maintains the integrity\
              \ of the financial system. By embracing the possibilities of Zero-Knowledge\
              \ Proofs, we can pave the way for a more secure, private, and equitable\
              \ digital future.\n\n- [Science and Technology](https://5g.wilsoncenter.org/issue/science-and-technology)\n\
              - [Digital Assets](https://5g.wilsoncenter.org/digitalassets)\n\n###\
              \ Author\n\n![Jared Ronis](https://5g.wilsoncenter.org/sites/default/files/styles/square/public/media/uploads/images/signal-2023-09-28-214334_002.jpeg)\n\
              \n[Jared Ronis](https://www.wilsoncenter.org/person/jared-ronis)\n\n\
              Research Analyst;\n\nStrategic Advisor, SeedAI\n\n\n![Science and Technology\
              \ Innovation Program](https://5g.wilsoncenter.org/themes/custom/wilson/assets/images/program-logos/science-and-technology-innovation-program.svg?20241212)\n\
              \n## Science and Technology Innovation Program\n\nThe Science and Technology\
              \ Innovation Program (STIP) serves as the bridge between technologists,\
              \ policymakers, industry, and global stakeholders.\n\n[Read more](https://www.wilsoncenter.org/program/science-and-technology-innovation-program)\n\
              \n![Science and Technology Innovation Program](https://5g.wilsoncenter.org/themes/custom/wilson/assets/images/program-logos/science-and-technology-innovation-program.svg?20241212)\n\
              \n## Explore More\n\n[Browse Insights & Analysis](https://www.wilsoncenter.org/insight-analysis?topic=167)\n\
              \n[Browse Insights & Analysis](https://www.wilsoncenter.org/insight-analysis?topic=167)\n\
              \n![Image of a quill and an open diary with a blockchain graphic on\
              \ it](https://5g.wilsoncenter.org/sites/default/files/styles/415x256/public/media/uploads/images/Cover%20for%20%233%20Blockchain%20Brief%20.png)\n\
              \n- Science and Technology\n\n## [Blockchain: The World's Least Private\
              \ Diary](https://5g.wilsoncenter.org/article/blockchain-worlds-least-private-diary)\n\
              \nPosted date/time:October 27, 2023\n\n- By\n- [Jared Ronis](https://www.wilsoncenter.org/person/jared-ronis)\n\
              \n![Cover photo for From Delphi to DeFi: How Crypto Oracles are Shaping\
              \ the Future of Finance ](https://5g.wilsoncenter.org/sites/default/files/styles/415x256/public/media/uploads/images/Untitled%20design%20%284%29.png)\n\
              \n- Science and Technology\n\n## [From Delphi to DeFi: How Crypto Oracles\
              \ are Shaping the Future of Finance](https://5g.wilsoncenter.org/article/delphi-defi-how-crypto-oracles-are-shaping-future-finance)\n\
              \nPosted date/time:October 20, 2023\n\n- By\n- [Jared Ronis](https://www.wilsoncenter.org/person/jared-ronis)\n\
              \n![Understanding Ethereum's Layer 1 and Layer 2: Differences, Adoption,\
              \ and Drawbacks - cover photo](https://5g.wilsoncenter.org/sites/default/files/styles/415x256/public/media/uploads/images/zoltan-tasi-uNXmhzcQjxg-unsplash.jpg)\n\
              \n- Science and Technology\n\n## [Understanding Ethereum's Layer 1 and\
              \ Layer 2: Differences, Adoption, and Drawbacks](https://5g.wilsoncenter.org/article/understanding-ethereums-layer-1-and-layer-2-differences-adoption-and-drawbacks)\n\
              \nPosted date/time:October 13, 2023\n\n- By\n- [Jared Ronis](https://www.wilsoncenter.org/person/jared-ronis)\n\
              \n![DeFi 101: The Good, the Bad, and the Regulatory](https://5g.wilsoncenter.org/sites/default/files/styles/415x256/public/media/uploads/images/DeFi%20101_%20The%20Good%2C%20the%20Bad%2C%20and%20the%20Regulatory%20cover%20photo.%20jpg.jpg)\n\
              \n- Science and Technology\n\n## [DeFi 101: The Good, the Bad, and the\
              \ Regulatory](https://5g.wilsoncenter.org/article/defi-101-good-bad-and-regulatory)\n\
              \nPosted date/time:September 29, 2023\n\n- By\n- [Jared Ronis](https://www.wilsoncenter.org/person/jared-ronis)\n\
              \nClose"
            metadata:
              og:title: 'Don’t Trust When You Can Verify: A Primer on Zero-Knowledge
                Proofs'
              favicon: https://5g.wilsoncenter.org/core/misc/favicon.ico
              title: 'Don’t Trust When You Can Verify: A Primer on Zero-Knowledge
                Proofs | Wilson Center'
              ogSiteName: Wilson Center
              og:image:height: '630'
              HandheldFriendly: 'true'
              msapplication-TileColor: '#0e6ea6'
              ogUrl: https://5g.wilsoncenter.org/article/dont-trust-when-you-can-verify-primer-zero-knowledge-proofs
              description: Zero-knowledge proofs (ZKPs) have emerged as a pivotal
                cryptographic innovation representing a paradigm shift replacing the
                need to trust with the ability to verify. This comprehensive exploration
                will shed light on how ZKPs are reshaping privacy and security paradigms
                across various sectors. By the end of this article, policymakers will
                have gained a nuanced understanding of ZKPs' potential to improve
                security while maintaining privacy across a wide range of use cases
                and why they are indispensable in today’s digital ecosystem.
              ogImage: https://5g.wilsoncenter.org/sites/default/files/styles/og_image/public/media/uploads/images/Cover%20for%20%233%2B%234%20Blockchain%20Brief%20.png
              ogDescription: Zero-knowledge proofs (ZKPs) have emerged as a pivotal
                cryptographic innovation representing a paradigm shift replacing the
                need to trust with the ability to verify. This comprehensive exploration
                will shed light on how ZKPs are reshaping privacy and security paradigms
                across various sectors. By the end of this article, policymakers will
                have gained a nuanced understanding of ZKPs' potential to improve
                security while maintaining privacy across a wide range of use cases
                and why they are indispensable in today’s digital ecosystem.
              og:site_name: Wilson Center
              twitter:card: summary_large_image
              MobileOptimized: width
              language: en
              og:image: https://5g.wilsoncenter.org/sites/default/files/styles/og_image/public/media/uploads/images/Cover%20for%20%233%2B%234%20Blockchain%20Brief%20.png
              og:type: article
              og:image:width: '1200'
              og:url: https://5g.wilsoncenter.org/article/dont-trust-when-you-can-verify-primer-zero-knowledge-proofs
              msapplication-config: /themes/custom/wilson/assets/pwa/browserconfig.xml
              viewport: width=device-width, initial-scale=1.0
              og:description: Zero-knowledge proofs (ZKPs) have emerged as a pivotal
                cryptographic innovation representing a paradigm shift replacing the
                need to trust with the ability to verify. This comprehensive exploration
                will shed light on how ZKPs are reshaping privacy and security paradigms
                across various sectors. By the end of this article, policymakers will
                have gained a nuanced understanding of ZKPs' potential to improve
                security while maintaining privacy across a wide range of use cases
                and why they are indispensable in today’s digital ecosystem.
              ogTitle: 'Don’t Trust When You Can Verify: A Primer on Zero-Knowledge
                Proofs'
              theme-color: '#ffffff'
              scrapeId: d51c0695-675b-404f-9421-074895ba2ec3
              sourceURL: https://5g.wilsoncenter.org/article/dont-trust-when-you-can-verify-primer-zero-knowledge-proofs
              url: https://5g.wilsoncenter.org/article/dont-trust-when-you-can-verify-primer-zero-knowledge-proofs
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
          - title: Top ZK Proof Development Companies to Watch in 2025
            description: This article reveals the leading firms that excel in zero-knowledge
              proof technology in blockchain.
            url: https://www.rumblefish.dev/blog/post/top-zk-proof-dev-companies-2025/
            markdown: '[![mobileRumblefishLogo](https://www.rumblefish.dev/_next/static/images/mainGradientRectangularLogo-3f4a056f53f0a5cbd1d2ea1878b028f1.svg)](https://www.rumblefish.dev/)


              Menu


              [![desktopRumblefishLogo](https://www.rumblefish.dev/_next/static/images/mainGradientRectangularLogo-3f4a056f53f0a5cbd1d2ea1878b028f1.svg)](https://www.rumblefish.dev/)


              Services


              [Case studies](https://www.rumblefish.dev/case-studies/)[Careers](https://www.rumblefish.dev/careers/)


              Blog


              Tools


              [About us](https://www.rumblefish.dev/team/)


              Contact


              ![Top ZK Proof Development Companies to Watch in 2025](https://strapi-uploads.rumblefish.dev/Blog_Post_Top_Image_3_1816b51e5a.png?fm=jpg&q=70&h=612&fit=pad)


              ## Top ZK Proof Development Companies to Watch in 2025


              Mon, Apr 7, 2025

              •12 min read


              ##### Category: Business Stories / Blockchain


              Wondering who the top ZK-proof development companies are in 2025? This
              article reveals the leading firms that excel in zero-knowledge proof
              technology in blockchain.


              ## Key Takeaways


              - Zero-knowledge proofs (ZKPs) are like the magic cloak of confidentiality
              for transactions, ensuring privacy without sacrificing trust.

              - Top ZK-proof development companies must ace technical know-how, stay
              innovative, and have a project portfolio that dazzles — no room for
              slackers here!

              - Emerging trends like zk-SNARKs and hardware acceleration are the turbo
              boosters of ZKPs, driving the blockchain world toward rapid scalability
              and secure interoperability.


              ![](https://strapi-uploads-staging-aldnr.rumblefish.dev/Blog_Post_Top_Image_2_2f457773b3.png)


              ## The Importance of Zero-Knowledge Proofs in Blockchain


              Zero-knowledge proofs (ZKPs) significantly **enhance security, privacy,
              and scalability in blockchain applications.** They enable a party to
              demonstrate their knowledge of certain information without disclosing
              the actual data involved. This capability for safeguarding confidentiality
              marks a pivotal advancement in an increasingly critical era of data
              privacy. Imagine executing a transaction on the blockchain where details
              remain concealed yet validated as genuine - that’s the remarkable efficacy
              of ZKPs.


              Incorporating zero-knowledge proofs within blockchain technology cultivates
              more secure and private digital platforms. In contexts like financial
              exchanges, **ZKPs are capable of verifying transactions’ integrity without
              exposing specific transactional information,** boosting both user privacy
              and trustworthiness. They contribute to enhanced scalability by expediting
              processing times - essential for broader acceptance of blockchain technologies.


              Projects employing zk-rollups stand out due to their proficiency in
              bolstering performance while diminishing costs and fortifying security
              measures. By authenticating transactions anonymously, zk-rollups uphold
              blockchain authenticity while substantially cutting down on related
              expenses - a boon that results in streamlined and economical solutions
              across the chain.


              Beyond mere monetary exchanges lies an expansive range of potential
              uses for zero-knowledge proofs - for instance **, ensuring supply chains
              validate product legitimacy without revealing trade secrets or sensitive
              company information.** Thus facilitating competitive advantage retention
              concurrently with adopting transparent and secure blockchains.


              To summarize, zero-knowledge proofs represent a fundamental component
              destined to underpin future advancements in blockchain technology.


              ## Criteria for Evaluating Top ZK Proof Development Companies


              When assessing the leading zero-knowledge proof development companies,
              various critical factors must be considered. At the top of this list
              is their level of technical mastery. **Implementing zero-knowledge proofs
              necessitates a profound comprehension of intricate cryptographic concepts.**
              The most proficient companies in this domain possess an advanced understanding
              of math and algorithms, which enables ZKPs to function effectively and
              securely.


              Another pivotal element is innovation. As the arena of zero-knowledge
              proofs continues to expand swiftly, staying at the forefront is imperative
              for competitive success. Companies need to continuously explore uncharted
              territory within ZKP technologies or identify creative uses for current
              methodologies, ensuring they can deliver state-of-the-art solutions.


              Examining a company’s track record through its project portfolio offers
              substantial evidence about its expertise — successfully navigating diverse
              challenges across numerous **Web3 projects** showcases versatility and
              skillfulness in delivering on complex requirements. Client testimonials
              and recurrent engagements also shed light on how dependable and effective
              these companies are – consistent positive feedback suggests not just
              meeting client needs but surpassing them.


              These benchmarks serve as guiding principles for pinpointing prime candidates
              amongst zero-knowledge proof development companies setting trends in
              2025.


              ## Leading ZK Proof Development Companies in 2025


              ![](https://strapi-uploads-staging-aldnr.rumblefish.dev/Linked_In_Post_Image_7_b7caa46609.jpg)


              The landscape of ZK proof development is brimming with innovation and
              excellence in 2025. Several companies have emerged as leaders in this
              space, each bringing unique strengths and expertise to the table. Starting
              with **Rumble Fish’s focus on expert development services,** these companies
              are at the forefront of integrating zero-knowledge proofs into real-world
              applications.


              Here’s what makes these companies stand out.


              ### Rumble Fish


              Rumble Fish has established itself as a **premier developer of zero-knowledge
              proof technology,** earning recognition for their dedication to creating
              exceptional development services. This commitment has secured them the
              status of a reliable ally for enterprises seeking to utilize zk proof
              technology. A perfect example of their cutting-edge ZK-proof efficiency
              is [their Original Works case study, where they describe how they cut
              ZK-proof processing time from 16 hours to just 3 minutes](https://www.rumblefish.dev/case-studies/decentralized-ddex-registry-original-works/)
              using technologies like Risc Zero and Rust.


              Possessing an impressive history and composed of seasoned professionals,
              Rumble Fish remains at the forefront in crafting cutting-edge solutions
              aimed at bolstering confidentiality and protection within the blockchain
              ecosystem.


              ### PixelPlex


              ​PixelPlex is actively engaged in the field of zero-knowledge proofs
              (ZKPs), offering services and solutions that leverage this advanced
              cryptographic technique. They provide ZK Rollup Scaling Solutions, which
              enhance Ethereum''s scalability by shifting computations off-chain,
              thereby increasing transaction throughput and reducing fees. Additionally,
              PixelPlex has developed DocFlow, a blockchain-powered document management
              system that utilizes optional ZKPs to ensure trust, privacy, and streamlined
              workflows.


              ### Rapid Innovation


              As a provider of ZK rollup layer-2 scaling solutions, Rapid Innovation
              offers top-tier blockchain services to projects looking to unlock their
              full potential in the Web3 space. Their team supports their customers
              from the initial stages and continues to provide ongoing assistance
              even after the ZK rollup network goes live for public use.


              ## Innovative Projects by Top ZK Proof Companies


              The advancement of the zero-knowledge proof sector thrives on inventive
              progress, with numerous enterprises at the forefront executing pioneering
              ventures. These initiatives range from **robust authentication protocols
              to combined zkRollups and distributed identity frameworks,** all extending
              the scope of capabilities for zero-knowledge proofs.


              We should delve into a few of the most stimulating endeavors currently
              underway in this domain.


              ### zkPass Oracle Protocol


              The zkPass project utilizes the zkTLS framework to tackle privacy issues
              in online transactions by providing secure verification of private internet
              data. By maintaining the confidentiality of sensitive information throughout
              the verification stages, zkPass distinguishes itself as a pioneering
              initiative within the domain of zk proof technology.


              ### Aztec Hybrid zkRollup


              The Aztec Network is revolutionizing the blockchain landscape with its
              hybrid zkRollup technology. By facilitating smart contract execution
              that can toggle between public and private states, it substantially
              improves the confidentiality of transactions on the Ethereum network.
              The core of this enhanced privacy is built upon zk-SNARKs, which underpin
              Aztec’s sophisticated privacy protocols.


              By significantly increasing transaction throughput via simultaneous
              processing capabilities for multiple transactions, Aztec’s approach
              to zk rollups positions itself as a standout among other projects in
              this space. This directly addresses scalability issues often faced within
              blockchain technology - cementing Aztec’s status as one of the top zk
              rollup endeavors available today and making it an important project
              to keep an eye on in 2025 and beyond.


              ### RISC Zero


              [RISC Zero](https://risczero.com/) is a general-purpose zkVM that uses
              zk-STARKs over the RISC-V architecture to generate verifiable proofs
              of arbitrary program execution. It enables developers to run familiar
              code (e.g., Rust) off-chain and produce zero-knowledge proofs that can
              be verified anywhere, including on-chain. The team has released an open-source
              zkVM, launched the Bonsai proving service, and secured partnerships
              across the Ethereum and modular blockchain ecosystems.


              ## Emerging Trends in Zero-Knowledge Proof Technology


              The realm of zero-knowledge proofs is in a state of rapid evolution,
              with innovative trends and technologies frequently surfacing that hold
              the potential to transform the blockchain environment. Notably, zk-SNARKs
              and zk-STARKs are at the forefront, offering promising enhancements
              to both scalability and cost-effectiveness for blockchain-based applications.
              **The integration of these advancements into ZKP systems is projected
              to lead to marked improvements in transaction speeds as well as overall
              scalability – pushing ZKPs toward greater accessibility and utility.**


              ![](https://strapi-uploads-staging-aldnr.rumblefish.dev/Linked_In_Post_Image_8_3827a76eba.jpg)


              The advent of hardware acceleration technology enhances this landscape,
              markedly elevating cryptographic computation within ZKP frameworks.
              Given that generating zero-knowledge proofs can require intensive computational
              resources, such technological aids prove crucial by empowering developers
              with the means to **craft more robustly efficient scalable solutions
              centered on zero-knowledge cryptography.**


              Interoperability emerges as another vital component driving wider acceptance
              of ZKPs. It serves an essential function by facilitating secure communication
              between disparate blockchain networks without unveiling sensitive transaction
              data, thereby knitting together a harmonized ecosystem conducive to
              conducting private transactions across varied platforms seamlessly.


              Privacy-focused initiatives continue shaping how various sectors adopt
              ZKPs—most notably within the finance and healthcare arenas— solidifying
              their relevance. By early May 2024 **, aggregate valuations soared beyond
              $21 billion among projects rooted in zero-knowledge crypto-tech alone
              -** a testament signaling intense growth prospects ahead for integrating
              such knowledge proofs extensively throughout blockchain industries worldwide.
              As recognition surges regarding their inherent advantages afforded through
              anonymity-preserving properties amongst stakeholders’ circles, we anticipate
              witnessing persistent strides forward in innovation coupled with heightened
              levels of investment targeting this cutting-edge field.


              ## Challenges and Opportunities in Adopting ZK Proofs


              ![](https://strapi-uploads-staging-aldnr.rumblefish.dev/Linked_In_Post_Image_9_649496a55d.jpg)


              The deployment of zero-knowledge proofs comes with significant hurdles.
              The most notable is the need for considerable technical expertise, as
              the incorporation of zk proofs requires a comprehensive grasp of cryptographic
              concepts that complicates and intensifies the resource demands during
              development. Consequently, this presents a substantial impediment to
              entities looking to integrate ZK proof technology. **Companies who are
              experts in the technology of ZKPs, like Rumble Fish, are a remedy to
              this particular challenge.**


              Generating zero-knowledge proofs poses high computational requirements
              that can lead to inefficiencies, particularly in systems lacking robust
              processing capabilities, which may hinder scalability. There are compatibility
              challenges due to different cryptographic standards and protocols across
              blockchain networks when trying to implement ZKPs within these existing
              infrastructures.


              The potential for innovation remains vast, with zero-knowledge proofs
              offering unmatched advantages regarding privacy enhancement, security
              improvement, and cost reduction associated with transactions. **Zero-knowledge
              enables discreet transactions while fostering more secure and scalable
              solutions on blockchain platforms.** With applications ranging from
              decentralized finance (DeFi) all the way through supply chain management,
              among others, there’s an expansive horizon for innovations using zk
              proof technologies as they progress over time.


              ## Summary


              Zero-knowledge proofs are catalyzing a significant shift in the blockchain
              sector by bolstering its security, enhancing privacy measures, and improving
              scalability. **Industry leaders such as Rumble Fish, RISC Zero, and
              Pixelplex spearhead this transformative phase with their cutting-edge
              approaches that expand the capabilities of zero-knowledge proof (ZKP)
              technology.** These innovations unlock a plethora of use cases for ZKPs,
              ranging from secure confidential transactions to robust decentralized
              identity checks.


              As we anticipate future advancements, it’s evident that zk proof technologies
              hold promising prospects for breakthroughs. Despite any obstacles faced
              along the way, room is abundant for inventive progress. The substantial
              influence zero-knowledge proofs exert on the blockchain infrastructure
              is undeniable. There is much enthusiasm about what lies ahead for zero-knowledge
              technology - a realm filled with untapped potential waiting to be explored.


              ## Frequently Asked Questions


              ### What are zero-knowledge proofs?


              A zero-knowledge proof lets someone (the prover) prove to another person
              (the verifier) that a certain statement is true without revealing any
              additional information beyond the fact that it''s true.


              ZKPs are powerful because they provide **privacy**, **security**, and
              **verifiability** all at once.


              You can:


              - Prove your identity without exposing your credentials.

              - Show that a transaction is valid without revealing its contents.

              - Demonstrate that a computation was done correctly without rerunning
              it or exposing the inputs.


              ### **Types of ZK Proofs**


              1. **zk-SNARKs** – Succinct, fast to verify, but need a trusted setup.

              2. **zk-STARKs** – Scalable, transparent (no trusted setup), and post-quantum
              secure.

              3. **Bulletproofs, Halo, PLONK, etc.** – Variants with different tradeoffs
              in speed, setup, and size.


              ### How do zero-knowledge proofs enhance blockchain security?


              Zero-knowledge proofs enhance blockchain security by allowing transactions
              and computations to be verified without exposing sensitive data. This
              means users can prove ownership, validity, or compliance (like age or
              account balance) without revealing the actual values involved. By enabling
              off-chain computation with on-chain verification, ZKPs reduce the risk
              of fraud while improving scalability. They also protect user privacy,
              which is often lacking in transparent blockchains like Ethereum. Overall,
              ZKPs strengthen trustless systems by ensuring correctness without sacrificing
              confidentiality or decentralization.


              ### What are zk-SNARKs and zk-STARKs?


              zk-SNARKs and zk-STARKs are both types of zero-knowledge proofs, but
              they have different design tradeoffs in terms of performance, transparency,
              and security.


              ![](https://strapi-uploads-staging-aldnr.rumblefish.dev/zk_snark_vs_zk_stark_1cfd4f86c2.png)


              🧬 **zk-SNARKs**


              - Stands for: Zero-Knowledge Succinct Non-interactive Argument of Knowledge

              - They are compact (small proof size) and quick to verify.

              - Require a trusted setup - an initial secret setup phase that, if compromised,
              could undermine security.

              - Generally more mature and widely used today (e.g., in Zcash, zkSync).

              - Efficient for smart contracts because the proofs are small and cheap
              to verify on-chain.


              🔭 **zk-STARKs**


              - Stands for: Zero-Knowledge Scalable Transparent Argument of Knowledge

              - They are transparent - no trusted setup is needed, making them more
              secure in the long term.

              - Post-quantum secure, meaning they''re resistant to future quantum
              attacks.

              - Proofs are larger than SNARKs but scale better with large computations.

              - Used by projects like Starknet and RISC Zero for more complex or large-scale
              proofs.


              In short:


              - SNARKs are small and fast but need setup,

              - STARKs are larger but safer and scale better.


              Categories


              ###### ![arrow](<Base64-Image-Removed>)Business stories


              ###### ![arrow](<Base64-Image-Removed>)Blockchain


              ###### ![arrow](<Base64-Image-Removed>)AI


              ###### ![arrow](<Base64-Image-Removed>)Code stories


              ###### ![arrow](<Base64-Image-Removed>)Software development


              ###### ![arrow](<Base64-Image-Removed>)FinTech


              ###### ![arrow](<Base64-Image-Removed>)AWS


              ###### ![arrow](<Base64-Image-Removed>)UX


              ###### ![arrow](<Base64-Image-Removed>)Mobile development


              Recent posts


              Mon, Aug 18, 2025


              ![article miniature](https://strapi-uploads.rumblefish.dev/Miniatures_for_blog_5_c11afbf5b4.png)


              [**Private Blockchain: Complete Guide ...**](https://www.rumblefish.dev/blog/post/private-blockchain-guide/)


              Sun, Aug 10, 2025


              ![article miniature](https://strapi-uploads.rumblefish.dev/Miniatures_for_blog_2_8b69671689.png)


              [**Building on XRP Ledger: All the Bas...**](https://www.rumblefish.dev/blog/post/basics-of-xrpl-development/)


              Mon, Jul 14, 2025


              ![article miniature](https://strapi-uploads.rumblefish.dev/7_De_Fi_projects_to_watch_54070ec3f8.png)


              [**How Can Blockchain Help Your Busine...**](https://www.rumblefish.dev/blog/post/blockchain-in-mobility/)


              Follow Us


              - [![Facebook](<Base64-Image-Removed>)](https://www.facebook.com/rumblefishsoftwaredevelopment)

              - [![LinkedIn](<Base64-Image-Removed>)](https://www.linkedin.com/company/rumblefishdev)

              - [![Medium](<Base64-Image-Removed>)](https://medium.com/@rumblefishdev)

              - [![Twitter](<Base64-Image-Removed>)](https://twitter.com/rumblefishdev)


              ### Get the latest technology insights on our blog


              ## Recent posts


              Business Stories


              Blockchain


              [Private Blockchain: Complete Guide to Permissioned Networks](https://www.rumblefish.dev/blog/post/private-blockchain-guide/)


              [Read more Private Blockchain: Complete Guide to Permissioned Networks](https://www.rumblefish.dev/blog/post/private-blockchain-guide/)


              Business Stories


              Blockchain


              [Building on XRP Ledger: All the Basics You Must Know](https://www.rumblefish.dev/blog/post/basics-of-xrpl-development/)


              [Read more Building on XRP Ledger: All the Basics You Must Know](https://www.rumblefish.dev/blog/post/basics-of-xrpl-development/)


              Business Stories


              Blockchain


              [How Can Blockchain Help Your Business Case #3: Mobility](https://www.rumblefish.dev/blog/post/blockchain-in-mobility/)


              [Read more How Can Blockchain Help Your Business Case #3: Mobility](https://www.rumblefish.dev/blog/post/blockchain-in-mobility/)


              ![AnimatedLogoTextImage](https://www.rumblefish.dev/_next/static/images/animatedLogoTextImage-a6f682664943b4657d212bb839fd8cef.svg)![AnimatedLogoFishesImage](https://www.rumblefish.dev/_next/static/images/animatedLogoFishesImage-611d232d5f7285c1982fbfdf7c26ef12.svg)


              RUMBLEFISH POLAND SP Z O.O.Filipa Eisenberga 11/3 31-523 Kraków, Polska


              NIP: 6772425725REGON: 368368380KRS: 0000696628


              P: +48 601 265 364E: hello@rumblefish.dev


              Copyright © 2025 Rumblefish


              Services [AWS Cloud Solutions](https://www.rumblefish.dev/services/aws-cloud-solutions/)
              [Web development](https://www.rumblefish.dev/services/web-development/)
              [Mobile development](https://www.rumblefish.dev/services/mobile-development/)
              [AI Chat Assistant Development](https://www.rumblefish.dev/services/ai-chat-assistant/)
              [DeFi Development](https://www.rumblefish.dev/services/defi-development/)
              [Fintech Software Development](https://www.rumblefish.dev/services/fintech-software-development/)
              [Blockchain Software Development](https://www.rumblefish.dev/services/blockchain-software-development/)
              [Dedicated Development Teams](https://www.rumblefish.dev/services/dedicated-development-teams/)
              [UI/UX](https://www.rumblefish.dev/services/product-design/) [IT Services
              for startup](https://www.rumblefish.dev/startup/) [View all services](https://www.rumblefish.dev/services/)


              Products [EVM Debugger](https://www.rumblefish.dev/evm-debugger/) [Deva
              Wallet](https://www.rumblefish.dev/deva-wallet/)


              Careers [Join Our Team](https://www.rumblefish.dev/careers/)


              Other [Case studies](https://www.rumblefish.dev/case-studies/) [About
              us](https://www.rumblefish.dev/team/) [Contact](https://www.rumblefish.dev/contact/)
              [Visit our Blog](https://www.rumblefish.dev/blog/)


              Social [Linkedin](https://www.linkedin.com/company/rumblefishdev/) [Facebook](https://www.facebook.com/rumblefishsoftwaredevelopment)
              [X](https://twitter.com/rumblefishdev)


              [![clutch_top_blockchain_company_poland_2025](https://www.rumblefish.dev/_next/static/images/top_clutch.co_blockchain_company_poland_2025-3b061023686615de2058cf84b55889cb.webp)![clutch_top_cloud_consulting_company_krakow_2025](https://www.rumblefish.dev/_next/static/images/top_clutch.co_cloud_consulting_company_krakow_2025-1adaa9d32ea97bbaef5c439f0538f639.webp)![clutch_top_smart_contract_development_company_krakow_2025](https://www.rumblefish.dev/_next/static/images/top_clutch.co_smart_contract_development_company_krakow_2025-4c8e855c074c646146fd9b7a050a5016.webp)](https://bit.ly/rf-clutch)


              [Start a Telegram chat![icon](<Base64-Image-Removed>)](https://t.me/rumblefishdev)'
            metadata:
              og:title: Top ZK Proof Development Companies to Watch in 2025
              language: en
              title: Rumble Fish | Blog | Top ZK Proof Development Companies to Watch
                in 2025
              viewport: minimum-scale=1, initial-scale=1, width=device-width
              next-head-count: '8'
              favicon: data:image/webp;base64,UklGRsQBAABXRUJQVlA4ILgBAACwCQCdASogACAAPpFAmkolo6IhqAgAsBIJaQARR+LL/iK4FdW5AnenPEZkXon2A/5V/Vf+J12vQz/ZVL2mfz4qvfz+myCBeuCHAvQmJ0OmU+kCSD0wAAD+/xq7rz+jBq+uzKOTp1T7OCyXGXluuPVl/C0lbHczQq4jbiLAPDr0o+6VjREIHQ5z4Xhbq5n+Dz/sTZsfo2Gw9c8/C7Ql0PFcOBVKcxTTPVmZqnXcbtAtHIZB+YHrWHmxiHNAnkjVuQcGXF17tAy4v3Irk94MjTK2Bq0pxNNffTX5ERJ4T+NYP6K1Bbw85D8ydq4JXdLmDPIznJ3jvyhrzLJJJtxqBcoxGrk1W3S7oNc9xG7nVNf1N9lcdejZI+umk38/duRtBN6eIE4hVR+Bn/i8M3/xivjgZlX91tKT9/dAl4IiSiBDVyVhXbf9/xNUvNXPmktf2iinhjIYbJiCbVHW1xjZcF4OiY6+RnRTdX3grR5DZdVoE1xFr0b9nlMWdRzogriMVeiPLaLkLP/Hv0WvonFAEbP95jAqz7Qnnm9e7eapzDXXA4Ifw5cOOwc+WVoVDn+N5c9DzKjCowAAAA==
              keywords: Business Stories, Blockchain
              description: <p>Wondering who the top zk proof development companies
                are in 2025? This article reveals the leading firms that excel in
                zero-knowledge proof technology in blockchain.</p>
              color-scheme: light dark
              og:image: https://strapi-uploads.rumblefish.dev/Miniatures_for_blog_2_7a9c617b3f.png
              scrapeId: da2f82de-238c-4de5-b005-73d6675db9dc
              sourceURL: https://www.rumblefish.dev/blog/post/top-zk-proof-dev-companies-2025/
              url: https://www.rumblefish.dev/blog/post/top-zk-proof-dev-companies-2025/
              statusCode: 200
              contentType: text/html
              proxyUsed: basic
              cacheState: miss
          - title: Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025 | Learn
            description: Top Zero-Knowledge Proof (ZKP) Projects of 2024 · Polygon
              Hermez · Immutable X · Mina Protocol (MINA) · dYdX (DYDX) · Loopring
              (LRC) · Horizen (ZEN).
            url: https://www.kucoin.com/learn/crypto/top-zero-knowledge-zk-proof-crypto-projects
            markdown: '[KuCoin Learn](https://www.kucoin.com/learn)


              [Crypto](https://www.kucoin.com/learn/crypto)


              Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025


              # Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025


              Intermediate


              Last Update April 2, 2025


              ![Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025](https://assets.staticimg.com/reaper-image/663ca291b16963000196221a_Top%20Zero-Knowledge%20%28ZK%29%20Proof%20Crypto%20Projects%20of%202024-16-9.jpg?d=800x450&format=webp)


              Zero-knowledge proofs are cryptographic methods that enable one party
              to prove to another that a statement is true without revealing any information
              beyond the validity of the statement itself. Here’s a look at some of
              the best zero-knowledge proof (ZKP) crypto projects in the market.


              Imagine being able to prove you know a secret without ever having to
              reveal it. This is the essence of Zero-Knowledge Proofs (ZKPs), a revolutionary
              concept in the blockchain and crypto landscape that enhances privacy
              and scalability. As we delve deeper into 2024, ZKPs are increasingly
              crucial due to their ability to execute transactions or prove knowledge
              without exposing any underlying data.


              Zero-knowledge proofs have been gaining traction for their role in addressing
              the dual challenges of privacy and scalability in blockchain technologies.
              They are particularly significant in an era where digital privacy concerns
              are peaking, and the demand for efficient, scalable blockchain solutions
              is critical. Their growing application across various crypto projects
              in 2024 underlines their potential to reshape the blockchain ecosystem.


              ## What Are Zero-Knowledge Proofs (ZKPs)?


              Zero-knowledge proofs allow a "prover" to convince a "verifier" that
              they know a value or that a statement is true without revealing any
              information beyond the statement''s validity. This process hinges on
              three critical properties:


              - **Completeness:** If the prover''s statement is true, the verifier
              will be convinced by the proof without any doubt.


              - **Soundness:** If the statement is false, no cheating prover can convince
              the verifier of its truthfulness, except with negligible probability.


              - **Zero-Knowledge:** The verifier learns nothing other than the fact
              that the statement is true, gaining no further information from the
              proof.



              The benefits of using ZKPs in cryptocurrency projects are manifold.
              They enhance privacy by enabling transactions where no sensitive information
              is disclosed. For example, in voting systems, they can confirm a user''s
              eligibility without revealing their identity. They also improve scalability
              through constructions like [zk-Rollups](https://www.kucoin.com/learn/crypto/top-ethereum-zk-rollup-projects),
              where transaction data is processed off-chain and only the validity
              proof is stored on the blockchain, thereby reducing the data load and
              speeding up transaction times.


              Consider the often-cited "Ali Baba cave" analogy for a more interactive
              understanding. Here, a person proves they know the secret to opening
              a hidden door inside a cave without revealing the secret itself. They
              do this by performing actions that are observable (like emerging from
              the correct door), but the secret phrase itself is never disclosed.


              This concept is not just theoretical; it''s already being implemented
              in significant projects for secure transactions, identity verification,
              and more, all without compromising the privacy of any party involved.


              **Here’s a deep dive into [zero-knowledge proof (ZKP)](https://www.kucoin.com/learn/crypto/zero-knowledge-proof-zkp-explained)
              technology and how it works.**


              ## Use Cases for Zero-Knowledge Proofs (ZKPs) in Blockchain


              Zero-knowledge proofs (ZKPs) are transforming how blockchain technology
              manages privacy and data integrity. Here''s how they''re being applied
              across various crypto projects and blockchain-based applications:


              1. **Financial Privacy:** ZKPs enable transactions where the validity
              of a transaction is confirmed without revealing any information about
              the transaction itself. This is crucial in cryptocurrencies like Zcash,
              where users can choose to hide transaction details such as the sender,
              recipient, and amount transferred while still maintaining a secure and
              verified ledger.


              2. **Scalable Blockchain Solutions:** Projects like zkSync and StarkWare
              utilize ZKPs to increase [blockchain scalability](https://www.kucoin.com/learn/crypto/blockchain-layer-1-vs-layer-2-scaling-solutions-explained).
              They use a technique called zk-Rollups, where transaction data is processed
              off-chain, and only the validity proofs are submitted to the blockchain.
              This drastically reduces the data load on the main chain, enabling faster
              and cheaper transactions.


              3. **Secure Voting Systems:** ZKPs can be used to ensure the integrity
              and anonymity of votes in electronic voting systems. They allow voters
              to prove their vote was counted without revealing who they voted for,
              providing privacy and transparency in the voting process.


              4. **Authentication Without Passwords:** In systems that require authentication,
              ZKPs can verify the identity of a user without the need to transmit
              a password or any other sensitive information. This method prevents
              attackers from intercepting passwords during transmission, enhancing
              the security of online platforms.


              5. **Supply Chain Traceability:** ZKPs can help verify the authenticity
              of products in a supply chain without revealing underlying trade secrets
              or confidential business information. For instance, a company could
              prove that its products meet certain environmental standards without
              disclosing its suppliers or detailed manufacturing processes.


              6. **Confidential Smart Contracts:** Platforms like [Aleph Zero](https://www.kucoin.com/price/AZERO)
              and [Mina Protocol](https://www.kucoin.com/price/MINA) are exploring
              the use of ZKPs to execute smart contracts that keep certain inputs
              and outputs private. This is particularly valuable in business contexts
              where contract details are sensitive and should not be publicly disclosed
              on the blockchain.



              ## Top Zero-Knowledge Proof (ZKP) Projects of 2024


              CoinGecko has listed 40 ZK crypto projects with a combined market cap
              of over $21.27 billion as of early May 2024. Here are some of the best
              and most popular crypto projects across sectors that leverage zero-knowledge
              (ZK) proofs:


              ### Polygon Hermez


              ![](https://lh7-us.googleusercontent.com/qgAASjV28kpsFqur65Lv4xiu9TJv1g1aAJIjOEjyCkgoCrxChO_gyjPwPeMV_nyEYVu6swgtyMOXXptcfORQJUI2cg4nm5AM6PaT-mlxF1KNxwqCJ_WzZVa6QQArPsjg5laXNnjNCfMfznEaMuj_j3g)


              [Polygon](https://www.kucoin.com/price/MATIC) Hermez is a decentralized
              scaling solution built on Ethereum, utilizing zero-knowledge (ZK) rollup
              technology. Originally known as Hermez Network, it was acquired by Polygon
              and rebranded to Polygon Hermez. This integration emphasizes low-cost,
              high-speed token transfers by leveraging ZK proofs to batch multiple
              transactions into single ones that are then processed on [Ethereum](https://www.kucoin.com/price/ETH),
              significantly reducing gas costs and enhancing transaction throughput.


              Polygon Hermez aims to improve scalability and efficiency for Ethereum,
              making blockchain technology more accessible and sustainable for widespread
              use. It uses a unique consensus mechanism known as Proof of Efficiency
              (PoE), designed to maintain network security and decentralization while
              being less vulnerable to the complexities and potential attacks associated
              with the earlier Proof of Donation (PoD) system. Recent advancements
              include the integration of Hermez into Polygon’s ecosystem, reflecting
              a strategic move towards enhancing Ethereum’s scalability using zero-knowledge
              technology.


              Key features of Polygon Hermez include substantial reductions in transaction
              costs—over 90% compared to Ethereum’s [mainnet](https://www.kucoin.com/learn/glossary/mainnet)—and
              significant throughput improvements, supporting the network''s scalability.
              However, challenges such as the complexity of ZK proofs and the need
              for specialized knowledge to implement and optimize these technologies
              could pose barriers to adoption. Looking forward, Polygon Hermez is
              set to continue evolving, focusing on enhancing its technology to better
              serve a growing user base within the Ethereum ecosystem.


              [![](https://lh7-us.googleusercontent.com/NthCC80qL1TaMaIg7ZygDrRqEDx-WLlzAvkTPPpJ3MnN7rJTWXb6zh7GFYsRwokfE6hxEQxz6T_WloI25L9Fx8kmBLVfQ1oJqWhQIzo_PkYWM5AiyUmtROY3hzgkDwgnS5gJ4S54u1d4LnAhO8fb2M4)](https://www.kucoin.com/trade/MATIC-USDT)


              ### Immutable X


              ![](https://lh7-us.googleusercontent.com/pJqHxMEniu4HDAchx8K4_8XNm5Qd8GoNkE9lQ2mognV513TULYO-raIt3PRVawLp-FNvyFiupCGoa5GfC08kV4IX0P7imz-ApH85GQO-80V6oExSyqUdzUKsWXd_D8LEvNEAUFl_H7A3hMqyDkH0MYc)


              [Immutable X](https://www.kucoin.com/price/IMX) leverages StarkWare''s
              StarkEx, a proven scalability engine that uses zero-knowledge rollups
              (ZK-rollups) for minting and trading. This collaboration integrates
              StarkEx''s advanced technology to enhance the performance and capacity
              of Immutable X, enabling it to handle a high volume of transactions
              while maintaining security and reducing costs.


              Immutable X, developed in partnership with StarkWare, operates on the
              principles of zero-knowledge proofs, which allow it to process transactions
              at high speeds with low gas fees. This integration provides a platform
              where developers can build and scale [Web3 games](https://www.kucoin.com/markets/gaming)
              without compromising on Ethereum’s security. Immutable X focuses on
              [NFTs](https://www.kucoin.com/markets/nft), providing a marketplace
              with fast transactions and zero [gas fees](https://www.kucoin.com/learn/glossary/gas-fees)
              for users. The key benefits of this partnership include massively increased
              scalability, significantly reduced operational costs and the retention
              of robust security features inherent to Ethereum. However, the sophisticated
              nature of ZK-rollups and the need for developers to understand this
              new technology layer might pose challenges for adoption​.


              [![](https://lh7-us.googleusercontent.com/fR0HuS04PhfbKVCpTGE3U6Kg_VmeUeLtK5H-HbazAIRvCHzAnPVy0-CCcskC7kRke3eTVBLl-FSqcoVkqDwHvGqUEThPJGQm95jv0LHDbdYYsozWJ9ETUCrYCs_5uKbHj4GhqhT_jM4ellaNX6DLgOY)](https://www.kucoin.com/trade/IMX-USDT)


              ### Mina Protocol (MINA)


              ![](https://lh7-us.googleusercontent.com/Mgi2FQJoUFwuclcw-mnzyuYN0hpcCBa4YyBu4B3qlzF2VQsNzGzXZ55ZseD4LCg_XgPG1uUjzkMB4QyF9f1jazmnUChcUV-mb5fMLSiw15JSVDnnS76t1VFB-pKzVXVxuUYtezqeyYTk_GJGSfdkxlg)


              Mina Protocol (MINA) stands out as a blockchain that focuses on true
              decentralization by maintaining a consistent, minimal blockchain size
              of only 22KB. This is achieved using Zero-Knowledge Succinct Non-Interactive
              Arguments of Knowledge (zk-SNARKs). This technique enables Mina to compress
              entire blockchain states into small snapshots, allowing any user to
              quickly verify the network''s state without needing to download a large
              blockchain history. This approach not only ensures greater accessibility
              but also reduces reliance on powerful intermediaries, thus preserving
              the decentralized nature of the blockchain.


              Mina''s mission is to streamline blockchain participation by making
              it as lightweight as possible, ensuring that anyone can verify the network
              right from their devices. This is achieved through its unique zk-SNARK
              technology, which updates with each new block, continuously compressing
              the blockchain''s history into a small proof. Mina also employs the
              Ouroboros Samisika [proof-of-stake](https://www.kucoin.com/learn/glossary/proof-of-stake-pos)
              [consensus mechanism](https://www.kucoin.com/learn/glossary/consensus-mechanism),
              which is less resource-intensive than traditional [proof-of-work](https://www.kucoin.com/learn/glossary/proof-of-work-pow)
              systems. Recent updates within the Mina ecosystem include advancements
              in [node](https://www.kucoin.com/learn/glossary/node) performance and
              the introduction of zkApps, which allow for [off-chain](https://www.kucoin.com/learn/glossary/off-chain)
              computation and enhanced privacy for [smart contracts](https://www.kucoin.com/learn/glossary/smart-contract).
              However, the innovative approach of using zk-SNARKs for all state transitions
              can introduce complexities in maintaining and developing on such a unique
              platform​.


              [![](https://lh7-us.googleusercontent.com/CJxjIm5DyseK3cMMHaWZ_lRP4nuGaNDApLqxbUfT8OsPI2xo9EZlyqBUT9APFCBLDk19rgb_oaNL1q16tpa4KVBOtdD77B-tmZy5wS8kNDkeGsAUrSDEsdsV44MDnWe8P2Hgs_H03_u48UpAF0qKDP4)](https://www.kucoin.com/trade/MINA-USDT)


              ### dYdX (DYDX)


              ![](https://lh7-us.googleusercontent.com/XehLmBzyLH3SkIzzJcsOSoyRK-Di7yLOK5pFqCmitHBoR-DtmYkvuNmBpU4l44oP9MTmukenBC92-pvRvJ1hqHCjTFsNKTVkZyNIQvCA6OrqZLuO6B4ZO3QDDK5JrGCZ9z_hf0EpAthNqZw7mrPSKcY)


              [dYdX](https://www.kucoin.com/price/DYDX) is a decentralized exchange
              platform that leverages blockchain technology to offer advanced financial
              services, such as perpetual trading, without intermediaries. Built on
              Ethereum and transitioning to its [Layer 2](https://www.kucoin.com/learn/crypto/best-layer-2-networks-to-watch)
              protocol powered by StarkWare, dYdX enables users to engage in high-leverage
              trading with significantly reduced transaction costs and improved transaction
              speeds. dYdX uses Zero-Knowledge Proofs (ZKPs), specifically a type
              known as zk-STARKs, to enhance the privacy and scalability of its trading
              platform. This technology allows dYdX to execute and verify trades on
              its decentralized platform without revealing any sensitive data about
              the transactions themselves. Using zk-STARKs is particularly advantageous
              because it offers high scalability and security without needing a trusted
              setup, which is required by another common type of ZKP known as zk-SNARKs.


              Recent developments in dYdX have seen the launch of version 4.0 (v4.0)
              of their platform, which includes the dYdX Chain—an open-source blockchain
              utilizing the [Cosmos](https://www.kucoin.com/price/ATOM) SDK for scalability
              and the CometBFT consensus protocol for security. This upgrade introduces
              features such as reduce-only orders and subaccount withdrawal gating
              to enhance trading [risk management](https://www.kucoin.com/learn/trading/mastering-risk-management-in-crypto-trading)
              and governance capabilities. However, the platform''s cutting-edge approach
              and reliance on complex technologies could pose challenges for less
              tech-savvy users. Additionally, while dYdX provides powerful tools for
              traders, the decentralized nature requires users to maintain self-custody
              of their funds, adding a layer of responsibility that may not suit all
              investors​.


              **Learn more about the [dYdX DEX and its workings](https://www.kucoin.com/learn/web3/dydx-beginner-s-guide-to-the-decentralized-exchange).**


              [![](https://lh7-us.googleusercontent.com/-QhS9cEL3tVi3lX_-of09uApUAK-pyItXW4Qeu_Y8t3K3JmRYW1kaV9fOTqlf4IRwNtETENFLLbVxuElBVI5qDPysh_9mSk6qqbVpBn1eU09fAGy4IPxlmf0sA3Av0IfMVNStSChOAnM3S6WmTe41rs)](https://www.kucoin.com/trade/DYDX-USDT)


              ### Loopring (LRC)


              ![](https://lh7-us.googleusercontent.com/_S9G2f49EaoRWqvIb3k4Sse47CLQBVSA5L_MA5UVhqnuNI9HXX1IfK1BwTg5-DM0G4C3LoExQSBUep0oxOjQfNVPXHv-YXIUOWHOHZDElRnBv-tzvSJyZF3Uw8e2q6hi2oe95Rvi4pebJVLlnKURB4c)


              [Loopring](https://www.kucoin.com/price/LRC) (LRC) is an advanced blockchain
              protocol based on Ethereum, which leverages Zero-Knowledge Rollups (zkRollups)
              to enhance the scalability and efficiency of decentralized exchanges
              (DEXs) and payment platforms. At its core, Loopring allows for the aggregation
              of hundreds of transactions into a single one, significantly reducing
              the gas costs and processing times associated with Ethereum transactions.
              The Loopring protocol achieves this by handling transactions off-chain
              and then settling them on-chain using zkRollups, which provides proof
              that transactions were executed correctly without revealing the transaction
              data itself. This method ensures both speed and security, allowing Loopring
              to process over 2,000 transactions per second​.


              The Loopring protocol also introduces a unique component called "ring
              miners," who match, verify, and settle trading orders. Miners are compensated
              for their services with fees in LRC or a split of the trading margins,
              creating an incentive for efficient order processing. Loopring''s architecture
              supports both automated market maker ( [AMM](https://www.kucoin.com/blog/what-are-automated-market-makers))
              models and traditional order book exchanges, making it versatile for
              various [trading strategies](https://www.kucoin.com/learn/trading).
              Despite its advantages, such as lower transaction costs and higher throughput,
              Loopring''s reliance on more complex technologies like zkRollups could
              pose a barrier to widespread adoption due to the technical knowledge
              required to implement and interact with such systems. Nonetheless, Loopring
              remains a significant player in the effort to scale Ethereum''s capabilities
              without compromising security.


              [![](https://lh7-us.googleusercontent.com/27rrhI0fj-8WjVlep1UoUae1zhcQHnKcXpzho-8CeIIm2Ygi1i8u-HeukAduKNgHv9Hl63r5IFTVoSi6EnrUp6D-hGgMmP3XJiibmLaRQeMi22vU0HNOQPvCfxOexOH35hqupnEsAp_KUiX1jcmuDXI)](https://www.kucoin.com/trade/LRC-USDT)


              ### Horizen (ZEN)


              ![](https://lh7-us.googleusercontent.com/S5pE9fnO0NUBhLgc49-mQDB2j6Z3VMW6qqCi3aN4XMiHAA8Sqj5Hy9wb3L8Wcdya7ln9vn_SM1m_M4VBgV99IGmzCdMGFr9B7U2shfxEVi_M4-H-FyMg_yj-tTxANwLPB11RtnW_VpzQa84_pOmEBIM)


              [Horizen](https://www.kucoin.com/price/ZEN) (ZEN) is a blockchain platform
              focused on privacy, utilizing Zero-Knowledge Proofs (zk-SNARKs) to ensure
              transaction confidentiality and anonymity. Originating as a fork from
              Zcash, which itself was derived from ZClassic, Horizen has expanded
              its mission beyond simple privacy. It aims to provide a secure and private
              infrastructure for messaging, publishing, and decentralized application
              ( [dApp](https://www.kucoin.com/learn/glossary/dapp)) development. This
              evolution is part of Horizen''s broader goal to build a fully inclusive
              environment where all applications can operate with complete privacy.


              The technological backbone of Horizen includes a unique node system
              consisting of full nodes, secure nodes, and super nodes, each playing
              different roles in the network''s ecosystem. Secure nodes, for instance,
              enhance network privacy through TLS encryption, while super nodes support
              sidechains that expand the network''s functionality and scalability.
              Recent developments in the Horizen ecosystem include the launch of the
              first [EVM](https://www.kucoin.com/learn/glossary/ethereum-virtual-machine-evm)-compatible
              sidechain, EON, enhancing the platform''s ability to host a variety
              of dApps and [DeFi projects](https://www.kucoin.com/markets/defi). Despite
              its advantages, Horizen faces challenges like the complexity of maintaining
              privacy in a regulatory environment, which is increasingly skeptical
              of anonymous cryptocurrencies. The project continues to innovate with
              new features, such as the Horizen [DAO](https://www.kucoin.com/learn/web3/everything-you-need-to-know-about-daos)
              for decentralized governance and ongoing enhancements to its sidechain
              capabilities.


              [![](https://lh7-us.googleusercontent.com/iFy0DO52cINYhSVU5a42zS3UXjP7NXYkt4YWAA6vQRCapUZv5f7qV28S6-OoYq071LR7yVzNF7BFOZmYHwmNW1XXGeR0BMN-ryI68NXcqs5aJrzWW6DjKl6c2GtJLpZEphbBbHkmTHKrClQ9tRiqSJY)](https://www.kucoin.com/trade/ZEN-USDT)


              ### Zcash (ZEC)


              ![](https://lh7-us.googleusercontent.com/NiydAYRUeMXw7KSABwSP7oFyEgrBkvcZ-vuDi_4N2ZwwyJ_Asox3XLTYcTBTBBY1kfxMOjwuxcOU130-qhgTQmPcVRiaXqsnl3Wsb5b9HOXbgDS9gEzEt3MW7jNx5iQ9YClu5lb9NiRV7a60BGR9XkE)


              [Zcash](https://www.kucoin.com/price/ZEC) (ZEC) is a cryptocurrency
              focused on enhancing privacy for its users, leveraging advanced cryptographic
              techniques known as zk-SNARKs (Zero-Knowledge Succinct Non-Interactive
              Arguments of Knowledge) to enable secure, private transactions. Unlike
              traditional cryptocurrencies that offer pseudonymity, Zcash provides
              the option of "shielded" transactions, which keep the sender, receiver,
              and transaction amount private. Launched in 2016 as a fork of [Bitcoin](https://www.kucoin.com/price/BTC),
              Zcash aims to combine the financial privacy that cash transactions offer
              with the global digital utility of cryptocurrency​.


              Zcash has undergone significant developments since its inception, including
              multiple network upgrades such as Sprout, Overwinter, Sapling, and,
              more recently, Heartwood and Canopy. These updates have continuously
              improved transaction efficiency and privacy capabilities and introduced
              features like Shielded Coinbase and FlyClient support, enhancing the
              usability of Zcash for both everyday transactions and enterprise applications.
              The introduction of "Halo" in 2019 marked a significant technological
              advancement by removing the need for a trusted setup to generate zero-knowledge
              proofs, thereby increasing the security and scalability of the network.
              Despite its strong privacy features, Zcash faces challenges such as
              regulatory scrutiny and the complexity of its technology, which may
              affect its adoption and user trust.


              [![](https://lh7-us.googleusercontent.com/GIbGfpIwJzQekYBlFxS8G_h81NHa_RJ1xN7hkW0zsYJNfZ0yJFgbDzl5A_ka63q1qnjepBoPne4yHuLmyWd-TKpwJAxRTOxWBajFioabe3vCLPR20Q3izrBcs0PPurKzFGOrpTkclrmFku691X0Prrw)](https://www.kucoin.com/trade/ZEC-USDT)


              ### Worldcoin (WLD)


              ![](https://lh7-us.googleusercontent.com/SCmyQsXOcb7UBznBiSo_sKsfmqkfMy2db-xvwTMRtdgBI9SSN6vwm4TDKThvqQ5LutRJPpFeULqa3V3wAbEe8znh5dvF2d-YDGzM2T5BN3cDYk8cFcEktrg3jNZ1YbsRN0BBRmkazG2jVwMGjKKdQUg)


              [Worldcoin](https://www.kucoin.com/price/WLD) (WLD) is a cryptocurrency
              project that combines digital identity verification with blockchain
              technology to provide a unique solution to global economic inclusion.
              The project, co-founded by Sam Altman, utilizes a device called an "Orb"
              to scan individuals'' irises to create a secure, blockchain-based digital
              identity known as World ID. This identity is used to issue Worldcoin
              tokens (WLD) to individuals, promoting a decentralized and inclusive
              global economy.


              Worldcoin utilizes zero-knowledge proofs (ZKPs) to enhance privacy andsecurity
              within its World ID system. Worldcoin employs ZKPs to confirm a user''s
              unique identity and humanity without disclosing any personal information.
              This allows for privacy-preserving interactions within the digital economy.
              Specifically, Worldcoin integrates a protocol called Semaphore, which
              uses ZKPs to enable users to prove membership in a group without revealing
              their identity. This is crucial for activities like voting or endorsements
              within the Worldcoin ecosystem, where privacy and anonymity are paramount.
              Implementing ZKPs ensures that activities carried out with a World ID
              cannot be linked to a person’s biometrics or other identity markers,
              safeguarding user privacy across different applications​.


              The project, however, has faced scrutiny and controversy, particularly
              regarding privacy and data security. The collection of biometric data
              through iris scanning has raised concerns about how this data is managed
              and protected. Additionally, the centralization of control over the
              project''s smart contracts has been viewed as contradictory to its decentralized
              ethos. Regulatory challenges also loom as different countries examine
              the legality and security of such biometric data collection. Despite
              these challenges, Worldcoin continues to expand to foster a more accessible
              and equitable digital economy. The initiative''s future success will
              depend significantly on its ability to address these privacy concerns
              and navigate regulatory environments effectively.


              **Learn more about [how Worldcoin works and how to get it](https://www.kucoin.com/learn/crypto/what-is-worldcoin-wld-and-how-to-get-it).**


              [![](https://lh7-us.googleusercontent.com/Tc-5pZAODbqTnKz1uVJZFnzDmsbmKnDrGg7D5-CmxwQoRS6bY2A8c8N3rm-zRKhtV4r60h8VZE-JFMdC6XFqnDgF-QLyGLTIJnjxhhMOI1Co6HtYcZ7HCNNZUHNpiDleRk2OHlBdN1QKAIx5iu_DyA4)](https://www.kucoin.com/trade/WLD-USDT)


              ### Marlin (POND)


              ![](https://lh7-us.googleusercontent.com/ILpSD600xjehdORcEhh-0ps0ZWTU8AWjdB0XCv4p21lbmhc8FO9VWjyKqt6Dqm73RaUudxVhjeK2nKqUXIzGW9HnEQxubBu0GrdDsU4BXx4vNt-SFc1sZNwGLFTO3L9_G2xEkVXdm65dIbTKCB3KFuE)


              [Marlin](https://www.kucoin.com/price/POND) (POND) is a decentralized
              protocol designed to optimize the execution of complex algorithms and
              computations off-chain while maintaining the integrity and security
              typical of [on-chain](https://www.kucoin.com/learn/glossary/on-chain)
              processes. The core of Marlin''s architecture involves the use of coprocessors
              across a distributed network of nodes that enable high-speed data processing
              with access to both blockchain history and Web 2.0 APIs. This setup
              allows for the offloading of intensive computational tasks from the
              blockchain, reducing costs and speeding up execution time. The verification
              of these off-chain computations is ensured by combining Zero-Knowledge
              Proofs (ZKPs) and Trusted Execution Environments (TEEs), which provide
              compact, secure verifications of computational correctness that can
              be easily validated on-chain​.


              Marlin has been developed to support a variety of programming environments
              and can execute programs written in languages like Solidity, C++, Rust,
              and Go. This flexibility is complemented by its scalable architecture,
              which includes different types of nodes, such as gateway, execution,
              and monitoring nodes, each serving a unique function within the network.
              Gateway nodes act as load balancers, execution nodes handle the actual
              computations, and monitoring nodes ensure the network''s reliability
              and performance. The Marlin ecosystem is powered by the POND token,
              which is used to provide security guarantees for the network. Nodes
              are required to stake POND tokens to participate, and they risk these
              stakes if they fail to adhere to the network''s operational standards.
              This staking mechanism incentivizes proper behavior and adherence to
              protocol rules.


              [![](https://lh7-us.googleusercontent.com/upeVyC8qH2dHPj0mJBfGCI4oC66nHh4ijMru1IK40XJvxfPAnhHNxQVXx_JfGjG56jV7mLCK63s3K8fY3LYy1S3hvCFtOLdhmrrs-NFUEyz1kfCnWgeUWDYDhytZ_LTt-nZ8RwbMGCL8B0GbdGauHzA)](https://www.kucoin.com/trade/POND-USDT)


              ### Aleph Zero (AZERO)


              ![](https://lh7-us.googleusercontent.com/EPefq76HKAe_JpAE0Cck0oh78CHanDtmq7meEQxfayHFyzaFkW8WU2wQbG8q2i15EAYIrtNVAUVSiGrPjKQLUH4O1sLDT5e_hVjYu4pUxZljiK-mFvRC1siuAwLKa0yp3tBaq9okk3kL-WfwRe6QB90)


              [Aleph Zero](https://www.kucoin.com/price/AZERO) (AZERO) is a public
              blockchain designed for speed, security, and privacy, utilizing a unique
              hybrid consensus protocol called AlephBFT, which combines Proof of Stake
              (PoS) and Directed Acyclic Graph ( [DAG](https://www.kucoin.com/learn/glossary/directed-acyclic-graph-dag))
              technologies. This protocol is geared to achieve high transaction throughputs
              with low fees and is built on a peer-reviewed system, ensuring robust,
              decentralized operation even amidst malicious activities. Aleph Zero''s
              consensus mechanism allows it to maintain efficient communication between
              nodes, which supports its claim of being both fast and secure​.


              A significant feature of Aleph Zero is its focus on privacy and security
              for enterprise applications through its multichain privacy layer, Liminal.
              Liminal employs zero-knowledge proofs (ZKPs) and secure multi-party
              computation (sMPC), enhancing privacy across blockchain networks that
              link to Aleph Zero. This makes it highly adaptable for businesses requiring
              confidential transactions while leveraging public blockchain security.
              The platform also supports private smart contracts, which are advantageous
              for enterprises that need to perform secure and private transactions
              and computations. Despite its advanced features, the real-world application
              and scalability of these technologies could face challenges as they
              are put to the test under actual operating conditions​.


              [![](https://lh7-us.googleusercontent.com/BTAVxwYON_U-4O3yVL239ev_A2fp1hEb3_MyIu424gbz5m4GyN2DLDRbyHL0H079jgqgz1iIYFk9PveO1My4ha3Bb_XycJkbn5Zcxnft2slu9lYyB_PFhWHh6hBP_1Deh2-nNybRDpS-8yEK3fHwF4s)](https://www.kucoin.com/trade/AZERO-USDT)


              ## Challenges and Risks of Zero-Knowledge (ZK) Technology


              While Zero-Knowledge Proofs (ZKPs) offer substantial benefits in privacy
              and scalability for blockchain applications, they also come with specific
              challenges and risks:


              1. **Complexity of Implementation:** Implementing ZKP requires a deep
              understanding of advanced cryptographic principles. This complexity
              can be a barrier for developers, potentially leading to errors and vulnerabilities
              in the design and implementation of ZKP systems. Developers must be
              well-versed in the underlying cryptography to ensure the integrity and
              security of the systems.


              2. **Computational Intensity:** The generation of ZKPs can be computationally
              intensive, especially for more complex proofs. This might result in
              higher costs and slower processing times compared to non-ZKP transactions,
              which could limit the practical usability of ZKPs in high-volume scenarios.


              3. **Initial Setup Vulnerability:** Certain ZKP schemes, like zk-SNARKs,
              require a "trusted setup" phase. If this setup phase is compromised,
              for example, if the generated parameters are not destroyed, it could
              lead to significant security vulnerabilities, including the creation
              of counterfeit proofs.


              4. **Scalability Concerns:** Although ZKPs can significantly reduce
              the data load on a blockchain, the scalability of ZKP implementations
              themselves can sometimes be a challenge. The technology to efficiently
              handle large volumes of transactions without compromising on speed is
              still under development.


              5. **Integration Complexity:** Integrating ZKP into existing systems
              poses significant challenges. It requires changes to the network protocols
              and possibly extensive updates to existing blockchain infrastructures,
              which can be a lengthy and complex process.


              6. **Legal and Regulatory Uncertainty:** The ability of ZKPs to anonymize
              transaction data could also raise regulatory issues, particularly in
              jurisdictions with strict financial transparency laws. Projects using
              ZKPs must navigate these regulations carefully to avoid legal challenges.



              Despite these challenges, the ongoing advancements in ZKP technology
              and increasing familiarity among developers are gradually reducing these
              risks, paving the way for broader adoption of secure and private blockchain
              applications.


              ## Future Outlook of ZK Technologies


              The future of ZKP projects looks promising, with continuous advancements
              expected to enhance blockchain privacy and scalability. The focus will
              likely be on developing more user-friendly ZKP systems that could support
              widespread adoption across various industries. Innovations such as zk-STARKs
              and zk-SNARKs are anticipated to drive significant improvements in transaction
              speeds and scalability without compromising security or privacy.


              One of the most exciting prospects is the development of [cross-chain](https://www.kucoin.com/learn/glossary/cross-chain)
              privacy layers, which will allow secure and private transactions across
              different blockchain networks, thereby broadening the scope of blockchain
              applications and services​. These advancements could radically transform
              how sensitive data is handled across networks, making ZKPs integral
              to the development of secure digital infrastructures. As interoperability
              and cross-chain functionalities improve, ZKP projects are expected to
              play a crucial role in enabling seamless and private transactions across
              diverse blockchain systems​.


              ## Closing Thoughts


              The potential of Zero-Knowledge Proof technologies to impact the blockchain
              landscape is immense. By enabling more secure, private, and scalable
              blockchain applications, ZKPs represent a cornerstone technology for
              the next generation of blockchain innovation. As these technologies
              continue to evolve and mature, keeping an eye on the developments in
              this space will be crucial for anyone involved in blockchain and privacy
              technologies. Following projects that utilize ZKP technologies can provide
              insights into the future of digital privacy and blockchain efficiency​.


              ## Further Reading


              - [What Is ZKsync (ZK): Ethereum’s ZK-Rollup Scaling Solution?](https://www.kucoin.com/learn/crypto/what-is-zksync-zk-ethereum-zk-rollup)

              - [Zero Knowledge Proof (ZKPs) in Blockchain: A Beginner’s Guide](https://www.kucoin.com/learn/crypto/zero-knowledge-proof-zkp-explained)


              - [Top Ethereum ZK Rollup Projects for 2024](https://www.kucoin.com/learn/crypto/top-ethereum-zk-rollup-projects)


              - [Top Ethereum Layer-2 Crypto Projects to Know in 2024](https://www.kucoin.com/learn/crypto/top-ethereum-layer-2-crypto-projects)


              - [Blockchain Layer 1 vs. Layer 2 Scaling Solutions: Explained](https://www.kucoin.com/learn/crypto/blockchain-layer-1-vs-layer-2-scaling-solutions-explained)


              - [Solana vs. Ethereum: Which Is Better in 2024?](https://www.kucoin.com/learn/crypto/solana-vs-ethereum-key-differences-and-insights)



              Disclaimer: The information on this page may have been obtained from
              third parties and does not necessarily reflect the views or opinions
              of KuCoin. This content is provided for general informational purposes
              only, without any representation or warranty of any kind, nor shall
              it be construed as financial or investment advice. KuCoin shall not
              be liable for any errors or omissions, or for any outcomes resulting
              from the use of this information.


              Investments in digital assets can be risky. Please carefully evaluate
              the risks of a product and your risk tolerance based on your own financial
              circumstances. For more information, please refer to our [Terms of Use](https://www.kucoin.com/legal/terms-of-use)
              and [Risk Disclosure](https://www.kucoin.com/legal/risk-disclosure-statement).


              Twitter Widget Iframe'
            metadata:
              description: Zero-knowledge proofs are cryptographic methods that enable
                one party to prove to another that a statement is true without revealing
                any information beyond the validity of the stat
              ogSiteName: KuCoin Learn
              favicon: https://www.kucoin.com/logo.png
              robots: notranslate
              twitter:description: Zero-knowledge proofs are cryptographic methods
                that enable one party to prove to another that a statement is true
                without revealing any information beyond the validity of the stat
              ogDescription: Zero-knowledge proofs are cryptographic methods that
                enable one party to prove to another that a statement is true without
                revealing any information beyond the validity of the stat
              og:type: article
              title: Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025 |  Learn
              og:url: https://www.kucoin.com/learn/crypto/top-zero-knowledge-zk-proof-crypto-projects
              og:description: Zero-knowledge proofs are cryptographic methods that
                enable one party to prove to another that a statement is true without
                revealing any information beyond the validity of the stat
              og:title: Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025 |  Learn
              language: en
              og:image:
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              og:site_name: KuCoin Learn
              baggage: sentry-environment=prod,sentry-release=seo-learn-web%403.0.17,sentry-public_key=463b6541b5124355ed815d890cacc17f,sentry-trace_id=451200d55a6383e7888f712f87aa36aa,sentry-sampled=false,sentry-sample_rand=0.9816071933307444,sentry-sample_rate=0.001
              twitter:card:
              - summary_large_image
              - summary_large_image
              ogTitle: Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025 |  Learn
              ogUrl: https://www.kucoin.com/learn/crypto/top-zero-knowledge-zk-proof-crypto-projects
              twitter:image:src:
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              twitter:title: Top Zero-Knowledge (ZK) Proof Crypto Projects of 2025
                |  Learn
              ogImage: https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              og:image:width:
              - '1200'
              - '1200'
              og:image:secure_url:
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              googlebot: notranslate
              sentry-trace: 451200d55a6383e7888f712f87aa36aa-c311aa2decc18e56-0
              twitter:image:
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              - https://assets.staticimg.com/cms/media/7feiEEHmJE61RECXMyp8rTcA5Qcsl0zSv6rz9NVjg.png
              og:image:height:
              - '630'
              - '630'
              twitter:image:alt: Top Zero-Knowledge (ZK) Proof Crypto Projects of
                2025 |  Learn
              viewport: width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no,viewport-fit=cover
              scrapeId: 25e59d1b-0997-49a7-bf88-8f5d95fc169d
              sourceURL: https://www.kucoin.com/learn/crypto/top-zero-knowledge-zk-proof-crypto-projects
              url: https://www.kucoin.com/learn/crypto/top-zero-knowledge-zk-proof-crypto-projects
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
          - title: 'Checks and balances: Machine learning and zero-knowledge proofs'
            description: Advancements in zero-knowledge proofs are now making it possible
              for users to demand trustlessness and verifiability of every digital
              ...
            url: https://a16zcrypto.com/posts/article/checks-and-balances-machine-learning-and-zero-knowledge-proofs/
            markdown: '4.5.23



              For the past few years, zero-knowledge proofs on blockchains have been
              useful for two key purposes: (1) scaling compute-constrained networks
              by processing transactions off-chain and verifying the results on mainnet;
              and (2) protecting user privacy by enabling shielded transactions, viewable
              only to those who possess the decryption key. Within the context of
              blockchains, it’s clear why these properties are desirable: a decentralized
              network like Ethereum can’t increase throughput or block size without
              untenable demands on validator processing power, bandwidth, and latency
              (hence the need for validity rollups), and all transactions are visible
              to anyone (hence the demand for on-chain privacy solutions).


              But zero-knowledge proofs are also useful for a third class of capabilities:
              efficiently verifying that _any_ kind of computation (not just those
              within an off-chain instantiation of the EVM) has run correctly. This
              has implications far beyond blockchains.


              Advancements in systems that leverage the ability of zero-knowledge
              proofs to succinctly verify computation are now making it possible for
              users to demand the same degree of trustlessness and verifiability assured
              by blockchains from every digital product in existence, most crucially
              from machine learning models. High demand for blockchain compute has
              incentivized zero-knowledge proof research, creating modern proving
              systems with smaller memory footprints and faster proving and verification
              times — making it now possible to verify certain small machine learning
              algorithms on-chain today.


              We’ve all by now likely experienced the potential of interacting with
              an extremely powerful machine learning product. A few days ago, I used
              GPT-4 to help me create an AI that consistently beats me at chess. It
              felt like a poetic microcosm of all of the advances in machine learning
              that have occurred over the past few decades: it took the developers
              at [IBM twelve years to produce Deep Blue](https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/),
              a [model](https://pdf.sciencedirectassets.com/271585/1-s2.0-S0004370200X00847/1-s2.0-S0004370201001291/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHsaCXVzLWVhc3QtMSJIMEYCIQCCFRMDylH%2BYZLzh1P%2F113W5YMdLcXXIif7Mjehsr%2FUDAIhAL189VHKBq5CYBJ1tsYiuQhRJDKHPO7c4zuG%2BRgodQhcKrMFCFMQBRoMMDU5MDAzNTQ2ODY1Igy1MsGcwroL2wF%2BmB4qkAW3nCjWdrqNxBI2Dq3ceIo6LrJd%2BRpfTO1sw8%2FhIa%2FNaJqqhVqMgsJQhEVHv1ZZkGt%2B02NYTrXBAq9kCKPpSREPNp4rdWlZbMlzw4W%2Ffw16jpZ7eHTqqdcxgXaRrXsgdSnmvCtm2p79uKASY4ChqlGu226aJ9q0BBuhdou9DSnnIffhyCS20cI%2Fv5h1z2ZhF8vLZRP7Wlk4wU8B19XJvElwZnqTkfrhYLJZi2vOZgJgHgtTy53DcHNy6DmCQCOZfloqjmSBKkQEfs%2FDYGsRXnyE3jn8Q8UPzMlhVYhsPWV4CaKHzH6O%2BkRA8Vb43aoRiOwQJQsba%2BdkA%2BNE%2FffMJzTkwNkItDYZj2dGz468kTe6WH6Mu%2BtbWccahX2jszNe5siwVI3JnHXSQei43DJSCZHNgih2VNu%2FI5G%2FVK9MMsHeG6qciQ7jlzKHNoVL7Nujy%2B7bsHU5pQeFvXFv%2Bcc3qCVjI7%2F0PoiDH8Ox3MxAAjKKLw4JmkTaRsfH6evl4Mo%2B70HFUfiT2K7OB14fO9dz2alo7gIlSylgPjd44Iu9SM6gqaOow%2FIS5MpxBw0KBrkx4OjD9%2BFJCbkEx64mFJ3s2EXwazOVOUI5CqpKmsXac78bYsb0q030hMcf2MDM5XUY2YeBw3O4jt5xsRi4nSy6oZvumS3jQVWlNYI7zD0YHFkWk6eHdtKEpshv%2BM2CluFUXzOYbW504K0%2B0N6BphO6Yv%2Bro7B9No5PbOIqf8rIjrccc0LU5NEkVTAGftUitjdjIW6AYt3LG%2BEUe75zPb82IQbRFqitOdU3Y0RQjDYSILYDuG7QVANH71r66Ob6QQmsUgo7V6aNzSumOy9Fra3lFu%2FDp9jb%2FDnsZ2qhDopPK9UGBTDLu46hBjqwAZIS4Q03lNRgGW2O1T8tpjp4DLI%2BLgsZFwx%2FYZd222%2FgV%2B58wO3E1lbkp5uAw4mKRMXrabqis6XKJrfniicoGXARDKl7mNaDn4t09pgJNB3m3SdEhKNGt%2FJ85sJbHE87FTE1rSdNDJN8akiUYWHOGPuuJispVyLjDoNkUD5scyyDJDIMIibVq%2FSXCCtMyGs%2FMBQsIhNUTY02h5Yp%2Bur%2F1vKK034FAHT3BEC8p6AXyw%2BK&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230329T030021Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYRQF5QX3G%2F20230329%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=6b8769a3d3b6cdcee7768a3a3f30ff2d9260a32d13edb672f17268e96e4b273a&hash=91e6e584e244d2d687bdd969df3f016316b5580678ac645986b5d5670a33ff8d&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0004370201001291&tid=spdf-7c18540e-371a-45d4-bad1-742b4842f77d&sid=af633d875dfa4543944a5de63e0a16060194gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0f155506035a07070f0205&rr=7af4dcaeb85b7bb0&cc=us)
              running on a 32-node IBM RS/6000 SP computer and capable of evaluating
              up to nearly 200 million chess moves per second, which beat the chess
              champion Gary Kasparov in 1997. By comparison, it took me a few hours
              – with minimal coding on my part – to create a program that could triumph
              over me.


              Admittedly, I doubt the AI I created would be able to beat Garry Kasparov
              at chess, but that’s not the point. The point is anyone playing around
              with GPT-4 has likely had a similar experience gaining superpowers:
              with little effort, you can create something that approaches or surpasses
              your own capabilities. We are all researchers at IBM; we are all Garry
              Kasparov.


              Obviously, this is thrilling and a bit daunting to consider. And for
              anyone working in the crypto industry, the natural impulse (after marveling
              at what machine learning can do) is to consider potential vectors of
              centralization, and ways those vectors can be decentralized into a network
              that people can transparently audit and own. Current models today are
              made by ingesting an enormous amount of publicly available text and
              data, but only a small number of people right now control and own those
              models. More specifically, the question isn’t “will AI be tremendously
              valuable,” the question is “how do we build these systems in such a
              way that anyone interacting with them will be able to reap its economic
              benefits and, if they so desire, ensure that their data is used in a
              way that honors their right to privacy.”


              Recently, there has been a vocal effort to pause or mitigate the advancement
              of major AI projects like Chat-GPT. Halting progress is likely not the
              solution here: it would instead be better to push for models that are
              open-source, and in cases where model providers want their weights or
              data to be private, to secure them with privacy-preserving zero-knowledge
              proofs that are on-chain and fully auditable. Today, the latter use-case
              around private model weights and data is not yet feasible on-chain,
              but advances in zero-knowledge proving systems will make it possible
              in the future.


              ## Verifiable and ownable machine learning


              A chess AI like the one I built using Chat-GPT feels relatively benign
              at this point: a program with a fairly uniform output, which doesn’t
              use data that violates valuable intellectual property or infringes on
              privacy. But what happens when we want assurance that the model we are
              told is being run behind an API is indeed the one that ran? Or if I
              wanted to ingest attested data into a model that lives on-chain, with
              assurance that the data is indeed coming from a legitimate party? And
              what if I wanted assurance that the “people” submitting data were in
              fact people, and not bots seeking to sybil-attack my network? Zero-knowledge
              proofs, with their ability to succinctly represent and verify arbitrary
              programs are a way to do this.


              It’s important to note that today, the primary use-case for zero-knowledge
              proofs in the context of machine learning on-chain is to verify correct
              computation. In other words, zero-knowledge proofs, and more specifically
              [SNARKs](https://a16zcrypto.com/content/article/snark-security-and-performance/)
              (Succinct Non-Interactive Arguments of Knowledge), are most useful for
              their succinctness properties in the ML context. This is because zero-knowledge
              proofs protect the privacy of the **prover** (and of the data it processed)
              from a prying verifier. Privacy-enhancing technologies like [Fully-Homomorphic
              Encryption](https://scholar.archive.org/work/vojosxnvefa4pp5aeop5drukpe/access/wayback/https://eccc.weizmann.ac.il/report/2018/125/download/)
              (FHE), [Functional Encryption](https://eprint.iacr.org/2010/543.pdf),
              or [Trusted Execution Environments](https://hal.science/hal-01246364/document)
              (TEE) are more applicable for letting an untrusted prover run computations
              over private input data (exploring those more deeply falls outside the
              scope of this piece).


              Let’s take a step back and understand at a high-level the kinds of machine
              learning applications you could represent in zero-knowledge. (For a
              deeper dive on ZK specifically, see our piece on [improvements in zero-knowledge
              proving algorithms and hardware](https://a16zcrypto.com/content/article/decentralized-speed-advances-in-zero-knowledge-proofs/),
              Justin Thaler’s work on SNARK performance [here](https://a16zcrypto.com/content/article/measuring-snark-performance-frontends-backends-and-the-future/)
              and [here](https://a16zcrypto.com/content/article/snark-security-and-performance/),
              or our [zero-knowledge canon](https://a16zcrypto.com/content/article/zero-knowledge-canon/).)
              Zero-knowledge proofs typically represent programs as arithmetic circuits:
              using these circuits, the prover generates a proof from public and private
              inputs, and the verifier mathematically computes that the output of
              this statement is correct — without obtaining any information about
              the private inputs.


              We’re still at a very early stage of what is computationally practical
              to verify using zero-knowledge proofs on-chain, but improvements in
              algorithms are expanding the realm of what is feasible. Here are five
              ways zero knowledge proofs can be applied in machine learning.


              **1\. Model Authenticity:** You want assurance that the machine learning
              model some entity claims has been run is indeed the one that ran. Examples
              include a case where a model is accessible behind an API, and the purveyor
              of a particular model has multiple versions – say, a cheaper, less accurate
              one, and a more expensive, higher-performance one. Without proofs, you
              have no way of knowing whether the purveyor is serving you the cheaper
              model when you’ve actually paid for the more expensive one (e.g., the
              purveyor wants to save on server costs and boost their profit margin).


              To do this, you’d want separate proofs for each instantiation of a model.
              A practical way to accomplish this is through Dan Boneh, Wilson Nguyen,
              and Alex Ozdemir’s framework for [functional commitments](https://eprint.iacr.org/2021/1342.pdf),
              a SNARK-based zero-knowledge commitment scheme that allows a model owner
              to commit to a model, which users can input their data into and receive
              verification that the committed model has run. Some [applications built
              on top](https://github.com/only4sim/myproject) of [Risc Zero](https://www.risczero.com/),
              a general purpose STARK-based VM, are also enabling this. Other [research
              conducted](https://medium.com/@danieldkang/open-sourcing-zkml-trustless-machine-learning-for-all-f5ee1dbf2499)
              by Daniel Kang, Tatsunori Hashimoto, Ion Stoica, and Yi Sun has demonstrated
              that it’s possible to verify valid inference on the ImageNet dataset,
              with 92% accuracy (which is on par with the [highest performing non-ZK
              verified ImageNet models](https://paperswithcode.com/sota/image-classification-on-imagenet)).


              But just receiving proof that the committed model has run is not necessarily
              enough. A model may not accurately represent a given program, so one
              would want the committed model to be audited by a third party. Functional
              commitments allow the prover to establish that it used a committed model,
              but they don’t guarantee anything about the model that has been committed.
              If we can make zero-knowledge proofs performative enough for proving
              training (see example #4, below), we could one day start to get those
              guarantees as well.


              **2\. Model Integrity:** You want assurance that the same machine learning
              algorithm is being run on different users’ data the same way. This is
              useful in areas where you don’t want arbitrary bias applied, like credit
              scoring decisions and loan applications. You could use functional commitments
              for this as well. To do this, you would commit to a model and its parameters,
              and allow people to submit data. The output would verify that the model
              ran with the committed  parameters for each user’s data. Alternatively,
              the model and its parameters could be made public and the users themselves
              could prove that they applied the appropriate model and parameters to
              their own (authenticated) data. This might be especially useful in the
              medical field, where certain information about patients is required
              by law to remain confidential. In the future, this could enable a medical
              diagnosis system that is able to learn and improve from realtime user
              data that remains completely private.


              **3\. Attestations:** You want to integrate attestations from external
              verified parties (e.g., any digital platform or piece of hardware that
              can produce a digital signature) into a model or any other kind of smart
              contract running on-chain. To do this, you would verify the signature
              using a zero-knowledge proof, and use the proof as an input in a program.
              [Anna Rose](https://twitter.com/AnnaRRose) and [Tarun Chitra](https://twitter.com/tarunchitra)
              recently hosted [an episode](https://zeroknowledge.fm/265-2/) of the
              Zero Knowledge podcast with [Daniel Kang](https://twitter.com/daniel_d_kang)
              and [Yi Sun](https://twitter.com/theyisun) where they explored recent
              advancements in this field.


              Specifically, Daniel and Yi recently [released work](https://arxiv.org/pdf/2211.04775.pdf)
              on ways to verify that images taken by cameras with attested sensors
              were subject to transformations like cropping, resizing, or limited
              redactions – useful in cases where you want to prove that an image wasn’t
              deepfaked but did undergo some legitimate form of editing. Dan Boneh
              and Trisha Datta [have also done similar work](https://medium.com/@boneh/using-zk-proofs-to-fight-disinformation-17e7d57fe52f)
              around verifying provenance of an image using zero-knowledge proofs.


              But, more broadly, any digitally attested piece of information is a
              candidate for this form of verification: Jason Morton, who is working
              on the [EZKL library](https://github.com/zkonduit/ezkl) (more on this
              in the following section) calls this “ [giving the blockchain eyes](https://www.youtube.com/watch?v=s9IfxTMq4ks&t=290s).”
              Any signed endpoint: (e.g., [Cloudflare’s SXG service](https://developers.cloudflare.com/fundamentals/speed/signed-exchanges/),
              third party notaries) produce digital signatures that can be verified,
              which could be useful for proving provenance and authenticity from a
              trusted party.


              **4\. Decentralized Inference or Training:** You want to perform machine-learning
              inference or training in a decentralized way, and allow people to submit
              data to a public model. To do this, you might deploy an already-existing
              model on-chain, or architect an entirely new network, and use zero-knowledge
              proofs to compress the model. Jason Morton’s [EZKL](https://github.com/zkonduit/ezkl)
              library is creating a method for ingesting ONXX and JSON files, and
              converting them into ZK-SNARK circuits. [A recent demo at ETH Denver](https://www.youtube.com/watch?v=YqnVAL3kkMk)
              showed that this can be used in applications like creating an image-recognition-based
              on-chain scavenger hunt, where creators of the game can upload a photo,
              generate a proof of the image, and players can upload images; the verifier
              checks whether the image the user uploads sufficiently matches the proof
              generated by the creator. EZKL now can verify models of up to 100 million
              parameters, implying that it could be used to verify [ImageNet-sized
              models](https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf)
              (which have 60 million parameters) on-chain.


              Other teams, like [Modulus Labs](https://www.moduluslabs.xyz/) are [benchmarking
              different proof systems for on-chain inference](https://drive.google.com/file/d/1tylpowpaqcOhKQtYolPlqvx6R2Gv4IzE/view). 
              Modulus’s benchmarks ran up to 18 million parameters. On the training
              side, [Gensyn](https://www.gensyn.ai/) is building a decentralized compute
              system, where users can input public data, and have their models trained
              by a decentralized network of nodes, with verification for correctness
              of training.


              **5\. Proof of Personhood:** You want to verify that someone is a unique
              person without compromising their privacy. To do this, you would create
              a method of verification – for example, biometric scanning, or a method
              for submitting government ID in an encrypted manner. Then you would
              use zero-knowledge proofs to check that someone has been verified, without
              revealing any information about that person’s identity, whether that
              identity is fully recognizable, or pseudonymous, like a public key.


              Worldcoin is doing this through their [proof-of-personhood protocol](https://worldcoin.org/blog/engineering/humanness-in-the-age-of-ai),
              a way to ensure sybil-resistance by generating unique iris codes for
              users. Crucially, private keys created for the WorldID (and the other
              private keys for the crypto wallet created for Worldcoin users) are
              completely separate from the iris code generated locally by the project’s
              eye-scanning orb.  This separation completely decouples biometric identifiers
              from any form of users’ keys that could be attributable to a person.
              Worldcoin [also permits applications](https://worldcoin.org/blog/announcements/introducing-world-id-and-sdk)
              to embed an SDK that allows users to log in with the WorldID, and leverages
              zero-knowledge proofs for privacy, by allowing the application to check
              that the person has a WorldID, but does not enable individual user tracking
              (for more detail, see this [blogpost](https://worldcoin.org/blog/developers/privacy-deep-dive)).


              This example is a form of combatting weaker, more malicious forms of
              artificial intelligence with the privacy-preserving properties of zero-knowledge
              proofs, so it’s quite different from the other examples listed above
              (e.g., proving that you are a real human, not a bot, without revealing
              any information about yourself).


              ## Model architectures and challenges


              Breakthroughs in proving systems that implement SNARKs (Succinct Non-Interactive
              Arguments of Knowledge) have been key drivers in putting many machine
              learning models on-chain. Some teams are making custom circuits in existing
              architectures (including Plonk, Plonky2, Air, and more). On the custom
              circuit side, [Halo 2](https://github.com/zcash/halo2) has become a
              popular backend used by both [Daniel Kang et. al.](https://medium.com/@danieldkang/trustless-verification-of-machine-learning-6f648fd8ba88)
              in their work, and Jason Morton’s EZKL project. Halo 2’s prover times
              are quasilinear, proof sizes are usually [just a few kilobytes](https://zcash.github.io/halo2/user/dev-tools.html?highlight=byte#cost-estimator),
              and verifier times are constant. Perhaps more importantly, Halo 2 has
              strong developer tooling, making it a popular SNARK backend used by
              developers. Other teams, like Risc Zero, are aiming for a generalized
              VM strategy. And others are creating custom frameworks using Justin
              Thaler’s [super-efficient proof systems](https://zkproof.org/2020/03/16/sum-checkprotocol/)
              based on the sum-check protocol.


              Proof generation and verifier times depend, in absolute terms, on the
              hardware generating and checking the proofs as well as the size of the
              circuit for proof generation. But the crucial thing to note here is
              that regardless of the program being represented, the proof size will
              always be relatively small, so the burden on the verifier checking the
              proof is constrained. There are, however, some subtleties here: for
              proof systems like Plonky2 which use a FRI-based commitment scheme,
              proof size may increase. (Unless it is wrapped in a pairing-based SNARK
              like Plonk or Groth16 at the end, which don’t grow in size with the
              complexity of the statement being proven.)


              The implication here for machine learning models is that once you have
              designed a proof system that accurately represents a model, the cost
              of actually verifying outputs will be quite cheap. The thing that developers
              have to make the most considerations of are prover time and memory:
              representing models in a way that they can be relatively quickly proven,
              and with proof sizes ideally around a few kilobytes. To prove the correct
              execution of machine learning models in zero knowledge, you need to
              encode model architecture (layers, nodes, and activation functions),
              parameters, constraints, and matrix multiplication operations and represent
              them as circuits. This involves breaking down these properties into
              arithmetic operations that can be performed over a finite field.


              The area is still nascent. Accuracy and fidelity may suffer in the process
              of converting a model into a circuit. When a model is represented as
              an arithmetic circuit, those aforementioned model parameters, constraints,
              and matrix multiplication operations may need to be approximated and
              simplified. And when arithmetic operations are encoded as elements in
              the proof’s finite field, some precision might be lost (or the cost
              to generate a proof without these optimization with current zero-knowledge
              frameworks would be untenably high). Additionally, parameters and activations
              of machine learning models are often encoded as 32-bits for precision,
              but zero-knowledge proofs today can’t represent 32-bit floating point
              operations in the necessary arithmetic circuit format without massive
              overheads. As a result, developers may choose to use quantized machine
              learning models, whose 32-bit integers have already been converted into
              8-bit precision. These types of models are favorable to representation
              as zero-knowledge proofs, but the model being verified might be a crude
              approximation of the higher-quality initial model.


              At this stage, it’s admittedly a game of catch-up. As zero-knowledge
              proofs become more optimized, machine learning models grow in complexity.
              There are a number of promising areas for optimizations already: proof
              recursion could reduce overall proof size by allowing proofs to be used
              as inputs for the next proof, unlocking proof compression. There are
              emerging frameworks too, like Linear A’s fork of Apache’s Tensor Virtual
              Machine (TVM), which advances a [transpiler](https://github.com/zk-ml/tachikoma)
              for converting floating-point numbers into zero-knowledge friendly integer
              representations. And finally, we at a16z crypto are optimistic that
              future work will make it much more reasonable to represent 32-bit integers
              in SNARKs.


              ## The two definitions of “scale”


              Zero-knowledge proofs scale through compression: SNARKs allow you to
              take an enormously complex system (a virtual machine, a machine learning
              model) and mathematically represent it so that the cost of verifying
              it is less than the cost of running it. Machine learning, on the other
              hand, scales through expansion: models today get better with more data,
              parameters, and GPUs/TPUs involved in the training and inference process.
              Centralized companies can run servers at a pretty much unbounded magnitude:
              charge a monthly fee for API calls, and cover the costs of operation.


              The economic realities of blockchain networks operate almost in the
              inverse: developers are encouraged to optimize their code to make it
              computationally feasible (and inexpensive) to run on-chain. This asymmetry
              has a tremendous benefit: it has created an environment where proof
              systems _need_ to become more efficient. We should be pushing for ways
              to demand the same benefits blockchains provide – namely, verifiable
              ownership, and a shared notion of truth – in machine learning as well.


              While blockchains have incentivized optimizing zk-SNARKs, every field
              in computing will benefit.


              \\*\\*\\*


              Acknowledgements: Justin Thaler, Dan Boneh, Guy Wuollet, Sam Ragsdale,
              Ali Yahya, Chris Dixon, Eddy Lazzarin, Tim Roughgarden, Robert Hackett,
              Tim Sullivan, Jason Morton, Peiyuan Liao, Tarun Chitra, Brian Retford,
              Daniel Kang, Yi Sun, Anna Rose, Modulus Labs, DC Builder.


              \\*\\*\\*


              [Elena Burger](https://a16zcrypto.com/team/elena-burger) is a deal partner
              at a16z crypto, with a focus on games, NFTs, web3 media, and decentralized
              infrastructure. Prior to joining the team, she spent four years as an
              equities analyst at Gilder, Gagnon, Howe, and Co. She has a Bachelor’s
              degree from Barnard College, Columbia University, where she majored
              in history.


              \\*\\*\\*


              _The views expressed here are those of the individual AH Capital Management,
              L.L.C. (“a16z”) personnel quoted and are not the views of a16z or its
              affiliates. Certain information contained in here has been obtained
              from third-party sources, including from portfolio companies of funds
              managed by a16z. While taken from sources believed to be reliable, a16z
              has not independently verified such information and makes no representations
              about the current or enduring accuracy of the information or its appropriateness
              for a given situation. In addition, this content may include third-party
              advertisements; a16z has not reviewed such advertisements and does not
              endorse any advertising content contained therein._


              _This content is provided for informational purposes only, and should
              not be relied upon as legal, business, investment, or tax advice. You
              should consult your own advisers as to those matters. References to
              any securities or digital assets are for illustrative purposes only,
              and do not constitute an investment recommendation or offer to provide
              investment advisory services. Furthermore, this content is not directed
              at nor intended for use by any investors or prospective investors, and
              may not under any circumstances be relied upon when making a decision
              to invest in any fund managed by a16z. (An offering to invest in an
              a16z fund will be made only by the private placement memorandum, subscription
              agreement, and other relevant documentation of any such fund and should
              be read in their entirety.) Any investments or portfolio companies mentioned,
              referred to, or described are not representative of all investments
              in vehicles managed by a16z, and there can be no assurance that the
              investments will be profitable or that other investments made in the
              future will have similar characteristics or results. A list of investments
              made by funds managed by Andreessen Horowitz (excluding investments
              for which the issuer has not provided permission for a16z to disclose
              publicly as well as unannounced investments in publicly traded digital
              assets) is available at https://a16z.com/investments/._


              _Charts and graphs provided within are for informational purposes solely
              and should not be relied upon when making any investment decision. Past
              performance is not indicative of future results. The content speaks
              only as of the date indicated. Any projections, estimates, forecasts,
              targets, prospects, and/or opinions expressed in these materials are
              subject to change without notice and may differ or be contrary to opinions
              expressed by others. Please see https://a16z.com/disclosures for additional
              important information._'
            metadata:
              og:title: 'Checks and balances: Machine learning and zero-knowledge
                proofs'
              publishedTime: '2023-04-05T16:03:52+00:00'
              ogTitle: 'Checks and balances: Machine learning and zero-knowledge proofs'
              twitter:card: summary_large_image
              twitter:title: 'Checks and balances: Machine learning and zero-knowledge
                proofs'
              ogLocale: en_US
              twitter:label1: Written by
              ogUrl: https://a16zcrypto.com/posts/article/checks-and-balances-machine-learning-and-zero-knowledge-proofs/
              parsely-title: 'Checks and balances: Machine learning and zero-knowledge
                proofs'
              description: Advancements in zero-knowledge proofs are now making it
                possible for users to demand trustlessness and verifiability of every
                digital product in existence.
              parsely-image-url: https://api.a16zcrypto.com/wp-content/uploads/2023/04/AI_and_ZK_1920x1080-150x150.jpg
              title: Machine learning and zero-knowledge proofs - a16z crypto
              ogSiteName: a16z crypto
              twitter:image: https://api.a16zcrypto.com/wp-content/uploads/2023/04/AI_and_ZK_TW.jpg
              og:image: https://api.a16zcrypto.com/wp-content/uploads/2023/04/AI_and_ZK_FB.jpg
              twitter:site:
              - '@a16zcrypto'
              - '@a16zcrypto'
              favicon: https://a16zcrypto.com/favicon.png
              twitter:data2: '0'
              twitter:data1: Elena Burger
              parsely-link: https://a16zcrypto.com/posts/article/checks-and-balances-machine-learning-and-zero-knowledge-proofs/
              format-detection: telephone=no
              og:type: article
              parsely-type: post
              article:published_time: '2023-04-05T16:03:52+00:00'
              og:image:type: image/jpeg
              parsely-section: research
              parsely-tags: machine learning,research,tech trends,zero knowledge &amp;
                succinct proof systems
              parsely-author: Elena Burger
              language: en
              og:image:width: '1200'
              og:locale: en_US
              twitter:description: Advancements in zero-knowledge proofs are now making
                it possible for users to demand trustlessness and verifiability of
                every digital product in existence.
              ogImage: https://api.a16zcrypto.com/wp-content/uploads/2023/04/AI_and_ZK_FB.jpg
              robots: index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1
              twitter:label2: Est. reading time
              og:url: https://a16zcrypto.com/posts/article/checks-and-balances-machine-learning-and-zero-knowledge-proofs/
              og:site_name: a16z crypto
              og:image:height: '630'
              ogDescription: Advancements in zero-knowledge proofs are now making
                it possible for users to demand trustlessness and verifiability of
                every digital product in existence.
              viewport: width=device-width,initial-scale=1
              og:description: Advancements in zero-knowledge proofs are now making
                it possible for users to demand trustlessness and verifiability of
                every digital product in existence.
              parsely-pub-date: '2023-04-05T16:03:52Z'
              scrapeId: 45255023-0115-42f0-b0d5-c9d5ba588989
              sourceURL: https://a16zcrypto.com/posts/article/checks-and-balances-machine-learning-and-zero-knowledge-proofs/
              url: https://a16zcrypto.com/posts/article/checks-and-balances-machine-learning-and-zero-knowledge-proofs/
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
          - title: 'Lattices Meet Hashes: Recent Advances in Post-Quantum Zero ...'
            description: The goal of this workshop is to share the current state-of-the-art
              results in the area of post-quantum zero-knowledge proofs and bring
              the two (seemingly ...
            url: https://bernoulli.epfl.ch/programs/lattices-meet-hashes/
            markdown: '[Skip to content](https://bernoulli.epfl.ch/programs/lattices-meet-hashes/#content)


              Menu


              [![](https://bernoulli.epfl.ch/wp-content/uploads/2022/09/Bernoulli-Center-Logo-Black-Subtitle_1@4x-1024x291.png)](https://bernoulli.epfl.ch/)


              [![](https://bernoulli.epfl.ch/wp-content/uploads/2022/09/Bernoulli-Center-Logo-Black-Subtitle_1@4x-1024x291.png)](https://bernoulli.epfl.ch/)


              Menu


              Search


              Search


              Close this search box.


              - [Home](https://bernoulli.epfl.ch/)


              - [Past Programme](https://bernoulli.epfl.ch/program_category/past-programs/)


              - Lattices Meet Hashes: Recent Advances in Post-Quantum Zero-Knowledge
              Proofs


              [![](https://bernoulli.epfl.ch/wp-content/uploads/2023/02/Lattices-meet-hashes.jpg)](https://bernoulli.epfl.ch/wp-content/uploads/2023/02/Lattices-meet-hashes.jpg)


              ## Lattices Meet Hashes: Recent Advances in Post-Quantum Zero-Knowledge
              Proofs


              Zero-knowledge proofs are a powerful cryptographic tool which has found
              numerous real-world applications in e.g. confidential transactions,
              anonymous credentials, e-voting and blockchain. Recently, due to the
              significant progress in building quantum computers, there has been tremendous
              interest in constructing such protocols from quantum-safe assumptions.


              The goal of this workshop is to share the current state-of-the-art results
              in the area of post-quantum zero-knowledge proofs and bring the two
              (seemingly separate) research communities together: lattice- and hash-based
              proof systems. Indeed, many recent lattice-based constructions (even
              unknowingly) borrow key techniques from hash-based proof systems, e.g.,
              the split-and-fold approach or the sumcheck protocol. We thus believe
              the two areas have a lot in common, and by sharing the knowledge in
              the related fields, we, as a cryptographic research community, can build
              more efficient and practical quantum-safe zero-knowledge protocols.


              #### Program:


              **Confirmed speakers:**


              [Thomas Attema](https://www.cwi.nl/en/people/thomas-attema/), CWI and
              TNO


              [Jonathan Bootle](https://jbootle.github.io/), IBM Research Zurich


              [Sarah Bordage](https://ic-people.epfl.ch/~bordage/), EPFL


              [Muhammed Esgin](https://mfesgin.github.io/), Monash University


              [Russell W. F. Lai](https://russell-lai.hk/), Aalto University


              [Vadim Lyubashevsky](https://researcher.watson.ibm.com/researcher/view.php?person=zurich-vad),
              IBM Research Zurich


              [Giulio Malavolta](https://sites.google.com/view/giuliomalavolta/),
              Max Planck Institute


              [Gregor Seiler](https://dblp.org/pid/184/3795.html), IBM Research Zurich


              [Nick Spooner](https://spooner.cc/), Warwick University


              [Akira Takahashi](https://akiratk0355.github.io/), University of Edinburgh


              [David Wu](https://www.cs.utexas.edu/~dwu4/), University of Texas


              #### Participants:


              Coming soon


              #### Registration:


              [Click here](https://lattices-meet-hashes23.epfl.ch/registration.html)


              [Website](https://lattices-meet-hashes23.epfl.ch/)


              Start date & time


              01/05/2023


              End date & time


              03/05/2023


              Location


              - [Bernoulli Center (Lausanne)](https://www.google.com/maps/place/EPFL+Bernoulli+center/@46.5198032,6.5716923,15z/data=!4m2!3m1!1s0x0:0x3a4de4ac4fbd08c1?sa=X&ved=2ahUKEwi1sKSOjvn6AhUSMuwKHQJMDC0Q_BJ6BAhGEAU)


              Host


              Bernoulli Center


              Organisers


              [Ngoc Khanh Nguyen](https://people.epfl.ch/khanh.nguyen), EPFL


              [Gal Arnon](https://www.wisdom.weizmann.ac.il/~galar/), Weizmann Institute


              Category


              [Past Programme](https://bernoulli.epfl.ch/program_category/past-programs/)


              ### Contact


              - Christiane Maillard, Bernadette Brun & Eliane Rasch

              - EPFL AVP-CP CIB


              - [GA 3 34 (Bâtiment GA), Station 5 \\

              \\

              CH-1015 Lausanne](https://www.google.com/maps/place/EPFL+Bernoulli+center/@46.5198032,6.5716923,15z/data=!4m2!3m1!1s0x0:0x3a4de4ac4fbd08c1?sa=X&ved=2ahUKEwiBhIO8gqv6AhXTi8MKHQD1AJIQ_BJ6BAhTEAU)

              - [+41 21 693 64 30](tel:+41216936430)

              - [bernoulli@epfl.ch](mailto:bernoulli@epfl.ch)


              ### About


              Advancing fundamental sciences in a collaborative environment.


              - [Mission](https://bernoulli.epfl.ch/about/#mission)

              - [Governance](https://bernoulli.epfl.ch/about/#governance)


              [Youtube](https://www.youtube.com/channel/UCO60DrAzEcS5ql9_e8hhEmQ)[Newspaper](https://bernoulli.epfl.ch/news/)


              Bernoulli Center for Fundamental Studies


              [![EPFL white logo](https://bernoulli.epfl.ch/wp-content/uploads/2022/09/EPFL_Logo_Digital_WHITE_PROD-768x333.png)](https://www.epfl.ch/)


              Copyright © 2025 All rights reserved.


              [Créé par Flash Design](https://flashdesign.ch/)'
            metadata:
              twitter:description: Zero-knowledge proofs are a powerful cryptographic
                tool which has found numerous real-world applications in e.g. confidential
                transactions, anonymous credentials, e-voting and blockchain. Recently,
                due to the significant progress in building quantum computers, there
                has been tremendous interest in constructing such protocols from quantum-safe
                assumptions. The goal of this workshop is to share the current state-of-the-art
              og:type:
              - article
              - article
              og:image:secure_url: https://bernoulli.epfl.ch/wp-content/uploads/2022/09/Bernoulli-Center-Logo-Black-Subtitle_1@4x.png
              og:site_name:
              - Bernoulli Center - For Fundamental Studies
              - Bernoulli Center
              og:image:width: '1920'
              og:locale:
              - en_US
              - en_US
              og:image:
              - https://bernoulli.epfl.ch/wp-content/uploads/2022/09/Bernoulli-Center-Logo-Black-Subtitle_1@4x.png
              - https://bernoulli.epfl.ch/wp-content/uploads/2023/02/Lattices-meet-hashes.jpg
              twitter:image: https://bernoulli.epfl.ch/wp-content/uploads/2022/09/Bernoulli-Center-Logo-Black-Subtitle_1@4x.png
              article:published_time: '2023-03-09T10:40:44+00:00'
              viewport: width=device-width, initial-scale=1
              twitter:title: 'Lattices Meet Hashes: Recent Advances in Post-Quantum
                Zero-Knowledge Proofs - Bernoulli Center'
              article:modified_time:
              - '2024-02-15T10:04:29+00:00'
              - '2024-02-15T10:04:29+00:00'
              robots: max-image-preview:large
              og:description:
              - Zero-knowledge proofs are a powerful cryptographic tool which has
                found numerous real-world applications in e.g. confidential transactions,
                anonymous credentials, e-voting and blockchain. Recently, due to the
                significant progress in building quantum computers, there has been
                tremendous interest in constructing such protocols from quantum-safe
                assumptions. The goal of this workshop is to share the current state-of-the-art
              - Zero-knowledge proofs are a powerful cryptographic tool which has
                found numerous real-world applications in e.g. confidential transactions,
                anonymous credentials, e-voting and blockchain. Recently, due to the
                significant progress in building quantum computers, there has been
                tremendous interest in constructing such protocols from quantum-safe
                assumptions. The goal of this workshop is to share the current state-of-the-art
                […]
              modifiedTime: '2024-02-15T10:04:29+00:00'
              ogTitle: 'Lattices Meet Hashes: Recent Advances in Post-Quantum Zero-Knowledge
                Proofs - Bernoulli Center'
              publishedTime: '2023-03-09T10:40:44+00:00'
              ogDescription: Zero-knowledge proofs are a powerful cryptographic tool
                which has found numerous real-world applications in e.g. confidential
                transactions, anonymous credentials, e-voting and blockchain. Recently,
                due to the significant progress in building quantum computers, there
                has been tremendous interest in constructing such protocols from quantum-safe
                assumptions. The goal of this workshop is to share the current state-of-the-art
              og:image:height: '1080'
              twitter:data1: 2 minutes
              generator:
              - All in One SEO (AIOSEO) 4.8.7
              - WordPress 6.8.2
              - 'Elementor 3.24.4; features: additional_custom_breakpoints; settings:
                css_print_method-external, google_font-enabled, font_display-auto'
              ogImage: https://bernoulli.epfl.ch/wp-content/uploads/2022/09/Bernoulli-Center-Logo-Black-Subtitle_1@4x.png
              title: 'Lattices Meet Hashes: Recent Advances in Post-Quantum Zero-Knowledge
                Proofs - Bernoulli Center'
              favicon: https://bernoulli.epfl.ch/wp-content/uploads/2022/09/favicon-150x150.png
              og:image:type: image/jpeg
              og:url:
              - https://bernoulli.epfl.ch/programs/lattices-meet-hashes/
              - https://bernoulli.epfl.ch/programs/lattices-meet-hashes/
              twitter:card:
              - summary_large_image
              - summary_large_image
              og:title:
              - 'Lattices Meet Hashes: Recent Advances in Post-Quantum Zero-Knowledge
                Proofs - Bernoulli Center'
              - 'Lattices Meet Hashes: Recent Advances in Post-Quantum Zero-Knowledge
                Proofs - Bernoulli Center'
              twitter:label1: Est. reading time
              language: en-US
              description: Zero-knowledge proofs are a powerful cryptographic tool
                which has found numerous real-world applications in e.g. confidential
                transactions, anonymous credentials, e-voting and blockchain. Recently,
                due to the significant progress in building quantum computers, there
                has been tremendous interest in constructing such protocols from quantum-safe
                assumptions. The goal of this workshop is to share the current state-of-the-art
              msapplication-TileImage: https://bernoulli.epfl.ch/wp-content/uploads/2022/09/favicon-300x300.png
              ogSiteName: Bernoulli Center - For Fundamental Studies
              ogUrl: https://bernoulli.epfl.ch/programs/lattices-meet-hashes/
              ogLocale: en_US
              scrapeId: 95a331b4-aad5-4fc9-8ac7-ea1634592d63
              sourceURL: https://bernoulli.epfl.ch/programs/lattices-meet-hashes/
              url: https://bernoulli.epfl.ch/programs/lattices-meet-hashes/
              statusCode: 200
              contentType: text/html; charset=UTF-8
              proxyUsed: basic
              cacheState: miss
    description: Direct tool call for web search about zero knowledge proofs
    status: success
  direct_extract:
    input:
      tool: firecrawl_extract_web_data
      tool_arguments:
        urls:
        - https://ethereum.org/en/zero-knowledge-proofs/
        extraction_prompt: Extract information about how zero knowledge proofs are
          being used in blockchain technology
        enable_web_search: false
    output:
      response: ''
      data:
        status: success
        data:
          extracted_data: !!python/object:firecrawl.firecrawl.ExtractResponse
            __dict__:
              id: null
              status: completed
              expiresAt: 2025-09-16 15:08:15+00:00
              success: true
              data:
                useCases:
                - benefits:
                  - Enhances user privacy
                  - Reduces financial surveillance
                  - Prevents identity theft
                  description: Zero-knowledge proofs are used to enable anonymous
                    payments, allowing users to conduct private transactions without
                    revealing their identities or transaction details.
                  blockchainPlatform: Zcash, Monero, Ethereum (via Tornado Cash)
                - benefits:
                  - Protects personal information
                  - Empowers users with control over their identity
                  description: Zero-knowledge proofs help in identity protection by
                    allowing individuals to validate their identity without revealing
                    sensitive personal information.
                  blockchainPlatform: Decentralized identity systems on Ethereum
                - benefits:
                  - Ensures privacy
                  - Confirms uniqueness without disclosing identity
                  description: The World ID protocol uses zero-knowledge proofs to
                    allow individuals to prove they are unique without revealing personal
                    information, functioning as a global digital passport.
                  blockchainPlatform: Ethereum
                - benefits:
                  - Reduces the need for personal data storage
                  - Enhances user convenience
                  description: Zero-knowledge proofs simplify authentication processes
                    by allowing users to prove their identity without sharing personal
                    information, improving user experience.
                  blockchainPlatform: Various online services
                - benefits:
                  - Improves processing speeds
                  - Reduces network congestion
                  description: Verifiable computation allows outsourcing computation
                    while maintaining verifiable results, using zero-knowledge proofs
                    to ensure correctness of offchain transactions.
                  blockchainPlatform: Ethereum
                - benefits:
                  - Enhances voting integrity
                  - Prevents collusion and bribery
                  description: Zero-knowledge proofs are used in blockchain voting
                    systems to prevent bribery and collusion, ensuring the integrity
                    of votes without revealing individual choices.
                  blockchainPlatform: Ethereum (via MACI)
              error: null
              warning: null
              sources: null
            __pydantic_extra__: null
            __pydantic_fields_set__: !!set
              success: null
              data: null
              status: null
              expiresAt: null
            __pydantic_private__: null
    description: Direct tool call to extract web data from Ethereum.org about zero
      knowledge proofs
    status: success
  scrape_heurist_homepage:
    input:
      query: Scap me data of heurist.ai and generate a response about their services
        and offerings
      raw_data_only: false
    output:
      response: I'm sorry, I was unable to scrape the content from heurist.ai due
        to a request timeout. This means I couldn't access the information on their
        website to tell you about their services and offerings.
      data:
        error: 'Failed to scrape URL: Request Timeout: Failed to scrape URL as the
          request timed out. Scrape timed out - No additional error details provided.'
    description: Scrape Heurist.ai homepage and generate response about services
    status: success
  heurist_services_query:
    input:
      query: What services and products does Heurist.ai offer? What makes them unique
        in the AI space?
      raw_data_only: false
    output:
      response: "Heurist.ai is a company focused on developing \"Heurist Chain,\"\
        \ a blockchain infrastructure designed for the AI cloud. Their services and\
        \ products are primarily centered around creating a decentralized, scalable,\
        \ and secure environment for AI applications.\n\nHere's a breakdown of what\
        \ they offer and what makes them unique:\n\n**Core Services and Products:**\n\
        \n*   **Heurist Chain Development:** Heurist.ai is building a blockchain specifically\
        \ tailored for AI, aiming to provide the necessary infrastructure for scaling\
        \ decentralized AI 3.0 applications.\n*   **Decentralized AI Infrastructure:**\
        \ Their network is designed to support:\n    *   **Hyper-scalable permanent\
        \ data storage:** Essential for the vast amounts of data AI systems require.\n\
        \    *   **Super-fast data availability:** Crucial for efficient AI operations.\n\
        \    *   **Flexible EVM-compatible decoupled execution:** Allowing for adaptable\
        \ smart contract, dApp, and agent deployment.\n*   **AI3.0 Ecosystem Stack:**\
        \ This stack includes components for building and deploying AI-powered decentralized\
        \ applications (super dApps) and agents:\n    *   **Permanent Storage (Distributed\
        \ Storage Network - DSN):** Ensures data integrity and availability for AI\
        \ data, as well as storing all chain data for retrievability.\n    *   **Decoupled\
        \ Execution (Domains):** Customizable execution environments for scalable\
        \ computation, decentralized AI training and inference, and secure agent workflows.\
        \ These domains separate smart contract calls and transaction execution from\
        \ consensus, enabling modular app-chains.\n    *   **Proof-of-Archival-Storage\
        \ (PoAS) Consensus:** A unique consensus chain for decentralized sequencing,\
        \ transaction validation, and settlement, ensuring a single, immutable source\
        \ of truth for blockchain state and history.\n*   **Auto Suite:** A set of\
        \ tools to interact with the Autonomys Network (which powers Heurist):\n \
        \   *   **Space Acres:** A desktop application for setting up and managing\
        \ blockchain nodes and farming operations.\n    *   **Explorer:** A web application\
        \ and block explorer for interacting with the network, registering operators,\
        \ and staking.\n    *   **Auto SDK:** A software development kit for AI and\
        \ web3 developers to simplify interaction with the network, even without deep\
        \ blockchain knowledge.\n\n**What Makes Heurist.ai Unique in the AI Space:**\n\
        \nHeurist.ai distinguishes itself by focusing on the intersection of AI and\
        \ blockchain, specifically addressing the infrastructure needs for a decentralized\
        \ AI future (AI3.0). Their uniqueness stems from:\n\n*   **Foundation Layer\
        \ for AI3.0:** They are building the fundamental infrastructure for a new\
        \ era of AI that is open, accessible, and collaborative, contrasting with\
        \ the centralized models (AI1.0 and AI2.0).\n*   **Quantum-Secure Focus (through\
        \ partnerships):** While the provided information mentions Asphere partnering\
        \ with QuStream to build quantum-secure blockchain infrastructure, and Asphere\
        \ is involved in developing Heurist Chain, it implies that Heurist.ai will\
        \ benefit from or integrate quantum-safe features. This is a significant differentiator\
        \ as quantum computing poses a future threat to conventional encryption.\n\
        *   **Novel Inclusive Consensus (Proof-of-Archival-Storage - PoAS):** This\
        \ mechanism aims to maintain the honest majority assumption and permissionless\
        \ nature of Nakamoto consensus without the high electricity cost of traditional\
        \ mining. This allows for independent scaling of transactions and storage\
        \ while maintaining decentralization.\n*   **Decoupled Architecture:** By\
        \ separating consensus from execution, Heurist Chain can independently scale\
        \ transaction throughput and storage, leading to higher performance and scalability\
        \ for AI applications.\n*   **Human-centric AI:** Their vision for AI3.0 emphasizes\
        \ humans not just interacting with AI, but customizing, training, and deploying\
        \ their own personalized AI agents, blurring the lines between creator and\
        \ consumer. This includes \"Auto ID,\" a self-sovereign identity domain for\
        \ humans and AI.\n*   **Comprehensive Ecosystem Stack:** They are not just\
        \ offering one component but a complete stack from storage and execution to\
        \ consensus and development tools, aiming to provide all necessary elements\
        \ for building and deploying AI-powered dApps and agents on-chain.\n\nIn essence,\
        \ Heurist.ai is positioning itself as a foundational technology provider for\
        \ a decentralized, secure, and highly scalable AI ecosystem, moving beyond\
        \ current centralized AI paradigms."
      data:
        status: success
        data:
          results:
          - title: How to buy Heurist AI (HEU) in Curacao - Bitget
            description: Step-by-step guide with videos for beginners on how to buy
              Heurist AI in Curacao with a credit card. Learn to buy HEU and other
              crypto instantly and safely.
            url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao
            markdown: 'Bitget App


              Trade smarter


              Open


              [![bitget logo](<Base64-Image-Removed>)](https://www.bitget.com/en-CA/)


              Buy crypto [Markets](https://www.bitget.com/en-CA/markets) TradeFuturesEarn
              [Web3](https://web3.bitget.com/source=bitget) SquareMore [![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/8ca573730343a8869f2cd66987081bf7.png)![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/9deb7e2d280fbeabfa0dc740114661db.png)](https://www.bitget.com/en-CA/events/elite-list/detail/232302)
              [![7th Anniversary](https://img.bgstatic.com/multiLang/web/d0111278d24794866903aca5214b18ff.png)![7th
              Anniversary](https://img.bgstatic.com/multiLang/web/08ef5b64fce043d51c46fa0ee5b2df43.png)](https://www.bitget.com/en-CA/events/competitionNew/440806028d3e543eafc70821cb9b13de)


              Pay with ![USD](https://img.bgstatic.com/fiat-country/USD.svg)USD


              [Buy & Sell\\

              \\

              Buy and sell crypto instantly](https://www.bitget.com/en-CA/buy-sell-crypto)
              [Credit / Debit card\\

              \\

              Buy crypto via VISA or Mastercard](https://www.bitget.com/en-CA/buy-sell-crypto)
              [Recurring Buy\\

              \\

              Buy crypto automatically at regular intervals](https://www.bitget.com/en-CA/buy-sell-crypto/recurring-buy)
              [P2P trading\\

              \\

              Buy crypto from verified merchants](https://www.bitget.com/en-CA/p2p-trade)
              [Bitget Card\\

              \\

              Spend globally with your card](https://www.bitget.com/en-CA/cards/landing)


              In the last 24 hours, the [GMCI30](https://www.bitget.com/en-CA/futures/usdt/GMCI30USDT)
              index is up by ![up](https://www.bitget.com/micro-runtime/assets/icon-caret-up.456c0c2b.svg)

              0.79%

              .


              No data


              Trade


              [Spot\\

              \\

              Buy and sell crypto with ease](https://www.bitget.com/en-CA/spot/BTCUSDT)
              [Margin\\

              \\

              Amplify your capital and maximize fund efficiency](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Onchain\\

              \\

              Going Onchain, without going Onchain!](https://www.bitget.com/en-CA/on-chain/)
              [Convert & block trade\\

              \\

              Convert crypto with one click and zero fees](https://www.bitget.com/en-CA/convert)


              Explore


              Launchhub


              Gain the edge early and start winning


              Copy


              Copy elite trader with one click


              Bots


              Simple, fast, and reliable AI trading bot


              Trade


              [USDT-M Futures\\

              \\

              Futures settled in USDT](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [USDC-M Futures\\

              \\

              Futures settled in USDC](https://www.bitget.com/en-CA/futures/usdc/BTCPERP)
              [Coin-M Futures\\

              \\

              Futures settled in cryptocurrencies](https://www.bitget.com/en-CA/futures/usd/BTCUSD)


              Explore


              Futures guide


              A beginner-to-advanced journey in futures trading


              Futures promotions


              Generous rewards await


              [Stock Futures\\

              \\

              Diversified Issuers. Unified in USDT.](https://www.bitget.com/en-CA/promotion/futures-rwa)


              [Overview\\

              \\

              A variety of products to grow your assets](https://www.bitget.com/en-CA/earning)
              [Simple Earn\\

              \\

              Deposit and withdraw anytime to earn flexible returns with zero risk](https://www.bitget.com/en-CA/earning/savings?source1=earn&source2=savings)


              On-chain Earn


              Earn profits daily without risking principal


              Structured Earn


              Robust financial innovation to navigate market swings


              VIP and Wealth Management


              Premium services for smart wealth management


              Loans


              Flexible borrowing with high fund security


              No data


              [Insights\\

              \\

              Insights from experts](https://www.bitget.com/en-CA/insights) [News\\

              \\

              Latest media articles](https://www.bitget.com/en-CA/news) [Bitget Academy\\

              \\

              Learn about crypto and the blockchain](https://www.bitget.com/en-CA/academy)
              [Bitget Blog\\

              \\

              In-depth analysis, trading bots, and industry trends](https://www.bitget.com/en-CA/blog)
              [Bitget Research\\

              \\

              Everything you need to know about the blockchain world](https://www.bitget.com/en-CA/research)


              Learn and explore


              [Help Center](https://www.bitget.com/en-CA/support) [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Rewards](https://www.bitget.com/en-CA/events/rewards) [Referral](https://www.bitget.com/en-CA/events/referral-all-program)
              [Submit feedback](https://www.bitget.com/en-CA/feedback)


              Institution


              [Institutional](https://www.bitget.com/en-CA/vip-institutional-services)
              [PRO program](https://www.bitget.com/en-CA/vip-institutional-services/pro)
              [VIP program](https://www.bitget.com/en-CA/vip/vipIntroduce) [Broker
              program](https://www.bitget.com/en-CA/broker) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)


              Programs


              [Affiliates](https://www.bitget.com/en-CA/affiliates) [Booster Platform](https://www.bitget.com/en-CA/events/kol-promotion)
              [Bitget Builders](https://www.bitget.com/en-CA/incubation-program) [Asset
              custody](https://www.bitget.com/en-CA/custody) [Tax API](https://www.bitget.com/en-CA/taxes-api)
              [GetAgent Member](https://www.bitget.com/en-CA/events/ai-get-agent/upgrade)


              No data


              No data


              [Log in](https://www.bitget.com/en-CA/login)


              [Log in](https://www.bitget.com/en-CA/login)


              [Sign up](https://www.bitget.com/en-CA/register)


              [Sign up](https://www.bitget.com/en-CA/register)


              Buy crypto [Markets](https://www.bitget.com/en-CA/markets) TradeFuturesEarn
              [Web3](https://web3.bitget.com/source=bitget) SquareMore [![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/8ca573730343a8869f2cd66987081bf7.png)![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/9deb7e2d280fbeabfa0dc740114661db.png)](https://www.bitget.com/en-CA/events/elite-list/detail/232302)
              [![7th Anniversary](https://img.bgstatic.com/multiLang/web/d0111278d24794866903aca5214b18ff.png)![7th
              Anniversary](https://img.bgstatic.com/multiLang/web/08ef5b64fce043d51c46fa0ee5b2df43.png)](https://www.bitget.com/en-CA/events/competitionNew/440806028d3e543eafc70821cb9b13de)


              Pay with ![USD](https://img.bgstatic.com/fiat-country/USD.svg)USD


              [Buy & Sell\\

              \\

              Buy and sell crypto instantly](https://www.bitget.com/en-CA/buy-sell-crypto)
              [Credit / Debit card\\

              \\

              Buy crypto via VISA or Mastercard](https://www.bitget.com/en-CA/buy-sell-crypto)
              [Recurring Buy\\

              \\

              Buy crypto automatically at regular intervals](https://www.bitget.com/en-CA/buy-sell-crypto/recurring-buy)
              [P2P trading\\

              \\

              Buy crypto from verified merchants](https://www.bitget.com/en-CA/p2p-trade)
              [Bitget Card\\

              \\

              Spend globally with your card](https://www.bitget.com/en-CA/cards/landing)


              In the last 24 hours, the [GMCI30](https://www.bitget.com/en-CA/futures/usdt/GMCI30USDT)
              index is up by ![up](https://www.bitget.com/micro-runtime/assets/icon-caret-up.456c0c2b.svg)

              0.79%

              .


              No data


              Trade


              [Spot\\

              \\

              Buy and sell crypto with ease](https://www.bitget.com/en-CA/spot/BTCUSDT)
              [Margin\\

              \\

              Amplify your capital and maximize fund efficiency](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Onchain\\

              \\

              Going Onchain, without going Onchain!](https://www.bitget.com/en-CA/on-chain/)
              [Convert & block trade\\

              \\

              Convert crypto with one click and zero fees](https://www.bitget.com/en-CA/convert)


              Explore


              Launchhub


              Gain the edge early and start winning


              Copy


              Copy elite trader with one click


              Bots


              Simple, fast, and reliable AI trading bot


              Trade


              [USDT-M Futures\\

              \\

              Futures settled in USDT](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [USDC-M Futures\\

              \\

              Futures settled in USDC](https://www.bitget.com/en-CA/futures/usdc/BTCPERP)
              [Coin-M Futures\\

              \\

              Futures settled in cryptocurrencies](https://www.bitget.com/en-CA/futures/usd/BTCUSD)


              Explore


              Futures guide


              A beginner-to-advanced journey in futures trading


              Futures promotions


              Generous rewards await


              [Stock Futures\\

              \\

              Diversified Issuers. Unified in USDT.](https://www.bitget.com/en-CA/promotion/futures-rwa)


              [Overview\\

              \\

              A variety of products to grow your assets](https://www.bitget.com/en-CA/earning)
              [Simple Earn\\

              \\

              Deposit and withdraw anytime to earn flexible returns with zero risk](https://www.bitget.com/en-CA/earning/savings?source1=earn&source2=savings)


              On-chain Earn


              Earn profits daily without risking principal


              Structured Earn


              Robust financial innovation to navigate market swings


              VIP and Wealth Management


              Premium services for smart wealth management


              Loans


              Flexible borrowing with high fund security


              No data


              [Insights\\

              \\

              Insights from experts](https://www.bitget.com/en-CA/insights) [News\\

              \\

              Latest media articles](https://www.bitget.com/en-CA/news) [Bitget Academy\\

              \\

              Learn about crypto and the blockchain](https://www.bitget.com/en-CA/academy)
              [Bitget Blog\\

              \\

              In-depth analysis, trading bots, and industry trends](https://www.bitget.com/en-CA/blog)
              [Bitget Research\\

              \\

              Everything you need to know about the blockchain world](https://www.bitget.com/en-CA/research)


              Learn and explore


              [Help Center](https://www.bitget.com/en-CA/support) [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Rewards](https://www.bitget.com/en-CA/events/rewards) [Referral](https://www.bitget.com/en-CA/events/referral-all-program)
              [Submit feedback](https://www.bitget.com/en-CA/feedback)


              Institution


              [Institutional](https://www.bitget.com/en-CA/vip-institutional-services)
              [PRO program](https://www.bitget.com/en-CA/vip-institutional-services/pro)
              [VIP program](https://www.bitget.com/en-CA/vip/vipIntroduce) [Broker
              program](https://www.bitget.com/en-CA/broker) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)


              Programs


              [Affiliates](https://www.bitget.com/en-CA/affiliates) [Booster Platform](https://www.bitget.com/en-CA/events/kol-promotion)
              [Bitget Builders](https://www.bitget.com/en-CA/incubation-program) [Asset
              custody](https://www.bitget.com/en-CA/custody) [Tax API](https://www.bitget.com/en-CA/taxes-api)
              [GetAgent Member](https://www.bitget.com/en-CA/events/ai-get-agent/upgrade)


              No data


              No data


              [Home](https://www.bitget.com/en-CA/)/


              [How to buy crypto](https://www.bitget.com/en-CA/how-to-buy)/


              [How to buy Heurist AI](https://www.bitget.com/en-CA/how-to-buy/heurist-ai)/


              Buy Heurist AI in Curacao/


              # **How to buy Heurist AI (HEU) in Curacao**


              Updated on:2025/09/16 09:08:49 (UTC+0)


              Sign up now to claim a welcome pack worth 6200 USDT!


              [Sign up now](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              Coin rating


              4.5


              Heurist AI (HEU) price: $0.02000


              [Buy HEU now](https://www.bitget.com/en-CA/buy-sell-crypto??channelCode=SSSS&vipCode=s1pz)


              Bitget is legally accessible in Curacao. You can buy Heurist AI in Curacao
              through Bitget.


              Note: Good things take time. This coin hasn''t been listed yet. Stay
              tuned to our announcements for listing updates. Once it''s available
              on Bitget, you can follow our tutorial to purchase it. The same tutorial
              applies to all listed cryptocurrencies on Bitget.


              ## Simple 3-step guide to buying HEU today in Curacao


              1


              Create your free Bitget account


              Provide your email address and place of residence.


              2


              Select a funding method


              Fund your account using your preferred payment method.


              3


              Complete your Heurist AI purchase


              Buy Heurist AI with as little as $5.


              ### Step 1: Create a free account on the Bitget website or the app


              [Sign up](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)
              or [download the Bitget app](https://www.bitget.com/en-CA/download?channelCode=SSSS&vipCode=s1pz)
              to start your journey on Bitget.


              Please verify your identity to ensure full compliance and enhance your
              Bitget experience.


              You can access the [identity verification page](https://www.bitget.com/en-CA/account/verified),
              select your country, upload your ID documents, and submit your selfie.
              You will receive a notification once your identity has been successfully
              verified.


              ### Step 2: Place an order for Heurist AI using a payment method of
              your choice:


              - #### Buy Heurist AI with a debit/credit card



              For Visa or Mastercard, select [Credit/Debit card](https://www.bitget.com/en-CA/buy-sell-crypto?channelCode=SSSS&vipCode=s1pz),
              then click Add New Card under the "Buy" tab




              ![Complete your payment on Bitget App image 1](https://img.bgstatic.com/image/third/buy_crypto_bitget_app_en-ca.png)Credit/Debit
              in the Buy Crypto tab of the Bitget app




              ![Enter the bank card details to complete your payment on Bitget Website
              image 1](https://img.bgstatic.com/image/third/buy_crypto_en-ca.png)Credit/Debit
              in the Buy Crypto tab of the Bitget website




              Select your preferred fiat currency, enter the amount you wish to spend,
              link your credit card, and then complete your payment with zero fees.




              ![Complete your payment on Bitget App image 2](https://img.bgstatic.com/image/third/complete_your_payment_on_bitget_app_en-ca.png)Add
              a new card to complete your payment on the Bitget app




              ![Enter the bank card details to complete your payment on Bitget Website
              image 2](https://img.bgstatic.com/image/third/payment_bitget_website_en-ca.png)Enter
              your bank card details to complete your payment on the Bitget website






              For Diners Club/Discover card, click Buy Crypto > [\[Third Party\]](https://www.bitget.com/en-CA/buy-sell-crypto/third-party/visa?fiatName=EUR)
              in the top navigation bar to place your Heurist AI order.






              ![player.png](https://www.bitget.com/how-to-buy/_next/static/media/player.7cdb5ddf.png)




              How to buy crypto with credit/debit card


              - #### Buy Heurist AI with Google Pay or Apple Pay





              Converting your Google Pay and Apple Pay balance into Heurist AI is
              easy and secure on Bitget. Simply click Buy Crypto > [\[Third Party\]](https://www.bitget.com/en-CA/buy-sell-crypto/third-party/apple-pay?fiatName=USD)
              in the top navigation bar to place your Heurist AI order.






              ![player.png](https://www.bitget.com/how-to-buy/_next/static/media/player.7cdb5ddf.png)




              How to buy crypto via third-party gateway


              - #### Buy with bank transfer



              We accept various payment methods, including iDeal and SEPA for EUR,
              PIX for BRL, PayID for AUD, UPI for INR, QRIS, DANA, and OVO for IDR,
              SPEI for MXN, and GCash for PHP. These services are facilitated by Alchemy
              Pay, Banxa, Mercuryo, and Simplex payment gateways. Simply select Buy
              Crypto > [\[Third Party\]](https://www.bitget.com/en-CA/buy-sell-crypto/third-party/visa?fiatName=USD)
              in the top navigation bar and select a fiat currency to place your Heurist
              AI order.


              - #### Buy Heurist AI with the fiat balance in your Bitget account



              You can [Deposit fiat funds](https://www.bitget.com/en-CA/fiat/deposit)
              using Advcash, SEPA, Faster Payments, or PIX payment gateways to top
              up your Bitget fiat balance. Then, click Buy Crypto > [\[Cash conversion\]](https://www.bitget.com/en-CA/buy-sell-crypto/cash-conversion)
              in the top navigation bar to place your Heurist AI order.


              - #### P2P trading



              With [Bitget P2P](https://www.bitget.com/en-CA/p2p-trade), you can buy
              crypto using over 100 payment methods, including bank transfers, cash,
              and e-wallets like Payeer, Zelle, Perfect Money, Advcash, and Wise.
              Simply place an order, pay the seller, and receive your crypto. Enjoy
              secure transactions with escrow protection.




              ![player.png](https://www.bitget.com/how-to-buy/_next/static/media/player.7cdb5ddf.png)




              How to buy crypto on Bitget P2P



              ### Step 3: Monitor Heurist AI in your Bitget spot wallet


              If you''ve chosen to purchase Heurist AI on Bitget, your Heurist AI
              will be instantly credited to your Bitget spot account upon payment
              completion. You can click Assets located on the top right corner of
              the page to check your assets. Additionally, you can buy, deposit, convert,
              trade, and withdraw them.


              ![Check your Assets](https://img.bgstatic.com/image/third/check_your_assets_en-ca.png)


              Check your assets


              Note: Want to keep tabs on coin prices? Visit our [Coin prices directory](https://www.bitget.com/en-CA/price)
              or [Heurist AI Price Page](https://www.bitget.com/en-CA/price/heurist-ai)
              and bookmark them to stay updated!


              ## Bitget—where the world trades Heurist AI


              [![Fast and efficient](https://www.bitget.com/how-to-buy/_next/static/media/fast-trades.ac40413c.svg)\\

              Fast and efficient\\

              \\

              Our advanced matching engine ensures a lightning-fast, smooth trading
              experience, making Bitget the go-to platform for speed and reliability.](https://www.bitget.com/en-CA/spot/BTCUSDT)
              [![Top-tier security](https://www.bitget.com/how-to-buy/_next/static/media/simple-trades.515de384.svg)\\

              Top-tier security\\

              \\

              With proof of reserves, a dedicated protection fund, and third-party
              custody mechanisms, Bitget prioritizes the safety of your assets, earning
              the trust of millions globally.](https://www.bitget.com/en-CA/download?openApp=1&channelCode=SSSS&vipCode=s1pz&groupId=230932)
              [![Ultimate trading experience](https://www.bitget.com/how-to-buy/_next/static/media/secure-trades.c998c363.svg)\\

              Ultimate trading experience\\

              \\

              Trade cryptocurrencies seamlessly with Bitget''s deep liquidity, empowering
              you to make confident, stress-free transactions every time.](https://www.bitget.com/en-CA/proof-of-reserves)


              ![24/7 support](https://www.bitget.com/how-to-buy/_next/static/media/transparent-trades.91161a2e.svg)


              24/7 support


              Bitget''s dedicated customer service team is available 24/7 to provide
              fast, professional assistance, ensuring an exceptional user experience.


              ### How to buy Heurist AI for free


              Using real money to buy Heurist AI is not the only way to obtainHeurist
              AI. If you have the time to allocate, you can get Heurist AI for free.


              - Learn how to earn Heurist AI for free through the [Learn2Earn promotion](https://www.bitget.com/en-CA/events/learn-to-earn)


              - Earn free Heurist AI by inviting friends to join Bitget''s [Assist2Earn
              promotion](https://www.bitget.com/en-CA/events/offer)


              - Receive free Heurist AI airdrops by joining [ongoing challenges and
              promotions](https://www.bitget.com/en-CA/support/sections/4413154768537)



              All crypto airdrops and rewards can be converted to Heurist AI through
              Bitget Convert, Bitget Swap, or Spot Trading.


              Note: Want to keep tabs on coin prices? Visit our [Coin prices directory](https://www.bitget.com/en-CA/price)
              or [Heurist AI Price Page](https://www.bitget.com/en-CA/price/heurist-ai)
              and bookmark them to stay updated!


              ### HEU/CNY price calculator


              HEU


              CNY


              [Buy HEU now](https://www.bitget.com/en-CA/register??channelCode=SSSS&vipCode=s1pz)


              ![Heurist AI](https://img.bgstatic.com/multiLang/coinPriceLogo/heurist-ai.png)


              ## Buy Heurist AI


              [HEU](https://www.bitget.com/en-CA/price/heurist-ai)/ USDCurrent price:


              $0.02000


              0.00


              -6.17%24H


              The live Heurist AI price today is $0.02000 USD, with a 24-hour trading
              volume of $475,009.7 USD. We update our HEU to USD price in real-time.
              HEU is -6.17% in the last 24 hours.


              [Buy Heurist AI now](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              ### How to buy Heurist AI for free


              Using real money to buy Heurist AI is not the only way to obtainHeurist
              AI. If you have the time to allocate, you can get Heurist AI for free.


              - Learn how to earn Heurist AI for free through the [Learn2Earn promotion](https://www.bitget.com/en-CA/events/learn-to-earn)


              - Earn free Heurist AI by inviting friends to join Bitget''s [Assist2Earn
              promotion](https://www.bitget.com/en-CA/events/offer)


              - Receive free Heurist AI airdrops by joining [ongoing challenges and
              promotions](https://www.bitget.com/en-CA/support/sections/4413154768537)



              All crypto airdrops and rewards can be converted to Heurist AI through
              Bitget Convert, Bitget Swap, or Spot Trading.


              Show more


              ## Buy other cryptos


              [How to buy Bitcoin![Bitcoin](https://img.bgstatic.com/multiLang/coin_img/2edf1ef8b333c40979976d1a49bc234c.png)](https://www.bitget.com/en-CA/how-to-buy/bitcoin
              "How to buy Bitcoin") [How to buy Ethereum![Ethereum](https://img.bgstatic.com/multiLang/coin_img/f6eba5dbcb1e8ce5ed7b053985f314b1.png)](https://www.bitget.com/en-CA/how-to-buy/ethereum
              "How to buy Ethereum") [How to buy Ripple![Ripple](https://img.bgstatic.com/multiLang/coin_img/39edd8e5c80256300562f68afb1ab525.png)](https://www.bitget.com/en-CA/how-to-buy/ripple
              "How to buy Ripple") [How to buy Dogecoin![Dogecoin](https://img.bgstatic.com/multiLang/coin_img/ae64499c8825452f6262177ee6dd525b.png)](https://www.bitget.com/en-CA/how-to-buy/dogecoin
              "How to buy Dogecoin") [How to buy Solana![Solana](https://img.bgstatic.com/multiLang/coin_img/1c1b05492d876ab7e3fa96ea2036ceb2.png)](https://www.bitget.com/en-CA/how-to-buy/solana
              "How to buy Solana") [How to buy Litecoin![Litecoin](https://img.bgstatic.com/multiLang/coin_img/c17bc60be2ebb5765648fc210530a109.png)](https://www.bitget.com/en-CA/how-to-buy/litecoin
              "How to buy Litecoin") [How to buy Binance![Binance](https://img.bgstatic.com/multiLang/coin_img/923b2c797a99f6a402c5969dce135b5e.png)](https://www.bitget.com/en-CA/how-to-buy/binance
              "How to buy Binance") [How to buy Tether![Tether](https://img.bgstatic.com/multiLang/coin_img/fcfda5844dcb17d3416221e202dd1266.png)](https://www.bitget.com/en-CA/how-to-buy/tether
              "How to buy Tether")


              ## Buy Heurist AI in a different country


              You can easily buy Heurist AI (Heurist AI) with the lowest fees and
              highest security wherever Bitget is available. Simply select your country
              in the search box below to start buying Heurist AI in your preferred
              location:


              [Curacao](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao)


              A selection of popular Heurist AI buying regions.


              [How to buy Heurist AI in Japan![Japan](https://www.bitget.com/how-to-buy/_next/static/media/japan.ba74055b.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/japan
              "How to buy Heurist AI in Japan") [How to buy Heurist AI in Canada![Canada](https://www.bitget.com/how-to-buy/_next/static/media/canada.f4843820.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/canada
              "How to buy Heurist AI in Canada") [How to buy Heurist AI in Turkey![Turkey](https://www.bitget.com/how-to-buy/_next/static/media/turkey.c3d6ce63.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/turkey
              "How to buy Heurist AI in Turkey") [How to buy Heurist AI in Switzerland![Switzerland](https://www.bitget.com/how-to-buy/_next/static/media/switzerland.246ccbf6.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/switzerland
              "How to buy Heurist AI in Switzerland") [How to buy Heurist AI in Spain![Spain](https://www.bitget.com/how-to-buy/_next/static/media/spain.8eee8a93.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/spain
              "How to buy Heurist AI in Spain") [How to buy Heurist AI in Mexico![Mexico](https://www.bitget.com/how-to-buy/_next/static/media/mexico.24510045.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/mexico
              "How to buy Heurist AI in Mexico")


              ## Buy other cryptos in your region


              [How to buy Bitcoin in Curacao![Bitcoin](https://img.bgstatic.com/multiLang/coin_img/2edf1ef8b333c40979976d1a49bc234c.png)](https://www.bitget.com/en-CA/how-to-buy/bitcoin/curacao
              "How to buy Bitcoin in Curacao") [How to buy Ethereum in Curacao![Ethereum](https://img.bgstatic.com/multiLang/coin_img/f6eba5dbcb1e8ce5ed7b053985f314b1.png)](https://www.bitget.com/en-CA/how-to-buy/ethereum/curacao
              "How to buy Ethereum in Curacao") [How to buy Ripple in Curacao![Ripple](https://img.bgstatic.com/multiLang/coin_img/39edd8e5c80256300562f68afb1ab525.png)](https://www.bitget.com/en-CA/how-to-buy/ripple/curacao
              "How to buy Ripple in Curacao") [How to buy Dogecoin in Curacao![Dogecoin](https://img.bgstatic.com/multiLang/coin_img/ae64499c8825452f6262177ee6dd525b.png)](https://www.bitget.com/en-CA/how-to-buy/dogecoin/curacao
              "How to buy Dogecoin in Curacao") [How to buy Solana in Curacao![Solana](https://img.bgstatic.com/multiLang/coin_img/1c1b05492d876ab7e3fa96ea2036ceb2.png)](https://www.bitget.com/en-CA/how-to-buy/solana/curacao
              "How to buy Solana in Curacao") [How to buy Litecoin in Curacao![Litecoin](https://img.bgstatic.com/multiLang/coin_img/c17bc60be2ebb5765648fc210530a109.png)](https://www.bitget.com/en-CA/how-to-buy/litecoin/curacao
              "How to buy Litecoin in Curacao") [How to buy Binance in Curacao![Binance](https://img.bgstatic.com/multiLang/coin_img/923b2c797a99f6a402c5969dce135b5e.png)](https://www.bitget.com/en-CA/how-to-buy/binance/curacao
              "How to buy Binance in Curacao") [How to buy Tether in Curacao![Tether](https://img.bgstatic.com/multiLang/coin_img/fcfda5844dcb17d3416221e202dd1266.png)](https://www.bitget.com/en-CA/how-to-buy/tether/curacao
              "How to buy Tether in Curacao")


              [![welcom-login.png](https://www.bitget.com/how-to-buy/_next/static/media/welcom-login-white.f8dfe2b9.svg)\\

              \\

              A welcome pack of 6200 USDT for new users!\\

              \\

              ![arrow-right.png](https://www.bitget.com/how-to-buy/_next/static/media/arrow-right.f132ed1b.png)](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              ## FAQ


              ### Can I buy $1 worth of Heurist AI?


              In theory, Heurist AI is divisible enough that you could buy just $1
              worth, but Bitget''s spot market requires a minimum order value of $5.


              ### Can I buy $10 of Heurist AI?


              Yes, can be divided and bought in an amount worth $10. Bitget''s spot
              market has a minimum order value of $5.


              ### Where else can I buy Heurist AI?


              If a token is not available for purchase via [the P2P market](https://www.bitget.com/en-CA/p2p-trade)
              or [debit/credit card](https://www.bitget.com/en-CA/buy-sell-crypto?channelCode=SSSS&vipCode=s1pz).
              You can place a buy order for it via [the spot market](https://www.bitget.com/en-CA/spot).


              ### Where is the best place to buy Heurist AI?


              The best place to buy Heurist AI is the exchange that provides hassle-free
              and secure transactions combined with a convenient interface and high
              liquidity. Millions of users every day choose Bitget as a trusted crypto
              purchase platform.


              ### Should I buy Heurist AI right now?


              You should make a decision on purchasing or investing in Heurist AI
              or other tokens after performing your own research and analysis. Bitget
              provides user-friendly crypto trading and purchasing services. Additional
              resources such as Bitget Academy and Bitget Insights help users to navigate
              the current market news and trends.


              Curaçao (the Country of Curaçao) is one of the ABC islands of the Netherlands,
              located in the Caribbean Sea and opposite the Venezuelan Sea. With an
              area of 444 square kilometers and a population of 160,000, it is one
              of the largest and most populous of the ABC Islands.


              The official languages of Curaçao are Papiamento, Dutch and English.
              Dutch and English are fully supported by both Bitget app and website.
              The local currency used in Curaçao is the Netherlands Antillean Guilder
              (ANG).


              Whether you are in Willemstad, Jan Thiel, or Piscadera, Bitget is ready
              to serve you with any kind of need in cryptocurrency, it only takes
              minutes away to invest in cryptos on Bitget, the fastest-growing [cryptocurrency
              exchange platform](https://www.bitget.com/) in the world. Bitget offers
              secure payment options to make trading easier for you, including [P2P
              trading](https://www.bitget.com/p2p-trade), crypto deposits, and other
              third-party merchants such as Apple Pay, Google Pay, and different credit
              card services.


              Curaçao is a must-visit destination for beach lovers and divers, with
              most of the scenic beaches located on the south and west sides of the
              island. You can also visit Willemstad, the capital of Curaçao, and stroll
              through the narrow streets of this harbor town to see the colorful Dutch
              colonial architecture.


              [Buy Heurist AI now](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              Cryptocurrency investment activities, including buying Heurist AI on
              Bitget, are subject to market risk. Bitget offers simple and convenient
              ways to buy Heurist AI instantly, and strives to provide transparent
              information about all cryptocurrencies available on the platform. However,
              we are not responsible for any outcomes resulting from your Heurist
              AI purchase. This page and its content do not constitute an endorsement
              of any specific cryptocurrency or method of acquisition.


              About Bitget


              [About Bitget](https://www.bitget.com/en-CA/promotion/aboutus) [Contact
              us](https://www.bitget.com/en-CA/contact-us) [Community](https://www.bitget.com/en-CA/bitget-community)
              [Careers](https://www.bitget.com/en-CA/hire) [Bitget Blog](https://www.bitget.com/en-CA/blog)
              [Bitget Token (BGB)](https://www.bitget.com/en-CA/events/BGB/intro)
              [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Proof of Reserves](https://www.bitget.com/en-CA/proof-of-reserves)
              [Protection Fund](https://www.bitget.com/en-CA/protection-fund) [Partner
              links](https://www.bitget.com/en-CA/links) [LALIGA partnership](https://www.bitget.com/en-CA/events/bitget-laliga)
              [MotoGP partnership](https://www.bitget.com/en-CA/events/bitget-MotoGP)
              [Blockchain4Youth](https://www.bitget.com/en-CA/promotion/blockchain4youth)
              [Blockchain4Her](https://www.bitget.com/en-CA/promotion/blockchain4her)
              [Sitemap](https://www.bitget.com/en-CA/sitemap/crypto/price)


              Products


              [Spot](https://www.bitget.com/en-CA/spot/BTCUSDT) [Futures](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [Onchain](https://www.bitget.com/en-CA/events/bitget-onchain) [Margin](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Earn](https://www.bitget.com/en-CA/earning) [Spot copy trading](https://www.bitget.com/en-CA/copy-trading/spot)
              [Futures copy trading](https://www.bitget.com/en-CA/copy-trading/futures)
              [Bot copy trading](https://www.bitget.com/en-CA/copy-trading/strategy)
              [Bots](https://www.bitget.com/en-CA/trading-bot/spot/BTCUSDT) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [TraderPro](https://www.bitget.com/en-CA/copy-trading/traderpro?utmTerm=footer)
              [Web3 wallet](https://web3.bitget.com/en-CA) [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)
              [Bitget swap](https://web3.bitget.com/en-CA/swap) [Telegram Apps Center](https://www.bitget.com/en-CA/telegram-apps)
              [Airdrop library](https://www.bitget.com/en-CA/airdrop)


              Buy crypto


              [Buy crypto](https://www.bitget.com/en-CA/buy-sell-crypto) [Buy Bitcoin](https://www.bitget.com/en-CA/how-to-buy/bitcoin)
              [Buy ETH](https://www.bitget.com/en-CA/how-to-buy/ethereum) [Buy DOGE](https://www.bitget.com/en-CA/how-to-buy/dogecoin)
              [Buy XRP](https://www.bitget.com/en-CA/how-to-buy/ripple) [Buy BGB](https://www.bitget.com/en-CA/how-to-buy/bitget-token)
              [Buy SHIB](https://www.bitget.com/en-CA/how-to-buy/shiba-inu) [Crypto
              prices](https://www.bitget.com/en-CA/price) [Bitcoin price](https://www.bitget.com/en-CA/price/bitcoin)
              [Ethereum price](https://www.bitget.com/en-CA/price/ethereum) [Solana
              price chart](https://www.bitget.com/en-CA/price/solana-price-chart)
              [Calculator](https://www.bitget.com/en-CA/price/calculator) [Bitcoin
              ETF](https://www.bitget.com/en-CA/price/bitcoin/etf) [Crypto wiki](https://www.bitget.com/en-CA/wiki)
              [XRP price](https://www.bitget.com/en-CA/price/ripple) [Pi Network price](https://www.bitget.com/en-CA/price/pi-network)
              [ADA price](https://www.bitget.com/en-CA/price/cardano) [Solana price](https://www.bitget.com/en-CA/price/solana)
              [Trump coin price](https://www.bitget.com/en-CA/price/trump) [Dogecoin
              price](https://www.bitget.com/en-CA/price/dogecoin) [BRC-20 price](https://www.bitget.com/en-CA/inscription/brc-20)


              Support


              [Submit feedback](https://www.bitget.com/en-CA/feedback) [Help Center](https://www.bitget.com/en-CA/support)
              [Verify official channels](https://www.bitget.com/en-CA/official-verification)
              [Anti-scam hub](https://www.bitget.com/en-CA/events/antiscam2025) [Listing
              application](https://www.bitget.com/en-CA/events/application-for-listing)
              [VIP services](https://www.bitget.com/en-CA/vip/vipIntroduce) [Affiliate
              program](https://www.bitget.com/en-CA/affiliates) [Institutional services](https://www.bitget.com/en-CA/vip-institutional-services)
              [Asset custody](https://www.bitget.com/en-CA/custody) [Download data](https://www.bitget.com/en-CA/data-download)
              [Promotions](https://www.bitget.com/en-CA/events/rewards) [Referral
              program](https://www.bitget.com/en-CA/events/referral) [Fee schedule](https://www.bitget.com/en-CA/fee)
              [Tax filing API](https://www.bitget.com/en-CA/taxes-api)


              Legal


              [Law enforcement request](https://www.bitget.com/en-CA/support/articles/12560603800342)
              [Regulatory request](https://www.bitget.com/en-CA/support/articles/12560603808542)
              [Compliance](https://www.bitget.com/en-CA/compliance) [Regulatory license](https://www.bitget.com/en-CA/promotion/regulatory-license)
              [AML/CFT policies](https://www.bitget.com/en-CA/support/articles/360041116691)
              [Privacy policy](https://www.bitget.com/en-CA/support/articles/360015150651)
              [Terms of Service](https://www.bitget.com/en-CA/support/articles/360014944032)
              [Risk disclosure](https://www.bitget.com/en-CA/support/articles/12560603797276)


              Scan to download


              About Bitget


              [About Bitget](https://www.bitget.com/en-CA/promotion/aboutus) [Contact
              us](https://www.bitget.com/en-CA/contact-us) [Community](https://www.bitget.com/en-CA/bitget-community)
              [Careers](https://www.bitget.com/en-CA/hire) [Bitget Academy](https://www.bitget.com/en-CA/academy)
              [Bitget Blog](https://www.bitget.com/en-CA/blog) [Bitget Token (BGB)](https://www.bitget.com/en-CA/events/BGB/intro)
              [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Proof of Reserves](https://www.bitget.com/en-CA/proof-of-reserves)
              [Protection Fund](https://www.bitget.com/en-CA/protection-fund) [Partner
              links](https://www.bitget.com/en-CA/links) [LALIGA partnership](https://www.bitget.com/en-CA/events/bitget-laliga)
              [MotoGP partnership](https://www.bitget.com/en-CA/events/bitget-MotoGP)
              [Blockchain4Youth](https://www.bitget.com/en-CA/promotion/blockchain4youth)
              [Blockchain4Her](https://www.bitget.com/en-CA/promotion/blockchain4her)
              [Sitemap](https://www.bitget.com/en-CA/sitemap/crypto/price)


              Products


              [Spot](https://www.bitget.com/en-CA/spot/BTCUSDT) [Futures](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [Onchain](https://www.bitget.com/en-CA/events/bitget-onchain) [Margin](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Earn](https://www.bitget.com/en-CA/earning) [Spot copy trading](https://www.bitget.com/en-CA/copy-trading/spot)
              [Futures copy trading](https://www.bitget.com/en-CA/copy-trading/futures)
              [Bot copy trading](https://www.bitget.com/en-CA/copy-trading/strategy)
              [Bots](https://www.bitget.com/en-CA/trading-bot/spot/BTCUSDT) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [TraderPro](https://www.bitget.com/en-CA/copy-trading/traderpro?utmTerm=footer)
              [Web3 wallet](https://web3.bitget.com/en-CA) [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)
              [Bitget swap](https://web3.bitget.com/en-CA/swap) [Telegram Apps Center](https://www.bitget.com/en-CA/telegram-apps)
              [Airdrop library](https://www.bitget.com/en-CA/airdrop)


              Buy crypto


              [Buy crypto](https://www.bitget.com/en-CA/buy-sell-crypto) [Buy Bitcoin](https://www.bitget.com/en-CA/how-to-buy/bitcoin)
              [Buy ETH](https://www.bitget.com/en-CA/how-to-buy/ethereum) [Buy DOGE](https://www.bitget.com/en-CA/how-to-buy/dogecoin)
              [Buy XRP](https://www.bitget.com/en-CA/how-to-buy/ripple) [Buy BGB](https://www.bitget.com/en-CA/how-to-buy/bitget-token)
              [Buy SHIB](https://www.bitget.com/en-CA/how-to-buy/shiba-inu) [Crypto
              prices](https://www.bitget.com/en-CA/price) [Bitcoin price](https://www.bitget.com/en-CA/price/bitcoin)
              [Ethereum price](https://www.bitget.com/en-CA/price/ethereum) [Solana
              price chart](https://www.bitget.com/en-CA/price/solana-price-chart)
              [Calculator](https://www.bitget.com/en-CA/price/calculator) [Bitcoin
              ETF](https://www.bitget.com/en-CA/price/bitcoin/etf) [Crypto wiki](https://www.bitget.com/en-CA/wiki)
              [XRP price](https://www.bitget.com/en-CA/price/ripple) [Pi Network price](https://www.bitget.com/en-CA/price/pi-network)
              [ADA price](https://www.bitget.com/en-CA/price/cardano) [Solana price](https://www.bitget.com/en-CA/price/solana)
              [Trump coin price](https://www.bitget.com/en-CA/price/trump) [Dogecoin
              price](https://www.bitget.com/en-CA/price/dogecoin) [BRC-20 price](https://www.bitget.com/en-CA/inscription/brc-20)


              Support


              [Submit feedback](https://www.bitget.com/en-CA/feedback) [Help Center](https://www.bitget.com/en-CA/support)
              [Verify official channels](https://www.bitget.com/en-CA/official-verification)
              [Anti-scam hub](https://www.bitget.com/en-CA/events/antiscam2025) [Listing
              application](https://www.bitget.com/en-CA/events/application-for-listing)
              [VIP services](https://www.bitget.com/en-CA/vip/vipIntroduce) [Affiliate
              program](https://www.bitget.com/en-CA/affiliates) [Institutional services](https://www.bitget.com/en-CA/vip-institutional-services)
              [Asset custody](https://www.bitget.com/en-CA/custody) [Download data](https://www.bitget.com/en-CA/data-download)
              [Promotions](https://www.bitget.com/en-CA/events/rewards) [Referral
              program](https://www.bitget.com/en-CA/events/referral) [Fee schedule](https://www.bitget.com/en-CA/fee)
              [Tax filing API](https://www.bitget.com/en-CA/taxes-api)


              Legal


              [Law enforcement request](https://www.bitget.com/en-CA/support/articles/12560603800342)
              [Regulatory request](https://www.bitget.com/en-CA/support/articles/12560603808542)
              [Compliance](https://www.bitget.com/en-CA/compliance) [Regulatory license](https://www.bitget.com/en-CA/promotion/regulatory-license)
              [AML/CFT policies](https://www.bitget.com/en-CA/support/articles/360041116691)
              [Privacy policy](https://www.bitget.com/en-CA/support/articles/360015150651)
              [Terms of Service](https://www.bitget.com/en-CA/support/articles/360014944032)
              [Risk disclosure](https://www.bitget.com/en-CA/support/articles/12560603797276)


              © 2025 Bitget


              Dark mode


              Customer Service'
            metadata:
              og:site_name: Bitget
              format-detection: telephone=no,email=no
              twitter:card: summary_large_image
              next-head-count: '61'
              favicon: https://static.bgbstatic.com/baseasset/favicon4.png
              apple-mobile-web-app-status-bar-style: black
              ogTitle: How to Buy Heurist AI (HEU) in Curacao with Credit Card Online
              description: Step-by-step guide with videos for beginners on how to
                buy Heurist AI in Curacao with a credit card. Learn to buy HEU and
                other crypto instantly and safely.
              og:description: Step-by-step guide with videos for beginners on how
                to buy Heurist AI in Curacao with a credit card. Learn to buy HEU
                and other crypto instantly and safely.
              og:image: https://static.bitget.com/video/en-how-to-buy.png
              og:url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao
              twitter:title: How to Buy Heurist AI (HEU) in Curacao with Credit Card
                Online
              title: How to Buy Heurist AI (HEU) in Curacao with Credit Card Online
              language: en-CA
              twitter:image: https://static.bitget.com/video/en-how-to-buy.png
              ogSiteName: Bitget
              og:title: How to Buy Heurist AI (HEU) in Curacao with Credit Card Online
              twitter:description: Step-by-step guide with videos for beginners on
                how to buy Heurist AI in Curacao with a credit card. Learn to buy
                HEU and other crypto instantly and safely.
              twitter:url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao
              twitter:image:alt: Bitget-Better trading
              twitter:site: '@bitgetglobal'
              theme-color: '#000000'
              ogUrl: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao
              ogDescription: Step-by-step guide with videos for beginners on how to
                buy Heurist AI in Curacao with a credit card. Learn to buy HEU and
                other crypto instantly and safely.
              viewport:
              - width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1,
                user-scalable=no
              - width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no
              apple-mobile-web-app-capable: 'yes'
              og:type: article
              ogImage: https://static.bitget.com/video/en-how-to-buy.png
              scrapeId: 4f3056e6-9d5c-4f86-b51d-96a880e9f053
              sourceURL: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao
              url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/curacao
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
          - title: 'Building the Future of Quantum-Secure Web3: Asphere Partners ...'
            description: Learn more about QuStream, Asphere's latest RaaS client,
              and how we're helping them build the network that will bring quantum
              security to blockchain.
            url: https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/
            markdown: '[?](https://helpdesk.ankr.com/)


              # Building the Future of Quantum-Secure Web3: Asphere Partners with
              QuStream


              [![Kevin Dwyer](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/xt_2a97c402c4.png)\\

              \\

              Kevin Dwyer\\

              \\

              August 20, 2025\\

              \\

              3 min read](https://www.ankr.com/blog/writer/kevin-dwyer/)


              ## In Brief


              - [QuStream: A Quantum-Secure Blockchain](https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/#qu-stream-a-quantum-secure-blockchain)

              - [Quantum-Safe Transactions](https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/#quantum-safe-transactions)

              - [Scalable & Decentralized by Design](https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/#scalable-decentralized-by-design)

              - [The Asphere X QuStream Partnership](https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/#the-asphere-x-qu-stream-partnership)

              - [Looking Ahead](https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/#looking-ahead)

              - [Join the Conversation on Our Channels!](https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/#join-the-conversation-on-our-channels)


              ![Medium_Post_19.08_2 (1).jpg](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Medium_Post_19_08_2_1_d85f9f35e6.jpg)


              As artificial intelligence and quantum computing initiate their paradigm
              shift, the risks to our data, identities, and financial systems are
              quickly evolving. Conventional encryption (previously considered formidable)
              is increasingly vulnerable to future quantum attacks. To stay ahead
              of these threats, Asphere has partnered with QuStream to co-engineer
              blockchain infrastructure built for the quantum age.


              Together, we are developing the QuStream blockchain as a Polkadot Rollup,
              combining the interoperability of the Polkadot ecosystem with QuStream’s
              pioneering encryption technology.


              Built with Asphere’s [Rollup as a Service](https://www.ankr.com/rollup-as-a-service-raas/),
              our engineering team will contribute with:


              - Blockchain engineering and implementation

              - Node infrastructure operations

              - Integrations & interoperability tooling

              - Ongoing operations, upgrades, and management


              ## QuStream: A Quantum-Secure Blockchain


              The QuStream blockchain is being designed as a quantum-secure network,
              integrating Proof of Stake consensus, decentralized encryption nodes,
              and data sharding. This layered approach ensures speed, scalability,
              and resilience while protecting transactions, smart contracts, and user
              data against both current and future threats.


              Key architecture includes:


              ### Validator Nodes


              - Maintain blockchain consensus.

              - Process transactions and execute smart contracts.

              - Form the backbone of the decentralized network.


              ### Encryption Nodes


              - Manage QuStream Encryption.

              - Generate dynamic, one-time-use private keys.

              - Use advanced sharding techniques to secure and fragment data, ensuring
              privacy even if a portion of the system is compromised.


              ### Double-Node Architecture


              By separating validator nodes from encryption nodes, QuStream enhances
              both efficiency and security. Validators focus on consensus and performance,
              while encryption nodes handle cryptographic operations, key generation,
              and data privacy.


              [Learn more about QuStream](https://qustream.com/network)


              ## Quantum-Safe Transactions


              Every transaction on QuStream is protected with dynamic private keys,
              eliminating the long-term vulnerabilities associated with static key
              systems. During the process, each key is broken into eight different
              fragments and hidden in the q-block.


              Here is a visualization of the embedded keys. See [more information
              here](https://research.oxfordscientifica.com/qustream/qkdvisual.html).


              ![Screenshot 2025-08-20 at 9.52.26 AM.png](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Screenshot_2025_08_20_at_9_52_26_AM_8c4fd7c38e.png)


              This dynamic encryption ensures that even if a single key were compromised,
              it could never be reused or applied to other transactions.


              At the heart of this system are Quantum Random Number Generator (QRNG)
              Servers, powered by Quantum Dice Apex 2100 hardware. Unlike traditional
              pseudo-random number generators, which rely on deterministic processes,
              QRNG servers draw randomness directly from quantum phenomena. This delivers
              true entropy—a level of unpredictability that is mathematically impossible
              to replicate or predict, even with quantum computers.


              The primary role of QRNG servers is to supply truly random numbers to
              QuStream nodes, ensuring reliable network operation, secure encryption,
              and robust transaction authentication.


              ## Scalable & Decentralized by Design


              To meet the demands of a global Web3 ecosystem, QuStream implements
              data sharding, distributing information across the network to improve
              throughput and resilience. Sharding allows the blockchain to handle
              high transaction volumes without sacrificing decentralization, ensuring
              that Web3 applications remain secure and scalable.


              Combined with Polkadot Rollup integration, this architecture guarantees
              interoperability with the broader Polkadot ecosystem while providing
              unmatched security for industries ranging from finance and healthcare
              to government, defense, and e-commerce.


              ## The Asphere X QuStream Partnership


              Asphere’s expertise in blockchain engineering complements QuStream’s
              cutting-edge encryption design. Together, we are building not just another
              blockchain, but the foundation for a quantum-secure Web3.


              This partnership signifies a major step toward a digital future where
              AI and quantum threats cannot undermine the trustless systems powering
              blockchain economies. From securing decentralized finance and smart
              contracts to protecting sensitive government and healthcare data, QuStream
              will redefine what it means to be “secure” in Web3.


              ## Looking Ahead


              The future of blockchain must anticipate the challenges of tomorrow,
              not just today. By building QuStream as a Polkadot Rollup with a quantum-secure
              foundation, we are laying the groundwork for a Web3 ecosystem that is
              scalable, resilient, and immune to the risks posed by quantum computing.


              ## Join the Conversation on Our Channels!


              [Twitter](https://twitter.com/ankr) \| [Telegram](https://t.me/ankrnetwork)
              \| [Substack](https://ankr.substack.com/) \|  [Discord](https://discord.ankr.com/)
              \| [YouTube](https://www.youtube.com/c/AnkrOfficial) \| [LinkedIn](https://www.linkedin.com/company/ankr/)
              \| [Reddit](https://www.reddit.com/r/Ankrofficial/) \| [All Links](https://id.tomo.inc/x@ankr)


              [Return to blog](https://www.ankr.com/blog/)


              # Similar articles.


              [![Destra Chooses Asphere RaaS to Build DePIN-Focused Rollup](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/destra_e9dfad191c.jpg)\\

              \\

              **Destra Chooses Asphere RaaS to Build DePIN-Focused Rollup** \\

              \\

              ![Kevin Dwyer](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/xt_2a97c402c4.png)\\

              \\

              Kevin Dwyer\\

              \\

              August 1, 2024\\

              \\

              ![destra.jpg](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/destra_e9dfad191c.jpg)\\

              \\

              Ankr and Asphere have joined hands with Destra Network to build the
              testnet and mainnet for the Arbitrum Orbit-based Destra Network rollup,
              accelerating the protocol''s...](https://www.ankr.com/blog/destra-chooses-asphere-raa-s-to-build-de-pin-focused-rollup/)[![Asphere
              Chosen to Develop Heurist Chain: A Blockchain Powerhouse for the AI
              Cloud](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Medium_Post_12_03_2_2x_485b967fc9.jpg)\\

              \\

              **Asphere Chosen to Develop Heurist Chain: A Blockchain Powerhouse for
              the AI Cloud** \\

              \\

              ![Kevin Dwyer](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/xt_2a97c402c4.png)\\

              \\

              Kevin Dwyer\\

              \\

              August 4, 2025\\

              \\

              ![Medium_Post_12.03_2@2x.jpg](https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Medium_Post_12_03_2_2x_485b967fc9.jpg)\\

              \\

              We’re excited to announce that Asphere, the enterprise services arm
              of Ankr, has teamed up with  to bring a bold new blockchain to life:...](https://www.ankr.com/blog/asphere-chosen-to-develop-heurist-chain-a-blockchain-powerhouse-for-the-ai-cloud/)'
            metadata:
              twitter:image: https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Medium_Post_19_08_2_1_d85f9f35e6.jpg
              theme-color: '#356DF3'
              ogTitle: 'Building the Future of Quantum-Secure Web3: Asphere Partners
                with QuStream'
              msapplication-TileColor: '#006dff'
              og:type: website
              twitter:card: summary_large_image
              ogDescription: 'Building the Future of Quantum-Secure Web3: Asphere
                Partners with QuStream'
              favicon: https://www.ankr.com/static/favicon/favicon-32x32.png
              ogLocale: en_US
              og:url: https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/
              og:image: https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Medium_Post_19_08_2_1_d85f9f35e6.jpg
              twitter:site: '@ankr'
              version: www-ankr-com-1.20.33a
              title: 'Building the Future of Quantum-Secure Web3: Asphere Partners
                with QuStream'
              ogSiteName: Ankr
              ogUrl: https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/
              description: Learn more about QuStream, Asphere's latest RaaS client,
                and how we're helping them build the network that will bring quantum
                security to blockchain.
              og:site_name: Ankr
              ogImage: https://s3-frontend-strapi.s3.us-west-1.amazonaws.com/Medium_Post_19_08_2_1_d85f9f35e6.jpg
              og:locale: en_US
              robots: index, follow
              og:title: 'Building the Future of Quantum-Secure Web3: Asphere Partners
                with QuStream'
              language: en
              og:description: 'Building the Future of Quantum-Secure Web3: Asphere
                Partners with QuStream'
              twitter:url: https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/
              twitter:title: 'Building the Future of Quantum-Secure Web3: Asphere
                Partners with QuStream'
              twitter:description: 'Building the Future of Quantum-Secure Web3: Asphere
                Partners with QuStream'
              viewport:
              - width=device-width
              - width=device-width, minimum-scale=1, initial-scale=1, shrink-to-fit=no,
                user-scalable=no
              scrapeId: 6acb70f0-41b5-40f8-b52e-48a78fa29657
              sourceURL: https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/
              url: https://www.ankr.com/blog/building-the-future-of-quantum-secure-web3-asphere-partners-with-qu-stream/
              statusCode: 200
              contentType: text/html
              proxyUsed: basic
              cacheState: miss
          - title: 'Autonomys: The Foundation Layer for AI3.0'
            description: Our network provides the infrastructure to scale decentralized
              AI3.0 applications on-chain—hyper-scalable permanent data storage, super
              fast data availability ...
            url: https://www.autonomys.xyz/
            markdown: '## This website uses cookies


              By clicking **"Accept"**, you agree to the storing of cookies on your
              device to enhance site navigation, analyze site usage, and assist in
              our marketing efforts. View our [Privacy Policy](https://www.autonomys.xyz/privacy-policy)
              for more information.


              [Accept](https://www.autonomys.xyz/#) [Reject All](https://www.autonomys.xyz/#)
              [Preferences](https://www.autonomys.xyz/#)


              Preferences


              [Confirm](https://www.autonomys.xyz/#) [Reject All](https://www.autonomys.xyz/#)


              **Manage Consent Preferences by Category**


              Essentials


              **Always active**


              Necessary for the site to function. Always On.


              Marketing


              Marketing


              Used for targeted advertising.


              Personalization


              Personalization


              Remembers your preferences and provides enhanced features.


              Analytics


              Analytics


              Measures usage and improves your experience.


              Marketing


              Marketing


              Used for targeted advertising.


              Personalization


              Personalization


              Remembers your preferences and provides enhanced features.


              Analytics


              Analytics


              Measures usage and improves your experience.


              Marketing


              Marketing


              Used for targeted advertising.


              Personalization


              Personalization


              Remembers your preferences and provides enhanced features.


              Analytics


              Analytics


              Measures usage and improves your experience.


              [Reject All](https://www.autonomys.xyz/#) [Accept All](https://www.autonomys.xyz/#)


              Thank you! Your submission has been received!


              Oops! Something went wrong while submitting the form.


              [Mainnet Phase-2 Launched](https://medium.com/subspace-network/the-phases-of-mainnet-3a08d7aa7178)
              // [Messari Q1 2025 Report](https://messari.io/report/state-of-autonomys-network-q1-2025)
              // [1-Pager Release](https://gateway.autonomys.xyz/file/bafkr6ie2hgiwiaimkyt4q6t3wkmigxlqgslu4nqlxb3xuie3ewm7c2uzze)


              [✖](https://www.autonomys.xyz/#)


              # The Foundation Layer for AI3.0


              [Start Farming](https://docs.autonomys.xyz/docs/farming-&-staking/farming/space-acres/space-acres-install)
              [Discover Your Role](https://www.autonomys.xyz/network-operators)


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e34c1fe4156c8cf0beb345_provides_bg.png)


              ## Our network provides the infrastructure to scale decentralized AI3.0
              applications on-chain—hyper-scalable permanent data storage, super fast
              data availability & flexible EVM-compatible decoupled execution.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e3708cdc3090c3bd68_partner-1.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e3f110209a997a6803_partner-2.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e2f0fee401bab54378_partner-3.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e36ce9e2e09a00ce83_partner-4.png)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e333b1e63df1c143c7_partner-5.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e3c2798e5016acb131_partner-6.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e3708cdc3090c3bd68_partner-1.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e3f110209a997a6803_partner-2.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e2f0fee401bab54378_partner-3.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e36ce9e2e09a00ce83_partner-4.png)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e333b1e63df1c143c7_partner-5.webp)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e203e3c2798e5016acb131_partner-6.webp)


              ## Autonomys Network


              Our AI3.0 ecosystem stack is designed to provide all the necessary components
              to build and deploy AI-powered dApps (super dApps) and agents, and includes:


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fc1f8bb1ced14ad5ddde36_autonomys-1.svg)


              ### Permanent Storage


              Our distributed storage network (DSN) ensures data integrity and permanent
              availability—crucial for storing vast amounts of AI data.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fc1f96eaae93067a883e85_autonomys-2.svg)


              ### Decoupled Execution


              Our customizable DecEx environments (domains) for secure, scalable smart
              contract, super dApp and agent deployment on Substrate or any-VM.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fc1fa3fc5d59158999072a_autonomys-3.svg)


              ### PoAS Consensus


              Our unique Proof-of-Archival-Storage (PoAS) consensus chain for decentralized
              sequencing, and transaction validation and settlement.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e34c20cd70d42190876fd9_powered_bg.webp)


              # AI3.0


              Open, accessible and collaborative web3-enabled AI model, app and agent
              development and deployment.


              AI1.0


              ## Centralized   Machine Learning


              Deep learning becomes widespread as developers are able to build models
              with the likes of TensorFlow and PyTorch running on cloud computing
              provided by Big Tech. Humans are primarily passive consumers of AI technologies,
              interacting with narrow, rule-based systems designed for specific tasks.


              AI2.0


              ## Centralized   Generative AI


              Large language models (LLMs), such as ChatGPT, Gemini and Claude, emerge
              alongside other Generative AI technologies built by Big Tech. Humans
              are offered more interactive AI experiences, albeit still through platforms
              controlled and deployed by centralized entities.


              AI3.0


              ## Decentralized   Human-centric AI


              Open, accessible and collaborative web3-enabled AI model, app and agent
              development and deployment. Decentralization ensures a transparent,
              composable and secure ecosystem where innovation thrives. Humans not
              only interact with AI, but customize, train and deploy their own highly
              personalized Autonomys agents to act on their behalf, blurring the boundary
              between AI creator and consumer. The Age of Autonomy is the culmination
              of this paradigm.


              ## Subspace Protocol


              Our novel Proof-of-Archival-Storage (PoAS) consensus mechanism maintains
              the honest majority assumption and permissionless nature of Nakamoto
              consensus without the massive electricity cost of mining.


              [Learn More](https://www.autonomys.xyz/solution) [Documentation](https://academy.autonomys.xyz/subspace-protocol/introduction)


              Autonomys — Under the Hood \| The Architecture of the Foundation Layer
              for AI3.0 - YouTube


              [Photo image of Autonomys Network](https://www.youtube.com/channel/UCojYRCZOtVTJHJXivOYJzeQ?embeds_widget_referrer=https%3A%2F%2Fwww.autonomys.xyz%2F&embeds_referring_euri=https%3A%2F%2Fcdn.embedly.com%2F&embeds_referring_origin=https%3A%2F%2Fcdn.embedly.com)


              Autonomys Network


              1.81K subscribers


              [Autonomys — Under the Hood \| The Architecture of the Foundation Layer
              for AI3.0](https://www.youtube.com/watch?v=9jTBihUeq70)


              Autonomys Network


              Search


              Watch later


              Share


              Copy link


              Info


              Shopping


              Tap to unmute


              If playback doesn''t begin shortly, try restarting your device.


              More videos


              ## More videos


              You''re signed out


              Videos you watch may be added to the TV''s watch history and influence
              TV recommendations. To avoid this, cancel and sign in to YouTube on
              your computer.


              CancelConfirm


              Share


              Include playlist


              An error occurred while retrieving sharing information. Please try again
              later.


              [Watch on](https://www.youtube.com/watch?v=9jTBihUeq70&embeds_widget_referrer=https%3A%2F%2Fwww.autonomys.xyz%2F&embeds_referring_euri=https%3A%2F%2Fcdn.embedly.com%2F&embeds_referring_origin=https%3A%2F%2Fcdn.embedly.com)


              0:00


              0:00 / 3:56

              •Live


              •


              ## Network Stack


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4807d9df5cd830c16a740_Arrow%202.svg)


              We have built the Autonomys Network from first principles to simultaneously
              achieve scalability, security and decentralization. At its core, the
              Autonomys Network implements Subspace, a novel storage-based consensus
              protocol that separates consensus from execution. This proposer-builder
              separation allows the Autonomys Network to independently scale transaction
              throughput and storage requirements while maintaining a fully decentralized
              blockchain.


              ### dApps


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841f614029d11c358059_dApps.png)


              Develop, deploy and interact with AI-powered decentralized applications
              (super dApps) and verifiable Auto ID-integrated on-chain agents (Autonomys
              agents). Utilize Autonomys Identity (Auto ID), our custom, self-sovereign
              identity domain for humans and AI.


              - Auto ID


              - On-chain agents


              - DAOs


              - Compute market



              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841f614029d11c358059_dApps.png)


              ### Domains (Execution)


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841f8c8950ee39c9db88_domains.png)


              Access a limitless number of independent configurable execution environments
              for scalable computation, decentralized AI training and inference, and
              secure agentic workflows, all via distributed compute. Domains separate
              smart contract calls and transaction execution from consensus, allowing
              for modular application-specific blockchains (app-chains) interoperable
              through our unique cross-domain communication protocol.


              - Optimistic execution


              - Low gas fees


              - Independent runtimes (EVM, WASM, etc.), state & history


              - Unlimited storage


              - Highest performance



              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841f8c8950ee39c9db88_domains.png)


              ### Consensus


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841f30cf03bc86d0c090_consensus.png)


              Harness shared security with verifiably decentralized sequencing, transaction
              validation and settlement via our Proof-of-Archival-Storage (PoAS) chain,
              and ensure a single, immutable source of truth for blockchain state
              and history across all nodes participating in the network.


              - Decentralized sequencing


              - Shared Security


              - Minimal state



              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841f30cf03bc86d0c090_consensus.png)


              ### Storage


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841fa90a02fb206ba263_storage.png)


              Ensure permanent data availability and integrity—crucial for storing
              vast amounts of AI data—with our distributed storage network (DSN) of
              farmers. Our DSN also stores all chain data, so the entire history is
              always retrievable, no matter how large it grows.


              - Permanent data availability and integrity


              - Recent history cache for fast retrieval



              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/67f4841fa90a02fb206ba263_storage.png)


              ## dApps


              Develop, deploy and interact with AI-powered decentralized applications
              (super dApps) and verifiable Auto ID-integrated on-chain agents (Autonomys
              agents). Utilize Autonomys Identity (Auto ID), our custom, self-sovereign
              identity domain for humans and AI.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1478a6a92b9c5b3f37708_network-1.svg)


              Auto ID


              On-chain agents


              DAOs


              Compute market


              ## Domains (Execution)


              Access a limitless number of independent configurable execution environments
              for scalable computation, decentralized AI training and inference, and
              secure agentic workflows, all via distributed compute. Domains separate
              smart contract calls and transaction execution from consensus, allowing
              for modular application-specific blockchains (app-chains) interoperable
              through our unique cross-domain communication protocol.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1477d68883ae2b68c1f45_network-2.svg)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1478a6a92b9c5b3f37708_network-1.svg)


              Optimistic execution


              Independent runtimes (EVM, WASM, etc.), state & history


              Highest performance


              Low gas fees


              Unlimited storage


              ## Consensus


              Harness shared security with verifiably decentralized sequencing, transaction
              validation and settlement via our Proof-of-Archival-Storage (PoAS) chain,
              and ensure a single, immutable source of truth for blockchain state
              and history across all nodes participating in the network.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f14774d1b46ea8a8cef7dd_network-3.svg)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1477d68883ae2b68c1f45_network-2.svg)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1478a6a92b9c5b3f37708_network-1.svg)


              Decentralized sequencing


              Shared Security


              Minimal state


              ## Storage


              Ensure permanent data availability and integrity—crucial for storing
              vast amounts of AI data—with our distributed storage network (DSN) of
              farmers. Our DSN also stores all chain data, so the entire history is
              always retrievable, no matter how large it grows.


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f14761ad89cba0836104cb_network-4.svg)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f14774d1b46ea8a8cef7dd_network-3.svg)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1477d68883ae2b68c1f45_network-2.svg)![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1478a6a92b9c5b3f37708_network-1.svg)


              Permanent data availability and integrity


              Recent history cache for fast retrieval


              # A Novel Inclusive Consensus


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f14874c362ed550f9ecb8a_icon-user.svg)


              ## 2k+


              Farmer Nodes


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f1488eea7be80b58295403_icon-network.svg)


              ## 600PB+


              SSD Storage Pledged


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f14897d3049f941b21bc8e_icon-upload-box.svg)


              ## >20


              GBPS


              Data Throughput


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f148a7da31b8e9e0d6b8f7_icon-lightning.svg)


              ## 100k+ $AI3 Wallets


              # A Novel Inclusive Consensus


              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/682d5553718ea2079a23ee25_globe.png)


              1


              Uniquely Capable


              Consensus Design


              1000+


              Globally Distributed


              Nodes


              500PB+


              Decentralized


              Storage Capacity


              [Explore](https://www.autonomys.xyz/solution)


              [Explore](https://www.autonomys.xyz/space-acres)


              [Explore](https://astral.autonomys.xyz/mainnet/consensus)


              # Auto Suite


              Farm


              ## Space Acres


              Multi-platform desktop application that simplifies setting up and managing
              a blockchain node and farming operation on the Autonomys Network.


              [Get Started](https://www.autonomys.xyz/space-acres)


              Stake


              ## Explorer


              Web application for interacting with the Autonomys Network, and block
              explorer for the consensus chain. Register operators, stake and nominate.


              [Get Started](https://autonomys.subscan.io/)


              Build


              ## Auto SDK


              Software development kit for AI and web3 developers that simplifies
              interacting with the Autonomys Network for those without a deep understanding
              of blockchains or smart contracts.


              [Get Started](https://www.autonomys.xyz/sdk)


              ## Powered by Autonomys


              Building on the Autonomys Network will help you unlock unparalleled
              performance, security and scalability.


              [List Project](https://www.autonomys.xyz/#) [Explore Ecosystem](https://www.autonomys.xyz/ecosystem)


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ba50cc35740f00288fc001_xt.png)


              ### XT


              Exchanges


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ba5065910b5e2ac1c2b157_Bitmart.svg)


              ### BitMart


              Exchanges


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ba4ffb9e74c6b09be2a985_MEXC.svg)


              ### MEXC


              Exchanges


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ba4f4bb2df81a4d95afd3c_logo%201.svg)


              ### KuCoin


              Exchanges


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ba4d6f59f56c4a66d7f32c_kraken.svg)


              ### Kraken


              Exchanges


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689cace7a4316433cc0ad37a_2D%20Style.png)


              ### Fireverse


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0f02867c0281244c7724_spoon-os-logo.png)


              ### SpoonOS


              Agents


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0ec35caabf8b48459333_Heurist.svg)


              ### Heurist


              Agents


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0e3d8b496e7687814343_Baselight_Emblem.png)


              ### Baselight


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0dd79a3eb9a94349712b_pai3-logo.6746f518.png)


              ### PAI3


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0d31fdaea4fa1e43abf3_ll%201.png)


              ### Beacon


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0c541bc78f1de56fb9fe_JiTYWpDFM00cdlMPd1ODmjC47B8.svg)


              ### DPSN


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/689c0b8cf185f503ef72467d_nexus_logo-only.svg)


              ### Nexus


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/682f114c4dba73f40298c832_Asset%205_2x.avif)


              ### DAIAA


              Community


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/681780bf97d1a7046e6a325c_The%20Graph.svg)


              ### The Graph


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68178068c45bf10a3f0c4e29_STP.svg)


              ### STP


              Agents


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/681580181810272f8a77a6d4_ROME.svg)


              ### Rome Protocol


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/67ef9fcc7b7ec20bd895ec7e_KU-Blockchain-logo.svg)


              ### KUBI


              Community


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/67ef9f58c8592506446c5a23_unnamed.png)


              ### Talisman


              AI


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/67c86b87671a7b5997cad8a6_gyhYEOCE_400x400.jpg)


              ### Safe


              Wallet


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/67c86b10509225cdeaa14d5b_pwDzhdNc_400x400.jpg)


              ### Phala


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6797ac0b1293cd5490101600_kGuSKgxj_400x400.jpg)


              ### Morphic


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6797aaf62751d213633b27c2_multiple_network_logo.jpeg)


              ### Multiple Network


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6781451fef14fcfb8e22634e_rR71okKY_400x400.jpg)


              ### DIN


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/677f3c3ec1710e6acd4cadcf_rivalz.svg)


              ### Rivalz


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/67699605653849839aa09588_scrt.svg)


              ### Secret Network


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/676184d7f36a8cf0d1d26e5e_qSA6jSgS_400x400.jpg)


              ### SEA DePIN


              Community


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6759ae3abc5d480110540582_FoxWallet-app-green-ea216a4e4ada916e00b3a4eedcd4144f.png)


              ### FoxWallet


              Wallet


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/675333f7816c5425f3520ff9_logo_badge_color.png)


              ### Fluence


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/673fb3b32bb4877b195dceb0_halborn.png)


              ### Halborn


              Security


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/673f8d7391c2e6617171d070_vWYn675P_400x400.jpg)


              ### Glacier Network


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726ec5f824130b80ea3af96_subscan_upscayl_16x_realesrgan-x4plus.png)


              ### Subscan


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726ebd8363df89b80be4628_6367f7e794885417fa3fb5ff_logo-mob%201.svg)


              ### Security Research Labs


              Security


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726eb857cab3af512aa0501_66d9e610dc44b32ca8a6f4cb_Full%20Dark%20Logo%201.svg)


              ### Tokensoft


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726eaba466a6a373e0fa84e_SUPRANATIONAL%2BLOGO_STACKED_WHITE%201.png)


              ### Supranational


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726ea7a8c4911607fef9c65_block%20science.svg)


              ### BlockScience


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726ea38a74f2475a7a18f42_Frame.svg)


              ### Edgeware


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726ea138c4911607fef7759_1701819587-logo%201.svg)


              ### Alchemy


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6726e78aab78afdf10018778_subwallet%201.svg)


              ### SubWallet


              Wallet


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6725999b91c04d291acde244_Protofire.svg)


              ### Protofire


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6725992b25ff4e4cd584d337_66d80e450df574aee515b802_Logo%201.svg)


              ### Impossible Cloud Network (ICN)


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/672598a12e9027f97c051ddf_6712cfe3f045700b98ad8216_native-logo%201.svg)


              ### Native


              DeFi


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/672598359b5ca75c00247161_compute_labs.png)


              ### Compute Labs


              DeFi


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/672597afd7f0f0e60ff5bb1d_white_logo.56effa5f.svg)


              ### Masa


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/672596d2ce390b4e836de7af_image.avif)


              ### Swan Chain


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/67259747a631d3ed09914c46_neuromesh.svg)


              ### NeuroMesh


              AI > Training


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671172204085356076ac5533_ecosystem-8.png)


              ### PublicAI


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671170bb14e8c689400ea8bc_ecosystem-2.svg)


              ### Hemera Protocol


              AI > Agents


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6711721784433cabd2f23f3b_ecosystem-7.png)


              ### ZkAGI


              DePIN


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/6711720cf20bb9b41711d1be_ecosystem-6.png)


              ### SubQuery


              Infrastructure


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671170b2705e47a0ac6298e9_ecosystem-1.svg)


              ### Ringfence


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671170a36f73b5ea0b21d7a8_ecosystem-3.svg)


              ### Vana


              Data


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671172028894be0640312244_ecosystem-5.png)


              ### GenLayer


              AI > Agents


              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671171f1df21cb421aae6c9f_ecosystem-4.png)


              ### EMC Protocol


              DePIN


              # News


              [**August 2025 \| Community Report** \\

              \\

              ![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/671b64e0f7feca626279dea7_image%205.png)\\

              \\

              BY\\

              \\

              AUTONOMYS\\

              \\

              September 11, 2025](https://www.autonomys.xyz/post/august-2025-community-report)


              # News


              [See All\\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e4541962aa3046153517ac_send-arrow.webp)](https://www.autonomys.xyz/blog)


              [![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68af1e4da5ca468b1b8b04a0_1_xMTO95MhPmhtMziuKsidTw.webp)\\

              **$AI3 IS NOW LIVE ON: Kraken, KuCoin, MEXC, BitMart, & XT** \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              BY\\

              \\

              AUTONOMYS\\

              \\

              August 27, 2025](https://www.autonomys.xyz/post/ai3-is-now-live-on-kraken-kucoin-mexc-bitmart-xt)


              [![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ae7b44b2f5c636e3e72428_0_lzXxg5ZXZgL7208I.webp)\\

              **$AI3 is Going Global: Listing August 27th on Kraken, KuCoin & MEXC**
              \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              BY\\

              \\

              AUTONOMYS\\

              \\

              August 26, 2025](https://www.autonomys.xyz/post/ai3-is-going-global-listing-august-27th-on-kraken-kucoin-mexc)


              [![](https://cdn.prod.website-files.com/67116c06faa0301e125b2d48/68ae7af2edc3b37cce54c437_1_fAko58VYCwZanSU3U234Dg.webp)\\

              **Boosting Early Staking: The Guardians of Growth Initiative** \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              BY\\

              \\

              AUTONOMYS\\

              \\

              August 26, 2025](https://www.autonomys.xyz/post/boosting-early-staking-the-guardians-of-growth-initiative)


              # News


              [**The Phases of Mainnet** \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              By Autonomys\\

              \\

              Sep 6, 2024](https://medium.com/subspace-network/the-phases-of-mainnet-3a08d7aa7178)


              # News


              [See All\\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e4541962aa3046153517ac_send-arrow.webp)](https://medium.com/@autonomysnetwork)


              [![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fa6b3af2d647de071005eb_0_um3xiOi-ZNSVf3Bc.webp)\\

              **What is Radical Autonomy? \| Empowering H+AI in the Age of Autonomy**
              \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              By Autonomys\\

              \\

              Jul 6, 2024](https://medium.com/subspace-network/what-is-radical-autonomy-empowering-h-ai-in-the-age-of-autonomy-b45e7ab59c8e)
              [![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fa6b885dbb233d0ae28b27_0_l9mQCEDueqR6-OTM.webp)\\

              **Autonomys x ZkAGI: Consolidating DePIN for Fair, Private AI** \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              By Autonomys\\

              \\

              Sep 28, 2024](https://medium.com/subspace-network/autonomys-x-zkagi-consolidating-depin-for-fair-private-ai-c5d10d14fe47)
              [![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fa6bbbb22a4506a5418233_0_DtGS0UGlW3X9EUmf.webp)\\

              **Autonomys x GenLayer: Decentralizing Infrastructure for Data and Internet
              Access** \\

              \\

              ![](https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66e454188f9c0177311348a7_logo-small.webp)\\

              \\

              By Autonomys\\

              \\

              Sep 25, 2024](https://medium.com/subspace-network/autonomys-x-genlayer-decentralizing-infrastructure-for-data-and-internet-access-0acb20525b21)


              ✖


              ## List Project


              Project Category


              Project CategoryInfrastructureDataComputePrivacyIdentityWalletOther


              Thank you! Your submission has been received!


              Oops! Something went wrong while submitting the form.'
            metadata:
              language: en
              viewport:
              - width=device-width, initial-scale=1
              - width=device-width, initial-scale=1
              ogTitle: 'Autonomys: The Foundation Layer for AI3.0'
              title: 'Autonomys: The Foundation Layer for AI3.0'
              twitter:title: 'Autonomys: The Foundation Layer for AI3.0'
              twitter:description: Infrastructure to scale decentralized AI 3.0 applications
                on-chain—hyper-scalable permanent data storage, super fast data availability
                & flexible EVM-compatible decoupled execution.
              favicon: https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66fc0b8219b158cb4719704e_32.png
              twitter:image: https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f29e3a1d2982db50479b07_Screenshot%202024-09-24%20at%201.08.23%E2%80%AFPM.png
              ogDescription: Infrastructure to scale decentralized AI 3.0 applications
                on-chain—hyper-scalable permanent data storage, super fast data availability
                & flexible EVM-compatible decoupled execution.
              description: Infrastructure to scale decentralized AI 3.0 applications
                on-chain—hyper-scalable permanent data storage, super fast data availability
                & flexible EVM-compatible decoupled execution.
              og:type: website
              generator: Webflow
              og:title: 'Autonomys: The Foundation Layer for AI3.0'
              ogImage: https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f29e3a1d2982db50479b07_Screenshot%202024-09-24%20at%201.08.23%E2%80%AFPM.png
              og:description: Infrastructure to scale decentralized AI 3.0 applications
                on-chain—hyper-scalable permanent data storage, super fast data availability
                & flexible EVM-compatible decoupled execution.
              og:image: https://cdn.prod.website-files.com/66d7181179fbc331d39e9df0/66f29e3a1d2982db50479b07_Screenshot%202024-09-24%20at%201.08.23%E2%80%AFPM.png
              twitter:card: summary_large_image
              scrapeId: ac6e7d84-9dd2-424a-9295-43dc9faeedf6
              sourceURL: https://www.autonomys.xyz/
              url: https://www.autonomys.xyz/
              statusCode: 200
              contentType: text/html
              proxyUsed: basic
              cacheState: miss
          - title: How to buy Heurist AI (HEU) in St Kitts & Nevis - Bitget
            description: The best place to buy Heurist AI is the exchange that provides
              hassle-free and secure transactions combined with a convenient interface
              and high liquidity.
            url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis
            markdown: 'Bitget App


              Trade smarter


              Open


              [![bitget logo](<Base64-Image-Removed>)](https://www.bitget.com/en-CA/)


              Buy crypto [Markets](https://www.bitget.com/en-CA/markets) TradeFuturesEarn
              [Web3](https://web3.bitget.com/source=bitget) SquareMore [![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/8ca573730343a8869f2cd66987081bf7.png)![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/9deb7e2d280fbeabfa0dc740114661db.png)](https://www.bitget.com/en-CA/events/elite-list/detail/232302)
              [![7th Anniversary](https://img.bgstatic.com/multiLang/web/d0111278d24794866903aca5214b18ff.png)![7th
              Anniversary](https://img.bgstatic.com/multiLang/web/08ef5b64fce043d51c46fa0ee5b2df43.png)](https://www.bitget.com/en-CA/events/competitionNew/440806028d3e543eafc70821cb9b13de)


              Pay with ![USD](https://img.bgstatic.com/fiat-country/USD.svg)USD


              [Buy & Sell\\

              \\

              Buy and sell crypto instantly](https://www.bitget.com/en-CA/buy-sell-crypto)
              [Credit / Debit card\\

              \\

              Buy crypto via VISA or Mastercard](https://www.bitget.com/en-CA/buy-sell-crypto)
              [Recurring Buy\\

              \\

              Buy crypto automatically at regular intervals](https://www.bitget.com/en-CA/buy-sell-crypto/recurring-buy)
              [P2P trading\\

              \\

              Buy crypto from verified merchants](https://www.bitget.com/en-CA/p2p-trade)
              [Bitget Card\\

              \\

              Spend globally with your card](https://www.bitget.com/en-CA/cards/landing)


              In the last 24 hours, the [GMCI30](https://www.bitget.com/en-CA/futures/usdt/GMCI30USDT)
              index is up by ![up](https://www.bitget.com/micro-runtime/assets/icon-caret-up.456c0c2b.svg)

              0.73%

              .


              No data


              Trade


              [Spot\\

              \\

              Buy and sell crypto with ease](https://www.bitget.com/en-CA/spot/BTCUSDT)
              [Margin\\

              \\

              Amplify your capital and maximize fund efficiency](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Onchain\\

              \\

              Going Onchain, without going Onchain!](https://www.bitget.com/en-CA/on-chain/)
              [Convert & block trade\\

              \\

              Convert crypto with one click and zero fees](https://www.bitget.com/en-CA/convert)


              Explore


              Launchhub


              Gain the edge early and start winning


              Copy


              Copy elite trader with one click


              Bots


              Simple, fast, and reliable AI trading bot


              Trade


              [USDT-M Futures\\

              \\

              Futures settled in USDT](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [USDC-M Futures\\

              \\

              Futures settled in USDC](https://www.bitget.com/en-CA/futures/usdc/BTCPERP)
              [Coin-M Futures\\

              \\

              Futures settled in cryptocurrencies](https://www.bitget.com/en-CA/futures/usd/BTCUSD)


              Explore


              Futures guide


              A beginner-to-advanced journey in futures trading


              Futures promotions


              Generous rewards await


              [Stock Futures\\

              \\

              Diversified Issuers. Unified in USDT.](https://www.bitget.com/en-CA/promotion/futures-rwa)


              [Overview\\

              \\

              A variety of products to grow your assets](https://www.bitget.com/en-CA/earning)
              [Simple Earn\\

              \\

              Deposit and withdraw anytime to earn flexible returns with zero risk](https://www.bitget.com/en-CA/earning/savings?source1=earn&source2=savings)


              On-chain Earn


              Earn profits daily without risking principal


              Structured Earn


              Robust financial innovation to navigate market swings


              VIP and Wealth Management


              Premium services for smart wealth management


              Loans


              Flexible borrowing with high fund security


              No data


              [Insights\\

              \\

              Insights from experts](https://www.bitget.com/en-CA/insights) [News\\

              \\

              Latest media articles](https://www.bitget.com/en-CA/news) [Bitget Academy\\

              \\

              Learn about crypto and the blockchain](https://www.bitget.com/en-CA/academy)
              [Bitget Blog\\

              \\

              In-depth analysis, trading bots, and industry trends](https://www.bitget.com/en-CA/blog)
              [Bitget Research\\

              \\

              Everything you need to know about the blockchain world](https://www.bitget.com/en-CA/research)


              Learn and explore


              [Help Center](https://www.bitget.com/en-CA/support) [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Rewards](https://www.bitget.com/en-CA/events/rewards) [Referral](https://www.bitget.com/en-CA/events/referral-all-program)
              [Submit feedback](https://www.bitget.com/en-CA/feedback)


              Institution


              [Institutional](https://www.bitget.com/en-CA/vip-institutional-services)
              [PRO program](https://www.bitget.com/en-CA/vip-institutional-services/pro)
              [VIP program](https://www.bitget.com/en-CA/vip/vipIntroduce) [Broker
              program](https://www.bitget.com/en-CA/broker) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)


              Programs


              [Affiliates](https://www.bitget.com/en-CA/affiliates) [Booster Platform](https://www.bitget.com/en-CA/events/kol-promotion)
              [Bitget Builders](https://www.bitget.com/en-CA/incubation-program) [Asset
              custody](https://www.bitget.com/en-CA/custody) [Tax API](https://www.bitget.com/en-CA/taxes-api)
              [GetAgent Member](https://www.bitget.com/en-CA/events/ai-get-agent/upgrade)


              No data


              No data


              [Log in](https://www.bitget.com/en-CA/login)


              [Log in](https://www.bitget.com/en-CA/login)


              [Sign up](https://www.bitget.com/en-CA/register)


              [Sign up](https://www.bitget.com/en-CA/register)


              Buy crypto [Markets](https://www.bitget.com/en-CA/markets) TradeFuturesEarn
              [Web3](https://web3.bitget.com/source=bitget) SquareMore [![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/8ca573730343a8869f2cd66987081bf7.png)![Futures
              Leaderboard](https://img.bgstatic.com/multiLang/web/9deb7e2d280fbeabfa0dc740114661db.png)](https://www.bitget.com/en-CA/events/elite-list/detail/232302)
              [![7th Anniversary](https://img.bgstatic.com/multiLang/web/d0111278d24794866903aca5214b18ff.png)![7th
              Anniversary](https://img.bgstatic.com/multiLang/web/08ef5b64fce043d51c46fa0ee5b2df43.png)](https://www.bitget.com/en-CA/events/competitionNew/440806028d3e543eafc70821cb9b13de)


              Pay with ![CNY](https://img.bgstatic.com/fiat-country/USD.svg)CNY


              No data


              No data


              Trade


              [Spot\\

              \\

              Buy and sell crypto with ease](https://www.bitget.com/en-CA/spot/BTCUSDT)
              [Margin\\

              \\

              Amplify your capital and maximize fund efficiency](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Onchain\\

              \\

              Going Onchain, without going Onchain!](https://www.bitget.com/en-CA/on-chain/)
              [Convert & block trade\\

              \\

              Convert crypto with one click and zero fees](https://www.bitget.com/en-CA/convert)


              Explore


              Launchhub


              Gain the edge early and start winning


              Copy


              Copy elite trader with one click


              Bots


              Simple, fast, and reliable AI trading bot


              Trade


              [USDT-M Futures\\

              \\

              Futures settled in USDT](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [USDC-M Futures\\

              \\

              Futures settled in USDC](https://www.bitget.com/en-CA/futures/usdc/BTCPERP)
              [Coin-M Futures\\

              \\

              Futures settled in cryptocurrencies](https://www.bitget.com/en-CA/futures/usd/BTCUSD)


              Explore


              Futures guide


              A beginner-to-advanced journey in futures trading


              Futures promotions


              Generous rewards await


              [Stock Futures\\

              \\

              Diversified Issuers. Unified in USDT.](https://www.bitget.com/en-CA/promotion/futures-rwa)


              [Overview\\

              \\

              A variety of products to grow your assets](https://www.bitget.com/en-CA/earning)
              [Simple Earn\\

              \\

              Deposit and withdraw anytime to earn flexible returns with zero risk](https://www.bitget.com/en-CA/earning/savings?source1=earn&source2=savings)


              On-chain Earn


              Earn profits daily without risking principal


              Structured Earn


              Robust financial innovation to navigate market swings


              VIP and Wealth Management


              Premium services for smart wealth management


              Loans


              Flexible borrowing with high fund security


              No data


              [Insights\\

              \\

              Insights from experts](https://www.bitget.com/en-CA/insights) [News\\

              \\

              Latest media articles](https://www.bitget.com/en-CA/news) [Bitget Academy\\

              \\

              Learn about crypto and the blockchain](https://www.bitget.com/en-CA/academy)
              [Bitget Blog\\

              \\

              In-depth analysis, trading bots, and industry trends](https://www.bitget.com/en-CA/blog)
              [Bitget Research\\

              \\

              Everything you need to know about the blockchain world](https://www.bitget.com/en-CA/research)


              Learn and explore


              [Help Center](https://www.bitget.com/en-CA/support) [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Rewards](https://www.bitget.com/en-CA/events/rewards) [Referral](https://www.bitget.com/en-CA/events/referral-all-program)
              [Submit feedback](https://www.bitget.com/en-CA/feedback)


              Institution


              [Institutional](https://www.bitget.com/en-CA/vip-institutional-services)
              [PRO program](https://www.bitget.com/en-CA/vip-institutional-services/pro)
              [VIP program](https://www.bitget.com/en-CA/vip/vipIntroduce) [Broker
              program](https://www.bitget.com/en-CA/broker) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)


              Programs


              [Affiliates](https://www.bitget.com/en-CA/affiliates) [Booster Platform](https://www.bitget.com/en-CA/events/kol-promotion)
              [Bitget Builders](https://www.bitget.com/en-CA/incubation-program) [Asset
              custody](https://www.bitget.com/en-CA/custody) [Tax API](https://www.bitget.com/en-CA/taxes-api)
              [GetAgent Member](https://www.bitget.com/en-CA/events/ai-get-agent/upgrade)


              No data


              No data


              [Home](https://www.bitget.com/en-CA/)/


              [How to buy crypto](https://www.bitget.com/en-CA/how-to-buy)/


              [How to buy Heurist AI](https://www.bitget.com/en-CA/how-to-buy/heurist-ai)/


              Buy Heurist AI in St Kitts & Nevis/


              # **How to buy Heurist AI (HEU) in St Kitts & Nevis**


              Updated on:2025/09/16 09:08:49 (UTC+0)


              Sign up now to claim a welcome pack worth 6200 USDT!


              [Sign up now](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              Coin rating


              4.5


              Heurist AI (HEU) price: $0.02000


              [Buy HEU now](https://www.bitget.com/en-CA/buy-sell-crypto??channelCode=SSSS&vipCode=s1pz)


              Bitget is legally accessible in St Kitts & Nevis. You can buy Heurist
              AI in St Kitts & Nevis through Bitget.


              Note: Good things take time. This coin hasn''t been listed yet. Stay
              tuned to our announcements for listing updates. Once it''s available
              on Bitget, you can follow our tutorial to purchase it. The same tutorial
              applies to all listed cryptocurrencies on Bitget.


              ## Simple 3-step guide to buying HEU today in St Kitts & Nevis


              1


              Create your free Bitget account


              Provide your email address and place of residence.


              2


              Select a funding method


              Fund your account using your preferred payment method.


              3


              Complete your Heurist AI purchase


              Buy Heurist AI with as little as $5.


              ### Step 1: Create a free account on the Bitget website or the app


              [Sign up](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)
              or [download the Bitget app](https://www.bitget.com/en-CA/download?channelCode=SSSS&vipCode=s1pz)
              to start your journey on Bitget.


              Please verify your identity to ensure full compliance and enhance your
              Bitget experience.


              You can access the [identity verification page](https://www.bitget.com/en-CA/account/verified),
              select your country, upload your ID documents, and submit your selfie.
              You will receive a notification once your identity has been successfully
              verified.


              ### Step 2: Place an order for Heurist AI using a payment method of
              your choice:


              - #### Buy Heurist AI with a debit/credit card



              For Visa or Mastercard, select [Credit/Debit card](https://www.bitget.com/en-CA/buy-sell-crypto?channelCode=SSSS&vipCode=s1pz),
              then click Add New Card under the "Buy" tab




              ![Complete your payment on Bitget App image 1](https://img.bgstatic.com/image/third/buy_crypto_bitget_app_en-ca.png)Credit/Debit
              in the Buy Crypto tab of the Bitget app




              ![Enter the bank card details to complete your payment on Bitget Website
              image 1](https://img.bgstatic.com/image/third/buy_crypto_en-ca.png)Credit/Debit
              in the Buy Crypto tab of the Bitget website




              Select your preferred fiat currency, enter the amount you wish to spend,
              link your credit card, and then complete your payment with zero fees.




              ![Complete your payment on Bitget App image 2](https://img.bgstatic.com/image/third/complete_your_payment_on_bitget_app_en-ca.png)Add
              a new card to complete your payment on the Bitget app




              ![Enter the bank card details to complete your payment on Bitget Website
              image 2](https://img.bgstatic.com/image/third/payment_bitget_website_en-ca.png)Enter
              your bank card details to complete your payment on the Bitget website






              For Diners Club/Discover card, click Buy Crypto > [\[Third Party\]](https://www.bitget.com/en-CA/buy-sell-crypto/third-party/visa?fiatName=EUR)
              in the top navigation bar to place your Heurist AI order.






              ![player.png](https://www.bitget.com/how-to-buy/_next/static/media/player.7cdb5ddf.png)




              How to buy crypto with credit/debit card


              - #### Buy Heurist AI with Google Pay or Apple Pay





              Converting your Google Pay and Apple Pay balance into Heurist AI is
              easy and secure on Bitget. Simply click Buy Crypto > [\[Third Party\]](https://www.bitget.com/en-CA/buy-sell-crypto/third-party/apple-pay?fiatName=USD)
              in the top navigation bar to place your Heurist AI order.






              ![player.png](https://www.bitget.com/how-to-buy/_next/static/media/player.7cdb5ddf.png)




              How to buy crypto via third-party gateway


              - #### Buy with bank transfer



              We accept various payment methods, including iDeal and SEPA for EUR,
              PIX for BRL, PayID for AUD, UPI for INR, QRIS, DANA, and OVO for IDR,
              SPEI for MXN, and GCash for PHP. These services are facilitated by Alchemy
              Pay, Banxa, Mercuryo, and Simplex payment gateways. Simply select Buy
              Crypto > [\[Third Party\]](https://www.bitget.com/en-CA/buy-sell-crypto/third-party/visa?fiatName=USD)
              in the top navigation bar and select a fiat currency to place your Heurist
              AI order.


              - #### Buy Heurist AI with the fiat balance in your Bitget account



              You can [Deposit fiat funds](https://www.bitget.com/en-CA/fiat/deposit)
              using Advcash, SEPA, Faster Payments, or PIX payment gateways to top
              up your Bitget fiat balance. Then, click Buy Crypto > [\[Cash conversion\]](https://www.bitget.com/en-CA/buy-sell-crypto/cash-conversion)
              in the top navigation bar to place your Heurist AI order.


              - #### P2P trading



              With [Bitget P2P](https://www.bitget.com/en-CA/p2p-trade), you can buy
              crypto using over 100 payment methods, including bank transfers, cash,
              and e-wallets like Payeer, Zelle, Perfect Money, Advcash, and Wise.
              Simply place an order, pay the seller, and receive your crypto. Enjoy
              secure transactions with escrow protection.




              ![player.png](https://www.bitget.com/how-to-buy/_next/static/media/player.7cdb5ddf.png)




              How to buy crypto on Bitget P2P



              ### Step 3: Monitor Heurist AI in your Bitget spot wallet


              If you''ve chosen to purchase Heurist AI on Bitget, your Heurist AI
              will be instantly credited to your Bitget spot account upon payment
              completion. You can click Assets located on the top right corner of
              the page to check your assets. Additionally, you can buy, deposit, convert,
              trade, and withdraw them.


              ![Check your Assets](https://img.bgstatic.com/image/third/check_your_assets_en-ca.png)


              Check your assets


              Note: Want to keep tabs on coin prices? Visit our [Coin prices directory](https://www.bitget.com/en-CA/price)
              or [Heurist AI Price Page](https://www.bitget.com/en-CA/price/heurist-ai)
              and bookmark them to stay updated!


              ## Bitget—where the world trades Heurist AI


              [![Fast and efficient](https://www.bitget.com/how-to-buy/_next/static/media/fast-trades.ac40413c.svg)\\

              Fast and efficient\\

              \\

              Our advanced matching engine ensures a lightning-fast, smooth trading
              experience, making Bitget the go-to platform for speed and reliability.](https://www.bitget.com/en-CA/spot/BTCUSDT)
              [![Top-tier security](https://www.bitget.com/how-to-buy/_next/static/media/simple-trades.515de384.svg)\\

              Top-tier security\\

              \\

              With proof of reserves, a dedicated protection fund, and third-party
              custody mechanisms, Bitget prioritizes the safety of your assets, earning
              the trust of millions globally.](https://www.bitget.com/en-CA/download?openApp=1&channelCode=SSSS&vipCode=s1pz&groupId=230932)
              [![Ultimate trading experience](https://www.bitget.com/how-to-buy/_next/static/media/secure-trades.c998c363.svg)\\

              Ultimate trading experience\\

              \\

              Trade cryptocurrencies seamlessly with Bitget''s deep liquidity, empowering
              you to make confident, stress-free transactions every time.](https://www.bitget.com/en-CA/proof-of-reserves)


              ![24/7 support](https://www.bitget.com/how-to-buy/_next/static/media/transparent-trades.91161a2e.svg)


              24/7 support


              Bitget''s dedicated customer service team is available 24/7 to provide
              fast, professional assistance, ensuring an exceptional user experience.


              ### How to buy Heurist AI for free


              Using real money to buy Heurist AI is not the only way to obtainHeurist
              AI. If you have the time to allocate, you can get Heurist AI for free.


              - Learn how to earn Heurist AI for free through the [Learn2Earn promotion](https://www.bitget.com/en-CA/events/learn-to-earn)


              - Earn free Heurist AI by inviting friends to join Bitget''s [Assist2Earn
              promotion](https://www.bitget.com/en-CA/events/offer)


              - Receive free Heurist AI airdrops by joining [ongoing challenges and
              promotions](https://www.bitget.com/en-CA/support/sections/4413154768537)



              All crypto airdrops and rewards can be converted to Heurist AI through
              Bitget Convert, Bitget Swap, or Spot Trading.


              Note: Want to keep tabs on coin prices? Visit our [Coin prices directory](https://www.bitget.com/en-CA/price)
              or [Heurist AI Price Page](https://www.bitget.com/en-CA/price/heurist-ai)
              and bookmark them to stay updated!


              ### HEU/CNY price calculator


              HEU


              CNY


              [Buy HEU now](https://www.bitget.com/en-CA/register??channelCode=SSSS&vipCode=s1pz)


              ![Heurist AI](https://img.bgstatic.com/multiLang/coinPriceLogo/heurist-ai.png)


              ## Buy Heurist AI


              [HEU](https://www.bitget.com/en-CA/price/heurist-ai)/ USDCurrent price:


              $0.02000


              0.00


              -6.17%24H


              The live Heurist AI price today is $0.02000 USD, with a 24-hour trading
              volume of $475,009.7 USD. We update our HEU to USD price in real-time.
              HEU is -6.17% in the last 24 hours.


              [Buy Heurist AI now](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              ### How to buy Heurist AI for free


              Using real money to buy Heurist AI is not the only way to obtainHeurist
              AI. If you have the time to allocate, you can get Heurist AI for free.


              - Learn how to earn Heurist AI for free through the [Learn2Earn promotion](https://www.bitget.com/en-CA/events/learn-to-earn)


              - Earn free Heurist AI by inviting friends to join Bitget''s [Assist2Earn
              promotion](https://www.bitget.com/en-CA/events/offer)


              - Receive free Heurist AI airdrops by joining [ongoing challenges and
              promotions](https://www.bitget.com/en-CA/support/sections/4413154768537)



              All crypto airdrops and rewards can be converted to Heurist AI through
              Bitget Convert, Bitget Swap, or Spot Trading.


              Show more


              ## Buy other cryptos


              [How to buy Bitcoin![Bitcoin](https://img.bgstatic.com/multiLang/coin_img/2edf1ef8b333c40979976d1a49bc234c.png)](https://www.bitget.com/en-CA/how-to-buy/bitcoin
              "How to buy Bitcoin") [How to buy Ethereum![Ethereum](https://img.bgstatic.com/multiLang/coin_img/f6eba5dbcb1e8ce5ed7b053985f314b1.png)](https://www.bitget.com/en-CA/how-to-buy/ethereum
              "How to buy Ethereum") [How to buy Ripple![Ripple](https://img.bgstatic.com/multiLang/coin_img/39edd8e5c80256300562f68afb1ab525.png)](https://www.bitget.com/en-CA/how-to-buy/ripple
              "How to buy Ripple") [How to buy Dogecoin![Dogecoin](https://img.bgstatic.com/multiLang/coin_img/ae64499c8825452f6262177ee6dd525b.png)](https://www.bitget.com/en-CA/how-to-buy/dogecoin
              "How to buy Dogecoin") [How to buy Solana![Solana](https://img.bgstatic.com/multiLang/coin_img/1c1b05492d876ab7e3fa96ea2036ceb2.png)](https://www.bitget.com/en-CA/how-to-buy/solana
              "How to buy Solana") [How to buy Litecoin![Litecoin](https://img.bgstatic.com/multiLang/coin_img/c17bc60be2ebb5765648fc210530a109.png)](https://www.bitget.com/en-CA/how-to-buy/litecoin
              "How to buy Litecoin") [How to buy Binance![Binance](https://img.bgstatic.com/multiLang/coin_img/923b2c797a99f6a402c5969dce135b5e.png)](https://www.bitget.com/en-CA/how-to-buy/binance
              "How to buy Binance") [How to buy Tether![Tether](https://img.bgstatic.com/multiLang/coin_img/fcfda5844dcb17d3416221e202dd1266.png)](https://www.bitget.com/en-CA/how-to-buy/tether
              "How to buy Tether")


              ## Buy Heurist AI in a different country


              You can easily buy Heurist AI (Heurist AI) with the lowest fees and
              highest security wherever Bitget is available. Simply select your country
              in the search box below to start buying Heurist AI in your preferred
              location:


              [St Kitts & Nevis](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis)


              A selection of popular Heurist AI buying regions.


              [How to buy Heurist AI in Japan![Japan](https://www.bitget.com/how-to-buy/_next/static/media/japan.ba74055b.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/japan
              "How to buy Heurist AI in Japan") [How to buy Heurist AI in Malaysia![Malaysia](https://www.bitget.com/how-to-buy/_next/static/media/malaysia.8af383b8.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/malaysia
              "How to buy Heurist AI in Malaysia") [How to buy Heurist AI in France![France](https://www.bitget.com/how-to-buy/_next/static/media/france.f0a8a21f.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/france
              "How to buy Heurist AI in France") [How to buy Heurist AI in Switzerland![Switzerland](https://www.bitget.com/how-to-buy/_next/static/media/switzerland.246ccbf6.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/switzerland
              "How to buy Heurist AI in Switzerland") [How to buy Heurist AI in Mexico![Mexico](https://www.bitget.com/how-to-buy/_next/static/media/mexico.24510045.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/mexico
              "How to buy Heurist AI in Mexico") [How to buy Heurist AI in Ecuador![Ecuador](https://www.bitget.com/how-to-buy/_next/static/media/ecuador.765c820e.png)](https://www.bitget.com/en-CA/how-to-buy/heurist-ai/ecuador
              "How to buy Heurist AI in Ecuador")


              ## Buy other cryptos in your region


              [How to buy Bitcoin in St Kitts & Nevis![Bitcoin](https://img.bgstatic.com/multiLang/coin_img/2edf1ef8b333c40979976d1a49bc234c.png)](https://www.bitget.com/en-CA/how-to-buy/bitcoin/st-kitts-nevis
              "How to buy Bitcoin in St Kitts & Nevis") [How to buy Ethereum in St
              Kitts & Nevis![Ethereum](https://img.bgstatic.com/multiLang/coin_img/f6eba5dbcb1e8ce5ed7b053985f314b1.png)](https://www.bitget.com/en-CA/how-to-buy/ethereum/st-kitts-nevis
              "How to buy Ethereum in St Kitts & Nevis") [How to buy Ripple in St
              Kitts & Nevis![Ripple](https://img.bgstatic.com/multiLang/coin_img/39edd8e5c80256300562f68afb1ab525.png)](https://www.bitget.com/en-CA/how-to-buy/ripple/st-kitts-nevis
              "How to buy Ripple in St Kitts & Nevis") [How to buy Dogecoin in St
              Kitts & Nevis![Dogecoin](https://img.bgstatic.com/multiLang/coin_img/ae64499c8825452f6262177ee6dd525b.png)](https://www.bitget.com/en-CA/how-to-buy/dogecoin/st-kitts-nevis
              "How to buy Dogecoin in St Kitts & Nevis") [How to buy Solana in St
              Kitts & Nevis![Solana](https://img.bgstatic.com/multiLang/coin_img/1c1b05492d876ab7e3fa96ea2036ceb2.png)](https://www.bitget.com/en-CA/how-to-buy/solana/st-kitts-nevis
              "How to buy Solana in St Kitts & Nevis") [How to buy Litecoin in St
              Kitts & Nevis![Litecoin](https://img.bgstatic.com/multiLang/coin_img/c17bc60be2ebb5765648fc210530a109.png)](https://www.bitget.com/en-CA/how-to-buy/litecoin/st-kitts-nevis
              "How to buy Litecoin in St Kitts & Nevis") [How to buy Binance in St
              Kitts & Nevis![Binance](https://img.bgstatic.com/multiLang/coin_img/923b2c797a99f6a402c5969dce135b5e.png)](https://www.bitget.com/en-CA/how-to-buy/binance/st-kitts-nevis
              "How to buy Binance in St Kitts & Nevis") [How to buy Tether in St Kitts
              & Nevis![Tether](https://img.bgstatic.com/multiLang/coin_img/fcfda5844dcb17d3416221e202dd1266.png)](https://www.bitget.com/en-CA/how-to-buy/tether/st-kitts-nevis
              "How to buy Tether in St Kitts & Nevis")


              [![welcom-login.png](https://www.bitget.com/how-to-buy/_next/static/media/welcom-login-white.f8dfe2b9.svg)\\

              \\

              A welcome pack of 6200 USDT for new users!\\

              \\

              ![arrow-right.png](https://www.bitget.com/how-to-buy/_next/static/media/arrow-right.f132ed1b.png)](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              ## FAQ


              ### Can I buy $1 worth of Heurist AI?


              In theory, Heurist AI is divisible enough that you could buy just $1
              worth, but Bitget''s spot market requires a minimum order value of $5.


              ### Can I buy $10 of Heurist AI?


              Yes, can be divided and bought in an amount worth $10. Bitget''s spot
              market has a minimum order value of $5.


              ### Where else can I buy Heurist AI?


              If a token is not available for purchase via [the P2P market](https://www.bitget.com/en-CA/p2p-trade)
              or [debit/credit card](https://www.bitget.com/en-CA/buy-sell-crypto?channelCode=SSSS&vipCode=s1pz).
              You can place a buy order for it via [the spot market](https://www.bitget.com/en-CA/spot).


              ### Where is the best place to buy Heurist AI?


              The best place to buy Heurist AI is the exchange that provides hassle-free
              and secure transactions combined with a convenient interface and high
              liquidity. Millions of users every day choose Bitget as a trusted crypto
              purchase platform.


              ### Should I buy Heurist AI right now?


              You should make a decision on purchasing or investing in Heurist AI
              or other tokens after performing your own research and analysis. Bitget
              provides user-friendly crypto trading and purchasing services. Additional
              resources such as Bitget Academy and Bitget Insights help users to navigate
              the current market news and trends.


              Saint Kitts and Nevis, officially known as the Federation of Saint Christopher
              and Nevis, is a microstate made up of two islands Saint Kitts and Nevis
              in the Lesser Antilles. The country uses English as the official language
              and transactions in the nation are made using East Caribbean dollar
              (XCD). The country has a total area of 261 km2 and a total population
              of 47,606.


              The land has volcanic origin that is now covered in thick rainforests.
              You can take a look at the breathtaking landscapes of the country by
              visiting Brimstone Hill Fortress National Park, St. Kitts Scenic Railway,
              Mount Liamuiga, or Frigate Bay.


              No matter where you are in the country, be it the capital Basseterre
              or the cities Cayon and Charlestown, using XCD to trade Heurist AI(HEU)
              poses no sweat with the highly-secure [Bitget exchange](https://www.bitget.com/compliance).
              The exchange provides a long list of payment methods for users so that
              they can be proactive and flexible in their trading strategies. Some
              of the methods are [P2P trading](https://www.bitget.com/p2p-trade),
              crypto deposits, and other third-party merchants such as Apple Pay,
              Google Pay, and different credit card services.


              [Buy Heurist AI now](https://www.bitget.com/en-CA/register?channelCode=SSSS&vipCode=s1pz)


              Cryptocurrency investment activities, including buying Heurist AI on
              Bitget, are subject to market risk. Bitget offers simple and convenient
              ways to buy Heurist AI instantly, and strives to provide transparent
              information about all cryptocurrencies available on the platform. However,
              we are not responsible for any outcomes resulting from your Heurist
              AI purchase. This page and its content do not constitute an endorsement
              of any specific cryptocurrency or method of acquisition.


              About Bitget


              [About Bitget](https://www.bitget.com/en-CA/promotion/aboutus) [Contact
              us](https://www.bitget.com/en-CA/contact-us) [Community](https://www.bitget.com/en-CA/bitget-community)
              [Careers](https://www.bitget.com/en-CA/hire) [Bitget Blog](https://www.bitget.com/en-CA/blog)
              [Bitget Token (BGB)](https://www.bitget.com/en-CA/events/BGB/intro)
              [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Proof of Reserves](https://www.bitget.com/en-CA/proof-of-reserves)
              [Protection Fund](https://www.bitget.com/en-CA/protection-fund) [Partner
              links](https://www.bitget.com/en-CA/links) [LALIGA partnership](https://www.bitget.com/en-CA/events/bitget-laliga)
              [MotoGP partnership](https://www.bitget.com/en-CA/events/bitget-MotoGP)
              [Blockchain4Youth](https://www.bitget.com/en-CA/promotion/blockchain4youth)
              [Blockchain4Her](https://www.bitget.com/en-CA/promotion/blockchain4her)
              [Sitemap](https://www.bitget.com/en-CA/sitemap/crypto/price)


              Products


              [Spot](https://www.bitget.com/en-CA/spot/BTCUSDT) [Futures](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [Onchain](https://www.bitget.com/en-CA/events/bitget-onchain) [Margin](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Earn](https://www.bitget.com/en-CA/earning) [Spot copy trading](https://www.bitget.com/en-CA/copy-trading/spot)
              [Futures copy trading](https://www.bitget.com/en-CA/copy-trading/futures)
              [Bot copy trading](https://www.bitget.com/en-CA/copy-trading/strategy)
              [Bots](https://www.bitget.com/en-CA/trading-bot/spot/BTCUSDT) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [TraderPro](https://www.bitget.com/en-CA/copy-trading/traderpro?utmTerm=footer)
              [Web3 wallet](https://web3.bitget.com/en-CA) [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)
              [Bitget swap](https://web3.bitget.com/en-CA/swap) [Telegram Apps Center](https://www.bitget.com/en-CA/telegram-apps)
              [Airdrop library](https://www.bitget.com/en-CA/airdrop)


              Buy crypto


              [Buy crypto](https://www.bitget.com/en-CA/buy-sell-crypto) [Buy Bitcoin](https://www.bitget.com/en-CA/how-to-buy/bitcoin)
              [Buy ETH](https://www.bitget.com/en-CA/how-to-buy/ethereum) [Buy DOGE](https://www.bitget.com/en-CA/how-to-buy/dogecoin)
              [Buy XRP](https://www.bitget.com/en-CA/how-to-buy/ripple) [Buy BGB](https://www.bitget.com/en-CA/how-to-buy/bitget-token)
              [Buy SHIB](https://www.bitget.com/en-CA/how-to-buy/shiba-inu) [Crypto
              prices](https://www.bitget.com/en-CA/price) [Bitcoin price](https://www.bitget.com/en-CA/price/bitcoin)
              [Ethereum price](https://www.bitget.com/en-CA/price/ethereum) [Solana
              price chart](https://www.bitget.com/en-CA/price/solana-price-chart)
              [Calculator](https://www.bitget.com/en-CA/price/calculator) [Bitcoin
              ETF](https://www.bitget.com/en-CA/price/bitcoin/etf) [Crypto wiki](https://www.bitget.com/en-CA/wiki)
              [XRP price](https://www.bitget.com/en-CA/price/ripple) [Pi Network price](https://www.bitget.com/en-CA/price/pi-network)
              [ADA price](https://www.bitget.com/en-CA/price/cardano) [Solana price](https://www.bitget.com/en-CA/price/solana)
              [Trump coin price](https://www.bitget.com/en-CA/price/trump) [Dogecoin
              price](https://www.bitget.com/en-CA/price/dogecoin) [BRC-20 price](https://www.bitget.com/en-CA/inscription/brc-20)


              Support


              [Submit feedback](https://www.bitget.com/en-CA/feedback) [Help Center](https://www.bitget.com/en-CA/support)
              [Verify official channels](https://www.bitget.com/en-CA/official-verification)
              [Anti-scam hub](https://www.bitget.com/en-CA/events/antiscam2025) [Listing
              application](https://www.bitget.com/en-CA/events/application-for-listing)
              [VIP services](https://www.bitget.com/en-CA/vip/vipIntroduce) [Affiliate
              program](https://www.bitget.com/en-CA/affiliates) [Institutional services](https://www.bitget.com/en-CA/vip-institutional-services)
              [Asset custody](https://www.bitget.com/en-CA/custody) [Download data](https://www.bitget.com/en-CA/data-download)
              [Promotions](https://www.bitget.com/en-CA/events/rewards) [Referral
              program](https://www.bitget.com/en-CA/events/referral) [Fee schedule](https://www.bitget.com/en-CA/fee)
              [Tax filing API](https://www.bitget.com/en-CA/taxes-api)


              Legal


              [Law enforcement request](https://www.bitget.com/en-CA/support/articles/12560603800342)
              [Regulatory request](https://www.bitget.com/en-CA/support/articles/12560603808542)
              [Compliance](https://www.bitget.com/en-CA/compliance) [Regulatory license](https://www.bitget.com/en-CA/promotion/regulatory-license)
              [AML/CFT policies](https://www.bitget.com/en-CA/support/articles/360041116691)
              [Privacy policy](https://www.bitget.com/en-CA/support/articles/360015150651)
              [Terms of Service](https://www.bitget.com/en-CA/support/articles/360014944032)
              [Risk disclosure](https://www.bitget.com/en-CA/support/articles/12560603797276)


              Scan to download


              About Bitget


              [About Bitget](https://www.bitget.com/en-CA/promotion/aboutus) [Contact
              us](https://www.bitget.com/en-CA/contact-us) [Community](https://www.bitget.com/en-CA/bitget-community)
              [Careers](https://www.bitget.com/en-CA/hire) [Bitget Academy](https://www.bitget.com/en-CA/academy)
              [Bitget Blog](https://www.bitget.com/en-CA/blog) [Bitget Token (BGB)](https://www.bitget.com/en-CA/events/BGB/intro)
              [Announcement Center](https://www.bitget.com/en-CA/support/announcement-center)
              [Proof of Reserves](https://www.bitget.com/en-CA/proof-of-reserves)
              [Protection Fund](https://www.bitget.com/en-CA/protection-fund) [Partner
              links](https://www.bitget.com/en-CA/links) [LALIGA partnership](https://www.bitget.com/en-CA/events/bitget-laliga)
              [MotoGP partnership](https://www.bitget.com/en-CA/events/bitget-MotoGP)
              [Blockchain4Youth](https://www.bitget.com/en-CA/promotion/blockchain4youth)
              [Blockchain4Her](https://www.bitget.com/en-CA/promotion/blockchain4her)
              [Sitemap](https://www.bitget.com/en-CA/sitemap/crypto/price)


              Products


              [Spot](https://www.bitget.com/en-CA/spot/BTCUSDT) [Futures](https://www.bitget.com/en-CA/futures/usdt/BTCUSDT)
              [Onchain](https://www.bitget.com/en-CA/events/bitget-onchain) [Margin](https://www.bitget.com/en-CA/spot/BTCUSDT?type=cross)
              [Earn](https://www.bitget.com/en-CA/earning) [Spot copy trading](https://www.bitget.com/en-CA/copy-trading/spot)
              [Futures copy trading](https://www.bitget.com/en-CA/copy-trading/futures)
              [Bot copy trading](https://www.bitget.com/en-CA/copy-trading/strategy)
              [Bots](https://www.bitget.com/en-CA/trading-bot/spot/BTCUSDT) [APIs](https://www.bitget.com/en-CA/bitget-api)
              [TraderPro](https://www.bitget.com/en-CA/copy-trading/traderpro?utmTerm=footer)
              [Web3 wallet](https://web3.bitget.com/en-CA) [Fiat OTC](https://www.bitget.com/en-CA/fiat/otc)
              [Bitget swap](https://web3.bitget.com/en-CA/swap) [Telegram Apps Center](https://www.bitget.com/en-CA/telegram-apps)
              [Airdrop library](https://www.bitget.com/en-CA/airdrop)


              Buy crypto


              [Buy crypto](https://www.bitget.com/en-CA/buy-sell-crypto) [Buy Bitcoin](https://www.bitget.com/en-CA/how-to-buy/bitcoin)
              [Buy ETH](https://www.bitget.com/en-CA/how-to-buy/ethereum) [Buy DOGE](https://www.bitget.com/en-CA/how-to-buy/dogecoin)
              [Buy XRP](https://www.bitget.com/en-CA/how-to-buy/ripple) [Buy BGB](https://www.bitget.com/en-CA/how-to-buy/bitget-token)
              [Buy SHIB](https://www.bitget.com/en-CA/how-to-buy/shiba-inu) [Crypto
              prices](https://www.bitget.com/en-CA/price) [Bitcoin price](https://www.bitget.com/en-CA/price/bitcoin)
              [Ethereum price](https://www.bitget.com/en-CA/price/ethereum) [Solana
              price chart](https://www.bitget.com/en-CA/price/solana-price-chart)
              [Calculator](https://www.bitget.com/en-CA/price/calculator) [Bitcoin
              ETF](https://www.bitget.com/en-CA/price/bitcoin/etf) [Crypto wiki](https://www.bitget.com/en-CA/wiki)
              [XRP price](https://www.bitget.com/en-CA/price/ripple) [Pi Network price](https://www.bitget.com/en-CA/price/pi-network)
              [ADA price](https://www.bitget.com/en-CA/price/cardano) [Solana price](https://www.bitget.com/en-CA/price/solana)
              [Trump coin price](https://www.bitget.com/en-CA/price/trump) [Dogecoin
              price](https://www.bitget.com/en-CA/price/dogecoin) [BRC-20 price](https://www.bitget.com/en-CA/inscription/brc-20)


              Support


              [Submit feedback](https://www.bitget.com/en-CA/feedback) [Help Center](https://www.bitget.com/en-CA/support)
              [Verify official channels](https://www.bitget.com/en-CA/official-verification)
              [Anti-scam hub](https://www.bitget.com/en-CA/events/antiscam2025) [Listing
              application](https://www.bitget.com/en-CA/events/application-for-listing)
              [VIP services](https://www.bitget.com/en-CA/vip/vipIntroduce) [Affiliate
              program](https://www.bitget.com/en-CA/affiliates) [Institutional services](https://www.bitget.com/en-CA/vip-institutional-services)
              [Asset custody](https://www.bitget.com/en-CA/custody) [Download data](https://www.bitget.com/en-CA/data-download)
              [Promotions](https://www.bitget.com/en-CA/events/rewards) [Referral
              program](https://www.bitget.com/en-CA/events/referral) [Fee schedule](https://www.bitget.com/en-CA/fee)
              [Tax filing API](https://www.bitget.com/en-CA/taxes-api)


              Legal


              [Law enforcement request](https://www.bitget.com/en-CA/support/articles/12560603800342)
              [Regulatory request](https://www.bitget.com/en-CA/support/articles/12560603808542)
              [Compliance](https://www.bitget.com/en-CA/compliance) [Regulatory license](https://www.bitget.com/en-CA/promotion/regulatory-license)
              [AML/CFT policies](https://www.bitget.com/en-CA/support/articles/360041116691)
              [Privacy policy](https://www.bitget.com/en-CA/support/articles/360015150651)
              [Terms of Service](https://www.bitget.com/en-CA/support/articles/360014944032)
              [Risk disclosure](https://www.bitget.com/en-CA/support/articles/12560603797276)


              © 2025 Bitget


              Dark mode


              Customer Service'
            metadata:
              ogUrl: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis
              twitter:site: '@bitgetglobal'
              twitter:card: summary_large_image
              description: Step-by-step guide with videos for beginners on how to
                buy Heurist AI in St Kitts & Nevis with a credit card. Learn to buy
                HEU and other crypto instantly and safely.
              ogDescription: Step-by-step guide with videos for beginners on how to
                buy Heurist AI in St Kitts & Nevis with a credit card. Learn to buy
                HEU and other crypto instantly and safely.
              og:type: article
              og:site_name: Bitget
              twitter:description: Step-by-step guide with videos for beginners on
                how to buy Heurist AI in St Kitts & Nevis with a credit card. Learn
                to buy HEU and other crypto instantly and safely.
              twitter:image:alt: Bitget-Better trading
              next-head-count: '61'
              og:title: How to Buy Heurist AI (HEU) in St Kitts & Nevis with Credit
                Card Online
              theme-color: '#000000'
              apple-mobile-web-app-capable: 'yes'
              ogSiteName: Bitget
              format-detection: telephone=no,email=no
              og:url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis
              ogImage: https://static.bitget.com/video/en-how-to-buy.png
              og:description: Step-by-step guide with videos for beginners on how
                to buy Heurist AI in St Kitts & Nevis with a credit card. Learn to
                buy HEU and other crypto instantly and safely.
              title: How to Buy Heurist AI (HEU) in St Kitts & Nevis with Credit Card
                Online
              favicon: https://static.bgbstatic.com/baseasset/favicon4.png
              ogTitle: How to Buy Heurist AI (HEU) in St Kitts & Nevis with Credit
                Card Online
              viewport:
              - width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1,
                user-scalable=no
              - width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no
              og:image: https://static.bitget.com/video/en-how-to-buy.png
              twitter:image: https://static.bitget.com/video/en-how-to-buy.png
              language: en-CA
              apple-mobile-web-app-status-bar-style: black
              twitter:title: How to Buy Heurist AI (HEU) in St Kitts & Nevis with
                Credit Card Online
              twitter:url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis
              scrapeId: 0e3f9f0b-b28b-43c2-844c-d89ef48df72c
              sourceURL: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis
              url: https://www.bitget.com/en-CA/how-to-buy/heurist-ai/st-kitts-nevis
              statusCode: 200
              contentType: text/html; charset=utf-8
              proxyUsed: basic
              cacheState: miss
    description: Natural language query about Heurist services and uniqueness in AI
      space
    status: success
